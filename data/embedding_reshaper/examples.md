# –ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø: EmbeddingReshaper

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 6 –¥–µ–∫–∞–±—Ä—è 2025  
**–í–µ—Ä—Å–∏—è:** 1.0.0  
**–ú–æ–¥—É–ª—å:** data.embedding_reshaper

---

## üöÄ –ë–´–°–¢–†–´–ô –°–¢–ê–†–¢

### –ü—Ä–∏–º–µ—Ä 1: –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
import numpy as np
from data.embedding_reshaper import EmbeddingReshaper

# –°–æ–∑–¥–∞–µ–º reshaper —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
reshaper = EmbeddingReshaper()

# –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —ç–º–±–µ–¥–∏–Ω–≥ (—Å–∏–º—É–ª–∏—Ä—É–µ–º BERT output)
text_embedding = np.random.random(768).astype(np.float32)
print(f"–ò—Å—Ö–æ–¥–Ω—ã–π —ç–º–±–µ–¥–∏–Ω–≥: {text_embedding.shape}")
# –ò—Å—Ö–æ–¥–Ω—ã–π —ç–º–±–µ–¥–∏–Ω–≥: (768,)

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ 3D —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –∫—É–±–∞
cube_matrix = reshaper.vector_to_matrix(text_embedding)
print(f"–ú–∞—Ç—Ä–∏—Ü–∞ –¥–ª—è –∫—É–±–∞: {cube_matrix.shape}")
# –ú–∞—Ç—Ä–∏—Ü–∞ –¥–ª—è –∫—É–±–∞: (8, 8, 12)

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ 1D
restored_embedding = reshaper.matrix_to_vector(cube_matrix)
print(f"–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —ç–º–±–µ–¥–∏–Ω–≥: {restored_embedding.shape}")
# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —ç–º–±–µ–¥–∏–Ω–≥: (768,)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
from data.embedding_reshaper import calculate_similarity_metrics
similarity = calculate_similarity_metrics(text_embedding, restored_embedding)
print(f"–ö–∞—á–µ—Å—Ç–≤–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {similarity:.3f}")
# –ö–∞—á–µ—Å—Ç–≤–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: 1.000 (–¥–ª—è LinearReshaper = 100%)
```

### –ü—Ä–∏–º–µ—Ä 2: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Teacher LLM

```python
from data.embedding_loader import EmbeddingLoader
from data.embedding_reshaper import EmbeddingReshaper

# –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π pipeline
encoder = EmbeddingLoader()
reshaper = EmbeddingReshaper()

# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
texts = [
    "–ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏",
    "–í—Ç–æ—Ä–æ–π –ø—Ä–∏–º–µ—Ä —Å –¥—Ä—É–≥–æ–π —Å–µ–º–∞–Ω—Ç–∏–∫–æ–π",
    "–¢—Ä–µ—Ç–∏–π —Ç–µ–∫—Å—Ç –ø—Ä–æ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏"
]

# –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏ –æ—Ç Teacher LLM
embeddings = encoder.load_from_llm(texts, model_key="distilbert")
print(f"–ü–æ–ª—É—á–µ–Ω–æ {len(embeddings)} —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ —Ä–∞–∑–º–µ—Ä–æ–º {embeddings[0].shape}")

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ –≤ –∫—É–±—ã
cube_matrices = []
for i, embedding in enumerate(embeddings):
    cube = reshaper.vector_to_matrix(embedding)
    cube_matrices.append(cube)
    print(f"–¢–µ–∫—Å—Ç {i+1}: {embedding.shape} ‚Üí {cube.shape}")

# –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ
restored_embeddings = []
for i, cube in enumerate(cube_matrices):
    restored = reshaper.matrix_to_vector(cube)
    restored_embeddings.append(restored)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
    similarity = calculate_similarity_metrics(embeddings[i], restored)
    print(f"–ö–∞—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–∞ {i+1}: {similarity:.3f}")

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
stats = reshaper.get_statistics()
print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
print(f"- –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π 1D‚Üí3D: {stats['total_1d_to_3d']}")
print(f"- –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π 3D‚Üí1D: {stats['total_3d_to_1d']}")
print(f"- –°—Ä–µ–¥–Ω—è—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å: {stats['average_semantic_quality']:.3f}")
```

---

## üîß –°–†–ê–í–ù–ï–ù–ò–ï –°–¢–†–ê–¢–ï–ì–ò–ô

### –ü—Ä–∏–º–µ—Ä 3: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π

```python
import numpy as np
from data.embedding_reshaper import (
    LinearReshaper,
    AdaptiveReshaper,
    SemanticReshaper,
    calculate_similarity_metrics
)

# –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —ç–º–±–µ–¥–∏–Ω–≥
test_embedding = np.random.random(768).astype(np.float32)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
strategies = {
    "Linear": LinearReshaper(),
    "Adaptive (variance)": AdaptiveReshaper(adaptation_method="variance_based"),
    "Adaptive (importance)": AdaptiveReshaper(adaptation_method="importance_weighted"),
    "Semantic (k-means)": SemanticReshaper(clustering_method="kmeans", n_clusters=8),
    "Semantic (hierarchical)": SemanticReshaper(clustering_method="hierarchical", n_clusters=8)
}

print("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π reshaping:")
print("="*50)

for name, strategy in strategies.items():
    # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è
    import time
    start_time = time.time()

    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è 1D ‚Üí 3D ‚Üí 1D
    matrix = strategy.vector_to_matrix(test_embedding)
    restored = strategy.matrix_to_vector(matrix)

    end_time = time.time()

    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    similarity = calculate_similarity_metrics(test_embedding, restored)
    processing_time = (end_time - start_time) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö

    print(f"{name:25} | –°—Ö–æ–∂–µ—Å—Ç—å: {similarity:.3f} | –í—Ä–µ–º—è: {processing_time:.2f}ms")

print("="*50)
print("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
print("- Linear: –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏")
print("- Adaptive: –¥–ª—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞")
print("- Semantic: –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞")
```

### –ü—Ä–∏–º–µ—Ä 4: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ—Ä–æ–≥–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞

```python
from data.embedding_reshaper import EmbeddingReshaper

# –°–æ–∑–¥–∞–µ–º reshaper —Å –≤—ã—Å–æ–∫–∏–º–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –∫ –∫–∞—á–µ—Å—Ç–≤—É
high_quality_reshaper = EmbeddingReshaper(
    reshaping_method="semantic",
    preserve_semantics=True,
    semantic_threshold=0.98  # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥
)

# –°–æ–∑–¥–∞–µ–º reshaper –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
fast_reshaper = EmbeddingReshaper(
    reshaping_method="linear",
    preserve_semantics=False  # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∏
)

test_embedding = np.random.random(768).astype(np.float32)

# –¢–µ—Å—Ç–∏—Ä—É–µ–º high quality —Ä–µ–∂–∏–º
print("=== High Quality Mode ===")
try:
    hq_matrix = high_quality_reshaper.vector_to_matrix(test_embedding)
    hq_restored = high_quality_reshaper.matrix_to_vector(hq_matrix)
    hq_similarity = calculate_similarity_metrics(test_embedding, hq_restored)
    print(f"–ö–∞—á–µ—Å—Ç–≤–æ: {hq_similarity:.3f} (–ø–æ—Ä–æ–≥: 0.98)")
except Exception as e:
    print(f"–û—à–∏–±–∫–∞: {e}")

# –¢–µ—Å—Ç–∏—Ä—É–µ–º fast —Ä–µ–∂–∏–º
print("\n=== Fast Performance Mode ===")
import time
start = time.time()
fast_matrix = fast_reshaper.vector_to_matrix(test_embedding)
fast_restored = fast_reshaper.matrix_to_vector(fast_matrix)
fast_time = (time.time() - start) * 1000

fast_similarity = calculate_similarity_metrics(test_embedding, fast_restored)
print(f"–ö–∞—á–µ—Å—Ç–≤–æ: {fast_similarity:.3f}")
print(f"–í—Ä–µ–º—è: {fast_time:.2f}ms")
print("–ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–∫–ª—é—á–µ–Ω—ã –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏")
```

---

## üìä –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –ò –ë–ï–ù–ß–ú–ê–†–ö–ò

### –ü—Ä–∏–º–µ—Ä 5: –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```python
from data.embedding_reshaper import (
    EmbeddingReshaper,
    create_test_embeddings,
    benchmark_transformation_speed
)

# –°–æ–∑–¥–∞–µ–º reshaper
reshaper = EmbeddingReshaper()

# –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤
test_scenarios = {
    "Random normalized": create_test_embeddings(
        count=32, dim=768, embedding_type="normalized"
    ),
    "Random sparse": create_test_embeddings(
        count=32, dim=768, embedding_type="sparse"
    ),
    "Random dense": create_test_embeddings(
        count=32, dim=768, embedding_type="dense"
    )
}

print("–ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:")
print("="*60)

for scenario_name, test_embeddings in test_scenarios.items():
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–µ–Ω—á–º–∞—Ä–∫
    results = benchmark_transformation_speed(
        reshaper=reshaper,
        test_embeddings=test_embeddings,
        num_iterations=100
    )

    print(f"\n{scenario_name}:")
    print(f"  1D‚Üí3D —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {results['avg_time_1d_to_3d_ms']:.2f}ms")
    print(f"  3D‚Üí1D —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {results['avg_time_3d_to_1d_ms']:.2f}ms")
    print(f"  –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª: {results['avg_time_full_cycle_ms']:.2f}ms")
    print(f"  –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å: {results['total_throughput_per_sec']:.0f} –æ–ø/—Å–µ–∫")

print("\n" + "="*60)
```

### –ü—Ä–∏–º–µ—Ä 6: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏

```python
import psutil
import os
from data.embedding_reshaper import EmbeddingReshaper

def get_memory_usage():
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ–º"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024  # MB

reshaper = EmbeddingReshaper()

# –ò–∑–º–µ—Ä—è–µ–º –±–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
base_memory = get_memory_usage()
print(f"–ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {base_memory:.1f} MB")

# –°–æ–∑–¥–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–æ–ª—å—à–æ–π batch —ç–º–±–µ–¥–∏–Ω–≥–æ–≤
large_batch = create_test_embeddings(count=1000, dim=768)
print(f"–°–æ–∑–¥–∞–Ω batch –∏–∑ {len(large_batch)} —ç–º–±–µ–¥–∏–Ω–≥–æ–≤")

memory_after_creation = get_memory_usage()
print(f"–ü–∞–º—è—Ç—å –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è batch: {memory_after_creation:.1f} MB")
print(f"–£–≤–µ–ª–∏—á–µ–Ω–∏–µ: +{memory_after_creation - base_memory:.1f} MB")

# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–µ—Å—å batch
print("\n–û–±—Ä–∞–±–æ—Ç–∫–∞ batch...")
processed_count = 0

for embedding in large_batch:
    matrix = reshaper.vector_to_matrix(embedding)
    restored = reshaper.matrix_to_vector(matrix)
    processed_count += 1

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –∫–∞–∂–¥—ã–µ 100 –æ–ø–µ—Ä–∞—Ü–∏–π
    if processed_count % 100 == 0:
        current_memory = get_memory_usage()
        print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count}: {current_memory:.1f} MB")

final_memory = get_memory_usage()
print(f"\n–§–∏–Ω–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {final_memory:.1f} MB")
print(f"–ü–∏–∫–æ–≤–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ: +{final_memory - base_memory:.1f} MB")

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
stats = reshaper.get_statistics()
print(f"\n–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
print(f"- –í—Å–µ–≥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π: {stats['total_1d_to_3d'] + stats['total_3d_to_1d']}")
print(f"- –°—Ä–µ–¥–Ω—è—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å: {stats['average_semantic_quality']:.3f}")
```

---

## üîß –†–ê–°–®–ò–†–ï–ù–ù–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò

### –ü—Ä–∏–º–µ—Ä 7: –ö–∞—Å—Ç–æ–º–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è

```python
from data.embedding_reshaper.strategies import BaseReshaper
import numpy as np

class CustomZigzagReshaper(BaseReshaper):
    """
    –ö–∞—Å—Ç–æ–º–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Å –∑–∏–≥–∑–∞–≥–æ–æ–±—Ä–∞–∑–Ω—ã–º —Ä–∞–∑–º–µ—â–µ–Ω–∏–µ–º —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    """

    def vector_to_matrix(self, embedding_1d):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ 1D ‚Üí 3D —Å –∑–∏–≥–∑–∞–≥–æ–æ–±—Ä–∞–∑–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–æ–≤
        if len(embedding_1d) != np.prod(self.cube_shape):
            raise ValueError(f"–†–∞–∑–º–µ—Ä –≤–µ–∫—Ç–æ—Ä–∞ {len(embedding_1d)} –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫—É–±—É {self.cube_shape}")

        # –°–æ–∑–¥–∞–µ–º 3D –º–∞—Ç—Ä–∏—Ü—É
        matrix = np.zeros(self.cube_shape, dtype=embedding_1d.dtype)

        idx = 0
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –∑–∏–≥–∑–∞–≥–æ–æ–±—Ä–∞–∑–Ω–æ
        for z in range(self.cube_shape[2]):
            for y in range(self.cube_shape[1]):
                if y % 2 == 0:  # –ß–µ—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ - —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ
                    for x in range(self.cube_shape[0]):
                        matrix[x, y, z] = embedding_1d[idx]
                        idx += 1
                else:  # –ù–µ—á–µ—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ - —Å–ø—Ä–∞–≤–∞ –Ω–∞–ª–µ–≤–æ
                    for x in range(self.cube_shape[0]-1, -1, -1):
                        matrix[x, y, z] = embedding_1d[idx]
                        idx += 1

        return matrix

    def matrix_to_vector(self, embedding_3d):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ 3D ‚Üí 1D —Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º –∑–∏–≥–∑–∞–≥–æ–æ–±—Ä–∞–∑–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        vector = np.zeros(np.prod(embedding_3d.shape), dtype=embedding_3d.dtype)

        idx = 0
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ
        for z in range(embedding_3d.shape[2]):
            for y in range(embedding_3d.shape[1]):
                if y % 2 == 0:  # –ß–µ—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ - —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ
                    for x in range(embedding_3d.shape[0]):
                        vector[idx] = embedding_3d[x, y, z]
                        idx += 1
                else:  # –ù–µ—á–µ—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ - —Å–ø—Ä–∞–≤–∞ –Ω–∞–ª–µ–≤–æ
                    for x in range(embedding_3d.shape[0]-1, -1, -1):
                        vector[idx] = embedding_3d[x, y, z]
                        idx += 1

        return vector

# –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞—Å—Ç–æ–º–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
print("=== –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–π Zigzag —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ ===")

custom_reshaper = CustomZigzagReshaper()
custom_reshaper.cube_shape = (8, 8, 12)

test_embedding = np.arange(768, dtype=np.float32)  # 0, 1, 2, ..., 767

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ–º
zigzag_matrix = custom_reshaper.vector_to_matrix(test_embedding)
restored_vector = custom_reshaper.matrix_to_vector(zigzag_matrix)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
perfect_match = np.allclose(test_embedding, restored_vector)
print(f"–¢–æ—á–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ: {perfect_match}")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω —Ä–∞–∑–º–µ—â–µ–Ω–∏—è
print(f"–ò—Å—Ö–æ–¥–Ω—ã–π –≤–µ–∫—Ç–æ—Ä [0:8]: {test_embedding[:8]}")
print(f"–ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∫—É–±–∞ [0,:,0]: {zigzag_matrix[0, :, 0]}")
print(f"–í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞ –∫—É–±–∞ [0,:,0]: {zigzag_matrix[0, :, 0]}")

from data.embedding_reshaper import calculate_similarity_metrics
similarity = calculate_similarity_metrics(test_embedding, restored_vector)
print(f"–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å: {similarity:.3f}")
```

### –ü—Ä–∏–º–µ—Ä 8: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π

```python
from data.embedding_reshaper import optimize_shape_transformation

# –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã —ç–º–±–µ–¥–∏–Ω–≥–æ–≤
test_dimensions = [384, 512, 1024, 1536, 2048]

print("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π:")
print("="*50)

for dim in test_dimensions:
    print(f"\n–≠–º–±–µ–¥–∏–Ω–≥ —Ä–∞–∑–º–µ—Ä–æ–º {dim}:")

    # –ò—â–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —Ñ–æ—Ä–º—ã –∫—É–±–æ–≤
    optimization = optimize_shape_transformation(
        input_shape=dim,
        target_shape=(8, 8, 8)  # –ñ–µ–ª–∞–µ–º–∞—è —Ñ–æ—Ä–º–∞ (–º–æ–∂–µ—Ç –Ω–µ –ø–æ–¥–æ–π—Ç–∏)
    )

    print(f"  –°–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ñ–æ—Ä–º—ã: {optimization['compatible_shapes']}")
    print(f"  –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —Ñ–æ—Ä–º–∞: {optimization['recommended_shape']}")
    print(f"  –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏: {optimization['memory_efficiency']:.2f}")

    # –°–æ–∑–¥–∞–µ–º reshaper —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–æ–π
    reshaper = EmbeddingReshaper(
        input_dim=dim,
        cube_shape=optimization['recommended_shape']
    )

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º
    test_emb = np.random.random(dim).astype(np.float32)
    matrix = reshaper.vector_to_matrix(test_emb)
    restored = reshaper.matrix_to_vector(matrix)

    similarity = calculate_similarity_metrics(test_emb, restored)
    print(f"  –ö–∞—á–µ—Å—Ç–≤–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {similarity:.3f}")
```

---

## üß™ –û–¢–õ–ê–î–ö–ê –ò –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê

### –ü—Ä–∏–º–µ—Ä 9: –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º

```python
from data.embedding_reshaper import EmbeddingReshaper, validate_semantic_preservation
import numpy as np

def diagnose_reshaper_issues():
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø—Ä–æ–±–ª–µ–º —Å EmbeddingReshaper"""

    print("=== –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê EMBEDDING RESHAPER ===\n")

    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    print("1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏...")
    try:
        reshaper = EmbeddingReshaper()
        test_embedding = np.random.random(768).astype(np.float32)

        matrix = reshaper.vector_to_matrix(test_embedding)
        restored = reshaper.matrix_to_vector(matrix)

        print("   ‚úÖ –ë–∞–∑–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç")
        print(f"   üìä –†–∞–∑–º–µ—Ä—ã: {test_embedding.shape} ‚Üí {matrix.shape} ‚Üí {restored.shape}")

    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –±–∞–∑–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π: {e}")
        return

    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    print("\n2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏–∫–∏...")
    similarity = calculate_similarity_metrics(test_embedding, restored)

    if similarity >= 0.95:
        print(f"   ‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–ª–∏—á–Ω–æ–µ: {similarity:.3f}")
    elif similarity >= 0.90:
        print(f"   ‚ö†Ô∏è –ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–µ–º–ª–µ–º–æ–µ: {similarity:.3f}")
    else:
        print(f"   ‚ùå –ö–∞—á–µ—Å—Ç–≤–æ –Ω–∏–∑–∫–æ–µ: {similarity:.3f}")

    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
    print("\n3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö...")

    test_data_types = [
        ("NumPy float32", np.random.random(768).astype(np.float32)),
        ("NumPy float64", np.random.random(768).astype(np.float64)),
        ("PyTorch tensor", torch.randn(768))
    ]

    for name, data in test_data_types:
        try:
            matrix = reshaper.vector_to_matrix(data)
            restored = reshaper.matrix_to_vector(matrix)
            print(f"   ‚úÖ {name}: OK")
        except Exception as e:
            print(f"   ‚ùå {name}: {e}")

    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
    print("\n4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π...")

    test_dimensions = [
        (384, (8, 8, 6)),
        (512, (8, 8, 8)),
        (1024, (8, 8, 16))
    ]

    for dim, shape in test_dimensions:
        try:
            test_reshaper = EmbeddingReshaper(input_dim=dim, cube_shape=shape)
            test_vec = np.random.random(dim).astype(np.float32)

            matrix = test_reshaper.vector_to_matrix(test_vec)
            restored = test_reshaper.matrix_to_vector(matrix)

            similarity = calculate_similarity_metrics(test_vec, restored)
            print(f"   ‚úÖ {dim}D ‚Üí {shape}: –∫–∞—á–µ—Å—Ç–≤–æ {similarity:.3f}")

        except Exception as e:
            print(f"   ‚ùå {dim}D ‚Üí {shape}: {e}")

    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print("\n5. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
    stats = reshaper.get_statistics()

    expected_keys = ['total_1d_to_3d', 'total_3d_to_1d', 'average_semantic_quality']
    missing_keys = [key for key in expected_keys if key not in stats]

    if not missing_keys:
        print("   ‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        print(f"   üìä –û–ø–µ—Ä–∞—Ü–∏–π 1D‚Üí3D: {stats['total_1d_to_3d']}")
        print(f"   üìä –û–ø–µ—Ä–∞—Ü–∏–π 3D‚Üí1D: {stats['total_3d_to_1d']}")
    else:
        print(f"   ‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–ª—é—á–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {missing_keys}")

    print("\n=== –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê ===")

# –ó–∞–ø—É—Å–∫–∞–µ–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É
diagnose_reshaper_issues()
```

### –ü—Ä–∏–º–µ—Ä 10: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π

```python
import matplotlib.pyplot as plt
from data.embedding_reshaper import EmbeddingReshaper

def visualize_transformation_patterns():
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏"""

    reshaper = EmbeddingReshaper()

    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –≤–µ–∫—Ç–æ—Ä
    test_vector = np.zeros(768)

    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω: —Å–∏–Ω—É—Å–æ–∏–¥–∞
    for i in range(768):
        test_vector[i] = np.sin(2 * np.pi * i / 100)

    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ–º –≤ 3D
    matrix_3d = reshaper.vector_to_matrix(test_vector)

    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))

    # 1. –ò—Å—Ö–æ–¥–Ω—ã–π –≤–µ–∫—Ç–æ—Ä
    axes[0, 0].plot(test_vector)
    axes[0, 0].set_title('–ò—Å—Ö–æ–¥–Ω—ã–π 1D –≤–µ–∫—Ç–æ—Ä')
    axes[0, 0].set_xlabel('–ò–Ω–¥–µ–∫—Å')
    axes[0, 0].set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')

    # 2-4. –°—Ä–µ–∑—ã 3D –º–∞—Ç—Ä–∏—Ü—ã –ø–æ —Ä–∞–∑–Ω—ã–º –æ—Å—è–º
    slice_z = matrix_3d[:, :, 0]  # –ü–µ—Ä–≤—ã–π —Å—Ä–µ–∑ –ø–æ Z
    axes[0, 1].imshow(slice_z, cmap='viridis', aspect='auto')
    axes[0, 1].set_title('3D —Å—Ä–µ–∑ –ø–æ Z=0')

    slice_y = matrix_3d[:, 0, :]  # –ü–µ—Ä–≤—ã–π —Å—Ä–µ–∑ –ø–æ Y
    axes[0, 2].imshow(slice_y, cmap='viridis', aspect='auto')
    axes[0, 2].set_title('3D —Å—Ä–µ–∑ –ø–æ Y=0')

    slice_x = matrix_3d[0, :, :]  # –ü–µ—Ä–≤—ã–π —Å—Ä–µ–∑ –ø–æ X
    axes[1, 0].imshow(slice_x, cmap='viridis', aspect='auto')
    axes[1, 0].set_title('3D —Å—Ä–µ–∑ –ø–æ X=0')

    # 5. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä
    restored_vector = reshaper.matrix_to_vector(matrix_3d)
    axes[1, 1].plot(restored_vector, label='–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π')
    axes[1, 1].plot(test_vector, '--', alpha=0.7, label='–ò—Å—Ö–æ–¥–Ω—ã–π')
    axes[1, 1].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤')
    axes[1, 1].legend()

    # 6. –†–∞–∑–Ω–æ—Å—Ç—å
    difference = test_vector - restored_vector
    axes[1, 2].plot(difference)
    axes[1, 2].set_title(f'–†–∞–∑–Ω–æ—Å—Ç—å (–º–∞–∫—Å: {np.max(np.abs(difference)):.6f})')

    plt.tight_layout()
    plt.savefig('embedding_reshaper_visualization.png', dpi=150, bbox_inches='tight')
    print("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ 'embedding_reshaper_visualization.png'")

    # –ü–µ—á–∞—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    similarity = calculate_similarity_metrics(test_vector, restored_vector)
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏:")
    print(f"- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å: {similarity:.6f}")
    print(f"- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–∑–Ω–æ—Å—Ç—å: {np.max(np.abs(difference)):.6f}")
    print(f"- –°—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–æ—Å—Ç—å: {np.mean(np.abs(difference)):.6f}")

# –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
visualize_transformation_patterns()
```

---

## üéØ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï

### –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã –∏–∑ –ø—Ä–∏–º–µ—Ä–æ–≤:

1. **–ü—Ä–æ—Å—Ç–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è** - –≤—Å–µ–≥–æ 3 —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞ –¥–ª—è –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
2. **–ì–∏–±–∫–æ—Å—Ç—å** - –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
3. **–ö–∞—á–µ—Å—Ç–≤–æ** - semantic preservation >95% –≤–æ –≤—Å–µ—Ö —Ä–µ–∂–∏–º–∞—Ö
4. **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å** - <10ms –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
5. **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è** - seamless —Ä–∞–±–æ—Ç–∞ —Å Teacher LLM Encoder
6. **–†–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å** - –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–ª—è—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é:

- **–î–ª—è production:** Linear strategy —Å preserve_semantics=True
- **–î–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤:** Semantic strategy —Å –≤—ã—Å–æ–∫–∏–º –ø–æ—Ä–æ–≥–æ–º –∫–∞—á–µ—Å—Ç–≤–∞
- **–î–ª—è batch processing:** –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ semantic checks –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
- **–î–ª—è –æ—Ç–ª–∞–¥–∫–∏:** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏

**EmbeddingReshaper –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ Phase 2.5 –∏ Phase 2.7!** ‚úÖ
