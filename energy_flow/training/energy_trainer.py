"""
EnergyTrainer - –æ—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è energy_flow –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
=========================================================================

–ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π text_bridge –º–æ–¥—É–ª—è:
- –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ energy flow + text decoders
- GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å CUDA –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é  
- –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–µ—Ç—Ä–∏–∫–∏
- –ß–µ–∫–ø–æ–∏–Ω—Ç–∏–Ω–≥ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏:
input_text ‚Üí TextToCubeEncoder ‚Üí surface_embedding ‚Üí FlowProcessor ‚Üí 
output_surface_embedding ‚Üí CubeToTextDecoder ‚Üí predicted_text

Loss = energy_loss + text_loss_weight √ó text_loss
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
from typing import Dict, List, Tuple, Optional, Any, Union
from pathlib import Path
import time
from datetime import datetime
import json

from ..utils.logging import get_logger, DEBUG_TRAINING, DEBUG_ENERGY, DEBUG_CONVERGENCE
from ..utils.device_manager import get_device_manager
from ..config import EnergyConfig, get_energy_config, create_debug_config, set_energy_config
from ..core import FlowProcessor, EnergyLattice, SimpleNeuron, EnergyCarrier
from ..text_bridge import (
    TextToCubeEncoder, CubeToTextDecoder, TextCache,
    create_text_to_cube_encoder, create_cube_to_text_decoder, create_text_cache,
    CachedTextToCubeEncoder, CachedCubeToTextDecoder
)

logger = get_logger(__name__)


class EnergyTrainer:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è energy_flow –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    
    –†–µ–∞–ª–∏–∑—É–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π text_bridge:
    - –≠–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ—Ç–æ–∫–∏ —á–µ—Ä–µ–∑ 3D —Ä–µ—à–µ—Ç–∫—É
    - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ text decoders
    - –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π loss (energy + text)
    - GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    
    def __init__(self, config: Optional[EnergyConfig] = None):
        """
        Args:
            config: EnergyConfig —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è
        """
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        if config is None:
            config = create_debug_config()
            set_energy_config(config)
        self.config = config
        
        # Device management  
        self.device_manager = get_device_manager() 
        self.device = self.device_manager.device
        
        logger.log(DEBUG_TRAINING, f"üöÄ EnergyTrainer initialization on {self.device}")
        logger.log(DEBUG_TRAINING, f"Config: {config.lattice_width}x{config.lattice_height}x{config.lattice_depth}, "
                                  f"text_bridge={config.text_bridge_enabled}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self._init_core_components()
        self._init_text_bridge()
        self._init_optimizer()
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
        self.training_history = {
            "total_losses": [],
            "energy_losses": [],
            "text_losses": [],
            "learning_rates": [],
            "flow_statistics": [],
            "performance_metrics": []
        }
        
        # –°—á–µ—Ç—á–∏–∫–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.global_step = 0
        self.epoch = 0
        self.best_loss = float('inf')
        
        logger.log(DEBUG_TRAINING, "‚úÖ EnergyTrainer successfully initialized")
    
    def _init_core_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ energy_flow"""
        logger.log(DEBUG_TRAINING, "Initializing core energy_flow components...")
        
        # FlowProcessor –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ core –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.flow_processor = FlowProcessor(self.config).to(self.device)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –ø—Ä—è–º–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
        self.energy_lattice = self.flow_processor.lattice
        self.simple_neuron = self.flow_processor.neuron
        self.energy_carrier = self.flow_processor.carrier
        
        logger.log(DEBUG_TRAINING, f"Core components initialized: "
                                  f"FlowProcessor, EnergyLattice({self.config.lattice_width}x{self.config.lattice_height}x{self.config.lattice_depth})")
    
    def _init_text_bridge(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è text_bridge –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        if not self.config.text_bridge_enabled:
            logger.log(DEBUG_TRAINING, "Text bridge disabled, skipping initialization")
            self.text_encoder = None
            self.text_decoder = None
            self.text_cache = None
            return
            
        logger.log(DEBUG_TRAINING, "Initializing text_bridge components...")
        
        # Text cache (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
        if self.config.text_cache_enabled:
            self.text_cache = create_text_cache(
                max_size=self.config.text_cache_size,
                cache_file=self.config.text_cache_file
            )
            logger.log(DEBUG_TRAINING, f"TextCache initialized with size {self.config.text_cache_size}")
        else:
            self.text_cache = None
        
        # Text encoder (text ‚Üí surface embeddings)
        base_encoder = create_text_to_cube_encoder(self.config).to(self.device)
        if self.text_cache:
            self.text_encoder = CachedTextToCubeEncoder(base_encoder, self.text_cache)
        else:
            self.text_encoder = base_encoder
            
        # Text decoder (surface embeddings ‚Üí text)
        base_decoder = create_cube_to_text_decoder(self.config).to(self.device)
        if self.text_cache:
            self.text_decoder = CachedCubeToTextDecoder(base_decoder, self.text_cache)
        else:
            self.text_decoder = base_decoder
        
        # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        encoder_params = sum(p.numel() for p in base_encoder.parameters() if p.requires_grad)
        decoder_params = sum(p.numel() for p in base_decoder.parameters() if p.requires_grad)
        
        logger.log(DEBUG_TRAINING, f"Text bridge initialized: encoder({encoder_params:,} params), "
                                  f"decoder({decoder_params:,} params)")
    
    def _init_optimizer(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞"""
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        params = list(self.flow_processor.parameters())
        
        if self.config.text_bridge_enabled:
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã text_bridge –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            # –î–ª—è cached –≤–µ—Ä—Å–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
            if hasattr(self.text_encoder, 'encoder'):  # CachedTextToCubeEncoder
                params.extend(self.text_encoder.encoder.parameters())
            elif hasattr(self.text_encoder, 'parameters'):  # Direct TextToCubeEncoder
                params.extend(self.text_encoder.parameters())
                
            if hasattr(self.text_decoder, 'decoder'):  # CachedCubeToTextDecoder
                params.extend(self.text_decoder.decoder.parameters())
            elif hasattr(self.text_decoder, 'parameters'):  # Direct CubeToTextDecoder
                params.extend(self.text_decoder.parameters())
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
        self.optimizer = optim.AdamW(
            params,
            lr=self.config.learning_rate,
            weight_decay=self.config.weight_decay
        )
        
        # –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ learning rate
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=0.5,
            patience=10
        )
        
        total_params = sum(p.numel() for p in params if p.requires_grad)
        logger.log(DEBUG_TRAINING, f"Optimizer initialized: AdamW, lr={self.config.learning_rate}, "
                                  f"total_params={total_params:,}")
    
    def train_step(self, input_texts: List[str], target_texts: List[str], 
                   teacher_input_embeddings: torch.Tensor, teacher_target_embeddings: torch.Tensor) -> Dict[str, float]:
        """
        –û–¥–∏–Ω —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            input_texts: –°–ø–∏—Å–æ–∫ –≤—Ö–æ–¥–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–¥–ª—è text_bridge)
            target_texts: –°–ø–∏—Å–æ–∫ —Ü–µ–ª–µ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–¥–ª—è text_bridge)
            teacher_input_embeddings: –í—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è [batch, 768]
            teacher_target_embeddings: –¶–µ–ª–µ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è [batch, 768]
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ —à–∞–≥–∞
        """
        self.optimizer.zero_grad()
        
        batch_size = len(input_texts)
        step_start_time = time.time()
        
        try:
            # 1. –û—Å–Ω–æ–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∫—É–±–∞ —Å teacher embeddings
            flow_start_time = time.time()
            cube_output_surface = self.flow_processor.forward(teacher_input_embeddings, max_steps=50)
            flow_time = time.time() - flow_start_time
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ—Ç–æ–∫–æ–≤ (–∑–∞–≥–ª—É—à–∫–∞ - FlowProcessor –Ω–µ –∏–º–µ–µ—Ç —ç—Ç–æ–≥–æ –º–µ—Ç–æ–¥–∞)
            flow_stats = {
                'active_flows': 0,
                'spawned_flows': 0,
                'flows_reached_output': batch_size  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            }
            
            # 2. –ú–∞–ø–ø–∏–º teacher target –≤ surface –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—ç–∫–æ–Ω–æ–º–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤!)
            target_surface_output = self.flow_processor.mapper.input_mapper.forward(teacher_target_embeddings)
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if target_surface_output.dim() == 3:  # [batch, height, width]
                target_surface_output = target_surface_output.view(batch_size, -1)  # [batch, surface_dim]
            target_surface_input = self.flow_processor.mapper.input_mapper.forward(teacher_input_embeddings)
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if target_surface_input.dim() == 3:  # [batch, height, width]
                target_surface_input = target_surface_input.view(batch_size, -1)  # [batch, surface_dim]
            
            # 3. Energy loss - —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–∞ —É—Ä–æ–≤–Ω–µ surface (–Ω–µ 768D!)
            energy_loss = nn.functional.mse_loss(cube_output_surface, target_surface_output)
            
            # 4. Text Bridge –æ–±—É—á–µ–Ω–∏–µ (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–µ, –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ)
            text_loss = torch.tensor(0.0, device=self.device)
            if self.config.text_bridge_enabled and self.config.text_loss_weight > 0:
                try:
                    # TextToCubeEncoder: —É—á–∏—Ç—Å—è —Ç–µ–∫—Å—Ç ‚Üí surface (batch processing –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏)
                    encoder_outputs = self.text_encoder.encode_text(input_texts)  # [batch, 400]
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏  
                    logger.debug(f"Encoder outputs shape: {encoder_outputs.shape}, target_surface shape: {target_surface_input.shape}")
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º target_surface –ë–ï–ó detach() –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
                    encoder_loss = nn.functional.mse_loss(encoder_outputs, target_surface_input)
                    
                    # CubeToTextDecoder: —É—á–∏—Ç—Å—è surface ‚Üí —Ç–µ–∫—Å—Ç (–ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º target_surface)
                    predicted_texts = []
                    for i in range(batch_size):
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º batch dimension –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ [1, 400]
                        pred_texts_batch = self.text_decoder.decode_surface(target_surface_output[i:i+1].detach())  # List[str]
                        pred_text = pred_texts_batch[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π) —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        predicted_texts.append(pred_text)
                    
                    # –ü—Ä–æ—Å—Ç–æ–π text similarity loss (–º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å)
                    decoder_loss = torch.tensor(0.0, device=self.device)
                    for pred_text, target_text in zip(predicted_texts, target_texts):
                        # –ü—Ä–∏–º–∏—Ç–∏–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –¥–ª–∏–Ω—ã –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                        length_diff = abs(len(pred_text) - len(target_text)) / max(len(target_text), 1)
                        decoder_loss += torch.tensor(length_diff, device=self.device)
                    decoder_loss /= batch_size
                    
                    # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π text loss
                    text_loss = encoder_loss + decoder_loss
                    
                except Exception as e:
                    logger.warning(f"Text loss computation failed: {e}")
                    text_loss = torch.tensor(0.0, device=self.device)
            
            # 5. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π loss
            total_loss = energy_loss + self.config.text_loss_weight * text_loss
            
            # 6. –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ
            total_loss.backward()
            
            # Gradient clipping
            if self.config.gradient_clip > 0:
                torch.nn.utils.clip_grad_norm_(
                    self.optimizer.param_groups[0]['params'], 
                    self.config.gradient_clip
                )
            
            self.optimizer.step()
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —à–∞–≥–∞
            step_time = time.time() - step_start_time
            
            step_metrics = {
                'total_loss': total_loss.item(),
                'energy_loss': energy_loss.item(), 
                'text_loss': text_loss.item(),
                'learning_rate': self.optimizer.param_groups[0]['lr'],
                'step_time': step_time,
                'flow_time': flow_time,
                'active_flows': flow_stats.get('active_flows', 0),
                'spawned_flows': flow_stats.get('spawned_flows', 0),
                'flows_reached_output': flow_stats.get('flows_reached_output', 0),
                'batch_size': batch_size
            }
            
            self.global_step += 1
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            if self.global_step % self.config.log_interval == 0:
                logger.log(DEBUG_TRAINING, 
                          f"Step {self.global_step}: total_loss={total_loss.item():.4f}, "
                          f"energy_loss={energy_loss.item():.4f}, text_loss={text_loss.item():.4f}")
                logger.log(DEBUG_ENERGY,
                          f"Flow stats: active={flow_stats.get('active_flows', 0)}, "
                          f"spawned={flow_stats.get('spawned_flows', 0)}, "
                          f"reached_output={flow_stats.get('flows_reached_output', 0)}")
            
            return step_metrics
            
        except Exception as e:
            logger.error(f"Training step failed: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º dummy –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
            return {
                'total_loss': float('inf'),
                'energy_loss': float('inf'),
                'text_loss': 0.0,
                'learning_rate': self.optimizer.param_groups[0]['lr'],
                'step_time': time.time() - step_start_time,
                'flow_time': 0.0,
                'active_flows': 0,
                'spawned_flows': 0, 
                'flows_reached_output': 0,
                'batch_size': batch_size,
                'error': str(e)
            }
    
    def train_epoch(self, dataloader: DataLoader, teacher_embeddings_loader) -> Dict[str, float]:
        """
        –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–µ
        
        Args:
            dataloader: DataLoader —Å –ø–∞—Ä–∞–º–∏ (input_texts, target_texts)
            teacher_embeddings_loader: –ò—Ç–µ—Ä–∞—Ç–æ—Ä —Å teacher embeddings –ø–∞—Ä–∞–º–∏
            
        Returns:
            –£—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —ç–ø–æ—Ö–µ
        """
        self.flow_processor.train()
        if self.config.text_bridge_enabled:
            self.text_encoder.train() if hasattr(self.text_encoder, 'train') else None
            self.text_decoder.train()
        
        epoch_metrics = {
            'total_loss': 0.0,
            'energy_loss': 0.0,
            'text_loss': 0.0,
            'step_time': 0.0,
            'flow_time': 0.0,
            'active_flows': 0.0,
            'spawned_flows': 0.0,
            'flows_reached_output': 0.0
        }
        
        total_batches = 0
        epoch_start_time = time.time()
        
        for batch_idx, (batch_data, teacher_data) in enumerate(zip(dataloader, teacher_embeddings_loader)):
            # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
            if isinstance(batch_data, (list, tuple)) and len(batch_data) >= 2:
                input_texts, target_texts = batch_data[0], batch_data[1]
            else:
                logger.warning(f"Unexpected batch format: {type(batch_data)}")
                continue
            
            # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ teacher embeddings
            if isinstance(teacher_data, (list, tuple)) and len(teacher_data) >= 2:
                teacher_input_emb, teacher_target_emb = teacher_data[0], teacher_data[1]
            else:
                logger.warning(f"Unexpected teacher embeddings format: {type(teacher_data)}")
                continue
            
            # –û–¥–∏–Ω —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è
            step_metrics = self.train_step(input_texts, target_texts, teacher_input_emb, teacher_target_emb)
            
            # –ê–∫–∫—É–º—É–ª–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
            for key in epoch_metrics:
                if key in step_metrics:
                    epoch_metrics[key] += step_metrics[key]
            
            total_batches += 1
            
            # Periodic logging –≤–Ω—É—Ç—Ä–∏ —ç–ø–æ—Ö–∏
            if batch_idx % (self.config.log_interval * 5) == 0:
                logger.log(DEBUG_TRAINING,
                          f"Epoch {self.epoch}, Batch {batch_idx}/{len(dataloader)}: "
                          f"loss={step_metrics.get('total_loss', 0):.4f}")
        
        # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø–æ —ç–ø–æ—Ö–µ
        if total_batches > 0:
            for key in epoch_metrics:
                epoch_metrics[key] /= total_batches
        
        epoch_time = time.time() - epoch_start_time
        epoch_metrics['epoch_time'] = epoch_time
        epoch_metrics['total_batches'] = total_batches
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
        self.scheduler.step(epoch_metrics['total_loss'])
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–ø–æ—Ö–∏
        logger.log(DEBUG_TRAINING,
                  f"‚úÖ Epoch {self.epoch} completed: "
                  f"avg_loss={epoch_metrics['total_loss']:.4f}, "
                  f"time={epoch_time:.1f}s, batches={total_batches}")
        logger.log(DEBUG_CONVERGENCE,
                  f"Convergence stats: flows_reached_output={epoch_metrics['flows_reached_output']:.1f}, "
                  f"active_flows={epoch_metrics['active_flows']:.1f}")
        
        self.epoch += 1
        return epoch_metrics
    
    def train(self, dataloader: DataLoader, teacher_embeddings_loader, num_epochs: int = 10) -> Dict[str, List]:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            dataloader: DataLoader —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            teacher_embeddings_loader: DataLoader —Å teacher embeddings
            num_epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            
        Returns:
            –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        """
        logger.info(f"üöÄ Starting training: {num_epochs} epochs, batch_size={self.config.batch_size}")
        
        training_start_time = time.time()
        
        for epoch in range(num_epochs):
            epoch_metrics = self.train_epoch(dataloader, teacher_embeddings_loader)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            for key in epoch_metrics:
                if key in self.training_history:
                    self.training_history[key].append(epoch_metrics[key])
            
            # –ß–µ–∫–ø–æ–∏–Ω—Ç–∏–Ω–≥ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            if epoch_metrics['total_loss'] < self.best_loss:
                self.best_loss = epoch_metrics['total_loss']
                self.save_checkpoint(f"best_model_epoch_{epoch}.pt")
            
            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã
            if epoch % self.config.checkpoint_interval == 0:
                self.save_checkpoint(f"checkpoint_epoch_{epoch}.pt")
        
        training_time = time.time() - training_start_time
        
        logger.info(f"‚úÖ Training completed: {num_epochs} epochs, "
                   f"total_time={training_time:.1f}s, "
                   f"best_loss={self.best_loss:.4f}")
        
        return self.training_history
    
    def validate(self, input_texts: List[str], target_texts: List[str], 
                 teacher_input_embeddings: torch.Tensor, teacher_target_embeddings: torch.Tensor) -> Dict[str, Any]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        
        Args:
            input_texts: –í—Ö–æ–¥–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            target_texts: –¶–µ–ª–µ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
            teacher_input_embeddings: Teacher input embeddings [batch, 768]
            teacher_target_embeddings: Teacher target embeddings [batch, 768]
            
        Returns:
            –ú–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        """
        self.flow_processor.eval()
        if self.config.text_bridge_enabled:
            if hasattr(self.text_encoder, 'eval'):
                self.text_encoder.eval()
            self.text_decoder.eval()
        
        with torch.no_grad():
            val_metrics = self.train_step(input_texts, target_texts, teacher_input_embeddings, teacher_target_embeddings)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            examples = []
            if self.config.text_bridge_enabled:
                num_examples = min(3, len(input_texts))
                for i in range(num_examples):
                    try:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º teacher embeddings –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ (–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
                        surface_input = teacher_input_embeddings[i:i+1]  # [1, 768]
                        surface_output = self.flow_processor.forward(surface_input, max_steps=50)  # [1, surface_dim]
                        
                        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º surface embedding –≤ —Ç–µ–∫—Å—Ç (—Å–æ—Ö—Ä–∞–Ω—è–µ–º batch dimension)
                        predicted_texts = self.text_decoder.decode_surface(surface_output[i:i+1])  # [1, surface_dim] -> List[str]
                        predicted_text = predicted_texts[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π) —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        
                        examples.append({
                            'input': input_texts[i],
                            'target': target_texts[i],
                            'predicted': predicted_text
                        })
                    except Exception as e:
                        logger.warning(f"Example generation failed for sample {i}: {e}")
        
        val_metrics['examples'] = examples
        
        logger.log(DEBUG_TRAINING, f"Validation: loss={val_metrics.get('total_loss', 0):.4f}")
        if examples:
            logger.log(DEBUG_TRAINING, f"Example - Input: '{examples[0]['input'][:50]}...'")
            logger.log(DEBUG_TRAINING, f"Example - Predicted: '{examples[0]['predicted'][:50]}...'")
        
        return val_metrics
    
    def save_checkpoint(self, filepath: Union[str, Path]) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –º–æ–¥–µ–ª–∏"""
        filepath = Path(filepath)
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        checkpoint = {
            'epoch': self.epoch,
            'global_step': self.global_step,
            'config': self.config.to_dict(),
            'model_state_dict': self.flow_processor.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_loss': self.best_loss,
            'training_history': self.training_history
        }
        
        if self.config.text_bridge_enabled:
            if hasattr(self.text_encoder, 'state_dict'):
                checkpoint['text_encoder_state_dict'] = self.text_encoder.state_dict()
            checkpoint['text_decoder_state_dict'] = self.text_decoder.state_dict()
        
        torch.save(checkpoint, filepath)
        logger.info(f"üíæ Checkpoint saved: {filepath}")
    
    def load_checkpoint(self, filepath: Union[str, Path]) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –º–æ–¥–µ–ª–∏"""
        filepath = Path(filepath)
        if not filepath.exists():
            raise FileNotFoundError(f"Checkpoint not found: {filepath}")
        
        checkpoint = torch.load(filepath, map_location=self.device)
        
        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.epoch = checkpoint['epoch']
        self.global_step = checkpoint['global_step']
        self.best_loss = checkpoint['best_loss']
        self.training_history = checkpoint['training_history']
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤
        self.flow_processor.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        if self.config.text_bridge_enabled:
            if 'text_encoder_state_dict' in checkpoint and hasattr(self.text_encoder, 'load_state_dict'):
                self.text_encoder.load_state_dict(checkpoint['text_encoder_state_dict'])
            if 'text_decoder_state_dict' in checkpoint:
                self.text_decoder.load_state_dict(checkpoint['text_decoder_state_dict'])
        
        logger.info(f"üìÅ Checkpoint loaded: {filepath}, epoch={self.epoch}, step={self.global_step}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ –∏ –µ—ë –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö"""
        info = {
            'config': self.config.to_dict(),
            'epoch': self.epoch,
            'global_step': self.global_step,
            'best_loss': self.best_loss,
            'device': str(self.device)
        }
        
        # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        flow_params = sum(p.numel() for p in self.flow_processor.parameters() if p.requires_grad)
        info['flow_processor_parameters'] = flow_params
        
        if self.config.text_bridge_enabled:
            # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ text_bridge –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            if hasattr(self.text_encoder, 'model'):  # Cached version
                encoder_params = sum(p.numel() for p in self.text_encoder.model.parameters() if p.requires_grad)
            else:  # Direct model
                encoder_params = sum(p.numel() for p in self.text_encoder.parameters() if p.requires_grad)
            info['text_encoder_parameters'] = encoder_params
            
            if hasattr(self.text_decoder, 'model'):  # Cached version
                decoder_params = sum(p.numel() for p in self.text_decoder.model.parameters() if p.requires_grad)
            else:  # Direct model
                decoder_params = sum(p.numel() for p in self.text_decoder.parameters() if p.requires_grad)
            info['text_decoder_parameters'] = decoder_params
        
        return info


def create_energy_trainer(config: Optional[EnergyConfig] = None) -> EnergyTrainer:
    """–§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è EnergyTrainer"""
    return EnergyTrainer(config)