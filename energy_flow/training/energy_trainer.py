"""
EnergyTrainer - –æ—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è energy_flow –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
=========================================================================

–ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π text_bridge –º–æ–¥—É–ª—è:
- –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ energy flow + text decoders
- GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å CUDA –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é  
- –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–µ—Ç—Ä–∏–∫–∏
- –ß–µ–∫–ø–æ–∏–Ω—Ç–∏–Ω–≥ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏:
input_text ‚Üí TextToCubeEncoder ‚Üí surface_embedding ‚Üí FlowProcessor ‚Üí 
output_surface_embedding ‚Üí CubeToTextDecoder ‚Üí predicted_text

Loss = energy_loss + text_loss_weight √ó text_loss
"""

# import torch
import torch as torch_module  # –ê–ª–∏–∞—Å –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è scoping –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
from typing import Dict, List, Tuple, Optional, Any, Union
from pathlib import Path
import time
from datetime import datetime
import json

from ..utils.logging import get_logger, DEBUG_TRAINING, DEBUG_ENERGY, DEBUG_CONVERGENCE, DEBUG_PERFORMANCE, DEBUG_PROFILING
from ..utils.device_manager import get_device_manager
from ..utils.checkpoint_utils import generate_checkpoint_path, create_checkpoint_summary
from ..config import EnergyConfig, get_energy_config, create_debug_config, set_energy_config
from ..core import FlowProcessor, EnergyLattice, SimpleNeuron, EnergyCarrier
from ..text_bridge import (
    TextToCubeEncoder, CubeToTextDecoder, TextCache,
    create_text_to_cube_encoder, create_cube_to_text_decoder, create_text_cache,
    CachedTextToCubeEncoder, CachedCubeToTextDecoder
)
from .checkpoint_loader import SimpleCheckpointLoader

logger = get_logger(__name__)


class EnergyTrainer:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è energy_flow –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    
    –†–µ–∞–ª–∏–∑—É–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π text_bridge:
    - –≠–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ—Ç–æ–∫–∏ —á–µ—Ä–µ–∑ 3D —Ä–µ—à–µ—Ç–∫—É
    - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ text decoders
    - –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π loss (energy + text)
    - GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    
    def __init__(self, config: Optional[EnergyConfig] = None):
        """
        Args:
            config: EnergyConfig —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è
        """
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        if config is None:
            config = create_debug_config()
            set_energy_config(config)
        self.config = config
        
        # Device management  
        self.device_manager = get_device_manager() 
        self.device = self.device_manager.device
        
        logger.log(DEBUG_TRAINING, f"üöÄ EnergyTrainer initialization on {self.device}")
        logger.log(DEBUG_TRAINING, f"Config: {config.lattice_width}x{config.lattice_height}x{config.lattice_depth}, "
                                  f"text_bridge={config.text_bridge_enabled}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self._init_core_components()
        self._init_text_bridge()
        self._init_optimizer()
        self._init_mixed_precision()
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
        self.training_history = {
            "total_losses": [],
            "energy_losses": [],
            "text_losses": [],
            "learning_rates": [],
            "flow_statistics": [],
            "performance_metrics": []
        }
        
        # –°—á–µ—Ç—á–∏–∫–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.global_step = 0  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Å—á–µ—Ç—á–∏–∫ —à–∞–≥–æ–≤ —á–µ—Ä–µ–∑ –≤—Å–µ —ç–ø–æ—Ö–∏ (–¥–ª—è curriculum learning)
        self.epoch = 0
        self.best_loss = float('inf')
        
        # Gradient accumulation —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.current_accumulation_step = 0
        self.accumulation_loss = 0.0
        self.accumulation_metrics = {}
        
        # Smart memory management –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è empty_cache() overhead
        self.step_counter = 0
        self.memory_cleanup_interval = 10  # Cleanup —Ç–æ–ª—å–∫–æ –∫–∞–∂–¥—ã–µ 10 —à–∞–≥–æ–≤ –≤–º–µ—Å—Ç–æ –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞
        self.memory_threshold_gb = 16.0    # Cleanup –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ 16GB –¥–ª—è RTX 5090
        
        # Checkpoint —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        self.checkpoint_loader = SimpleCheckpointLoader()
        self.checkpoint_base_dir = Path("checkpoints/energy_flow")
        
        logger.log(DEBUG_TRAINING, "‚úÖ EnergyTrainer successfully initialized")
    
    def _init_core_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ energy_flow"""
        logger.log(DEBUG_TRAINING, "Initializing core energy_flow components...")
        
        # FlowProcessor –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ core –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.flow_processor = FlowProcessor(self.config).to(self.device)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –ø—Ä—è–º–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
        self.energy_lattice = self.flow_processor.lattice
        self.simple_neuron = self.flow_processor.neuron
        self.energy_carrier = self.flow_processor.carrier
        
        logger.log(DEBUG_TRAINING, f"Core components initialized: "
                                  f"FlowProcessor, EnergyLattice({self.config.lattice_width}x{self.config.lattice_height}x{self.config.lattice_depth})")
    
    def _init_text_bridge(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è text_bridge –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        if not self.config.text_bridge_enabled:
            logger.log(DEBUG_TRAINING, "Text bridge disabled, skipping initialization")
            self.text_encoder = None
            self.text_decoder = None
            self.text_cache = None
            return
            
        logger.log(DEBUG_TRAINING, "Initializing text_bridge components...")
        
        # Text cache (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
        if self.config.text_cache_enabled:
            self.text_cache = create_text_cache(
                max_size=self.config.text_cache_size,
                cache_file=self.config.text_cache_file
            )
            logger.log(DEBUG_TRAINING, f"TextCache initialized with size {self.config.text_cache_size}")
        else:
            self.text_cache = None
        
        # Text encoder (text ‚Üí surface embeddings)
        base_encoder = create_text_to_cube_encoder(self.config).to(self.device)
        if self.text_cache:
            self.text_encoder = CachedTextToCubeEncoder(base_encoder, self.text_cache)
        else:
            self.text_encoder = base_encoder
            
        # Text decoder (surface embeddings ‚Üí text)
        base_decoder = create_cube_to_text_decoder(self.config).to(self.device)
        if self.text_cache:
            self.text_decoder = CachedCubeToTextDecoder(base_decoder, self.text_cache)
        else:
            self.text_decoder = base_decoder
        
        # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        encoder_params = sum(p.numel() for p in base_encoder.parameters() if p.requires_grad)
        decoder_params = sum(p.numel() for p in base_decoder.parameters() if p.requires_grad)
        
        logger.log(DEBUG_TRAINING, f"Text bridge initialized: encoder({encoder_params:,} params), "
                                  f"decoder({decoder_params:,} params)")
    
    def _init_optimizer(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞"""
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        params = list(self.flow_processor.parameters())
        
        if self.config.text_bridge_enabled:
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã text_bridge –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            # –î–ª—è cached –≤–µ—Ä—Å–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
            if hasattr(self.text_encoder, 'encoder'):  # CachedTextToCubeEncoder
                params.extend(self.text_encoder.encoder.parameters())
            elif hasattr(self.text_encoder, 'parameters'):  # Direct TextToCubeEncoder
                params.extend(self.text_encoder.parameters())
                
            if hasattr(self.text_decoder, 'decoder'):  # CachedCubeToTextDecoder
                params.extend(self.text_decoder.decoder.parameters())
            elif hasattr(self.text_decoder, 'parameters'):  # Direct CubeToTextDecoder
                params.extend(self.text_decoder.parameters())
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
        self.optimizer = optim.AdamW(
            params,
            lr=self.config.learning_rate,
            weight_decay=self.config.weight_decay
        )
        
        # –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ learning rate
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=0.5,
            patience=10
        )
        
        total_params = sum(p.numel() for p in params if p.requires_grad)
        logger.log(DEBUG_TRAINING, f"Optimizer initialized: AdamW, lr={self.config.learning_rate}, "
                                  f"total_params={total_params:,}")
    
    def _init_mixed_precision(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Mixed Precision Training"""
        if self.config.use_mixed_precision and torch_module.cuda.is_available():
            # GradScaler –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ scaling –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
            if self.config.use_gradient_scaling:
                self.scaler = torch_module.cuda.amp.GradScaler(
                    init_scale=self.config.gradient_scale_init,
                    enabled=True
                )
                logger.log(DEBUG_TRAINING, f"üîß Mixed Precision: GradScaler initialized with scale={self.config.gradient_scale_init}")
            else:
                self.scaler = None
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ autocast –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            self.autocast_kwargs = {
                'device_type': 'cuda',
                'dtype': self.config.mixed_precision_dtype,
                'enabled': True
            }
            
            logger.log(DEBUG_TRAINING, f"üöÄ Mixed Precision Training enabled: {self.config.mixed_precision_dtype}")
            logger.log(DEBUG_TRAINING, f"   Expected benefits: 1.5x speedup, 50% memory saving")
        else:
            self.scaler = None
            self.autocast_kwargs = {'enabled': False}
            
            if not self.config.use_mixed_precision:
                logger.log(DEBUG_TRAINING, "Mixed Precision Training disabled by config")
            else:
                logger.log(DEBUG_TRAINING, "Mixed Precision Training disabled: CUDA not available")
    
    def _compute_losses(self, input_texts: List[str], target_texts: List[str], 
                       teacher_input_embeddings: torch_module.Tensor, teacher_target_embeddings: torch_module.Tensor) -> Dict[str, Any]:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç losses –±–µ–∑ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è (–¥–ª—è validation)
        
        Args:
            input_texts: –°–ø–∏—Å–æ–∫ –≤—Ö–æ–¥–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–¥–ª—è text_bridge)
            target_texts: –°–ø–∏—Å–æ–∫ —Ü–µ–ª–µ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–¥–ª—è text_bridge)
            teacher_input_embeddings: –í—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è [batch, 768]
            teacher_target_embeddings: –¶–µ–ª–µ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è [batch, 768]
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ (–±–µ–∑ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è)
        """
        batch_size = len(input_texts)
        step_start_time = time.time()
        
        try:
            # 1. –û—Å–Ω–æ–≤–Ω–æ–π forward pass –∫—É–±–∞ —Å teacher embeddings
            flow_start_time = time.time()
            cube_output_surface = self.flow_processor.forward(teacher_input_embeddings)
            flow_time = time.time() - flow_start_time
            
            # 2. –ú–∞–ø–ø–∏–º teacher target –≤ surface –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            target_surface_output = self.flow_processor.mapper.input_mapper.forward(teacher_target_embeddings)
            target_surface_input = self.flow_processor.mapper.input_mapper.forward(teacher_input_embeddings)
            
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ
            if target_surface_output.dim() == 3:
                target_surface_output = target_surface_output.view(batch_size, -1)
            if target_surface_input.dim() == 3:
                target_surface_input = target_surface_input.view(batch_size, -1)
            
            # 3. Energy loss - —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–∞ —É—Ä–æ–≤–Ω–µ surface
            energy_loss = nn.functional.mse_loss(cube_output_surface, target_surface_output)
            
            # 4. Text Bridge –±–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è validation
            text_loss = torch_module.tensor(0.0, device=self.device)
            if self.config.text_bridge_enabled and self.config.text_loss_weight > 0:
                try:
                    encoder_outputs = self.text_encoder.encode_text(input_texts)
                    # –í validation —Ä–µ–∂–∏–º–µ –Ω–µ —Ç—Ä–µ–±—É–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
                    target_surface_input_grad = target_surface_input.clone().detach()
                    encoder_loss = nn.functional.mse_loss(encoder_outputs, target_surface_input_grad)
                    text_loss = encoder_loss
                except Exception as e:
                    logger.warning(f"‚ùå Text bridge computation failed: {e}")
                    text_loss = torch_module.tensor(0.1, device=self.device)
            
            # 5. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π loss
            total_loss = energy_loss + self.config.text_loss_weight * text_loss
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —à–∞–≥–∞
            step_time = time.time() - step_start_time
            flow_stats = {'flows_reached_output': batch_size}
            
            return {
                'total_loss': total_loss.item() if hasattr(total_loss, 'item') else float(total_loss),
                'energy_loss': energy_loss.item() if hasattr(energy_loss, 'item') else float(energy_loss),
                'text_loss': text_loss.item() if hasattr(text_loss, 'item') else float(text_loss),
                'flow_time': flow_time,
                'step_time': step_time,
                'flow_stats': flow_stats,
                'gradients_computed': False,
                'total_params_with_grads': 0,
            }
            
        except Exception as e:
            logger.error(f"‚ùå Forward pass failed: {e}")
            return {
                'total_loss': float('inf'),
                'energy_loss': float('inf'),
                'text_loss': float('inf'),
                'flow_time': 0,
                'step_time': 0,
                'flow_stats': {'error': str(e)},
                'gradients_computed': False,
                'total_params_with_grads': 0,
            }
    
    def train_step(self, input_texts: List[str], target_texts: List[str],
                   teacher_input_embeddings: torch_module.Tensor, teacher_target_embeddings: torch_module.Tensor,
                   global_training_step: Optional[int] = None) -> Dict[str, float]:
        """
        –û–¥–∏–Ω —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        
        Args:
            input_texts: –°–ø–∏—Å–æ–∫ –≤—Ö–æ–¥–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–¥–ª—è text_bridge)
            target_texts: –°–ø–∏—Å–æ–∫ —Ü–µ–ª–µ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–¥–ª—è text_bridge)
            teacher_input_embeddings: –í—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è [batch, 768]
            teacher_target_embeddings: –¶–µ–ª–µ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è [batch, 768]
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ —à–∞–≥–∞
        """
        # Gradient accumulation: –æ—á–∏—â–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã —Ç–æ–ª—å–∫–æ –≤ –Ω–∞—á–∞–ª–µ accumulation
        if self.current_accumulation_step == 0:
            self.optimizer.zero_grad()
            self.accumulation_loss = 0.0
            self.accumulation_metrics = {}
        
        batch_size = len(input_texts)
        step_start_time = time.time()
        
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        logger.log(DEBUG_TRAINING, f"üîÑ Starting train_step: batch_size={batch_size}, "
                                  f"accumulation_step={self.current_accumulation_step+1}/{self.config.gradient_accumulation_steps}")
        logger.log(DEBUG_TRAINING, f"üìä Input texts: {len(input_texts)} samples")
        logger.log(DEBUG_TRAINING, f"üìä Teacher embeddings: {teacher_input_embeddings.shape} -> {teacher_target_embeddings.shape}")
        
        try:
            # 1. –û—Å–Ω–æ–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∫—É–±–∞ —Å teacher embeddings –° MIXED PRECISION
            flow_start_time = time.time()
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            logger.log(DEBUG_TRAINING, f"üìà Teacher input requires_grad: {teacher_input_embeddings.requires_grad}")
            logger.log(DEBUG_TRAINING, f"üìà Teacher target requires_grad: {teacher_target_embeddings.requires_grad}")
            
            # –ü–†–ò–ú–ï–ù–Ø–ï–ú AUTOCAST –î–õ–Ø MIXED PRECISION (1.5x speedup, 50% memory)
            with torch_module.autocast(**self.autocast_kwargs):
                # –ü–µ—Ä–µ–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —à–∞–≥ –¥–ª—è curriculum learning –≤ FlowProcessor
                cube_output_surface = self.flow_processor.forward(
                    teacher_input_embeddings, 
                    global_training_step=global_training_step or self.global_step
                )
            flow_time = time.time() - flow_start_time
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã—Ö–æ–¥ –∫—É–±–∞
            logger.log(DEBUG_TRAINING, f"üìä Cube output surface shape: {cube_output_surface.shape}")
            logger.log(DEBUG_TRAINING, f"üìä Cube output surface stats: mean={cube_output_surface.mean():.4f}, std={cube_output_surface.std():.4f}")
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ—Ç–æ–∫–æ–≤
            flow_stats = {
                'active_flows': 0,
                'spawned_flows': 0,
                'flows_reached_output': batch_size
            }
            
            # 2. –ú–∞–ø–ø–∏–º teacher target –≤ surface –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –° MIXED PRECISION
            with torch_module.autocast(**self.autocast_kwargs):
                target_surface_output = self.flow_processor.mapper.input_mapper.forward(teacher_target_embeddings)
                target_surface_input = self.flow_processor.mapper.input_mapper.forward(teacher_input_embeddings)
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º—ã
            logger.log(DEBUG_TRAINING, f"üìä Target surface output shape: {target_surface_output.shape}")
            logger.log(DEBUG_TRAINING, f"üìä Target surface input shape: {target_surface_input.shape}")
            
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ
            if target_surface_output.dim() == 3:
                target_surface_output = target_surface_output.view(batch_size, -1)
            if target_surface_input.dim() == 3:
                target_surface_input = target_surface_input.view(batch_size, -1)
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø–æ—Å–ª–µ reshape
            logger.log(DEBUG_TRAINING, f"üìà Target surface output requires_grad: {target_surface_output.requires_grad}")
            logger.log(DEBUG_TRAINING, f"üìà Target surface input requires_grad: {target_surface_input.requires_grad}")
            
            # 3. Energy loss - —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–∞ —É—Ä–æ–≤–Ω–µ surface –° MIXED PRECISION
            with torch_module.autocast(**self.autocast_kwargs):
                energy_loss = nn.functional.mse_loss(cube_output_surface, target_surface_output)
            
            # 4. Text Bridge –æ–±—É—á–µ–Ω–∏–µ - –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ë–ê–¢–ß–ï–í–ê–Ø –í–ï–†–°–ò–Ø
            text_loss = torch_module.tensor(0.0, device=self.device)
            if self.config.text_bridge_enabled and self.config.text_loss_weight > 0:
                text_bridge_start_time = time.time()
                try:
                    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 1: –ë–∞—Ç—á–µ–≤–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ ‚Üí surface
                    if logger.isEnabledFor(DEBUG_TRAINING):
                        logger.log(DEBUG_TRAINING, f"üìù Processing text bridge (batch={len(input_texts)})")
                    
                    encoder_outputs = self.text_encoder.encode_text(input_texts)
                    if logger.isEnabledFor(DEBUG_TRAINING):
                        logger.log(DEBUG_TRAINING, f"üìä Encoder outputs: {encoder_outputs.shape}")
                    
                    # Encoder loss: text ‚Üí surface mapping
                    target_surface_input_grad = target_surface_input.clone().detach().requires_grad_(True)
                    encoder_loss = nn.functional.mse_loss(encoder_outputs, target_surface_input_grad)
                    
                    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 2: –ò—Å–ø–æ–ª—å–∑—É–µ–º –£–ñ–ï –í–´–ß–ò–°–õ–ï–ù–ù–´–ô cube_output_surface!
                    # –í–º–µ—Å—Ç–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö forward passes –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞
                    decoder_loss = torch_module.tensor(0.0, device=self.device)
                    
                    try:
                        # –ë–∞—Ç—á–µ–≤–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ surface ‚Üí text
                        predicted_texts = self.text_decoder.decode_surface(cube_output_surface)
                        
                        # –ë–∞—Ç—á–µ–≤–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ text similarity loss
                        if predicted_texts and len(predicted_texts) == len(target_texts):
                            similarities = []
                            for pred_text, target_text in zip(predicted_texts, target_texts):
                                if pred_text and target_text:
                                    pred_words = set(pred_text.lower().split())
                                    target_words = set(target_text.lower().split())
                                    intersection = len(pred_words & target_words)
                                    union = len(pred_words | target_words)
                                    similarity = intersection / max(union, 1)
                                    similarities.append(similarity)
                                else:
                                    similarities.append(0.0)
                            
                            # Vectorized similarity loss
                            similarities_tensor = torch_module.tensor(similarities, device=self.device)
                            decoder_loss = (1.0 - similarities_tensor).mean()
                            
                            if logger.isEnabledFor(DEBUG_TRAINING):
                                avg_similarity = similarities_tensor.mean().item()
                                logger.log(DEBUG_TRAINING, f"üìù Avg text similarity: {avg_similarity:.3f}")
                        else:
                            decoder_loss = torch_module.tensor(1.0, device=self.device)
                            if logger.isEnabledFor(DEBUG_TRAINING):
                                logger.log(DEBUG_TRAINING, f"‚ö†Ô∏è Text decoding mismatch: {len(predicted_texts)} vs {len(target_texts)}")
                    
                    except Exception as decode_error:
                        if logger.isEnabledFor(DEBUG_TRAINING):
                            logger.log(DEBUG_TRAINING, f"‚ùå Batch text decoding failed: {decode_error}")
                        decoder_loss = torch_module.tensor(1.0, device=self.device)
                    
                    # Combined text loss
                    text_loss = encoder_loss + 0.1 * decoder_loss
                    
                    # Performance logging
                    text_bridge_time = time.time() - text_bridge_start_time
                    if logger.isEnabledFor(DEBUG_TRAINING):
                        logger.log(DEBUG_TRAINING, 
                                 f"üìä Text bridge: encoder={encoder_loss:.4f}, decoder={decoder_loss:.4f}, "
                                 f"total={text_loss:.4f}, time={text_bridge_time*1000:.1f}ms")
                    
                except Exception as e:
                    logger.warning(f"‚ùå Text bridge computation failed: {e}")
                    text_loss = torch_module.tensor(0.1, device=self.device)
            
            # 5. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π loss (–±–µ–∑ forward_movement_reward - –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è —Å–∞–º–∞)
            total_loss = energy_loss + self.config.text_loss_weight * text_loss
            
            # –í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è forward_reward (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –º–µ—Ç—Ä–∏–∫)
            forward_reward = torch_module.tensor(0.0, device=self.device)
            
            # 6. Gradient accumulation: –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º loss 
            normalized_loss = total_loss / self.config.gradient_accumulation_steps
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞—Ç–Ω—ã–º —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ–º
            logger.log(DEBUG_TRAINING, f"üìä Losses: energy={energy_loss:.4f}, text={text_loss:.4f}, "
                                      f"total={total_loss:.4f}, normalized={normalized_loss:.4f}")
            logger.log(DEBUG_TRAINING, f"üìä Total loss requires_grad: {total_loss.requires_grad}")
            
            # 8. –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —Å normalized loss –ò GRADIENT SCALING
            if self.scaler is not None:
                # Mixed precision backward pass —Å gradient scaling
                self.scaler.scale(normalized_loss).backward()
            else:
                # –û–±—ã—á–Ω—ã–π backward pass
                normalized_loss.backward()
            
            # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–æ–∑–≤—Ä–∞—Ç–∞
            self.accumulation_loss += total_loss.item()
            if not self.accumulation_metrics:
                self.accumulation_metrics = {
                    'energy_loss': energy_loss.item(),
                    'text_loss': text_loss.item(), 
                    'forward_reward': forward_reward.item(),
                    'batch_size': batch_size
                }
            else:
                self.accumulation_metrics['energy_loss'] += energy_loss.item()
                self.accumulation_metrics['text_loss'] += text_loss.item()
                self.accumulation_metrics['forward_reward'] += forward_reward.item()
                self.accumulation_metrics['batch_size'] += batch_size
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
            total_params = 0
            grad_norms = []
            for param_group in self.optimizer.param_groups:
                for param in param_group['params']:
                    if param.grad is not None:
                        total_params += 1
                        grad_norm = param.grad.norm().item()
                        grad_norms.append(grad_norm)
            
            if grad_norms:
                avg_grad_norm = sum(grad_norms) / len(grad_norms)
                max_grad_norm = max(grad_norms)
                logger.log(DEBUG_TRAINING, f"üìä Gradients: {total_params} params, avg_norm={avg_grad_norm:.6f}, max_norm={max_grad_norm:.6f}")
            
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ accumulation
            self.current_accumulation_step += 1
            
            # Gradient clipping –∏ optimizer step —Ç–æ–ª—å–∫–æ –Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º accumulation —à–∞–≥–µ
            is_accumulation_complete = self.current_accumulation_step >= self.config.gradient_accumulation_steps
            
            if is_accumulation_complete:
                if self.scaler is not None:
                    # MIXED PRECISION: gradient clipping –∏ optimizer step —Å scaler
                    if self.config.gradient_clip > 0:
                        # Unscale gradients –ø–µ—Ä–µ–¥ clipping
                        self.scaler.unscale_(self.optimizer)
                        torch_module.nn.utils.clip_grad_norm_(
                            self.optimizer.param_groups[0]['params'],
                            self.config.gradient_clip
                        )
                    
                    # Optimizer step —Å scaling check
                    self.scaler.step(self.optimizer)
                    self.scaler.update()  # –û–±–Ω–æ–≤–ª—è–µ–º scale factor
                else:
                    # –û–ë–´–ß–ù–´–ô: gradient clipping –∏ optimizer step
                    if self.config.gradient_clip > 0:
                        torch_module.nn.utils.clip_grad_norm_(
                            self.optimizer.param_groups[0]['params'],
                            self.config.gradient_clip
                        )
                    
                    self.optimizer.step()
                
                self.global_step += 1  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º global_step —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –ø–æ–ª–Ω–æ–≥–æ accumulation
                
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º accumulation —Å—á–µ—Ç—á–∏–∫
                self.current_accumulation_step = 0
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —à–∞–≥–∞
            step_time = time.time() - step_start_time
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è accumulation
            if is_accumulation_complete:
                # –§–∏–Ω–∞–ª—å–Ω—ã–µ accumulated –º–µ—Ç—Ä–∏–∫–∏
                step_metrics = {
                    'total_loss': self.accumulation_loss / self.config.gradient_accumulation_steps,
                    'energy_loss': self.accumulation_metrics['energy_loss'] / self.config.gradient_accumulation_steps,
                    'text_loss': self.accumulation_metrics['text_loss'] / self.config.gradient_accumulation_steps,
                    'forward_reward': self.accumulation_metrics['forward_reward'] / self.config.gradient_accumulation_steps,
                    'learning_rate': self.optimizer.param_groups[0]['lr'],
                    'step_time': step_time,
                    'flow_time': flow_time,
                    'active_flows': flow_stats.get('active_flows', 0),
                    'spawned_flows': flow_stats.get('spawned_flows', 0),
                    'flows_reached_output': flow_stats.get('flows_reached_output', 0),
                    'batch_size': self.accumulation_metrics['batch_size'],
                    'effective_batch_size': self.accumulation_metrics['batch_size'],  # –†–µ–∞–ª—å–Ω—ã–π accumulated —Ä–∞–∑–º–µ—Ä
                    'accumulation_complete': True
                }
            else:
                # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (accumulating)
                step_metrics = {
                    'total_loss': total_loss.item(),
                    'energy_loss': energy_loss.item(),
                    'text_loss': text_loss.item(),
                    'forward_reward': forward_reward.item(),
                    'learning_rate': self.optimizer.param_groups[0]['lr'],
                    'step_time': step_time,
                    'flow_time': flow_time,
                    'active_flows': flow_stats.get('active_flows', 0),
                    'spawned_flows': flow_stats.get('spawned_flows', 0),
                    'flows_reached_output': flow_stats.get('flows_reached_output', 0),
                    'batch_size': batch_size,
                    'effective_batch_size': batch_size,
                    'accumulation_complete': False,
                    'accumulation_step': self.current_accumulation_step
                }
            
            # –£–°–õ–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω—É–∂–Ω–æ–º —É—Ä–æ–≤–Ω–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
            if logger.isEnabledFor(DEBUG_PERFORMANCE):
                try:
                    # Throughput metrics
                    throughput_samples_per_sec = batch_size / step_time if step_time > 0 else 0
                    
                    # GPU utilization (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
                    gpu_utilization = 0
                    memory_used_gb = 0
                    memory_utilization_percent = 0
                    
                    if torch_module.cuda.is_available():
                        memory_used_gb = torch_module.cuda.memory_allocated() / 1e9
                        memory_reserved_gb = torch_module.cuda.memory_reserved() / 1e9
                        
                        # GPU utilization —Ç—Ä–µ–±—É–µ—Ç nvidia-ml-py3, –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ
                        try:
                            gpu_utilization = torch_module.cuda.utilization() if hasattr(torch_module.cuda, 'utilization') else 0
                        except:
                            gpu_utilization = 0
                        
                        # Memory utilization –∫–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏
                        if memory_reserved_gb > 0:
                            memory_utilization_percent = (memory_used_gb / memory_reserved_gb) * 100
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º performance –º–µ—Ç—Ä–∏–∫–∏
                    step_metrics.update({
                        'throughput_samples_per_sec': throughput_samples_per_sec,
                        'gpu_utilization_percent': gpu_utilization,
                        'memory_used_gb': memory_used_gb,
                        'memory_utilization_percent': memory_utilization_percent,
                    })
                    
                    # Text bridge timing (–µ—Å–ª–∏ –±—ã–ª –∞–∫—Ç–∏–≤–µ–Ω)
                    if 'text_bridge_time' in locals():
                        step_metrics['text_bridge_time_ms'] = text_bridge_time * 1000
                        step_metrics['energy_computation_time_ms'] = flow_time * 1000
                    
                    logger.log(DEBUG_PERFORMANCE, 
                             f"‚ö° Performance: {throughput_samples_per_sec:.1f} samples/s, "
                             f"GPU: {gpu_utilization:.0f}%, Memory: {memory_used_gb:.1f}GB ({memory_utilization_percent:.0f}%)")
                
                except Exception as perf_error:
                    # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫ –≤ –º–µ—Ç—Ä–∏–∫–∞—Ö
                    if logger.isEnabledFor(DEBUG_TRAINING):
                        logger.log(DEBUG_TRAINING, f"Performance metrics error: {perf_error}")
            
            # –î–ï–¢–ê–õ–¨–ù–û–ï –ü–†–û–§–ò–õ–ò–†–û–í–ê–ù–ò–ï (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ DEBUG_PROFILING)
            if logger.isEnabledFor(DEBUG_PROFILING):
                try:
                    # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ç–∞–π–º–∏–Ω–≥–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
                    energy_percentage = (flow_time / step_time * 100) if step_time > 0 else 0
                    text_bridge_percentage = 0
                    
                    if 'text_bridge_time' in locals():
                        text_bridge_percentage = (text_bridge_time / step_time * 100) if step_time > 0 else 0
                    
                    logger.log(DEBUG_PROFILING,
                             f"üî¨ Profiling: Energy {energy_percentage:.1f}%, "
                             f"TextBridge {text_bridge_percentage:.1f}%, "
                             f"Other {100 - energy_percentage - text_bridge_percentage:.1f}%")
                
                except Exception as prof_error:
                    pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ accumulation –∏–ª–∏ –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —à–∞–≥–æ–≤ –≤ debug —Ä–µ–∂–∏–º–µ
            if is_accumulation_complete and self.global_step % self.config.log_interval == 0:
                avg_loss = self.accumulation_loss / self.config.gradient_accumulation_steps
                avg_energy = self.accumulation_metrics['energy_loss'] / self.config.gradient_accumulation_steps
                avg_text = self.accumulation_metrics['text_loss'] / self.config.gradient_accumulation_steps
                avg_forward_reward = self.accumulation_metrics['forward_reward'] / self.config.gradient_accumulation_steps
                logger.log(DEBUG_TRAINING,
                          f"‚úÖ Step {self.global_step} (accumulated): total_loss={avg_loss:.4f}, "
                          f"energy_loss={avg_energy:.4f}, text_loss={avg_text:.4f}, forward_reward={avg_forward_reward:.4f}")
            elif not is_accumulation_complete and logger.isEnabledFor(DEBUG_TRAINING):
                logger.log(DEBUG_TRAINING,
                          f"üîÑ Accumulating {self.current_accumulation_step}/{self.config.gradient_accumulation_steps}: "
                          f"total_loss={total_loss.item():.4f}, forward_reward={forward_reward.item():.4f}")
            
            # SMART MEMORY MANAGEMENT: Conditional cleanup –≤–º–µ—Å—Ç–æ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ empty_cache()
            # –£—Å—Ç—Ä–∞–Ω—è–µ—Ç 15-20% performance penalty –æ—Ç forced memory reallocation
            self.step_counter += 1
            
            if torch_module.cuda.is_available():
                current_memory_gb = torch_module.cuda.memory_allocated() / 1e9
                
                # Cleanup —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ (–∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤ –ò–õ–ò –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ threshold)
                should_cleanup = (
                    self.step_counter % self.memory_cleanup_interval == 0 or  # –ö–∞–∂–¥—ã–µ 10 —à–∞–≥–æ–≤
                    current_memory_gb > self.memory_threshold_gb              # –ò–ª–∏ –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ø–æ—Ä–æ–≥–∞
                )
                
                if should_cleanup:
                    torch_module.cuda.empty_cache()
                    memory_after_cleanup = torch_module.cuda.memory_allocated() / 1e9
                    
                    if logger.isEnabledFor(DEBUG_PERFORMANCE):
                        logger.log(DEBUG_PERFORMANCE, 
                                  f"üßπ Smart cleanup: {current_memory_gb:.1f}GB ‚Üí {memory_after_cleanup:.1f}GB "
                                  f"(step {self.step_counter}, interval={self.memory_cleanup_interval})")
                elif logger.isEnabledFor(DEBUG_PERFORMANCE):
                    logger.log(DEBUG_PERFORMANCE, 
                              f"‚ö° Skipped cleanup: {current_memory_gb:.1f}GB < {self.memory_threshold_gb:.1f}GB threshold")
            
            return step_metrics
            
        except Exception as e:
            logger.error(f"‚ùå Training step failed: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º dummy –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
            return {
                'total_loss': float('inf'),
                'energy_loss': float('inf'),
                'text_loss': 0.0,
                'learning_rate': self.optimizer.param_groups[0]['lr'],
                'step_time': time.time() - step_start_time,
                'flow_time': 0.0,
                'active_flows': 0,
                'spawned_flows': 0,
                'flows_reached_output': 0,
                'batch_size': batch_size,
                'error': str(e)
            }
    
    def train_epoch(self, dataloader: DataLoader, teacher_embeddings_loader) -> Dict[str, float]:
        """
        –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–µ
        
        Args:
            dataloader: DataLoader —Å –ø–∞—Ä–∞–º–∏ (input_texts, target_texts)
            teacher_embeddings_loader: –ò—Ç–µ—Ä–∞—Ç–æ—Ä —Å teacher embeddings –ø–∞—Ä–∞–º–∏
            
        Returns:
            –£—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —ç–ø–æ—Ö–µ
        """
        self.flow_processor.train()
        if self.config.text_bridge_enabled:
            self.text_encoder.train() if hasattr(self.text_encoder, 'train') else None
            self.text_decoder.train()
        
        epoch_metrics = {
            'total_loss': 0.0,
            'energy_loss': 0.0,
            'text_loss': 0.0,
            'step_time': 0.0,
            'flow_time': 0.0,
            'active_flows': 0.0,
            'spawned_flows': 0.0,
            'flows_reached_output': 0.0
        }
        
        total_batches = 0
        epoch_start_time = time.time()
        
        for batch_idx, (batch_data, teacher_data) in enumerate(zip(dataloader, teacher_embeddings_loader)):
            # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
            if isinstance(batch_data, (list, tuple)) and len(batch_data) >= 2:
                input_texts, target_texts = batch_data[0], batch_data[1]
            else:
                logger.warning(f"Unexpected batch format: {type(batch_data)}")
                continue
            
            # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ teacher embeddings
            if isinstance(teacher_data, (list, tuple)) and len(teacher_data) >= 2:
                teacher_input_emb, teacher_target_emb = teacher_data[0], teacher_data[1]
            else:
                logger.warning(f"Unexpected teacher embeddings format: {type(teacher_data)}")
                continue
            
            # –û–¥–∏–Ω —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è - –ø–µ—Ä–µ–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —à–∞–≥ –¥–ª—è curriculum learning  
            step_metrics = self.train_step(input_texts, target_texts, teacher_input_emb, teacher_target_emb, 
                                         global_training_step=self.global_step)
            
            # –ê–∫–∫—É–º—É–ª–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
            for key in epoch_metrics:
                if key in step_metrics:
                    epoch_metrics[key] += step_metrics[key]
            
            total_batches += 1
            
            # Periodic logging –≤–Ω—É—Ç—Ä–∏ —ç–ø–æ—Ö–∏
            if batch_idx % (self.config.log_interval * 5) == 0:
                logger.log(DEBUG_TRAINING,
                          f"Epoch {self.epoch}, Batch {batch_idx}/{len(dataloader)}: "
                          f"loss={step_metrics.get('total_loss', 0):.4f}")
        
        # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø–æ —ç–ø–æ—Ö–µ
        if total_batches > 0:
            for key in epoch_metrics:
                epoch_metrics[key] /= total_batches
        
        epoch_time = time.time() - epoch_start_time
        epoch_metrics['epoch_time'] = epoch_time
        epoch_metrics['total_batches'] = total_batches
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
        self.scheduler.step(epoch_metrics['total_loss'])
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–ø–æ—Ö–∏
        logger.log(DEBUG_TRAINING,
                  f"‚úÖ Epoch {self.epoch} completed: "
                  f"avg_loss={epoch_metrics['total_loss']:.4f}, "
                  f"time={epoch_time:.1f}s, batches={total_batches}")
        logger.log(DEBUG_CONVERGENCE,
                  f"Convergence stats: flows_reached_output={epoch_metrics['flows_reached_output']:.1f}, "
                  f"active_flows={epoch_metrics['active_flows']:.1f}")
        
        self.epoch += 1
        return epoch_metrics
    
    def train(self, dataloader: DataLoader, teacher_embeddings_loader, num_epochs: int = 10) -> Dict[str, List]:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            dataloader: DataLoader —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            teacher_embeddings_loader: DataLoader —Å teacher embeddings
            num_epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            
        Returns:
            –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        """
        logger.info(f"üöÄ Starting training: {num_epochs} epochs, batch_size={self.config.batch_size}")
        
        training_start_time = time.time()
        
        for epoch in range(num_epochs):
            epoch_metrics = self.train_epoch(dataloader, teacher_embeddings_loader)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            for key in epoch_metrics:
                if key in self.training_history:
                    self.training_history[key].append(epoch_metrics[key])
            
            # –£–º–Ω–æ–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∏–Ω–≥ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            if epoch_metrics['total_loss'] < self.best_loss:
                self.best_loss = epoch_metrics['total_loss']
                self.save_smart_checkpoint(
                    current_loss=epoch_metrics['total_loss'],
                    is_best=True,
                    custom_suffix=f"step_{self.global_step}"
                )
            
            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ —É–º–Ω—ã–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã
            if epoch % self.config.checkpoint_interval == 0:
                self.save_smart_checkpoint(
                    current_loss=epoch_metrics['total_loss'],
                    is_best=False,
                    custom_suffix=f"periodic_step_{self.global_step}"
                )
        
        training_time = time.time() - training_start_time
        
        logger.info(f"‚úÖ Training completed: {num_epochs} epochs, "
                   f"total_time={training_time:.1f}s, "
                   f"best_loss={self.best_loss:.4f}")
        
        return self.training_history
    
    def validate(self, input_texts: List[str], target_texts: List[str], 
                 teacher_input_embeddings: torch_module.Tensor, teacher_target_embeddings: torch_module.Tensor) -> Dict[str, Any]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        
        Args:
            input_texts: –í—Ö–æ–¥–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            target_texts: –¶–µ–ª–µ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
            teacher_input_embeddings: Teacher input embeddings [batch, 768]
            teacher_target_embeddings: Teacher target embeddings [batch, 768]
            
        Returns:
            –ú–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        """
        self.flow_processor.eval()
        if self.config.text_bridge_enabled:
            if hasattr(self.text_encoder, 'eval'):
                self.text_encoder.eval()
            self.text_decoder.eval()

        with torch_module.no_grad():
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –ë–ï–ó –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è - —Ç–æ–ª—å–∫–æ forward pass
            val_metrics = self._compute_losses(input_texts, target_texts, teacher_input_embeddings, teacher_target_embeddings)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            examples = []
            if self.config.text_bridge_enabled:
                num_examples = min(3, len(input_texts))
                for i in range(num_examples):
                    try:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º teacher embeddings –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ (–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
                        surface_input = teacher_input_embeddings[i:i+1]  # [1, 768]
                        surface_output = self.flow_processor.forward(surface_input)  # [1, surface_dim]

                        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º surface embedding –≤ —Ç–µ–∫—Å—Ç (surface_output —É–∂–µ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä [1, surface_dim])
                        predicted_texts = self.text_decoder.decode_surface(surface_output)  # [1, surface_dim] -> List[str]
                        predicted_text = predicted_texts[0] if predicted_texts else ""  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
                        
                        examples.append({
                            'input': input_texts[i],
                            'target': target_texts[i],
                            'predicted': predicted_text
                        })
                    except Exception as e:
                        logger.warning(f"Example generation failed for sample {i}: {e}")
        
        val_metrics['examples'] = examples
        
        logger.log(DEBUG_TRAINING, f"Validation: loss={val_metrics.get('total_loss', 0):.4f}")
        if examples:
            logger.log(DEBUG_TRAINING, f"Example - Input: '{examples[0]['input'][:50]}...'")
            logger.log(DEBUG_TRAINING, f"Example - Predicted: '{examples[0]['predicted'][:50]}...'")
        
        return val_metrics
    
    def save_checkpoint(self, filepath: Union[str, Path]) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –º–æ–¥–µ–ª–∏ (legacy –º–µ—Ç–æ–¥)"""
        filepath = Path(filepath)
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        checkpoint = {
            'epoch': self.epoch,
            'global_step': self.global_step,
            'config': self.config.to_dict(),
            'model_state_dict': self.flow_processor.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_loss': self.best_loss,
            'training_history': self.training_history
        }
        
        if self.config.text_bridge_enabled:
            if hasattr(self.text_encoder, 'state_dict'):
                checkpoint['text_encoder_state_dict'] = self.text_encoder.state_dict()
            checkpoint['text_decoder_state_dict'] = self.text_decoder.state_dict()

        torch_module.save(checkpoint, filepath)
        logger.info(f"üíæ Checkpoint saved: {filepath}")
    
    def save_smart_checkpoint(
        self, 
        current_loss: float, 
        is_best: bool = False, 
        custom_suffix: Optional[str] = None,
        save_to_active: bool = True
    ) -> Path:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ —Å —É–º–Ω—ã–º –∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ–º
        
        Args:
            current_loss: –¢–µ–∫—É—â–∏–π loss –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –∏–º—è
            is_best: –Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ —á–µ–∫–ø–æ–∏–Ω—Ç –ª—É—á—à–∏–º
            custom_suffix: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å—É—Ñ—Ñ–∏–∫—Å –¥–ª—è –∏–º–µ–Ω–∏
            save_to_active: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ –≤ active –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —á–µ–∫–ø–æ–∏–Ω—Ç—É
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        if save_to_active:
            base_dir = self.checkpoint_base_dir / "active"
        else:
            base_dir = self.checkpoint_base_dir
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—É—Ç—å —Å —É–º–Ω—ã–º –∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ–º
        checkpoint_path = generate_checkpoint_path(
            config=self.config,
            epoch=self.epoch,
            loss=current_loss,
            base_dir=base_dir,
            is_best=is_best,
            custom_suffix=custom_suffix
        )
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        checkpoint_path.parent.mkdir(parents=True, exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        checkpoint = {
            'epoch': self.epoch,
            'global_step': self.global_step,
            'config': self.config.to_dict(),
            'model_state_dict': self.flow_processor.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_loss': self.best_loss,
            'training_history': self.training_history,
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è —É–º–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            'current_loss': current_loss,
            'is_best_checkpoint': is_best,
            'save_timestamp': datetime.now().isoformat(),
            'custom_suffix': custom_suffix
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º text_bridge —Å–æ—Å—Ç–æ—è–Ω–∏—è
        if self.config.text_bridge_enabled:
            if hasattr(self.text_encoder, 'state_dict'):
                checkpoint['text_encoder_state_dict'] = self.text_encoder.state_dict()
            elif hasattr(self.text_encoder, 'encoder') and hasattr(self.text_encoder.encoder, 'state_dict'):
                checkpoint['text_encoder_state_dict'] = self.text_encoder.encoder.state_dict()
                
            if hasattr(self.text_decoder, 'state_dict'):
                checkpoint['text_decoder_state_dict'] = self.text_decoder.state_dict()
            elif hasattr(self.text_decoder, 'decoder') and hasattr(self.text_decoder.decoder, 'state_dict'):
                checkpoint['text_decoder_state_dict'] = self.text_decoder.decoder.state_dict()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç
        torch_module.save(checkpoint, checkpoint_path)

        # –°–æ–∑–¥–∞–µ–º summary –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        summary = create_checkpoint_summary(checkpoint_path)
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        prefix = "üèÜ BEST" if is_best else "üíæ"
        logger.info(f"{prefix} Smart checkpoint saved:")
        logger.info(f"   üìÅ Path: {checkpoint_path}")
        logger.info(f"   üìä Epoch: {self.epoch}, Loss: {current_loss:.4f}")
        logger.info(f"   üìè Size: {summary.get('size_mb', 0):.1f} MB")
        if custom_suffix:
            logger.info(f"   üè∑Ô∏è  Suffix: {custom_suffix}")
        
        return checkpoint_path
    
    def load_smart_checkpoint(
        self, 
        checkpoint_path: Optional[Union[str, Path]] = None,
        load_latest: bool = False,
        load_best: bool = False,
        strict_validation: bool = False
    ) -> bool:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ —Å —É–º–Ω—ã–º –ø–æ–∏—Å–∫–æ–º –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        
        Args:
            checkpoint_path: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É
            load_latest: –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç –∏–∑ active
            load_best: –ó–∞–≥—Ä—É–∑–∏—Ç—å –ª—É—á—à–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç –∏–∑ active
            strict_validation: –ï—Å–ª–∏ True, –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –ø—Ä–µ—Ä—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É
            
        Returns:
            True –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
        """
        checkpoint_data = None
        loaded_path = None
        
        if checkpoint_path:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
            checkpoint_data = self.checkpoint_loader.load_checkpoint(
                checkpoint_path, 
                current_config=self.config,
                strict_validation=strict_validation
            )
            loaded_path = Path(checkpoint_path)
        elif load_best:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
            checkpoint_data = self.checkpoint_loader.load_best_checkpoint(
                current_config=self.config,
                strict_validation=strict_validation
            )
            if checkpoint_data:
                from ..utils.checkpoint_utils import find_best_checkpoint
                best_path = find_best_checkpoint(self.checkpoint_loader.active_dir)
                loaded_path = best_path
        elif load_latest:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
            checkpoint_data = self.checkpoint_loader.load_latest_checkpoint(
                current_config=self.config,
                strict_validation=strict_validation
            )
            if checkpoint_data:
                from ..utils.checkpoint_utils import find_latest_checkpoint
                latest_path = find_latest_checkpoint(self.checkpoint_loader.active_dir)
                loaded_path = latest_path
        
        if checkpoint_data is None:
            logger.warning("No checkpoint loaded")
            return False
        
        try:
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            self.epoch = checkpoint_data.get('epoch', 0)
            self.global_step = checkpoint_data.get('global_step', 0)
            self.best_loss = checkpoint_data.get('best_loss', float('inf'))
            self.training_history = checkpoint_data.get('training_history', {
                "total_losses": [], "energy_losses": [], "text_losses": [],
                "learning_rates": [], "flow_statistics": [], "performance_metrics": []
            })
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–µ–π
            if 'model_state_dict' in checkpoint_data:
                self.flow_processor.load_state_dict(checkpoint_data['model_state_dict'])
            
            if 'optimizer_state_dict' in checkpoint_data:
                self.optimizer.load_state_dict(checkpoint_data['optimizer_state_dict'])
                
            if 'scheduler_state_dict' in checkpoint_data:
                self.scheduler.load_state_dict(checkpoint_data['scheduler_state_dict'])
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º text_bridge —Å–æ—Å—Ç–æ—è–Ω–∏—è
            if self.config.text_bridge_enabled:
                if 'text_encoder_state_dict' in checkpoint_data:
                    if hasattr(self.text_encoder, 'load_state_dict'):
                        self.text_encoder.load_state_dict(checkpoint_data['text_encoder_state_dict'])
                    elif hasattr(self.text_encoder, 'encoder'):
                        self.text_encoder.encoder.load_state_dict(checkpoint_data['text_encoder_state_dict'])
                
                if 'text_decoder_state_dict' in checkpoint_data:
                    if hasattr(self.text_decoder, 'load_state_dict'):
                        self.text_decoder.load_state_dict(checkpoint_data['text_decoder_state_dict'])
                    elif hasattr(self.text_decoder, 'decoder'):
                        self.text_decoder.decoder.load_state_dict(checkpoint_data['text_decoder_state_dict'])
            
            logger.info(f"‚úÖ Smart checkpoint loaded successfully:")
            logger.info(f"   üìÅ From: {loaded_path.name if loaded_path else 'Unknown'}")
            logger.info(f"   üìä Epoch: {self.epoch}, Step: {self.global_step}")
            logger.info(f"   üéØ Best loss: {self.best_loss:.4f}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load checkpoint state: {e}")
            return False
    
    def load_checkpoint(self, filepath: Union[str, Path], strict_validation: bool = False) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –º–æ–¥–µ–ª–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        
        Args:
            filepath: –ü—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É
            strict_validation: –ï—Å–ª–∏ True, –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–∫—É
        """
        filepath = Path(filepath)
        if not filepath.exists():
            raise FileNotFoundError(f"Checkpoint not found: {filepath}")

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º checkpoint_loader –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
        checkpoint = self.checkpoint_loader.load_checkpoint(
            filepath,
            current_config=self.config,
            strict_validation=strict_validation
        )
        
        if checkpoint is None:
            raise RuntimeError(f"Failed to load checkpoint from {filepath}")

        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.epoch = checkpoint['epoch']
        self.global_step = checkpoint['global_step']
        self.best_loss = checkpoint['best_loss']
        self.training_history = checkpoint['training_history']
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤
        self.flow_processor.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        if self.config.text_bridge_enabled:
            if 'text_encoder_state_dict' in checkpoint and hasattr(self.text_encoder, 'load_state_dict'):
                self.text_encoder.load_state_dict(checkpoint['text_encoder_state_dict'])
            if 'text_decoder_state_dict' in checkpoint:
                self.text_decoder.load_state_dict(checkpoint['text_decoder_state_dict'])
        
        logger.info(f"üìÅ Checkpoint loaded: {filepath}, epoch={self.epoch}, step={self.global_step}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ –∏ –µ—ë –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö"""
        info = {
            'config': self.config.to_dict(),
            'epoch': self.epoch,
            'global_step': self.global_step,
            'best_loss': self.best_loss,
            'device': str(self.device)
        }
        
        # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        flow_params = sum(p.numel() for p in self.flow_processor.parameters() if p.requires_grad)
        info['flow_processor_parameters'] = flow_params
        
        if self.config.text_bridge_enabled:
            # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ text_bridge –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            if hasattr(self.text_encoder, 'model'):  # Cached version
                encoder_params = sum(p.numel() for p in self.text_encoder.model.parameters() if p.requires_grad)
            else:  # Direct model
                encoder_params = sum(p.numel() for p in self.text_encoder.parameters() if p.requires_grad)
            info['text_encoder_parameters'] = encoder_params
            
            if hasattr(self.text_decoder, 'model'):  # Cached version
                decoder_params = sum(p.numel() for p in self.text_decoder.model.parameters() if p.requires_grad)
            else:  # Direct model
                decoder_params = sum(p.numel() for p in self.text_decoder.parameters() if p.requires_grad)
            info['text_decoder_parameters'] = decoder_params
        
        return info


def create_energy_trainer(config: Optional[EnergyConfig] = None) -> EnergyTrainer:
    """–§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è EnergyTrainer"""
    return EnergyTrainer(config)