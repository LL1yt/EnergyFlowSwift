"""
EnergyTrainer - –æ—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è energy_flow –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
=========================================================================

–ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π text_bridge –º–æ–¥—É–ª—è:
- –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ energy flow + text decoders
- GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å CUDA –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é  
- –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–µ—Ç—Ä–∏–∫–∏
- –ß–µ–∫–ø–æ–∏–Ω—Ç–∏–Ω–≥ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏:
input_text ‚Üí TextToCubeEncoder ‚Üí surface_embedding ‚Üí FlowProcessor ‚Üí 
output_surface_embedding ‚Üí CubeToTextDecoder ‚Üí predicted_text

Loss = energy_loss + text_loss_weight √ó text_loss
"""

# import torch
import torch as torch_module  # –ê–ª–∏–∞—Å –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è scoping –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
from typing import Dict, List, Tuple, Optional, Any, Union
from pathlib import Path
import time
from datetime import datetime
import json
import os
import psutil

from ..utils.logging import (
    get_logger,
    DEBUG_TRAINING,
    DEBUG_ENERGY,
    DEBUG_MEMORY,
    DEBUG_CONVERGENCE,
    DEBUG_PERFORMANCE,
    DEBUG_PROFILING,
    summarize_step,
    gated_log,
    debug_every,
    info_every,
    gated_scalar,
    gated_metrics,
    item_str,
    format_first_n,
)
from ..utils.device_manager import get_device_manager
from ..utils.checkpoint_utils import generate_checkpoint_path, create_checkpoint_summary
from ..config import EnergyConfig, get_energy_config, create_debug_config, set_energy_config
from ..core import FlowProcessor, EnergyLattice, SimpleNeuron, EnergyCarrier
from ..text_bridge import (
    TextToCubeEncoder, CubeToTextDecoder, TextCache,
    create_text_to_cube_encoder, create_cube_to_text_decoder, create_text_cache,
    CachedTextToCubeEncoder, CachedCubeToTextDecoder
)
from ..utils.memory_cleanup import collect_garbage  # CPU memory cleanup
from .checkpoint_loader import SimpleCheckpointLoader

logger = get_logger(__name__)


class EnergyTrainer:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è energy_flow –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    
    –†–µ–∞–ª–∏–∑—É–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π text_bridge:
    - –≠–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ—Ç–æ–∫–∏ —á–µ—Ä–µ–∑ 3D —Ä–µ—à–µ—Ç–∫—É
    - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ text decoders
    - –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π loss (energy + text)
    - GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    
    def __init__(self, config: Optional[EnergyConfig] = None):
        """
        Args:
            config: EnergyConfig —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è
        """
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        if config is None:
            config = create_debug_config()
            set_energy_config(config)
        self.config = config
        
        # Device management  
        self.device_manager = get_device_manager() 
        self.device = self.device_manager.device
        
        logger.log(DEBUG_TRAINING, f"üöÄ EnergyTrainer initialization on {self.device}")
        logger.log(DEBUG_TRAINING, f"Config: {config.lattice_width}x{config.lattice_height}x{config.lattice_depth}, "
                                  f"text_bridge={config.text_bridge_enabled}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self._init_core_components()
        self._init_text_bridge()
        self._init_optimizer()
        self._init_mixed_precision()
        
        # –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–≤–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è (–≤—Ä–µ–º–µ–Ω–Ω—ã–µ): —Å–Ω–∏–∑–∏–º LR –∏ —É—Å–∏–ª–∏–º –∫–ª–∏–ø–ø–∏–Ω–≥
        try:
            original_lr = self.optimizer.param_groups[0]['lr']
            new_lr = max(original_lr * 0.25, 1e-6)
            for pg in self.optimizer.param_groups:
                pg['lr'] = new_lr
            # –£—Å–∏–ª–∏–º gradient clip, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
            if getattr(self.config, 'gradient_clip', 0.0) <= 0.0:
                self.config.gradient_clip = 0.1
            else:
                self.config.gradient_clip = min(self.config.gradient_clip, 0.1)
            logger.info(f"Stability tweaks: lr {original_lr:.2e} -> {new_lr:.2e}, gradient_clip={self.config.gradient_clip}")
        except Exception:
            pass
        
        # –í–∫–ª—é—á–∏–º –∞–Ω–æ–º–∞–ª–∏–∏ –Ω–∞ –ø–µ—Ä–≤—ã—Ö —à–∞–≥–∞—Ö (–ø–æ—Ç–æ–º –æ—Ç–∫–ª—é—á–∏–º)
        self._anomaly_steps_remaining = 2
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
        self.training_history = {
            "total_losses": [],
            "energy_losses": [],
            "text_losses": [],
            "learning_rates": [],
            "flow_statistics": [],
            "performance_metrics": []
        }
        
        # –°—á–µ—Ç—á–∏–∫–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.global_step = 0  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Å—á–µ—Ç—á–∏–∫ —à–∞–≥–æ–≤ —á–µ—Ä–µ–∑ –≤—Å–µ —ç–ø–æ—Ö–∏ (–¥–ª—è curriculum learning)
        self.epoch = 0
        self.best_loss = float('inf')
        
        # Gradient accumulation —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.current_accumulation_step = 0
        self.accumulation_loss = 0.0
        self.accumulation_metrics = {}
        
        # Smart memory management –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è empty_cache() overhead
        self.step_counter = 0
        self.memory_cleanup_interval = 10  # Cleanup —Ç–æ–ª—å–∫–æ –∫–∞–∂–¥—ã–µ 10 —à–∞–≥–æ–≤ –≤–º–µ—Å—Ç–æ –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞
        self.memory_threshold_gb = 16.0    # Cleanup –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ 16GB –¥–ª—è RTX 5090
        
        # Checkpoint —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        self.checkpoint_loader = SimpleCheckpointLoader()
        self.checkpoint_base_dir = Path("checkpoints/energy_flow")
        
        logger.log(DEBUG_TRAINING, "‚úÖ EnergyTrainer successfully initialized")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∏–∫–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ GPU –ø–∞–º—è—Ç–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏
        if torch_module.cuda.is_available():
            try:
                torch_module.cuda.reset_peak_memory_stats()
            except Exception:
                pass
    
    def _init_core_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ energy_flow"""
        logger.log(DEBUG_TRAINING, "Initializing core energy_flow components...")
        
        # FlowProcessor –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ core –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.flow_processor = FlowProcessor(self.config).to(self.device)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –ø—Ä—è–º–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
        self.energy_lattice = self.flow_processor.lattice
        self.simple_neuron = self.flow_processor.neuron
        self.energy_carrier = self.flow_processor.carrier
        
        logger.log(DEBUG_TRAINING, f"Core components initialized: "
                                  f"FlowProcessor, EnergyLattice({self.config.lattice_width}x{self.config.lattice_height}x{self.config.lattice_depth})")
    
    def _init_text_bridge(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è text_bridge –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        if not self.config.text_bridge_enabled:
            logger.log(DEBUG_TRAINING, "Text bridge disabled, skipping initialization")
            self.text_encoder = None
            self.text_decoder = None
            self.text_cache = None
            return
            
        logger.log(DEBUG_TRAINING, "Initializing text_bridge components...")
        
        # Text cache (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
        if self.config.text_cache_enabled:
            self.text_cache = create_text_cache(
                max_size=self.config.text_cache_size,
                cache_file=self.config.text_cache_file
            )
            logger.log(DEBUG_TRAINING, f"TextCache initialized with size {self.config.text_cache_size}")
        else:
            self.text_cache = None
        
        # Text encoder (text ‚Üí surface embeddings)
        base_encoder = create_text_to_cube_encoder(self.config).to(self.device)
        if self.text_cache:
            self.text_encoder = CachedTextToCubeEncoder(base_encoder, self.text_cache)
        else:
            self.text_encoder = base_encoder
            
        # Text decoder (surface embeddings ‚Üí text)
        base_decoder = create_cube_to_text_decoder(self.config).to(self.device)
        if self.text_cache:
            self.text_decoder = CachedCubeToTextDecoder(base_decoder, self.text_cache)
        else:
            self.text_decoder = base_decoder
        
        # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        encoder_params = sum(p.numel() for p in base_encoder.parameters() if p.requires_grad)
        decoder_params = sum(p.numel() for p in base_decoder.parameters() if p.requires_grad)
        
        logger.log(DEBUG_TRAINING, f"Text bridge initialized: encoder({encoder_params:,} params), "
                                  f"decoder({decoder_params:,} params)")
    
    def _init_optimizer(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞"""
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        params = list(self.flow_processor.parameters())
        
        if self.config.text_bridge_enabled:
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã text_bridge –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            # –î–ª—è cached –≤–µ—Ä—Å–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
            if hasattr(self.text_encoder, 'encoder'):  # CachedTextToCubeEncoder
                params.extend(self.text_encoder.encoder.parameters())
            elif hasattr(self.text_encoder, 'parameters'):  # Direct TextToCubeEncoder
                params.extend(self.text_encoder.parameters())
                
            if hasattr(self.text_decoder, 'decoder'):  # CachedCubeToTextDecoder
                params.extend(self.text_decoder.decoder.parameters())
            elif hasattr(self.text_decoder, 'parameters'):  # Direct CubeToTextDecoder
                params.extend(self.text_decoder.parameters())
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
        self.optimizer = optim.AdamW(
            params,
            lr=self.config.learning_rate,
            weight_decay=self.config.weight_decay
        )
        
        # –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ learning rate
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=0.5,
            patience=10
        )
        
        total_params = sum(p.numel() for p in params if p.requires_grad)
        logger.log(DEBUG_TRAINING, f"Optimizer initialized: AdamW, lr={self.config.learning_rate}, "
                                  f"total_params={total_params:,}")
    
    def _init_mixed_precision(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Mixed Precision Training"""
        if self.config.use_mixed_precision and torch_module.cuda.is_available():
            # GradScaler –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ scaling –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
            if self.config.use_gradient_scaling:
                self.scaler = torch_module.cuda.amp.GradScaler(
                    init_scale=self.config.gradient_scale_init,
                    enabled=True
                )
                logger.log(DEBUG_TRAINING, f"üîß Mixed Precision: GradScaler initialized with scale={self.config.gradient_scale_init}")
            else:
                self.scaler = None
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ autocast –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            self.autocast_kwargs = {
                'device_type': 'cuda',
                'dtype': self.config.mixed_precision_dtype,
                'enabled': True
            }
            
            logger.log(DEBUG_TRAINING, f"üöÄ Mixed Precision Training enabled: {self.config.mixed_precision_dtype}")
            logger.log(DEBUG_TRAINING, f"   Expected benefits: 1.5x speedup, 50% memory saving")
        else:
            self.scaler = None
            self.autocast_kwargs = {'enabled': False}
            
            if not self.config.use_mixed_precision:
                logger.log(DEBUG_TRAINING, "Mixed Precision Training disabled by config")
            else:
                logger.log(DEBUG_TRAINING, "Mixed Precision Training disabled: CUDA not available")
    
    def _snapshot_memory(self, stage: str, extra: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """–°–Ω–∏–º–æ–∫ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞–º—è—Ç–∏ (GPU/CPU) –∏ –≤–∞–∂–Ω—ã—Ö —Ñ–ª–∞–≥–æ–≤.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –º–µ—Ç—Ä–∏–∫ –∏ –ª–æ–≥–∏—Ä—É–µ—Ç –Ω–∞ —É—Ä–æ–≤–Ω–µ DEBUG.
        """
        metrics: Dict[str, Any] = {
            'stage': stage,
            'global_step': self.global_step,
        }
        # CPU RSS
        try:
            proc = psutil.Process(os.getpid())
            rss_gb = proc.memory_info().rss / 1e9
            metrics['cpu_rss_gb'] = round(rss_gb, 3)
        except Exception:
            pass
        # GPU metrics
        if torch_module.cuda.is_available():
            if logger.isEnabledFor(DEBUG_MEMORY):
                try:
                    torch_module.cuda.synchronize()
                except Exception:
                    pass
            try:
                metrics.update({
                    'gpu_alloc_gb': round(torch_module.cuda.memory_allocated() / 1e9, 3),
                    'gpu_reserved_gb': round(torch_module.cuda.memory_reserved() / 1e9, 3),
                    'gpu_max_alloc_gb': round(torch_module.cuda.max_memory_allocated() / 1e9, 3),
                    'gpu_max_reserved_gb': round(getattr(torch_module.cuda, 'max_memory_reserved', lambda: 0.0)() / 1e9, 3) if hasattr(torch_module.cuda, 'max_memory_reserved') else None,
                })
            except Exception:
                pass
        # AMP / scaler info
        try:
            metrics['autocast_enabled'] = bool(self.autocast_kwargs.get('enabled', False))
        except Exception:
            pass
        try:
            if self.scaler is not None and hasattr(self.scaler, 'get_scale'):
                metrics['grad_scale'] = float(self.scaler.get_scale())
        except Exception:
            pass
        # Merge extras
        if extra:
            metrics.update(extra)
        # Log compact line
        if logger.isEnabledFor(10):
            msg = (
                f"üß† Mem[{stage}]: CPU {metrics.get('cpu_rss_gb','?')}GB; "
                f"GPU alloc {metrics.get('gpu_alloc_gb','?')}GB, res {metrics.get('gpu_reserved_gb','?')}GB, "
                f"max_alloc {metrics.get('gpu_max_alloc_gb','?')}GB"
            )
            logger.log(DEBUG_MEMORY, msg)
        return metrics
    
    def _compute_losses(self, input_texts: List[str], target_texts: List[str], 
                       teacher_input_embeddings: torch_module.Tensor, teacher_target_embeddings: torch_module.Tensor) -> Dict[str, Any]:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç losses –±–µ–∑ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è (–¥–ª—è validation)
        
        Args:
            input_texts: –°–ø–∏—Å–æ–∫ –≤—Ö–æ–¥–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–¥–ª—è text_bridge)
            target_texts: –°–ø–∏—Å–æ–∫ —Ü–µ–ª–µ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–¥–ª—è text_bridge)
            teacher_input_embeddings: –í—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è [batch, 768]
            teacher_target_embeddings: –¶–µ–ª–µ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è [batch, 768]
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ (–±–µ–∑ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è)
        """
        batch_size = len(input_texts)
        step_start_time = time.time()
        
        try:
            # –í–∫–ª—é—á–∞–µ–º anomaly detection —Ç–∞–∫–∂–µ –Ω–∞ forward –¥–ª—è –ø–µ—Ä–≤—ã—Ö —à–∞–≥–æ–≤
            try:
                if self._anomaly_steps_remaining and self._anomaly_steps_remaining > 0:
                    torch_module.autograd.set_detect_anomaly(True)
            except Exception:
                pass
            # Ensure tensors are on the correct device
            try:
                teacher_input_embeddings = teacher_input_embeddings.to(self.device, non_blocking=True)
                teacher_target_embeddings = teacher_target_embeddings.to(self.device, non_blocking=True)
            except Exception:
                teacher_input_embeddings = teacher_input_embeddings.to(self.device)
                teacher_target_embeddings = teacher_target_embeddings.to(self.device)

            # 1. –û—Å–Ω–æ–≤–Ω–æ–π forward pass –∫—É–±–∞ —Å teacher embeddings
            flow_start_time = time.time()
            cube_output_surface = self.flow_processor.forward(teacher_input_embeddings)
            flow_time = time.time() - flow_start_time
            
            # 2. –ú–∞–ø–ø–∏–º teacher target –≤ surface –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            target_surface_output = self.flow_processor.mapper.input_mapper.forward(teacher_target_embeddings)
            target_surface_input = self.flow_processor.mapper.input_mapper.forward(teacher_input_embeddings)
            
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ
            if target_surface_output.dim() == 3:
                target_surface_output = target_surface_output.view(batch_size, -1)
            if target_surface_input.dim() == 3:
                target_surface_input = target_surface_input.view(batch_size, -1)
            
            # 3. Energy loss - —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–∞ —É—Ä–æ–≤–Ω–µ surface
            energy_loss = nn.functional.mse_loss(cube_output_surface, target_surface_output)
            
            # 4. Text Bridge –±–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è validation
            text_loss = torch_module.tensor(0.0, device=self.device)
            if self.config.text_bridge_enabled and self.config.text_loss_weight > 0:
                try:
                    encoder_outputs = self.text_encoder.encode_text(input_texts)
                    # –í validation —Ä–µ–∂–∏–º–µ –Ω–µ —Ç—Ä–µ–±—É–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
                    target_surface_input_grad = target_surface_input.clone().detach()
                    encoder_loss = nn.functional.mse_loss(encoder_outputs, target_surface_input_grad)
                    text_loss = encoder_loss
                except Exception as e:
                    logger.warning(f"‚ùå Text bridge computation failed: {e}")
                    text_loss = torch_module.tensor(0.1, device=self.device)
            
            # 5. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π loss
            total_loss = energy_loss + self.config.text_loss_weight * text_loss
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —à–∞–≥–∞
            step_time = time.time() - step_start_time
            flow_stats = {'flows_reached_output': batch_size}
            
            return {
                'total_loss': total_loss.item() if hasattr(total_loss, 'item') else float(total_loss),
                'energy_loss': energy_loss.item() if hasattr(energy_loss, 'item') else float(energy_loss),
                'text_loss': text_loss.item() if hasattr(text_loss, 'item') else float(text_loss),
                'flow_time': flow_time,
                'step_time': step_time,
                'flow_stats': flow_stats,
                'gradients_computed': False,
                'total_params_with_grads': 0,
            }
            
        except Exception as e:
            logger.error(f"‚ùå Forward pass failed: {e}")
            return {
                'total_loss': float('inf'),
                'energy_loss': float('inf'),
                'text_loss': float('inf'),
                'flow_time': 0,
                'step_time': 0,
                'flow_stats': {'error': str(e)},
                'gradients_computed': False,
                'total_params_with_grads': 0,
            }
    
    def train_step(self, input_texts: List[str], target_texts: List[str],
                   teacher_input_embeddings: torch_module.Tensor, teacher_target_embeddings: torch_module.Tensor,
                   global_training_step: Optional[int] = None) -> Dict[str, float]:
        """
        –û–¥–∏–Ω —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        
        Args:
            input_texts: –°–ø–∏—Å–æ–∫ –≤—Ö–æ–¥–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–¥–ª—è text_bridge)
            target_texts: –°–ø–∏—Å–æ–∫ —Ü–µ–ª–µ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–¥–ª—è text_bridge)
            teacher_input_embeddings: –í—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è [batch, 768]
            teacher_target_embeddings: –¶–µ–ª–µ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è [batch, 768]
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ —à–∞–≥–∞
        """
        # Gradient accumulation: –æ—á–∏—â–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã —Ç–æ–ª—å–∫–æ –≤ –Ω–∞—á–∞–ª–µ accumulation
        if torch_module.cuda.is_available() and logger.isEnabledFor(DEBUG_MEMORY):
            try:
                torch_module.cuda.reset_peak_memory_stats()
            except Exception:
                pass
        self._snapshot_memory('begin', {'acc_step': self.current_accumulation_step + 1})
        if self.current_accumulation_step == 0:
            # set_to_none=True –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç –ø–∞–º—è—Ç—å –ø–æ–¥ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –±—ã—Å—Ç—Ä–µ–µ, —Å–Ω–∏–∂–∞—è –ø–∏–∫–æ–≤–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
            self.optimizer.zero_grad(set_to_none=True)
            self.accumulation_loss = 0.0
            self.accumulation_metrics = {}
        
        batch_size = len(input_texts)
        step_start_time = time.time()
        
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        logger.log(DEBUG_TRAINING, f"üîÑ Starting train_step: batch_size={batch_size}, "
                                  f"accumulation_step={self.current_accumulation_step+1}/{self.config.gradient_accumulation_steps}")
        logger.log(DEBUG_TRAINING, f"üìä Input texts: {len(input_texts)} samples")
        logger.log(DEBUG_TRAINING, f"üìä Teacher embeddings: {teacher_input_embeddings.shape} -> {teacher_target_embeddings.shape}")

        if not torch_module.isfinite(teacher_input_embeddings).all() or not torch_module.isfinite(teacher_target_embeddings).all():
            logger.warning("Non-finite values detected in teacher embeddings; sanitizing")
            teacher_input_embeddings = torch_module.nan_to_num(teacher_input_embeddings)
            teacher_target_embeddings = torch_module.nan_to_num(teacher_target_embeddings)

        try:
            # Ensure tensors are on the correct device
            try:
                teacher_input_embeddings = teacher_input_embeddings.to(self.device, non_blocking=True)
                teacher_target_embeddings = teacher_target_embeddings.to(self.device, non_blocking=True)
            except Exception:
                teacher_input_embeddings = teacher_input_embeddings.to(self.device)
                teacher_target_embeddings = teacher_target_embeddings.to(self.device)

            # 1. –û—Å–Ω–æ–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∫—É–±–∞ —Å teacher embeddings –° MIXED PRECISION
            flow_start_time = time.time()
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            logger.log(DEBUG_TRAINING, f"üìà Teacher input requires_grad: {teacher_input_embeddings.requires_grad}")
            logger.log(DEBUG_TRAINING, f"üìà Teacher target requires_grad: {teacher_target_embeddings.requires_grad}")
            
            # –ü–†–ò–ú–ï–ù–Ø–ï–ú AUTOCAST –î–õ–Ø MIXED PRECISION (1.5x speedup, 50% memory)
            with torch_module.autocast(**self.autocast_kwargs):
                # –ü–µ—Ä–µ–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —à–∞–≥ –¥–ª—è curriculum learning –≤ FlowProcessor
                cube_output_surface = self.flow_processor.forward(
                    teacher_input_embeddings, 
                    global_training_step=global_training_step or self.global_step
                )
            flow_time = time.time() - flow_start_time
            self._snapshot_memory('after_forward', {'flow_time_ms': flow_time * 1000.0})
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: —Ä–µ–¥–∫–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º—ã –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –≤—ã—Ö–æ–¥–∞ –∫—É–±–∞
            debug_every(
                logger,
                step=self.global_step,
                key="cube/output",
                msg_factory=lambda: (
                    f"üìä Cube surface: shape={tuple(cube_output_surface.shape)}, "
                    f"mean={item_str(cube_output_surface.mean())}, std={item_str(cube_output_surface.std())}"
                ),
                level=DEBUG_TRAINING,
                first_n_steps=3,
            )
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ—Ç–æ–∫–æ–≤
            flow_stats = {
                'active_flows': 0,
                'spawned_flows': 0,
                'flows_reached_output': batch_size
            }
            
            # 2. –ú–∞–ø–ø–∏–º teacher target –≤ surface –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ë–ï–ó –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∞
            # –≠—Ç–∏ —Ç–µ–Ω–∑–æ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∫–∞–∫ —Ü–µ–ª–∏, –ø–æ—ç—Ç–æ–º—É –≤—ã—á–∏—Å–ª—è–µ–º –∏—Ö –ø–æ–¥ no_grad(),
            # —á—Ç–æ–±—ã –Ω–µ —É–¥–µ—Ä–∂–∏–≤–∞—Ç—å –≥—Ä–∞—Ñ –∏ —ç–∫–æ–Ω–æ–º–∏—Ç—å –ø–∞–º—è—Ç—å –º–µ–∂–¥—É –º–∏–∫—Ä–æ-—à–∞–≥–∞–º–∏
            with torch_module.no_grad():
                with torch_module.autocast(**self.autocast_kwargs):
                    target_surface_output = self.flow_processor.mapper.input_mapper.forward(teacher_target_embeddings)
                    target_surface_input = self.flow_processor.mapper.input_mapper.forward(teacher_input_embeddings)
            
            # –ë—ã—Å—Ç—Ä—ã–µ NaN-–≥–≤–∞—Ä–¥—ã –Ω–∞ surface —Ç–µ–Ω–∑–æ—Ä–∞—Ö
            if not torch_module.isfinite(cube_output_surface).all() or not torch_module.isfinite(target_surface_output).all():
                logger.warning("‚ö†Ô∏è Non-finite tensors in cube/target surface; skipping micro-step safely")
                # –ó–∞–ø–æ–ª–Ω–∏–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏, —á—Ç–æ–±—ã –º–µ—Ç—Ä–∏–∫–∏ –Ω–µ –ª–æ–º–∞–ª–∏—Å—å
                safe_metrics = {
                    'total_loss': float('inf'),
                    'energy_loss': float('inf'),
                    'text_loss': 0.0,
                    'learning_rate': self.optimizer.param_groups[0]['lr'],
                    'step_time': time.time() - step_start_time,
                    'flow_time': flow_time,
                    'active_flows': 0,
                    'spawned_flows': 0,
                    'flows_reached_output': 0,
                    'batch_size': batch_size,
                    'accumulation_complete': False,
                    'accumulation_step': self.current_accumulation_step
                }
                return safe_metrics
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: —Ä–µ–¥–∫–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º target surface
            debug_every(
                logger,
                step=self.global_step,
                key="cube/targets",
                msg_factory=lambda: (
                    f"üìä Target surfaces: output_shape={tuple(target_surface_output.shape)}, "
                    f"input_shape={tuple(target_surface_input.shape)}"
                ),
                level=DEBUG_TRAINING,
                first_n_steps=3,
            )
            
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ
            if target_surface_output.dim() == 3:
                target_surface_output = target_surface_output.view(batch_size, -1)
            if target_surface_input.dim() == 3:
                target_surface_input = target_surface_input.view(batch_size, -1)
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø–æ—Å–ª–µ reshape
            logger.log(DEBUG_TRAINING, f"üìà Target surface output requires_grad: {target_surface_output.requires_grad}")
            logger.log(DEBUG_TRAINING, f"üìà Target surface input requires_grad: {target_surface_input.requires_grad}")
            
            # 3. Energy loss - —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–∞ —É—Ä–æ–≤–Ω–µ surface –° MIXED PRECISION
            with torch_module.autocast(**self.autocast_kwargs):
                energy_loss = nn.functional.mse_loss(cube_output_surface, target_surface_output)
            self._snapshot_memory('after_energy_loss')
            
            # 4. Text Bridge –æ–±—É—á–µ–Ω–∏–µ - –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ë–ê–¢–ß–ï–í–ê–Ø –í–ï–†–°–ò–Ø
            text_loss = torch_module.tensor(0.0, device=self.device)
            if self.config.text_bridge_enabled and self.config.text_loss_weight > 0:
                text_bridge_start_time = time.time()
                try:
                    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 1: –ë–∞—Ç—á–µ–≤–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ ‚Üí surface
                    if logger.isEnabledFor(DEBUG_TRAINING):
                        logger.log(DEBUG_TRAINING, f"üìù Processing text bridge (batch={len(input_texts)})")
                    
                    encoder_outputs = self.text_encoder.encode_text(input_texts)
                    if logger.isEnabledFor(DEBUG_TRAINING):
                        logger.log(DEBUG_TRAINING, f"üìä Encoder outputs: {encoder_outputs.shape}")
                    
                    # Encoder loss: text ‚Üí surface mapping
                    target_surface_input_grad = target_surface_input.clone().detach().requires_grad_(True)
                    encoder_loss = nn.functional.mse_loss(encoder_outputs, target_surface_input_grad)
                    
                    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 2: –ò—Å–ø–æ–ª—å–∑—É–µ–º –£–ñ–ï –í–´–ß–ò–°–õ–ï–ù–ù–´–ô cube_output_surface!
                    # –í–º–µ—Å—Ç–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö forward passes –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞
                    decoder_loss = torch_module.tensor(0.0, device=self.device)
                    
                    try:
                        # –ë–∞—Ç—á–µ–≤–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ surface ‚Üí text (–≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω–µ –Ω—É–∂–Ω—ã)
                        with torch_module.no_grad():
                            predicted_texts = self.text_decoder.decode_surface(cube_output_surface)
                        
                        # –ë–∞—Ç—á–µ–≤–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ text similarity loss
                        if predicted_texts and len(predicted_texts) == len(target_texts):
                            similarities = []
                            for pred_text, target_text in zip(predicted_texts, target_texts):
                                if pred_text and target_text:
                                    pred_words = set(pred_text.lower().split())
                                    target_words = set(target_text.lower().split())
                                    intersection = len(pred_words & target_words)
                                    union = len(pred_words | target_words)
                                    similarity = intersection / max(union, 1)
                                    similarities.append(similarity)
                                else:
                                    similarities.append(0.0)
                            
                            # Vectorized similarity loss
                            similarities_tensor = torch_module.tensor(similarities, device=self.device)
                            decoder_loss = (1.0 - similarities_tensor).mean()
                            
                            if logger.isEnabledFor(DEBUG_TRAINING):
                                avg_similarity = similarities_tensor.mean().item()
                                logger.log(DEBUG_TRAINING, f"üìù Avg text similarity: {avg_similarity:.3f}")
                        else:
                            decoder_loss = torch_module.tensor(1.0, device=self.device)
                            if logger.isEnabledFor(DEBUG_TRAINING):
                                logger.log(DEBUG_TRAINING, f"‚ö†Ô∏è Text decoding mismatch: {len(predicted_texts)} vs {len(target_texts)}")
                    
                    except Exception as decode_error:
                        if logger.isEnabledFor(DEBUG_TRAINING):
                            logger.log(DEBUG_TRAINING, f"‚ùå Batch text decoding failed: {decode_error}")
                        decoder_loss = torch_module.tensor(1.0, device=self.device)
                    
                    # Combined text loss
                    text_loss = encoder_loss + 0.1 * decoder_loss
                    
                    # Performance logging
                    text_bridge_time = time.time() - text_bridge_start_time
                    self._snapshot_memory('after_text_bridge', {'text_bridge_time_ms': text_bridge_time * 1000.0})
                    if logger.isEnabledFor(DEBUG_TRAINING):
                        logger.log(DEBUG_TRAINING, 
                                 f"üìä Text bridge: encoder={encoder_loss:.4f}, decoder={decoder_loss:.4f}, "
                                 f"total={text_loss:.4f}, time={text_bridge_time*1000:.1f}ms")
                    
                except Exception as e:
                    logger.warning(f"‚ùå Text bridge computation failed: {e}")
                    text_loss = torch_module.tensor(0.1, device=self.device)
            
            # 5. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π loss (–±–µ–∑ forward_movement_reward - –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è —Å–∞–º–∞)
            total_loss = energy_loss + self.config.text_loss_weight * text_loss
            
            # –í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è forward_reward (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –º–µ—Ç—Ä–∏–∫)
            forward_reward = torch_module.tensor(0.0, device=self.device)
            
            # 6. Gradient accumulation: –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º loss 
            normalized_loss = total_loss / self.config.gradient_accumulation_steps

            # Guard against non-finite loss
            if not torch_module.isfinite(normalized_loss):
                logger.warning("‚ö†Ô∏è Non-finite loss detected (NaN/Inf). Skipping backward for this micro-step.")
                # Replace with zero to avoid breaking accumulation
                normalized_loss = torch_module.zeros((), device=self.device, dtype=total_loss.dtype)
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞—Ç–Ω—ã–º —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ–º (—Ä–µ–¥–∫–æ –∏ –ª–µ–Ω–∏–≤–æ)
            debug_every(
                logger,
                step=self.global_step,
                key="losses/detail",
                msg_factory=lambda: (
                    f"üìä Losses: energy={item_str(energy_loss)}, text={item_str(text_loss)}, "
                    f"total={item_str(total_loss)}, normalized={item_str(normalized_loss)}; "
                    f"requires_grad={bool(getattr(total_loss, 'requires_grad', False))}"
                ),
                level=DEBUG_TRAINING,
                first_n_steps=5,
            )
            
            # 8. –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —Å normalized loss –ò GRADIENT SCALING
            self._snapshot_memory('pre_backward')
            backward_start = time.time()

            # –í–∫–ª—é—á–∞–µ–º anomaly detection –Ω–∞ –ø–µ—Ä–≤—ã—Ö —à–∞–≥–∞—Ö –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ NaN
            anomaly_prev = None
            try:
                if self._anomaly_steps_remaining and self._anomaly_steps_remaining > 0:
                    anomaly_prev = torch_module.autograd.set_detect_anomaly(True)
            except Exception:
                anomaly_prev = None

            if self.scaler is not None:
                # –°–Ω–∏–∑–∏–º init scale –¥–ª—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –Ω–∞ –ø–µ—Ä–≤—ã—Ö —à–∞–≥–∞—Ö
                try:
                    if self._anomaly_steps_remaining and self._anomaly_steps_remaining > 0 and hasattr(self.scaler, 'update'):
                        # —É–º–µ–Ω—å—à–∞—Ç—å scale –≤—Ä—É—á–Ω—É—é –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è, –Ω–æ –º–æ–∂–Ω–æ —Å–Ω–∏–∂–∞—Ç—å —á–µ—Ä–µ–∑ _get_scale if needed
                        pass
                except Exception:
                    pass
                # Mixed precision backward pass —Å gradient scaling
                self.scaler.scale(normalized_loss).backward()
            else:
                # –û–±—ã—á–Ω—ã–π backward pass
                normalized_loss.backward()
            backward_time = (time.time() - backward_start) * 1000.0
            self._snapshot_memory('post_backward', {'backward_time_ms': backward_time, 'threads': getattr(torch_module, 'get_num_threads', lambda: None)()})
            # –û—Ç–∫–ª—é—á–∞–µ–º anomaly detection –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —à–∞–≥–æ–≤
            try:
                if self._anomaly_steps_remaining and self._anomaly_steps_remaining > 0:
                    self._anomaly_steps_remaining -= 1
                    if self._anomaly_steps_remaining == 0:
                        torch_module.autograd.set_detect_anomaly(False)
            except Exception:
                pass
            
            # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–æ–∑–≤—Ä–∞—Ç–∞
            self.accumulation_loss += total_loss.item()
            if not self.accumulation_metrics:
                self.accumulation_metrics = {
                    'energy_loss': energy_loss.item(),
                    'text_loss': text_loss.item(), 
                    'forward_reward': forward_reward.item(),
                    'batch_size': batch_size
                }
            else:
                self.accumulation_metrics['energy_loss'] += energy_loss.item()
                self.accumulation_metrics['text_loss'] += text_loss.item()
                self.accumulation_metrics['forward_reward'] += forward_reward.item()
                self.accumulation_metrics['batch_size'] += batch_size
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ ‚Äî –≤—ã—á–∏—Å–ª—è–µ–º —Ä–µ–¥–∫–æ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å overhead
            grad_diag_needed = (
                logger.isEnabledFor(DEBUG_TRAINING)
                and (
                    self.current_accumulation_step + 1 >= self.config.gradient_accumulation_steps
                    or (self.global_step % max(1, self.config.log_interval * 2) == 0)
                )
            )
            if grad_diag_needed:
                total_params = 0
                grad_norms = []
                bad_grads = False
                for param_group in self.optimizer.param_groups:
                    for param in param_group['params']:
                        if param.grad is not None:
                            total_params += 1
                            g = param.grad
                            if torch_module.isfinite(g).all():
                                try:
                                    grad_norms.append(g.norm().item())
                                except Exception:
                                    pass
                            else:
                                bad_grads = True
                if grad_norms:
                    avg_grad_norm = sum(grad_norms) / len(grad_norms)
                    max_grad_norm = max(grad_norms)
                    debug_every(
                        logger,
                        step=self.global_step,
                        key="grads/stats",
                        msg_factory=lambda: f"üìä Gradients: {total_params} params, avg_norm={avg_grad_norm:.6f}, max_norm={max_grad_norm:.6f}",
                        level=DEBUG_TRAINING,
                        first_n_steps=3,
                    )
                if bad_grads:
                    logger.warning("‚ö†Ô∏è Detected NaN/Inf in gradients. This micro-step will be skipped.")
                # Zero any non-finite grads to prevent optimizer corruption
                for param_group in self.optimizer.param_groups:
                    for param in param_group['params']:
                        if param.grad is not None and not torch_module.isfinite(param.grad).all():
                            param.grad = None
            
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ accumulation
            self.current_accumulation_step += 1
            
            # Gradient clipping –∏ optimizer step —Ç–æ–ª—å–∫–æ –Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º accumulation —à–∞–≥–µ
            is_accumulation_complete = self.current_accumulation_step >= self.config.gradient_accumulation_steps
            
            if is_accumulation_complete:
                if self.scaler is not None:
                    pre_step_scale = None
                    try:
                        pre_step_scale = float(self.scaler.get_scale())
                    except Exception:
                        pass
                    # Unscale –ø–µ—Ä–µ–¥ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏—è–º–∏
                    self.scaler.unscale_(self.optimizer)
                    # –û—á–∏—Å—Ç–∫–∞ –∏ –º—è–≥–∫–∏–π per-param –∫–ª–∏–ø–ø–∏–Ω–≥
                    self._clean_and_clip_grads(max_norm=getattr(self.config, 'gru_max_gradient_norm', 1.0))
                    # –ì–ª–æ–±–∞–ª—å–Ω—ã–π clipping
                    if self.config.gradient_clip > 0:
                        torch_module.nn.utils.clip_grad_norm_(
                            self.optimizer.param_groups[0]['params'],
                            self.config.gradient_clip
                        )
                    if getattr(self.config, 'enable_detailed_gradient_monitoring', False):
                        self._monitor_gradients(self.flow_processor)
                    # Optimizer step —Å scaling check
                    self.scaler.step(self.optimizer)
                    self.scaler.update()  # –û–±–Ω–æ–≤–ª—è–µ–º scale factor
                    self._snapshot_memory('post_optimizer_step', {'grad_scale_before': pre_step_scale, 'grad_scale_after': float(self.scaler.get_scale()) if hasattr(self.scaler, 'get_scale') else None})
                else:
                    # –û–ë–´–ß–ù–´–ô –ø—É—Ç—å: –æ—á–∏—Å—Ç–∫–∞ –∏ –∫–ª–∏–ø–ø–∏–Ω–≥
                    self._clean_and_clip_grads(max_norm=getattr(self.config, 'gru_max_gradient_norm', 1.0))
                    if self.config.gradient_clip > 0:
                        torch_module.nn.utils.clip_grad_norm_(
                            self.optimizer.param_groups[0]['params'],
                            self.config.gradient_clip
                        )
                    if getattr(self.config, 'enable_detailed_gradient_monitoring', False):
                        self._monitor_gradients(self.flow_processor)
                    self.optimizer.step()
                    self._snapshot_memory('post_optimizer_step')
                
                self.global_step += 1  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º global_step —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –ø–æ–ª–Ω–æ–≥–æ accumulation
                
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º accumulation —Å—á–µ—Ç—á–∏–∫
                self.current_accumulation_step = 0
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —à–∞–≥–∞
            step_time = time.time() - step_start_time
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è accumulation
            if is_accumulation_complete:
                # –§–∏–Ω–∞–ª—å–Ω—ã–µ accumulated –º–µ—Ç—Ä–∏–∫–∏
                step_metrics = {
                    'total_loss': self.accumulation_loss / self.config.gradient_accumulation_steps,
                    'energy_loss': self.accumulation_metrics['energy_loss'] / self.config.gradient_accumulation_steps,
                    'text_loss': self.accumulation_metrics['text_loss'] / self.config.gradient_accumulation_steps,
                    'forward_reward': self.accumulation_metrics['forward_reward'] / self.config.gradient_accumulation_steps,
                    'learning_rate': self.optimizer.param_groups[0]['lr'],
                    'step_time': step_time,
                    'flow_time': flow_time,
                    'active_flows': flow_stats.get('active_flows', 0),
                    'spawned_flows': flow_stats.get('spawned_flows', 0),
                    'flows_reached_output': flow_stats.get('flows_reached_output', 0),
                    'batch_size': self.accumulation_metrics['batch_size'],
                    'effective_batch_size': self.accumulation_metrics['batch_size'],  # –†–µ–∞–ª—å–Ω—ã–π accumulated —Ä–∞–∑–º–µ—Ä
                    'accumulation_complete': True
                }
            else:
                # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (accumulating)
                step_metrics = {
                    'total_loss': total_loss.item(),
                    'energy_loss': energy_loss.item(),
                    'text_loss': text_loss.item(),
                    'forward_reward': forward_reward.item(),
                    'learning_rate': self.optimizer.param_groups[0]['lr'],
                    'step_time': step_time,
                    'flow_time': flow_time,
                    'active_flows': flow_stats.get('active_flows', 0),
                    'spawned_flows': flow_stats.get('spawned_flows', 0),
                    'flows_reached_output': flow_stats.get('flows_reached_output', 0),
                    'batch_size': batch_size,
                    'effective_batch_size': batch_size,
                    'accumulation_complete': False,
                    'accumulation_step': self.current_accumulation_step
                }
            
            # –£–°–õ–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω—É–∂–Ω–æ–º —É—Ä–æ–≤–Ω–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
            if logger.isEnabledFor(DEBUG_PERFORMANCE):
                try:
                    # Throughput metrics
                    throughput_samples_per_sec = batch_size / step_time if step_time > 0 else 0
                    
                    # GPU utilization (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
                    gpu_utilization = 0
                    memory_used_gb = 0
                    memory_utilization_percent = 0
                    
                    if torch_module.cuda.is_available():
                        memory_used_gb = torch_module.cuda.memory_allocated() / 1e9
                        memory_reserved_gb = torch_module.cuda.memory_reserved() / 1e9
                        
                        # GPU utilization —Ç—Ä–µ–±—É–µ—Ç nvidia-ml-py3, –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ
                        try:
                            gpu_utilization = torch_module.cuda.utilization() if hasattr(torch_module.cuda, 'utilization') else 0
                        except:
                            gpu_utilization = 0
                        
                        # Memory utilization –∫–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏
                        if memory_reserved_gb > 0:
                            memory_utilization_percent = (memory_used_gb / memory_reserved_gb) * 100
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º performance –º–µ—Ç—Ä–∏–∫–∏
                    step_metrics.update({
                        'throughput_samples_per_sec': throughput_samples_per_sec,
                        'gpu_utilization_percent': gpu_utilization,
                        'memory_used_gb': memory_used_gb,
                        'memory_utilization_percent': memory_utilization_percent,
                    })
                    
                    # Text bridge timing (–µ—Å–ª–∏ –±—ã–ª –∞–∫—Ç–∏–≤–µ–Ω)
                    if 'text_bridge_time' in locals():
                        step_metrics['text_bridge_time_ms'] = text_bridge_time * 1000
                        step_metrics['energy_computation_time_ms'] = flow_time * 1000
                    
                    logger.log(DEBUG_PERFORMANCE, 
                             f"‚ö° Performance: {throughput_samples_per_sec:.1f} samples/s, "
                             f"GPU: {gpu_utilization:.0f}%, Memory: {memory_used_gb:.1f}GB ({memory_utilization_percent:.0f}%)")
                
                except Exception as perf_error:
                    # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫ –≤ –º–µ—Ç—Ä–∏–∫–∞—Ö
                    if logger.isEnabledFor(DEBUG_TRAINING):
                        logger.log(DEBUG_TRAINING, f"Performance metrics error: {perf_error}")
            
            # –î–ï–¢–ê–õ–¨–ù–û–ï –ü–†–û–§–ò–õ–ò–†–û–í–ê–ù–ò–ï (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ DEBUG_PROFILING)
            if logger.isEnabledFor(DEBUG_PROFILING):
                try:
                    # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ç–∞–π–º–∏–Ω–≥–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
                    energy_percentage = (flow_time / step_time * 100) if step_time > 0 else 0
                    text_bridge_percentage = 0
                    
                    if 'text_bridge_time' in locals():
                        text_bridge_percentage = (text_bridge_time / step_time * 100) if step_time > 0 else 0
                    
                    logger.log(DEBUG_PROFILING,
                             f"üî¨ Profiling: Energy {energy_percentage:.1f}%, "
                             f"TextBridge {text_bridge_percentage:.1f}%, "
                             f"Other {100 - energy_percentage - text_bridge_percentage:.1f}%")
                
                except Exception as prof_error:
                    pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ accumulation –∏–ª–∏ –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —à–∞–≥–æ–≤ –≤ debug —Ä–µ–∂–∏–º–µ
            if is_accumulation_complete:
                # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π —Å–≤–æ–¥ –ø–æ —à–∞–≥—É —Å –≥–µ–π—Ç–æ–º —á–∞—Å—Ç–æ—Ç—ã
                avg_loss = self.accumulation_loss / self.config.gradient_accumulation_steps
                avg_energy = self.accumulation_metrics['energy_loss'] / self.config.gradient_accumulation_steps
                avg_text = self.accumulation_metrics['text_loss'] / self.config.gradient_accumulation_steps
                avg_forward_reward = self.accumulation_metrics['forward_reward'] / self.config.gradient_accumulation_steps
                gated_log(
                    logger,
                    DEBUG_TRAINING,
                    step=self.global_step,
                    key='train_step_summary',
                    msg_or_factory=lambda: summarize_step({
                        'loss': avg_loss,
                        'energy': avg_energy,
                        'text': avg_text,
                        'fwd': avg_forward_reward,
                        'lr': self.optimizer.param_groups[0]['lr'],
                    }, step=self.global_step, prefix='TRAIN'),
                    first_n_steps=5,
                    every=self.config.log_interval,
                )
            elif logger.isEnabledFor(DEBUG_TRAINING):
                gated_log(
                    logger,
                    DEBUG_TRAINING,
                    step=self.current_accumulation_step,
                    key='train_accumulating',
                    msg_or_factory=lambda: (
                        f"üîÑ Accumulating {self.current_accumulation_step}/{self.config.gradient_accumulation_steps}: "
                        f"total_loss={item_str(total_loss)}, forward_reward={item_str(forward_reward)}"
                    ),
                    first_n_steps=2,
                    every=0,
                )
            
            # SMART MEMORY MANAGEMENT: Conditional cleanup –≤–º–µ—Å—Ç–æ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ empty_cache()
            # –£—Å—Ç—Ä–∞–Ω—è–µ—Ç 10-20% performance penalty –æ—Ç forced memory reallocation
            self.step_counter += 1

            # Periodic CPU garbage collection to cap host RAM growth
            try:
                if (self.step_counter % 5) == 0:
                    collect_garbage()
            except Exception:
                pass

            # Proactively drop large temporaries to let GC reclaim GPU memory sooner
            try:
                for _tmp in [
                    'cube_output_surface', 'target_surface_output', 'target_surface_input',
                    'encoder_outputs', 'similarities_tensor'
                ]:
                    if _tmp in locals():
                        obj = locals()[_tmp]
                        if isinstance(obj, torch_module.Tensor):
                            del obj
                del _tmp
            except Exception:
                pass

            if torch_module.cuda.is_available():
                if logger.isEnabledFor(DEBUG_MEMORY):
                    # Synchronize only when profiling memory usage
                    try:
                        torch_module.cuda.synchronize()
                    except Exception:
                        pass

                current_alloc_gb = torch_module.cuda.memory_allocated() / 1e9
                current_reserved_gb = torch_module.cuda.memory_reserved() / 1e9
                current_gb = max(current_alloc_gb, current_reserved_gb)
                
                # Cleanup —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ (–∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤ –ò–õ–ò –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ threshold –ø–æ alloc –ò–õ–ò reserved)
                should_cleanup = (
                    self.step_counter % self.memory_cleanup_interval == 0 or  # –ö–∞–∂–¥—ã–µ 10 —à–∞–≥–æ–≤
                    current_alloc_gb > self.memory_threshold_gb or
                    current_reserved_gb > max(self.memory_threshold_gb, current_alloc_gb * 1.5)
                )
                
                if should_cleanup:
                    # –°–Ω–∏–º–µ–º –ø–∏–∫–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π
                    self._snapshot_memory('pre_cleanup', {'current_gb': current_gb})
                    # Use best-effort cleanup sequence (GPU + CPU)
                    try:
                        torch_module.cuda.empty_cache()
                        if hasattr(torch_module.cuda, 'ipc_collect'):
                            torch_module.cuda.ipc_collect()
                    except Exception:
                        pass
                    # Periodic CPU GC to reduce host RAM pressure
                    try:
                        collect_garbage()
                    except Exception:
                        pass
                    memory_after_alloc = torch_module.cuda.memory_allocated() / 1e9
                    memory_after_reserved = torch_module.cuda.memory_reserved() / 1e9
                    
                    if logger.isEnabledFor(DEBUG_PERFORMANCE):
                        logger.log(
                            DEBUG_PERFORMANCE,
                            f"üßπ Smart cleanup: alloc {current_alloc_gb:.1f}‚Üí{memory_after_alloc:.1f}GB, "
                            f"reserved {current_reserved_gb:.1f}‚Üí{memory_after_reserved:.1f}GB "
                            f"(step {self.step_counter}, interval={self.memory_cleanup_interval})"
                        )
                    # –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–∏–∫ –∏ –ª–æ–≥–∏—Ä—É–µ–º
                    try:
                        torch_module.cuda.reset_peak_memory_stats()
                    except Exception:
                        pass
                    self._snapshot_memory('post_cleanup')
                elif logger.isEnabledFor(DEBUG_PERFORMANCE):
                    logger.log(
                        DEBUG_PERFORMANCE,
                        f"‚ö° Skipped cleanup: alloc {current_alloc_gb:.1f}GB, reserved {current_reserved_gb:.1f}GB < {self.memory_threshold_gb:.1f}GB threshold"
                    )
            
            # Early release of large Python references to help GC
            try:
                del input_texts
                del target_texts
            except Exception:
                pass
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–Ω–∏–º–æ–∫ –ø–∞–º—è—Ç–∏ –¥–ª—è —à–∞–≥–∞
            end_metrics = self._snapshot_memory('end', {'accumulation_complete': bool(is_accumulation_complete)})
            # –ï—Å–ª–∏ –∑–∞–º–µ—Ç–µ–Ω —Å–∫–∞—á–æ–∫ CPU RSS –∑–∞ —à–∞–≥, –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
            try:
                if 'cpu_rss_gb' in end_metrics:
                    # –°—Ä–∞–≤–Ω–∏—Ç—å —Å begin –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –Ω–∞–ø—Ä—è–º—É—é, –Ω–æ backward_time_ms –ø–æ–¥—Å–∫–∞–∂–µ—Ç
                    if end_metrics.get('backward_time_ms') and end_metrics['backward_time_ms'] > 2000:
                        logger.log(DEBUG_PERFORMANCE, f"‚è≥ Backward took {end_metrics['backward_time_ms']:.0f}ms; CPU_RSS={end_metrics['cpu_rss_gb']}GB")
            except Exception:
                pass
            return step_metrics
            
        except Exception as e:
            logger.error(f"‚ùå Training step failed: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º dummy –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
            return {
                'total_loss': float('inf'),
                'energy_loss': float('inf'),
                'text_loss': 0.0,
                'learning_rate': self.optimizer.param_groups[0]['lr'],
                'step_time': time.time() - step_start_time,
                'flow_time': 0.0,
                'active_flows': 0,
                'spawned_flows': 0,
                'flows_reached_output': 0,
                'batch_size': batch_size,
                'error': str(e)
            }

    def _clean_and_clip_grads(self, max_norm: float = 1.0) -> None:
        """–û–±–Ω—É–ª—è–µ—Ç NaN/Inf –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –∏ –º—è–≥–∫–æ –∫–ª–∏–ø–ø–∏—Ç per-param –¥–ª—è —á–∏—Å–ª–µ–Ω–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏."""
        try:
            for group in self.optimizer.param_groups:
                for p in group['params']:
                    if p.grad is None:
                        continue
                    g = p.grad
                    # Sanitize non-finite grads
                    if not torch_module.isfinite(g).all():
                        logger.warning("üßØ Non-finite gradient detected; zeroing it")
                        p.grad = torch_module.zeros_like(g)
                        continue
                    # Per-param gentle clip
                    if max_norm and max_norm > 0:
                        gn = g.norm()
                        if gn > max_norm:
                            scale = (max_norm / (gn + 1e-6)).to(g.dtype)
                            p.grad.mul_(scale)
        except Exception:
            pass

    def _monitor_gradients(self, model: torch_module.nn.Module) -> None:
        """–ü–æ–¥—Ä–æ–±–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º (–≤–∫–ª—é—á–∞–µ–º –ø–æ —Ñ–ª–∞–≥—É)."""
        try:
            total = 0; nan_cnt = 0; inf_cnt = 0; large_cnt = 0
            for name, p in model.named_parameters():
                if p.grad is None:
                    continue
                total += 1
                g = p.grad
                if torch_module.isnan(g).any():
                    nan_cnt += 1
                    logger.error(f"NaN gradient in {name}")
                    continue
                if torch_module.isinf(g).any():
                    inf_cnt += 1
                    logger.error(f"Inf gradient in {name}")
                    continue
                n = g.norm().item()
                if n > 100.0:
                    large_cnt += 1
                    logger.warning(f"Large gradient ({n:.2f}) in {name}")
            if nan_cnt or inf_cnt:
                logger.error(f"Gradient health: {nan_cnt} NaN, {inf_cnt} Inf, {large_cnt} large out of {total}")
            elif large_cnt:
                logger.warning(f"Gradient health: {large_cnt} large out of {total}")
        except Exception:
            pass
    
    def train_epoch(self, dataloader: DataLoader, teacher_embeddings_loader) -> Dict[str, float]:
        """
        –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–µ
        
        Args:
            dataloader: DataLoader —Å –ø–∞—Ä–∞–º–∏ (input_texts, target_texts)
            teacher_embeddings_loader: –ò—Ç–µ—Ä–∞—Ç–æ—Ä —Å teacher embeddings –ø–∞—Ä–∞–º–∏
            
        Returns:
            –£—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —ç–ø–æ—Ö–µ
        """
        self.flow_processor.train()
        if self.config.text_bridge_enabled:
            self.text_encoder.train() if hasattr(self.text_encoder, 'train') else None
            self.text_decoder.train()
        
        epoch_metrics = {
            'total_loss': 0.0,
            'energy_loss': 0.0,
            'text_loss': 0.0,
            'step_time': 0.0,
            'flow_time': 0.0,
            'active_flows': 0.0,
            'spawned_flows': 0.0,
            'flows_reached_output': 0.0
        }
        
        total_batches = 0
        epoch_start_time = time.time()
        
        for batch_idx, (batch_data, teacher_data) in enumerate(zip(dataloader, teacher_embeddings_loader)):
            # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
            if isinstance(batch_data, (list, tuple)) and len(batch_data) >= 2:
                input_texts, target_texts = batch_data[0], batch_data[1]
            else:
                logger.warning(f"Unexpected batch format: {type(batch_data)}")
                continue
            
            # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ teacher embeddings
            if isinstance(teacher_data, (list, tuple)) and len(teacher_data) >= 2:
                teacher_input_emb, teacher_target_emb = teacher_data[0], teacher_data[1]
            else:
                logger.warning(f"Unexpected teacher embeddings format: {type(teacher_data)}")
                continue

            # Ensure teacher embeddings reside on the correct device (move batch-wise)
            try:
                teacher_input_emb = teacher_input_emb.to(self.device, non_blocking=True)
                teacher_target_emb = teacher_target_emb.to(self.device, non_blocking=True)
            except Exception:
                # Fallback in case non_blocking not supported
                teacher_input_emb = teacher_input_emb.to(self.device)
                teacher_target_emb = teacher_target_emb.to(self.device)
            
            # –û–¥–∏–Ω —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è - –ø–µ—Ä–µ–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —à–∞–≥ –¥–ª—è curriculum learning  
            step_metrics = self.train_step(input_texts, target_texts, teacher_input_emb, teacher_target_emb, 
                                         global_training_step=self.global_step)
            
            # –ê–∫–∫—É–º—É–ª–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
            for key in epoch_metrics:
                if key in step_metrics:
                    epoch_metrics[key] += step_metrics[key]
            
            total_batches += 1
            
            # Periodic logging –≤–Ω—É—Ç—Ä–∏ —ç–ø–æ—Ö–∏
            if batch_idx % (self.config.log_interval * 5) == 0:
                logger.log(DEBUG_TRAINING,
                          f"Epoch {self.epoch}, Batch {batch_idx}/{len(dataloader)}: "
                          f"loss={step_metrics.get('total_loss', 0):.4f}")
        
        # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø–æ —ç–ø–æ—Ö–µ
        if total_batches > 0:
            for key in epoch_metrics:
                epoch_metrics[key] /= total_batches
        
        epoch_time = time.time() - epoch_start_time
        epoch_metrics['epoch_time'] = epoch_time
        epoch_metrics['total_batches'] = total_batches
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
        self.scheduler.step(epoch_metrics['total_loss'])
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–ø–æ—Ö–∏
        epoch_summary = summarize_step({'loss': epoch_metrics['total_loss'], 'time_s': epoch_time, 'batches': total_batches}, prefix='EPOCH')
        logger.log(DEBUG_TRAINING, f"‚úÖ {epoch_summary}")
        logger.log(DEBUG_CONVERGENCE,
                  f"Convergence stats: flows_reached_output={epoch_metrics['flows_reached_output']:.1f}, "
                  f"active_flows={epoch_metrics['active_flows']:.1f}")
        
        self.epoch += 1
        return epoch_metrics
    
    def train(self, dataloader: DataLoader, teacher_embeddings_loader, num_epochs: int = 10) -> Dict[str, List]:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            dataloader: DataLoader —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            teacher_embeddings_loader: DataLoader —Å teacher embeddings
            num_epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            
        Returns:
            –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        """
        logger.info(f"üöÄ Starting training: {num_epochs} epochs, batch_size={self.config.batch_size}")
        
        training_start_time = time.time()
        
        for epoch in range(num_epochs):
            epoch_metrics = self.train_epoch(dataloader, teacher_embeddings_loader)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            for key in epoch_metrics:
                if key in self.training_history:
                    self.training_history[key].append(epoch_metrics[key])
            
            # –£–º–Ω–æ–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∏–Ω–≥ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            if epoch_metrics['total_loss'] < self.best_loss:
                self.best_loss = epoch_metrics['total_loss']
                self.save_smart_checkpoint(
                    current_loss=epoch_metrics['total_loss'],
                    is_best=True,
                    custom_suffix=f"step_{self.global_step}"
                )
            
            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ —É–º–Ω—ã–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã
            if epoch % self.config.checkpoint_interval == 0:
                self.save_smart_checkpoint(
                    current_loss=epoch_metrics['total_loss'],
                    is_best=False,
                    custom_suffix=f"periodic_step_{self.global_step}"
                )
        
        training_time = time.time() - training_start_time
        
        logger.info(f"‚úÖ Training completed: {num_epochs} epochs, "
                   f"total_time={training_time:.1f}s, "
                   f"best_loss={self.best_loss:.4f}")
        
        return self.training_history
    
    def validate(self, input_texts: List[str], target_texts: List[str], 
                 teacher_input_embeddings: torch_module.Tensor, teacher_target_embeddings: torch_module.Tensor) -> Dict[str, Any]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        
        Args:
            input_texts: –í—Ö–æ–¥–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            target_texts: –¶–µ–ª–µ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
            teacher_input_embeddings: Teacher input embeddings [batch, 768]
            teacher_target_embeddings: Teacher target embeddings [batch, 768]
            
        Returns:
            –ú–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        """
        self.flow_processor.eval()
        if self.config.text_bridge_enabled:
            if hasattr(self.text_encoder, 'eval'):
                self.text_encoder.eval()
            self.text_decoder.eval()

        with torch_module.no_grad():
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –ë–ï–ó –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è - —Ç–æ–ª—å–∫–æ forward pass
            val_metrics = self._compute_losses(input_texts, target_texts, teacher_input_embeddings, teacher_target_embeddings)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            examples = []
            if self.config.text_bridge_enabled:
                num_examples = min(3, len(input_texts))
                for i in range(num_examples):
                    try:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º teacher embeddings –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ (–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
                        surface_input = teacher_input_embeddings[i:i+1]
                        try:
                            surface_input = surface_input.to(self.device, non_blocking=True)
                        except Exception:
                            surface_input = surface_input.to(self.device)
                        surface_output = self.flow_processor.forward(surface_input)  # [1, surface_dim]

                        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º surface embedding –≤ —Ç–µ–∫—Å—Ç (surface_output —É–∂–µ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä [1, surface_dim])
                        predicted_texts = self.text_decoder.decode_surface(surface_output)  # [1, surface_dim] -> List[str]
                        predicted_text = predicted_texts[0] if predicted_texts else ""  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
                        
                        examples.append({
                            'input': input_texts[i],
                            'target': target_texts[i],
                            'predicted': predicted_text
                        })
                    except Exception as e:
                        logger.warning(f"Example generation failed for sample {i}: {e}")
        
        val_metrics['examples'] = examples
        
        logger.log(DEBUG_TRAINING, f"Validation: loss={val_metrics.get('total_loss', 0):.4f}")
        if examples:
            logger.log(DEBUG_TRAINING, f"Example - Input: '{examples[0]['input'][:50]}...'")
            logger.log(DEBUG_TRAINING, f"Example - Predicted: '{examples[0]['predicted'][:50]}...'")
        
        return val_metrics
    
    def save_checkpoint(self, filepath: Union[str, Path]) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –º–æ–¥–µ–ª–∏ (legacy –º–µ—Ç–æ–¥)"""
        filepath = Path(filepath)
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        checkpoint = {
            'epoch': self.epoch,
            'global_step': self.global_step,
            'config': self.config.to_dict(),
            'model_state_dict': self.flow_processor.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_loss': self.best_loss,
            'training_history': self.training_history
        }
        
        if self.config.text_bridge_enabled:
            if hasattr(self.text_encoder, 'state_dict'):
                checkpoint['text_encoder_state_dict'] = self.text_encoder.state_dict()
            checkpoint['text_decoder_state_dict'] = self.text_decoder.state_dict()

        torch_module.save(checkpoint, filepath)
        logger.info(f"üíæ Checkpoint saved: {filepath}")
    
    def save_smart_checkpoint(
        self, 
        current_loss: float, 
        is_best: bool = False, 
        custom_suffix: Optional[str] = None,
        save_to_active: bool = True
    ) -> Path:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ —Å —É–º–Ω—ã–º –∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ–º
        
        Args:
            current_loss: –¢–µ–∫—É—â–∏–π loss –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –∏–º—è
            is_best: –Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ —á–µ–∫–ø–æ–∏–Ω—Ç –ª—É—á—à–∏–º
            custom_suffix: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å—É—Ñ—Ñ–∏–∫—Å –¥–ª—è –∏–º–µ–Ω–∏
            save_to_active: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ –≤ active –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —á–µ–∫–ø–æ–∏–Ω—Ç—É
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        if save_to_active:
            base_dir = self.checkpoint_base_dir / "active"
        else:
            base_dir = self.checkpoint_base_dir
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—É—Ç—å —Å —É–º–Ω—ã–º –∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ–º
        checkpoint_path = generate_checkpoint_path(
            config=self.config,
            epoch=self.epoch,
            loss=current_loss,
            base_dir=base_dir,
            is_best=is_best,
            custom_suffix=custom_suffix
        )
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        checkpoint_path.parent.mkdir(parents=True, exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        checkpoint = {
            'epoch': self.epoch,
            'global_step': self.global_step,
            'config': self.config.to_dict(),
            'model_state_dict': self.flow_processor.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_loss': self.best_loss,
            'training_history': self.training_history,
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è —É–º–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            'current_loss': current_loss,
            'is_best_checkpoint': is_best,
            'save_timestamp': datetime.now().isoformat(),
            'custom_suffix': custom_suffix
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º text_bridge —Å–æ—Å—Ç–æ—è–Ω–∏—è
        if self.config.text_bridge_enabled:
            if hasattr(self.text_encoder, 'state_dict'):
                checkpoint['text_encoder_state_dict'] = self.text_encoder.state_dict()
            elif hasattr(self.text_encoder, 'encoder') and hasattr(self.text_encoder.encoder, 'state_dict'):
                checkpoint['text_encoder_state_dict'] = self.text_encoder.encoder.state_dict()
                
            if hasattr(self.text_decoder, 'state_dict'):
                checkpoint['text_decoder_state_dict'] = self.text_decoder.state_dict()
            elif hasattr(self.text_decoder, 'decoder') and hasattr(self.text_decoder.decoder, 'state_dict'):
                checkpoint['text_decoder_state_dict'] = self.text_decoder.decoder.state_dict()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç
        torch_module.save(checkpoint, checkpoint_path)

        # –°–æ–∑–¥–∞–µ–º summary –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        summary = create_checkpoint_summary(checkpoint_path)
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        prefix = "üèÜ BEST" if is_best else "üíæ"
        logger.info(f"{prefix} Smart checkpoint saved:")
        logger.info(f"   üìÅ Path: {checkpoint_path}")
        logger.info(f"   üìä Epoch: {self.epoch}, Loss: {current_loss:.4f}")
        logger.info(f"   üìè Size: {summary.get('size_mb', 0):.1f} MB")
        if custom_suffix:
            logger.info(f"   üè∑Ô∏è  Suffix: {custom_suffix}")
        
        return checkpoint_path
    
    def load_smart_checkpoint(
        self, 
        checkpoint_path: Optional[Union[str, Path]] = None,
        load_latest: bool = False,
        load_best: bool = False,
        strict_validation: bool = False
    ) -> bool:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ —Å —É–º–Ω—ã–º –ø–æ–∏—Å–∫–æ–º –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        
        Args:
            checkpoint_path: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É
            load_latest: –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç –∏–∑ active
            load_best: –ó–∞–≥—Ä—É–∑–∏—Ç—å –ª—É—á—à–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç –∏–∑ active
            strict_validation: –ï—Å–ª–∏ True, –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –ø—Ä–µ—Ä—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É
            
        Returns:
            True –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
        """
        checkpoint_data = None
        loaded_path = None
        
        if checkpoint_path:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
            checkpoint_data = self.checkpoint_loader.load_checkpoint(
                checkpoint_path, 
                current_config=self.config,
                strict_validation=strict_validation
            )
            loaded_path = Path(checkpoint_path)
        elif load_best:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
            checkpoint_data = self.checkpoint_loader.load_best_checkpoint(
                current_config=self.config,
                strict_validation=strict_validation
            )
            if checkpoint_data:
                from ..utils.checkpoint_utils import find_best_checkpoint
                best_path = find_best_checkpoint(self.checkpoint_loader.active_dir)
                loaded_path = best_path
        elif load_latest:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
            checkpoint_data = self.checkpoint_loader.load_latest_checkpoint(
                current_config=self.config,
                strict_validation=strict_validation
            )
            if checkpoint_data:
                from ..utils.checkpoint_utils import find_latest_checkpoint
                latest_path = find_latest_checkpoint(self.checkpoint_loader.active_dir)
                loaded_path = latest_path
        
        if checkpoint_data is None:
            logger.warning("No checkpoint loaded")
            return False
        
        try:
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            self.epoch = checkpoint_data.get('epoch', 0)
            self.global_step = checkpoint_data.get('global_step', 0)
            self.best_loss = checkpoint_data.get('best_loss', float('inf'))
            self.training_history = checkpoint_data.get('training_history', {
                "total_losses": [], "energy_losses": [], "text_losses": [],
                "learning_rates": [], "flow_statistics": [], "performance_metrics": []
            })
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–µ–π
            if 'model_state_dict' in checkpoint_data:
                self.flow_processor.load_state_dict(checkpoint_data['model_state_dict'])
            
            if 'optimizer_state_dict' in checkpoint_data:
                self.optimizer.load_state_dict(checkpoint_data['optimizer_state_dict'])
                
            if 'scheduler_state_dict' in checkpoint_data:
                self.scheduler.load_state_dict(checkpoint_data['scheduler_state_dict'])
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º text_bridge —Å–æ—Å—Ç–æ—è–Ω–∏—è
            if self.config.text_bridge_enabled:
                if 'text_encoder_state_dict' in checkpoint_data:
                    if hasattr(self.text_encoder, 'load_state_dict'):
                        self.text_encoder.load_state_dict(checkpoint_data['text_encoder_state_dict'])
                    elif hasattr(self.text_encoder, 'encoder'):
                        self.text_encoder.encoder.load_state_dict(checkpoint_data['text_encoder_state_dict'])
                
                if 'text_decoder_state_dict' in checkpoint_data:
                    if hasattr(self.text_decoder, 'load_state_dict'):
                        self.text_decoder.load_state_dict(checkpoint_data['text_decoder_state_dict'])
                    elif hasattr(self.text_decoder, 'decoder'):
                        self.text_decoder.decoder.load_state_dict(checkpoint_data['text_decoder_state_dict'])
            
            logger.info(f"‚úÖ Smart checkpoint loaded successfully:")
            logger.info(f"   üìÅ From: {loaded_path.name if loaded_path else 'Unknown'}")
            logger.info(f"   üìä Epoch: {self.epoch}, Step: {self.global_step}")
            logger.info(f"   üéØ Best loss: {self.best_loss:.4f}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load checkpoint state: {e}")
            return False
    
    def load_checkpoint(self, filepath: Union[str, Path], strict_validation: bool = False) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –º–æ–¥–µ–ª–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        
        Args:
            filepath: –ü—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É
            strict_validation: –ï—Å–ª–∏ True, –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–∫—É
        """
        filepath = Path(filepath)
        if not filepath.exists():
            raise FileNotFoundError(f"Checkpoint not found: {filepath}")

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º checkpoint_loader –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
        checkpoint = self.checkpoint_loader.load_checkpoint(
            filepath,
            current_config=self.config,
            strict_validation=strict_validation
        )
        
        if checkpoint is None:
            raise RuntimeError(f"Failed to load checkpoint from {filepath}")

        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.epoch = checkpoint['epoch']
        self.global_step = checkpoint['global_step']
        self.best_loss = checkpoint['best_loss']
        self.training_history = checkpoint['training_history']
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤
        self.flow_processor.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        if self.config.text_bridge_enabled:
            if 'text_encoder_state_dict' in checkpoint and hasattr(self.text_encoder, 'load_state_dict'):
                self.text_encoder.load_state_dict(checkpoint['text_encoder_state_dict'])
            if 'text_decoder_state_dict' in checkpoint:
                self.text_decoder.load_state_dict(checkpoint['text_decoder_state_dict'])
        
        logger.info(f"üìÅ Checkpoint loaded: {filepath}, epoch={self.epoch}, step={self.global_step}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ –∏ –µ—ë –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö"""
        info = {
            'config': self.config.to_dict(),
            'epoch': self.epoch,
            'global_step': self.global_step,
            'best_loss': self.best_loss,
            'device': str(self.device)
        }
        
        # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        flow_params = sum(p.numel() for p in self.flow_processor.parameters() if p.requires_grad)
        info['flow_processor_parameters'] = flow_params
        
        if self.config.text_bridge_enabled:
            # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ text_bridge –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            if hasattr(self.text_encoder, 'model'):  # Cached version
                encoder_params = sum(p.numel() for p in self.text_encoder.model.parameters() if p.requires_grad)
            else:  # Direct model
                encoder_params = sum(p.numel() for p in self.text_encoder.parameters() if p.requires_grad)
            info['text_encoder_parameters'] = encoder_params
            
            if hasattr(self.text_decoder, 'model'):  # Cached version
                decoder_params = sum(p.numel() for p in self.text_decoder.model.parameters() if p.requires_grad)
            else:  # Direct model
                decoder_params = sum(p.numel() for p in self.text_decoder.parameters() if p.requires_grad)
            info['text_decoder_parameters'] = decoder_params
        
        return info


def create_energy_trainer(config: Optional[EnergyConfig] = None) -> EnergyTrainer:
    """–§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è EnergyTrainer"""
    return EnergyTrainer(config)