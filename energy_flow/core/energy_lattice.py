"""
Energy Lattice - 3D —Ä–µ—à–µ—Ç–∫–∞ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø–æ—Ç–æ–∫–∞–º–∏
===================================================================

–£–ø—Ä–∞–≤–ª—è–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–º–∏ –ø–æ—Ç–æ–∫–∞–º–∏, –∏—Ö –ø–æ–∑–∏—Ü–∏—è–º–∏ –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ–º —Å —Ä–µ—à–µ—Ç–∫–æ–π.
–†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –≤—Ö–æ–¥–Ω–æ–π –∏ –≤—ã—Ö–æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω–∞–º–∏ –∫—É–±–∞.
"""

import torch
import torch.nn as nn
from typing import List, Dict, Optional, Tuple, NamedTuple
from dataclasses import dataclass, field
import numpy as np

from ..utils.logging import get_logger, log_memory_state
from ..config import get_energy_config, create_debug_config, set_energy_config
from ..utils.device_manager import get_device_manager

logger = get_logger(__name__)


class Position3D(NamedTuple):
    """3D –ø–æ–∑–∏—Ü–∏—è –≤ —Ä–µ—à–µ—Ç–∫–µ"""
    x: int
    y: int
    z: int


@dataclass
class EnergyFlow:
    """–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–æ–∫–∞"""
    id: int
    position: torch.Tensor  # [3] - —Ç–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è
    energy: torch.Tensor    # [embedding_dim] - —ç–Ω–µ—Ä–≥–∏—è/—ç–º–±–µ–¥–¥–∏–Ω–≥
    hidden_state: torch.Tensor  # [num_layers, hidden_size] - —Å–æ—Å—Ç–æ—è–Ω–∏–µ GRU
    batch_idx: int = 0  # –ò–Ω–¥–µ–∫—Å –≤ –±–∞—Ç—á–µ
    parent_id: Optional[int] = None
    age: int = 0  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –∂–∏–∑–Ω–∏ –ø–æ—Ç–æ–∫–∞
    is_active: bool = True


class EnergyLattice(nn.Module):
    """
    3D —Ä–µ—à–µ—Ç–∫–∞ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø–æ—Ç–æ–∫–∞–º–∏
    
    –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
    - –†–∞–∑–º–µ—â–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –Ω–∞ –≤—Ö–æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω–µ
    - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω—ã–º–∏ –ø–æ—Ç–æ–∫–∞–º–∏
    - –°–±–æ—Ä –≤—ã—Ö–æ–¥–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –≤—ã—Ö–æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã
    """
    
    def __init__(self, config=None):
        """
        Args:
            config: EnergyConfig —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        """
        super().__init__()
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        if config is None:
            config = create_debug_config()
            set_energy_config(config)
        self.config = config
        
        # Device manager
        self.device_manager = get_device_manager()
        self.device = self.device_manager.device
        
        # –†–∞–∑–º–µ—Ä—ã —Ä–µ—à–µ—Ç–∫–∏
        self.width = config.lattice_width
        self.height = config.lattice_height
        self.depth = config.lattice_depth
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ—Ç–æ–∫–æ–≤
        self.max_active_flows = config.max_active_flows
        self.energy_dim = 1  # –°–∫–∞–ª—è—Ä–Ω–∞—è —ç–Ω–µ—Ä–≥–∏—è –æ—Ç mapper'–∞
        
        # –ê–∫—Ç–∏–≤–Ω—ã–µ –ø–æ—Ç–æ–∫–∏
        self.active_flows: Dict[int, EnergyFlow] = {}
        self.next_flow_id = 0
        
        # –ë—É—Ñ–µ—Ä –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ (–±—É—Ñ–µ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–±–æ—Ä)
        self.output_buffer: Dict[Tuple[int, int], List[EnergyFlow]] = {}  # (x,y) -> [flows]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_created': 0,
            'total_completed': 0,
            'total_died': 0,
            'max_concurrent': 0
        }
        
        logger.info(f"EnergyLattice initialized: {self.width}x{self.height}x{self.depth}")
        logger.info(f"Input/output cells: {self.width * self.height}, max flows: {self.max_active_flows}")
    
    def place_initial_energy(self, embeddings: torch.Tensor, mapper=None) -> List[int]:
        """
        –†–∞–∑–º–µ—â–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–∞ –≤—Ö–æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω–µ –∫—É–±–∞ (z=0)
        
        Args:
            embeddings: [batch, embedding_dim] - –≤—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (768D)
            mapper: EnergyFlowMapper –¥–ª—è –ø—Ä–æ–µ–∫—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            flow_ids: –°–ø–∏—Å–æ–∫ ID —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤
        """
        batch_size = embeddings.shape[0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
        expected_dim = self.config.input_embedding_dim_from_teacher
        if embeddings.shape[1] != expected_dim:
            raise ValueError(f"Expected embedding dim {expected_dim}, got {embeddings.shape[1]}")
        
        # –û—á–∏—â–∞–µ–º –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ—Ç–æ–∫–∏
        self._cleanup_inactive_flows()
        
        flow_ids = []
        
        if mapper is None:
            raise ValueError("EnergyFlowMapper is required! No fallback logic allowed.")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–ø–ø–µ—Ä –¥–ª—è –ø—Ä–æ–µ–∫—Ü–∏–∏ 768D -> surface_dim
        cell_energies = mapper.map_to_surface(embeddings)
        
        for (x, y), energy, batch_idx in cell_energies:
            if len(self.active_flows) >= self.max_active_flows:
                logger.warning(f"Reached max active flows limit: {self.max_active_flows}")
                break
            
            # –°–æ–∑–¥–∞–µ–º –ø–æ—Ç–æ–∫ —Å —ç–Ω–µ—Ä–≥–∏–µ–π –∏–∑ –º–∞–ø–ø–µ—Ä–∞
            position = torch.tensor([x, y, 0], dtype=torch.float32, device=self.device)
            flow_id = self._create_flow(position, energy, batch_idx=batch_idx)
            flow_ids.append(flow_id)
            
            # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ª–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 5 —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤
            if len(flow_ids) <= 5:
                logger.debug_init(f"üÜï Created flow {flow_id}: position=({x}, {y}, 0), energy_norm={torch.norm(energy):.3f}")
        
        logger.info(f"Created {len(flow_ids)} initial flows on input surface")
        return flow_ids
    
    def _create_flow(self, position: torch.Tensor, energy: torch.Tensor, 
                    batch_idx: int = 0,
                    parent_id: Optional[int] = None,
                    hidden_state: Optional[torch.Tensor] = None) -> int:
        """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–π –ø–æ—Ç–æ–∫"""
        flow_id = self.next_flow_id
        self.next_flow_id += 1
        
        # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–æ
        if hidden_state is None:
            # –†–∞–∑–º–µ—Ä—ã –±–µ—Ä–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
            num_layers = self.config.carrier_num_layers
            hidden_size = self.config.carrier_hidden_size
            hidden_state = torch.zeros(num_layers, hidden_size, device=self.device)
        
        flow = EnergyFlow(
            id=flow_id,
            position=position,
            energy=energy,
            hidden_state=hidden_state,
            batch_idx=batch_idx,
            parent_id=parent_id,
            age=0,
            is_active=True
        )
        
        self.active_flows[flow_id] = flow
        self.stats['total_created'] += 1
        self.stats['max_concurrent'] = max(self.stats['max_concurrent'], len(self.active_flows))
        
        return flow_id
    
    def get_active_flows(self) -> List[EnergyFlow]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤"""
        return [flow for flow in self.active_flows.values() if flow.is_active]
    
    def update_flow(self, flow_id: int, 
                   new_position: torch.Tensor,
                   new_energy: torch.Tensor,
                   new_hidden: torch.Tensor):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Ç–æ–∫–∞"""
        if flow_id not in self.active_flows:
            return
        
        flow = self.active_flows[flow_id]
        flow.position = new_position
        flow.energy = new_energy
        flow.hidden_state = new_hidden
        flow.age += 1
        
        # –ë—É—Ñ–µ—Ä–∏–∑—É–µ–º –ø–æ—Ç–æ–∫–∏ –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –≤—ã—Ö–æ–¥–∞
        if new_position[2] >= self.depth - 1:
            self._buffer_output_flow(flow_id)
            logger.debug(f"Flow {flow_id} reached output side at age {flow.age} (buffered for collection)")
    
    def spawn_flows(self, parent_id: int, spawn_energies: List[torch.Tensor]) -> List[int]:
        """
        –°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–µ –ø–æ—Ç–æ–∫–∏ –æ—Ç —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ
        
        Args:
            parent_id: ID —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –ø–æ—Ç–æ–∫–∞
            spawn_energies: –°–ø–∏—Å–æ–∫ —ç–Ω–µ—Ä–≥–∏–π –¥–ª—è –Ω–æ–≤—ã—Ö –ø–æ—Ç–æ–∫–æ–≤
            
        Returns:
            new_flow_ids: ID —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤
        """
        if parent_id not in self.active_flows:
            return []
        
        parent = self.active_flows[parent_id]
        new_flow_ids = []
        
        for energy in spawn_energies:
            if len(self.active_flows) >= self.max_active_flows:
                logger.warning("Cannot spawn: max flows reached")
                break
            
            # –ù–æ–≤—ã–µ –ø–æ—Ç–æ–∫–∏ –Ω–∞—á–∏–Ω–∞—é—Ç —Å –ø–æ–∑–∏—Ü–∏–∏ —Ä–æ–¥–∏—Ç–µ–ª—è
            flow_id = self._create_flow(
                parent.position.clone(),
                energy,
                batch_idx=parent.batch_idx,  # –ù–∞—Å–ª–µ–¥—É–µ–º batch_idx –æ—Ç —Ä–æ–¥–∏—Ç–µ–ª—è
                parent_id=parent_id,
                hidden_state=parent.hidden_state.clone()
            )
            new_flow_ids.append(flow_id)
        
        if new_flow_ids:
            logger.debug(f"Spawned {len(new_flow_ids)} flows from parent {parent_id}")
        
        return new_flow_ids
    
    def deactivate_flow(self, flow_id: int, reason: str = "energy_depleted"):
        """–î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç –ø–æ—Ç–æ–∫"""
        if flow_id in self.active_flows:
            self.active_flows[flow_id].is_active = False
            if reason != "reached_output":
                self.stats['total_died'] += 1
            logger.debug(f"Flow {flow_id} deactivated: {reason}")
    
    def update_flow(self, flow_id: int, new_position: torch.Tensor, new_energy: torch.Tensor, new_hidden: torch.Tensor):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Ç–æ–∫–∞"""
        if flow_id in self.active_flows:
            flow = self.active_flows[flow_id]
            flow.position = new_position.clone()
            flow.energy = new_energy.clone()
            flow.hidden_state = new_hidden.clone()
            flow.age += 1
    
    def batch_deactivate_flows(self, dead_flow_ids: torch.Tensor, 
                              energy_dead_mask: torch.Tensor,
                              backward_dead_mask: torch.Tensor, 
                              bounds_dead_mask: torch.Tensor):
        """–í–ï–ö–¢–û–†–ò–ó–û–í–ê–ù–ù–ê–Ø –¥–µ–∞–∫—Ç–∏–≤–∞—Ü–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø–æ—Ç–æ–∫–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ"""
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–Ω–∑–æ—Ä—ã –≤ —Å–ø–∏—Å–∫–∏ Python –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥–∞–ª—å–Ω–µ–π—à–∏—Ö GPU-CPU —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–π
        dead_ids = dead_flow_ids.detach().cpu().tolist()
        energy_dead = energy_dead_mask.detach().cpu().tolist()
        backward_dead = backward_dead_mask.detach().cpu().tolist()
        bounds_dead = bounds_dead_mask.detach().cpu().tolist()
        
        deactivated_count = 0
        for i, flow_id in enumerate(dead_ids):
            if flow_id in self.active_flows:
                self.active_flows[flow_id].is_active = False
                deactivated_count += 1
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏—á–∏–Ω—É –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ
                if energy_dead[i]:
                    reason = "energy_depleted"
                elif backward_dead[i]:
                    reason = "backward_z_movement"
                else:  # bounds_dead[i]
                    reason = "out_of_bounds"
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–µ–∑ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                self.stats['total_died'] += 1
        
        if deactivated_count > 0:
            logger.debug(f"Batch deactivated {deactivated_count} flows")
    
    def batch_update_flows(self, alive_flow_ids: torch.Tensor,
                          alive_positions: torch.Tensor,
                          alive_energies: torch.Tensor,
                          alive_hidden: torch.Tensor):
        """–í–ï–ö–¢–û–†–ò–ó–û–í–ê–ù–ù–û–ï –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø–æ—Ç–æ–∫–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ"""
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–æ–ª—å–∫–æ ID –≤ CPU, –æ—Å—Ç–∞–ª—å–Ω–æ–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –Ω–∞ GPU
        alive_ids = alive_flow_ids.detach().cpu().tolist()
        
        updated_count = 0
        for i, flow_id in enumerate(alive_ids):
            if flow_id in self.active_flows:
                flow = self.active_flows[flow_id]
                # –û–±–Ω–æ–≤–ª—è–µ–º –ë–ï–ó .clone() –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è (–¥–∞–Ω–Ω—ã–µ —É–∂–µ –æ—Ç–¥–µ–ª–µ–Ω—ã –æ—Ç –≥—Ä–∞—Ñ–∞)
                flow.position = alive_positions[i]
                flow.energy = alive_energies[i] 
                flow.hidden_state = alive_hidden[i]
                flow.age += 1
                updated_count += 1
        
        if updated_count > 0:
            logger.debug(f"Batch updated {updated_count} flows")
    
    def _buffer_output_flow(self, flow_id: int):
        """–ü–æ–º–µ—â–∞–µ—Ç –ø–æ—Ç–æ–∫ –≤ –±—É—Ñ–µ—Ä –≤—ã—Ö–æ–¥–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤"""
        if flow_id not in self.active_flows:
            return
        
        flow = self.active_flows[flow_id]
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –ø–æ–∑–∏—Ü–∏—é –µ—Å–ª–∏ –ø–æ—Ç–æ–∫ –≤—ã—à–µ–ª –∑–∞ –ø—Ä–µ–¥–µ–ª—ã
        if flow.position[2] > self.depth - 1:
            corrected_flow = EnergyFlow(
                id=flow.id,
                position=torch.tensor([
                    flow.position[0], 
                    flow.position[1], 
                    self.depth - 1  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞ –≤—ã—Ö–æ–¥–Ω—É—é —Å—Ç–æ—Ä–æ–Ω—É
                ], device=self.device),
                energy=flow.energy,
                hidden_state=flow.hidden_state,
                parent_id=flow.parent_id,
                age=flow.age,
                is_active=flow.is_active
            )
            buffered_flow = corrected_flow
        else:
            buffered_flow = flow
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–µ—Ç–∫—É –Ω–∞ –≤—ã—Ö–æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω–µ
        x = int(torch.clamp(buffered_flow.position[0], 0, self.width - 1).item())
        y = int(torch.clamp(buffered_flow.position[1], 0, self.height - 1).item())
        key = (x, y)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä
        if key not in self.output_buffer:
            self.output_buffer[key] = []
        self.output_buffer[key].append(buffered_flow)
        
        # –î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫ –ø–æ—Å–ª–µ –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏–∏
        flow.is_active = False
        self.stats['total_completed'] += 1
        
        logger.debug(f"Flow {flow_id} buffered to output cell ({x}, {y})")
    
    def get_buffered_flows_count(self) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –≤ –≤—ã—Ö–æ–¥–Ω–æ–º –±—É—Ñ–µ—Ä–µ"""
        return sum(len(flows) for flows in self.output_buffer.values())
    
    def clear_output_buffer(self):
        """–û—á–∏—â–∞–µ—Ç –±—É—Ñ–µ—Ä –≤—ã—Ö–æ–¥–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤"""
        cleared_count = self.get_buffered_flows_count()
        self.output_buffer.clear()
        logger.debug(f"Cleared output buffer ({cleared_count} flows)")
    
    def get_all_buffered_flows(self) -> List[EnergyFlow]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –ø–æ—Ç–æ–∫–∏ –∏–∑ –±—É—Ñ–µ—Ä–∞"""
        all_flows = []
        for flows in self.output_buffer.values():
            all_flows.extend(flows)
        return all_flows
    
    def collect_buffered_energy(self) -> Tuple[torch.Tensor, List[int]]:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç —ç–Ω–µ—Ä–≥–∏—é –∏–∑ –±—É—Ñ–µ—Ä–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤
        
        Returns:
            output_embeddings: [batch, embedding_dim] - —Å–æ–±—Ä–∞–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            flow_ids: ID –ø–æ—Ç–æ–∫–æ–≤ –≤ –±—É—Ñ–µ—Ä–µ
        """
        if not self.output_buffer:
            logger.debug("No flows in output buffer")
            return torch.zeros(0, self.embedding_dim, device=self.device), []
        
        flow_ids = []
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É –≤–∑–≤–µ—à–µ–Ω–Ω–æ–≥–æ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è
        output_embeddings = []
        aggregation_stats = []
        
        logger.debug(f"Collecting from buffer: {len(self.output_buffer)} cells with flows")
        
        for y in range(self.height):
            for x in range(self.width):
                key = (x, y)
                if key in self.output_buffer:
                    flows_in_cell = self.output_buffer[key]
                    
                    # –°–æ–±–∏—Ä–∞–µ–º ID –≤—Å–µ—Ö –ø–æ—Ç–æ–∫–æ–≤ –≤ —ç—Ç–æ–π –∫–ª–µ—Ç–∫–µ
                    for flow in flows_in_cell:
                        flow_ids.append(flow.id)
                    
                    if len(flows_in_cell) == 1:
                        # –û–¥–∏–Ω –ø–æ—Ç–æ–∫ - –ø—Ä–æ—Å—Ç–æ –±–µ—Ä–µ–º –µ–≥–æ —ç–Ω–µ—Ä–≥–∏—é
                        aggregated = flows_in_cell[0].energy
                        stats = f"single_flow(id={flows_in_cell[0].id})"
                    else:
                        # –ù–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Ç–æ–∫–æ–≤ - –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
                        energies = torch.stack([flow.energy for flow in flows_in_cell])
                        
                        # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ (—ç–Ω–µ—Ä–≥–∏—è * –≤–æ–∑—Ä–∞—Å—Ç)
                        weights = []
                        for flow in flows_in_cell:
                            energy_magnitude = torch.norm(flow.energy).item()
                            age_factor = 1.0 + flow.age * 0.1
                            weight = energy_magnitude * age_factor
                            weights.append(weight)
                        
                        weights = torch.tensor(weights, device=self.device)
                        weights = weights / weights.sum()  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
                        
                        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
                        aggregated = (energies * weights.unsqueeze(-1)).sum(dim=0)
                        
                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                        flow_ids_cell = [flow.id for flow in flows_in_cell]
                        avg_age = sum(flow.age for flow in flows_in_cell) / len(flows_in_cell)
                        stats = f"weighted_avg({len(flows_in_cell)}_flows, ids={flow_ids_cell}, avg_age={avg_age:.1f})"
                        
                        logger.debug(f"Cell ({x},{y}): {stats}")
                    
                    aggregation_stats.append(stats)
                else:
                    # –ü—É—Å—Ç–∞—è –∫–ª–µ—Ç–∫–∞
                    aggregated = torch.zeros(self.embedding_dim, device=self.device)
                
                output_embeddings.append(aggregated)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
        output_embeddings = torch.stack(output_embeddings)  # [width*height, embedding_dim]
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        output_embeddings = output_embeddings.view(-1)[:self.config.input_embedding_dim_from_teacher]
        output_embeddings = output_embeddings.unsqueeze(0)  # [1, 768]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        cells_with_flows = len([stats for stats in aggregation_stats if 'flow' in stats])
        multi_flow_cells = len([stats for stats in aggregation_stats if 'weighted_avg' in stats])
        
        logger.info(f"Collected energy from {len(flow_ids)} buffered flows")
        logger.info(f"Output grid: {cells_with_flows}/{self.width*self.height} cells with flows, "
                   f"{multi_flow_cells} cells with multiple flows")
        
        return output_embeddings, flow_ids
    
    def collect_buffered_surface_energy(self) -> Tuple[torch.Tensor, List[int]]:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç surface embeddings –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –±—É—Ñ–µ—Ä–∞ –ë–ï–ó –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ 768D
        
        Returns:
            output_surface_embeddings: [batch, surface_dim] - surface embeddings
            completed_flows: ID –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤
        """
        if not self.output_buffer:
            logger.debug("No flows in output buffer")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤—ã–µ surface embeddings —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
            surface_dim = self.width * self.height
            # –ò—â–µ–º –ª—é–±–æ–π tensor —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏ –≤ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ—Ç–æ–∫–∞—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–≤—è–∑–∞–Ω–Ω–æ–≥–æ –Ω—É–ª–µ–≤–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞
            reference_tensor = None
            for flow in self.active_flows.values():
                if flow.energy.requires_grad:
                    reference_tensor = flow.energy
                    break
            if reference_tensor is not None:
                zero_tensor = torch.zeros(1, surface_dim, device=self.device, dtype=reference_tensor.dtype, requires_grad=True)
                return zero_tensor * 0.0, []  # –£–º–Ω–æ–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—É—é —Å–≤—è–∑—å
            else:
                return torch.zeros(1, surface_dim, device=self.device), []
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –∏–∑ –ø–æ—Ç–æ–∫–æ–≤ –≤ –±—É—Ñ–µ—Ä–µ
        all_buffered_flows = self.get_all_buffered_flows()
        if not all_buffered_flows:
            surface_dim = self.width * self.height
            # –ò—â–µ–º reference tensor –≤ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ—Ç–æ–∫–∞—Ö
            reference_tensor = None
            for flow in self.active_flows.values():
                if flow.energy.requires_grad:
                    reference_tensor = flow.energy
                    break
            if reference_tensor is not None:
                zero_tensor = torch.zeros(1, surface_dim, device=self.device, dtype=reference_tensor.dtype, requires_grad=True)
                return zero_tensor * 0.0, []
            else:
                return torch.zeros(1, surface_dim, device=self.device), []
            
        batch_indices = {flow.batch_idx for flow in all_buffered_flows}
        batch_size = max(batch_indices) + 1 if batch_indices else 1
        
        # –°–æ–∑–¥–∞–µ–º surface tensor —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–π —Å–≤—è–∑—å—é
        surface_dim = self.width * self.height
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç–Ω–µ—Ä–≥–∏—é –ø–µ—Ä–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –∫–∞–∫ reference –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ–Ω–∑–æ—Ä–∞ —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏
        reference_energy = all_buffered_flows[0].energy
        if reference_energy.requires_grad:
            # –°–æ–∑–¥–∞–µ–º —Ç–µ–Ω–∑–æ—Ä —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–π —Å–≤—è–∑—å—é –∏—Å–ø–æ–ª—å–∑—É—è —Ä–µ–∞–ª—å–Ω—É—é —ç–Ω–µ—Ä–≥–∏—é –ø–æ—Ç–æ–∫–æ–≤
            output_surface = torch.zeros(batch_size, surface_dim, device=self.device, dtype=reference_energy.dtype)
            # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—É—é —Å–≤—è–∑—å —á–µ—Ä–µ–∑ —Å—É–º–º—É –≤—Å–µ—Ö —ç–Ω–µ—Ä–≥–∏–π –ø–æ—Ç–æ–∫–æ–≤
            all_energies = torch.stack([flow.energy for flow in all_buffered_flows])
            energy_sum = all_energies.sum()
            output_surface = output_surface + energy_sum * 0.0  # –ù—É–ª–µ–≤–æ–µ –≤–ª–∏—è–Ω–∏–µ, –Ω–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–∞—è —Å–≤—è–∑—å
        else:
            output_surface = torch.zeros(batch_size, surface_dim, device=self.device)
        flow_ids = []
        
        logger.debug(f"Collecting surface energy from buffer: {len(self.output_buffer)} cells, batch_size={batch_size}")
        
        # –ò—Ç–µ—Ä–∏—Ä—É–µ–º –ø–æ –≤—Å–µ–º –∫–ª–µ—Ç–∫–∞–º –±—É—Ñ–µ—Ä–∞
        for (x, y), flows in self.output_buffer.items():
            if not flows:
                continue
                
            # –°–æ–±–∏—Ä–∞–µ–º ID –≤—Å–µ—Ö –ø–æ—Ç–æ–∫–æ–≤ –≤ —ç—Ç–æ–π –∫–ª–µ—Ç–∫–µ
            cell_flow_ids = [flow.id for flow in flows]
            flow_ids.extend(cell_flow_ids)
            
            if len(flows) == 1:
                # –û–¥–∏–Ω –ø–æ—Ç–æ–∫ - –ø—Ä–æ—Å—Ç–æ –±–µ—Ä–µ–º –µ–≥–æ —ç–Ω–µ—Ä–≥–∏—é
                flow = flows[0]
                aggregated_energy = flow.energy
                batch_idx = flow.batch_idx
                logger.debug(f"Cell ({x},{y}): single_flow(id={flow.id}, batch={batch_idx})")
            else:
                # –ù–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Ç–æ–∫–æ–≤ - –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
                energies = []
                weights = []
                batch_indices_cell = []
                
                for flow in flows:
                    energy_magnitude = torch.norm(flow.energy).item()
                    age_factor = 1.0 + flow.age * 0.1
                    weight = energy_magnitude * age_factor
                    
                    energies.append(flow.energy)
                    weights.append(weight)
                    batch_indices_cell.append(flow.batch_idx)
                
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞
                weights = torch.tensor(weights, device=self.device)
                weights = weights / weights.sum()
                
                # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ —ç–Ω–µ—Ä–≥–∏–π
                energies_tensor = torch.stack(energies)  # [num_flows, 1]
                aggregated_energy = (energies_tensor * weights.unsqueeze(-1)).sum(dim=0)  # [1]
                
                # –î–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ –±–µ—Ä–µ–º batch_idx –ø–µ—Ä–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞
                batch_idx = batch_indices_cell[0]
                
                avg_age = sum(flow.age for flow in flows) / len(flows)
                logger.debug(f"Cell ({x},{y}): weighted_avg({len(flows)}_flows, ids={cell_flow_ids}, avg_age={avg_age:.1f}, batch={batch_idx})")
            
            # –†–∞–∑–º–µ—â–∞–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —ç–Ω–µ—Ä–≥–∏—é –≤ surface tensor
            if 0 <= x < self.width and 0 <= y < self.height and 0 <= batch_idx < batch_size:
                surface_idx = y * self.width + x  # –õ–∏–Ω–µ–∞—Ä–∏–∑–∞—Ü–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º .item() —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã!
                if aggregated_energy.numel() == 1:
                    output_surface[batch_idx, surface_idx] = aggregated_energy.squeeze()
                else:
                    output_surface[batch_idx, surface_idx] = aggregated_energy[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –±–µ–∑ .item()
            else:
                logger.warning(f"Invalid coordinates or batch_idx: ({x},{y}), batch={batch_idx}")
        
        logger.info(f"Collected surface energy from {len(flow_ids)} buffered flows across {len(self.output_buffer)} cells")
        return output_surface, flow_ids
    
    def collect_output_energy(self, mapper=None) -> Tuple[torch.Tensor, List[int]]:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç —ç–Ω–µ—Ä–≥–∏—é —Å –≤—ã—Ö–æ–¥–Ω–æ–π –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏
        
        Args:
            mapper: EnergyFlowMapper –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            
        Returns:
            output_embeddings: [batch, embedding_dim] - —Å–æ–±—Ä–∞–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            flow_ids: ID –ø–æ—Ç–æ–∫–æ–≤, –¥–æ—Å—Ç–∏–≥—à–∏—Ö –≤—ã—Ö–æ–¥–∞
        """
        if mapper is None:
            raise ValueError("EnergyFlowMapper is required! No fallback logic allowed.")
        
        # –°–æ–±–∏—Ä–∞–µ–º —ç–Ω–µ—Ä–≥–∏—é –∏–∑ –±—É—Ñ–µ—Ä–∞ –ø–æ –∫–ª–µ—Ç–∫–∞–º
        surface_energy = {}
        flow_ids = []
        
        for (x, y), flows in self.output_buffer.items():
            if flows:
                # –£—Å—Ä–µ–¥–Ω—è–µ–º —ç–Ω–µ—Ä–≥–∏—é –≤ –∫–ª–µ—Ç–∫–µ —Å –≤–µ—Å–∞–º–∏
                energies = []
                weights = []
                
                for flow in flows:
                    energy_magnitude = torch.norm(flow.energy)  # –£–±–∏—Ä–∞–µ–º .item() –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è CPU-GPU —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
                    age_factor = 1 + flow.age * 0.1
                    weight = energy_magnitude * age_factor
                    
                    energies.append(flow.energy)
                    weights.append(weight)
                    flow_ids.append(flow.id)
                
                # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
                weights = torch.tensor(weights, device=self.device)
                weights = weights / weights.sum()
                
                avg_energy = sum(e * w for e, w in zip(energies, weights))
                surface_energy[(x, y)] = avg_energy
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –∏–∑ –ø–æ—Ç–æ–∫–æ–≤
        all_flows = list(self.active_flows.values()) + list(self.get_all_buffered_flows())
        batch_indices = {flow.batch_idx for flow in all_flows} if all_flows else {0}
        batch_size = max(batch_indices) + 1 if batch_indices else 1
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ –º–∞–ø–ø–µ—Ä
        output_embeddings = mapper.collect_from_surface(surface_energy, batch_size)
        
        logger.info(f"Collected energy from {len(surface_energy)} cells using mapper")
        return output_embeddings, flow_ids
    
    def _cleanup_inactive_flows(self):
        """–£–¥–∞–ª—è–µ—Ç –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ—Ç–æ–∫–∏ –∏–∑ –ø–∞–º—è—Ç–∏"""
        inactive_ids = [fid for fid, flow in self.active_flows.items() if not flow.is_active]
        
        for flow_id in inactive_ids:
            del self.active_flows[flow_id]
        
        if inactive_ids:
            logger.debug(f"Cleaned up {len(inactive_ids)} inactive flows")
    
    def get_statistics(self) -> Dict[str, any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–µ—à–µ—Ç–∫–∏"""
        active_count = len(self.get_active_flows())
        
        return {
            **self.stats,
            'current_active': active_count,
            'utilization': active_count / self.max_active_flows if self.max_active_flows > 0 else 0
        }
    
    def reset(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–µ—à–µ—Ç–∫–∏"""
        self.active_flows.clear()
        self.output_buffer.clear()  # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
        self.next_flow_id = 0
        self.stats = {
            'total_created': 0,
            'total_completed': 0,
            'total_died': 0,
            'max_concurrent': 0
        }
        logger.info("EnergyLattice reset")


def create_energy_lattice(config=None) -> EnergyLattice:
    """–§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è EnergyLattice"""
    return EnergyLattice(config)