"""
–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
===========================================

–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ—Ç–æ–∫–æ–≤.
–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞–∑–º–µ—Ä—ã —Ä–µ—à–µ—Ç–∫–∏, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–µ–π, –ø–æ—Ä–æ–≥–∏ —ç–Ω–µ—Ä–≥–∏–∏ –∏ —Ç.–¥.
"""

from dataclasses import dataclass, field
from typing import Optional, Dict, Any
import torch

# –ò–º–ø–æ—Ä—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (delayed –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤)
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from ..utils.normalization import NormalizationManager

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º GPU –∫–∞–∫ default device –¥–ª—è –≤—Å–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
if torch.cuda.is_available():
    torch.set_default_device('cuda')
    torch.set_default_dtype(torch.float32)
    print(f"üöÄ Energy Flow: Default device set to CUDA ({torch.cuda.get_device_name()})")
else:
    print("‚ö†Ô∏è Energy Flow: CUDA not available, using CPU")


@dataclass
class EnergyConfig:
    """–û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã"""
    
    # –†–∞–∑–º–µ—Ä—ã —Ä–µ—à–µ—Ç–∫–∏
    lattice_width: int
    lattice_height: int 
    lattice_depth: int
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —ç–Ω–µ—Ä–≥–∏–∏ (–¥–ª—è —Å–∫–∞–ª—è—Ä–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [-1, 1])
    max_active_flows: int = 1000
    energy_threshold: float = 0.05  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —ç–Ω–µ—Ä–≥–∏—è –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è (–Ω–∏–∑–∫–∏–π –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)
    spawn_threshold: float = 0.6    # –ü–æ—Ä–æ–≥ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ (—É–º–µ—Ä–µ–Ω–Ω—ã–π)
    max_spawn_per_step: int = 3     # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ spawn'–æ–≤ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–µ–π
    # GRU (EnergyCarrier)
    carrier_hidden_size: int = 1024
    carrier_num_layers: int = 3
    carrier_dropout: float = 0.1
    
    # SimpleNeuron
    neuron_hidden_dim: int = 32
    neuron_output_dim: int = 64  # –î–æ–ª–∂–µ–Ω —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –≤—Ö–æ–¥–æ–º GRU
    
    # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    input_embedding_dim_from_teacher: int = 768  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ—Ç language models
    output_embedding_dim_to_teacher: int = input_embedding_dim_from_teacher # –†–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
    # embedding_per_cell –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤ embedding_mapper –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–æ–≤ —Ä–µ—à–µ—Ç–∫–∏
    
    # –û–±—É—á–µ–Ω–∏–µ
    learning_rate: float = 1e-4
    batch_size: int = 32
    gradient_clip: float = 1.0
    weight_decay: float = 1e-5
    
    # Device settings
    device: str = "cuda" if torch.cuda.is_available() else "cpu"
    dtype: torch.dtype = torch.float32
    
    # Text Bridge –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç‚Üî–∫—É–±)
    text_bridge_enabled: bool = True           # –í–∫–ª—é—á–∏—Ç—å text bridge –º–æ–¥—É–ª—å
    text_cache_enabled: bool = False           # –í–∫–ª—é—á–∏—Ç—å LRU –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
    text_cache_size: int = 10000              # –†–∞–∑–º–µ—Ä LRU –∫—ç—à–∞
    text_cache_file: Optional[str] = None     # –§–∞–π–ª –¥–ª—è –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–≥–æ –∫—ç—à–∞ (None = auto)
    text_loss_weight: float = 0.1             # –í–µ—Å text loss –≤ –æ–±—â–µ–º loss (0.0-1.0)
    iterative_correction_steps: int = 3       # –®–∞–≥–∏ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–ª—è decoder
    text_generation_max_length: int = 64      # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    text_generation_num_beams: int = 4        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ beams –¥–ª—è beam search
    text_generation_temperature: float = 1.0  # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
    
    # Adaptive max_steps (convergence detection)
    convergence_enabled: bool = True         # –í–∫–ª—é—á–∏—Ç—å –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
    convergence_threshold: float = 0.95      # –ü–æ—Ä–æ–≥ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏–∏ (–¥–æ–ª—è –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã—Ö –≤—ã—Ö–æ–¥–æ–≤)
    convergence_min_steps: int = 5           # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤
    convergence_patience: int = 3            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∞
    
    # Logging
    log_interval: int = 10
    checkpoint_interval: int = 100
    
    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (experimental features)
    initial_z_bias: float = 1.0  # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π bias –¥–ª—è Z –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (–ø–æ–º–æ—â—å –Ω–µ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏)
    use_forward_movement_bias: bool = False  # –í–∫–ª—é—á–∞—Ç—å –ª–∏ bias –¥–ª—è –¥–≤–∏–∂–µ–Ω–∏—è –≤–ø–µ—Ä–µ–¥
    progressive_z_multiplier: float = 2.1  # –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ bias'–∞
    exploration_noise: float = 0.5  # –°–ª—É—á–∞–π–Ω—ã–π —à—É–º –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –ø—É—Ç–µ–π
    use_exploration_noise: bool = True  # –í–∫–ª—é—á–∞—Ç—å –ª–∏ exploration noise
    
    def __post_init__(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤
        assert self.lattice_width > 0, "lattice_width –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å > 0"
        assert self.lattice_height > 0, "lattice_height –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å > 0"
        assert self.lattice_depth > 0, "lattice_depth –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å > 0"
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–µ—Ç–æ–∫ –Ω–∞ –≤—Ö–æ–¥–Ω–æ–π/–≤—ã—Ö–æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω–µ
        self.input_cells = self.lattice_width * self.lattice_height
        self.output_cells = self.lattice_width * self.lattice_height
        
        # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –≤ embedding_mapper –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —ç–Ω–µ—Ä–≥–∏–∏
        assert 0 < self.energy_threshold < 1, "energy_threshold –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ (0, 1)"
        assert 0 < self.spawn_threshold <= 1, "spawn_threshold –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ (0, 1]"
        assert self.max_spawn_per_step > 0, "max_spawn_per_step –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π
        assert self.carrier_hidden_size > 0, "carrier_hidden_size –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0"
        assert self.carrier_num_layers > 0, "carrier_num_layers –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0"
        assert self.neuron_hidden_dim > 0, "neuron_hidden_dim –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0"
        assert self.neuron_output_dim > 0, "neuron_output_dim –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ Text Bridge –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if self.text_bridge_enabled:
            assert 0.0 <= self.text_loss_weight <= 1.0, "text_loss_weight –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ [0.0, 1.0]"
            assert self.text_cache_size > 0, "text_cache_size –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0"
            assert self.iterative_correction_steps > 0, "iterative_correction_steps –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0"
            assert self.text_generation_max_length > 0, "text_generation_max_length –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0"
            assert self.text_generation_num_beams > 0, "text_generation_num_beams –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0"
            assert self.text_generation_temperature > 0, "text_generation_temperature –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ convergence –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if self.convergence_enabled:
            assert 0.0 < self.convergence_threshold <= 1.0, "convergence_threshold –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ (0.0, 1.0]"
            assert self.convergence_min_steps > 0, "convergence_min_steps –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0"
            assert self.convergence_patience > 0, "convergence_patience –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0"
        
        # –°–æ–∑–¥–∞–µ–º NormalizationManager
        self._normalization_manager = None  # Lazy initialization
    
    @property
    def total_cells(self) -> int:
        """–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–µ—Ç–æ–∫ –≤ —Ä–µ—à–µ—Ç–∫–µ"""
        return self.lattice_width * self.lattice_height * self.lattice_depth
    
    @property 
    def surface_dimension(self) -> int:
        """–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –∫—É–±–∞ (–¥–ª—è text_bridge)"""
        return self.lattice_width * self.lattice_height
    
    def to_dict(self) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"""
        return {
            k: v for k, v in self.__dict__.items() 
            if not k.startswith('_') and not callable(v)
        }
    
    @property
    def normalization_manager(self) -> 'NormalizationManager':
        """–ü–æ–ª—É—á–µ–Ω–∏–µ NormalizationManager (lazy initialization)"""
        if self._normalization_manager is None:
            from ..utils.normalization import create_normalization_manager
            self._normalization_manager = create_normalization_manager(
                self.lattice_width, self.lattice_height, self.lattice_depth
            )
        return self._normalization_manager


# –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤

def create_debug_config() -> EnergyConfig:
    """–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º text_bridge"""
    return EnergyConfig(
        lattice_width=20,
        lattice_height=20,
        lattice_depth=10,
        max_active_flows=1000,
        energy_threshold=0.01,  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (—Å–∫–∞–ª—è—Ä–Ω–∞—è —ç–Ω–µ—Ä–≥–∏—è)
        spawn_threshold=0.7,    # –ù–µ–º–Ω–æ–≥–æ –≤—ã—à–µ –±–∞–∑–æ–≤–æ–≥–æ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è spawn'–æ–≤
        max_spawn_per_step=2,   # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π spawn –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        batch_size=8,
        carrier_hidden_size=256,  # –£–º–µ–Ω—å—à–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        carrier_num_layers=2,
        carrier_dropout=0.05,   # –ù–∏–∑–∫–∏–π dropout –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        log_interval=1,
        
        # Text Bridge –≤–∫–ª—é—á–µ–Ω –¥–ª—è debug
        text_bridge_enabled=True,
        text_cache_enabled=False,  # –û—Ç–∫–ª—é—á–µ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        text_cache_size=1000,          # –ú–µ–Ω—å—à–∏–π –∫—ç—à –¥–ª—è debug
        text_loss_weight=0.2,          # –ü–æ–≤—ã—à–µ–Ω–Ω—ã–π –≤–µ—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è text bridge
        iterative_correction_steps=2,  # –ú–µ–Ω—å—à–µ —à–∞–≥–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã
        text_generation_max_length=32, # –ö–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è debug
        text_generation_num_beams=2,   # –ú–µ–Ω—å—à–µ beams –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        text_generation_temperature=0.8
    )


def create_experiment_config() -> EnergyConfig:
    """–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤"""
    return EnergyConfig(
        lattice_width=50,
        lattice_height=50,
        lattice_depth=20,
        max_active_flows=5000,
        batch_size=16,
        carrier_hidden_size=512,
        carrier_num_layers=2,
        
        # Text Bridge –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
        text_bridge_enabled=True,
        text_cache_enabled=True,
        text_cache_size=5000,
        text_loss_weight=0.15,
        iterative_correction_steps=3,
        text_generation_max_length=48,
        text_generation_num_beams=3,
        text_generation_temperature=0.9
    )


def create_optimized_config() -> EnergyConfig:
    """–ü–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è RTX 5090"""
    return EnergyConfig(
        lattice_width=100,
        lattice_height=100,
        lattice_depth=50,
        max_active_flows=10000,
        batch_size=32,
        carrier_hidden_size=1024,
        carrier_num_layers=3,
        
        # Text Bridge –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        text_bridge_enabled=True,
        text_cache_enabled=True,
        text_cache_size=10000,         # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∫—ç—à
        text_loss_weight=0.1,          # –ë–∞–∑–æ–≤—ã–π –≤–µ—Å
        iterative_correction_steps=3,  # –ü–æ–ª–Ω—ã–µ —à–∞–≥–∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
        text_generation_max_length=64, # –ü–æ–ª–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞
        text_generation_num_beams=4,   # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
        text_generation_temperature=1.0
    )


# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
_global_config: Optional[EnergyConfig] = None


def set_energy_config(config: EnergyConfig):
    """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
    global _global_config
    _global_config = config


def get_energy_config() -> EnergyConfig:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
    if _global_config is None:
        raise RuntimeError("Energy config not set. Call set_energy_config() first.")
    return _global_config