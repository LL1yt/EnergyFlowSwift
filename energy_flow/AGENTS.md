# CLAUDE.md — Energy Flow (краткий старт для LLM)

Цель: дать ИИ минимально-достаточный контекст о проекте energy_flow для начала работы без истории чата. Держи ответы краткими, практичными и ориентированными на код.

—

### Контекст проекта

- Исследовательский проект на одного разработчика
- Структура: AA/ , AA/new_rebuild/ (легаси), AA/archive/ (старые версии) AA/energy_flow/ (активная разработка)
- Тесты и трейнеры запускаются из корня AA/

## Принципы работы

**Приоритет: вдумчивость, постепенность, эффективность**

- Сначала разобраться в проблеме, потом действовать
- Простой вариант → тесты → оптимизация при необходимости

### Основные принципы

- Модульность
- Централизованные конфигурации и логирование
- Минимальные церемонии, максимальная эффективность
- Современные языковые возможности
- Прямолинейные решения вместо сложных абстракций
- Проект исследовательский, не продакшн
- Без fallback - лучше ошибка чем костыли
- RTX 5090 32GB - используем по максимуму. стараемся не использовать cpu там где это может замедлить gpu

### Что исключаем

- **НЕТ** CLI автоматизации
- **НЕТ** Множественных конфигураций
- **НЕТ** Legacy совместимости
- **НЕТ** Динамических конфигураций
- **НЕТ** хардкодам
- **НЕТ** fallback

Проект кратко

- Исследовательская энергетическая архитектура на 3D решетке. Энергия представлена RNN-потоками (GRU), которые перемещаются через простые одинаковые нейроны по всей решетке.
- Потоки параллельны и независимы. Выход агрегируется на выходной поверхности куба и сравнивается с целевыми surface embeddings (есть двунаправочный текстовый мост).
- Максимум эффективности на GPU, минимум церемоний. Проект исследовательский, не продакшн.

Ключевые директории (внутри energy_flow/)

- config/ — EnergyConfig и фабрики (DEBUG/EXPERIMENT/OPTIMIZED)
- core/ — ядро:
  - energy_carrier.py — GRU-поток (EnergyCarrier), выдает next_position, энергию и spawn_info
  - simple_neuron.py — легкий нейрон для каждой клетки, формирует вход для GRU
  - energy_lattice.py — 3D решетка, хранит/обновляет потоки, буферизует выход
  - flow_processor.py — координация шагов, параллельная обработка, сбор выхода
  - embedding_mapper.py — маппинг 768D ↔ surface_dim и сбор выходов
- text_bridge/ — текст ↔ surface embeddings (инверсия/валидация, кэш)
- training/ — EnergyTrainer, цикл обучения
- utils/ — логирование, управление устройствами и хелперы

Инварианты и правила

- Координаты нормализованы в диапазоне [-1, 1]. После любых смещений обязателен clamp.
- Движение по оси Z из центра к краевым-выходным поверхностям. Выходы буферизуются и собираются взвешенно.
- Все новые тензоры по умолчанию создаются на GPU (если доступен).
- Размерность поверхности: surface_dim = lattice_width × lattice_height; должна согласовываться с маппером и текстовым мостом.
- Общие веса для нейрона и для EnergyCarrier по всей решетке. Спавн потоков ограничен конфигом.

Режимы конфигурации

- DEBUG: 20×20×10, уменьшенные размеры моделей, много логов
- EXPERIMENT: 28×28×60, баланс - сейчас тут работаем
- OPTIMIZED: 100×100×50, минимум логов

Минимальный рабочий сценарий (псевдокод)

1. Создай конфиг (например EXPERIMENT) и установи его в проекте
2. Инициализируй ядро: Lattice3D, SimpleNeuron, EnergyCarrier, FlowProcessor
3. Подай входные эмбеддинги (768D → mapper → surface) и выполнй шаги распространения
4. Собери выход с поверхности и верни в embedding/text пространство при необходимости

Что важно при изменениях

- Сначала простой корректный вариант → потом профилирование и векторизация. Убирай Python-циклы из горячих путей.
- Никаких fallback/скрытой магии: лучше явная ошибка, чем неявная деградация.
- Централизованное логирование, уважай кастомные уровни DEBUG\_\*.
- Проверяй согласованность размерностей при любом изменении surface/решетки/мостов.

Частые ошибки, которых избегаем

- Округление координат до сетки до финального clamp: теряются мелкие смещения → залипание.
- Поиск ближайшей точки решетки через полный перебор: используй арифметическое квантование индексов.
- Дубли/полупустые ветки кода: держи одну реализацию и заполняй все ветви возвращаемыми значениями.
- Несогласованность конфигов с чекпоинтами: валидируй соответствие ключевых параметров при загрузке.

Быстрые ссылки по компонентам

- EnergyCarrier.forward → выдает structured_output: energy_value, next_position, spawn_info
- EnergyLattice: буферизованный сбор выхода, корректировка координат за пределами решетки
- FlowProcessor: шаги, батчевая обработка SimpleNeuron → EnergyCarrier, гибридный сбор выхода
- EmbeddingMapper: 768D ↔ surface_dim, сбор и инверсия для оценки
- Text Bridge: валидация/инверсия surface embeddings ↔ текст (легковесные модели, LRU-кэш)

Стиль и приоритеты

- Краткость, прямолинейность, измеримая польза. Сначала работающее решение, затем оптимизация только по данным профилирования.
- Используем возможности GPU по максимуму (векторизация, отсутствие лишних .clone, отсутствие циклов по батчу).
- Тесты — простые проверочные прогоны и sanity-check на реальных путях данных/обучения.

Если контекст отсутствует

- Предполагай запуск в DEBUG-конфигурации и включенное логирование. Не изобретай новых абстракций — следуй существующей архитектуре и соглашениям.

---

### SNLI: caching / fraction vs limit (2025-09 update)

Новая семантика выборки SNLI для воспроизводимости и скорости:

1. `snli_fraction` определяет размер базового поднабора train (sample без замены). Он формируется один раз и кэшируется как JSONL в `cache/snli/`.
2. `snli_seed` (если указан) делает выборку детерминированной. Меняешь seed или fraction — получаешь новый файл.
3. `--snli-limit` / `max_samples` теперь лишь срез (truncate) уже подготовленного базового поднабора; не вызывает новую выборку и не влияет на кэш.
4. Первый вызов даже с лимитом создаёт полный subset по fraction, потом обрезает результат.
5. Для обновления данных: удали соответствующий cache-файл или измени fraction/seed.
6. Преимущества: стабильные эксперименты, единообразная статистика, отсутствие пересекающихся ограничений.

Рекомендуемый паттерн: подбирай достаточно большую `snli_fraction` (например 0.3) для охвата разнообразия; используй `--snli-limit` для быстрых итераций на подмножестве без пересборки кэша.
