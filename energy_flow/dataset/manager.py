"""
DatasetManager - —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏
===========================================================

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è:
- –ü—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ —É—á–∏—Ç–µ–ª—è
- –ó–∞–≥—Ä—É–∑–∫–∏ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
- –ì–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –æ—Ç –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è
- –°–æ–∑–¥–∞–Ω–∏—è DataLoader –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
"""

import torch
from torch.utils.data import Dataset, DataLoader
from typing import List, Dict, Tuple, Optional, Any, Union
from pathlib import Path
import time

from .config import DatasetConfig
from .providers import (
    BaseDataProvider, 
    TeacherModelProvider, 
    SNLIProvider, 
    PrecomputedProvider,
    create_teacher_model_provider,
    create_snli_provider,
    create_precomputed_provider
)
from ..config import EnergyConfig
from ..utils.logging import get_logger, DEBUG_INIT, DEBUG_TRAINING

logger = get_logger(__name__)


class EnergyFlowDataset(Dataset):
    """
    Dataset –∫–ª–∞—Å—Å –¥–ª—è energy_flow –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    
    –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –ø–∞—Ä–∞–º (input_text, target_text)
    –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º –æ—Ç –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è
    """
    
    def __init__(self, text_pairs: List[Tuple[str, str]], 
                 input_embeddings: torch.Tensor, 
                 target_embeddings: torch.Tensor,
                 metadata: Optional[List[Dict]] = None):
        """
        Args:
            text_pairs: –°–ø–∏—Å–æ–∫ –ø–∞—Ä (input_text, target_text)
            input_embeddings: –í—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ [N, embed_dim]
            target_embeddings: –¶–µ–ª–µ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ [N, embed_dim]
            metadata: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã
        """
        assert len(text_pairs) == len(input_embeddings) == len(target_embeddings), \
            f"Size mismatch: {len(text_pairs)} texts vs {len(input_embeddings)} vs {len(target_embeddings)} embeddings"
        
        self.text_pairs = text_pairs
        self.input_embeddings = input_embeddings
        self.target_embeddings = target_embeddings
        self.metadata = metadata or [{}] * len(text_pairs)
        
    def __len__(self) -> int:
        return len(self.text_pairs)
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        return {
            'input_text': self.text_pairs[idx][0],
            'target_text': self.text_pairs[idx][1],
            'input_embedding': self.input_embeddings[idx],
            'target_embedding': self.target_embeddings[idx],
            'metadata': self.metadata[idx]
        }


class DatasetManager:
    """
    –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏ energy_flow
    
    –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
    - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è
    - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
    - –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
    - –°–æ–∑–¥–∞–Ω–∏–µ DataLoader –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    """
    
    def __init__(self, config: DatasetConfig, energy_config: Optional[EnergyConfig] = None):
        """
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
            energy_config: –û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è energy_flow (–¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏)
        """
        self.config = config
        self.energy_config = energy_config
        
        # –û–±–Ω–æ–≤–ª—è–µ–º config –∏–∑ energy_config –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω
        if energy_config:
            self.config.update_from_energy_config(energy_config)
        
        # –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        self.teacher_provider: Optional[TeacherModelProvider] = None
        self.providers: Dict[str, BaseDataProvider] = {}
        
        # –ö—ç—à –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self._prepared_dataset: Optional[EnergyFlowDataset] = None
        self._dataset_statistics: Optional[Dict[str, Any]] = None
        
        logger.log(DEBUG_INIT, f"DatasetManager initialized: sources={config.dataset_sources}")
    
    def ensure_teacher_model(self) -> bool:
        """
        –£–±–µ–∂–¥–∞–µ—Ç—Å—è —á—Ç–æ –º–æ–¥–µ–ª—å-—É—á–∏—Ç–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ
        
        Returns:
            True –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞
        """
        logger.info("üîç Checking teacher model availability...")
        
        if self.teacher_provider is None:
            self.teacher_provider = create_teacher_model_provider(self.config)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
        if not self.teacher_provider.is_available():
            logger.info("üì• Teacher model not available locally, attempting download...")
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
            if not self.teacher_provider.download_model_if_needed():
                logger.error("‚ùå Failed to download teacher model")
                return False
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä
        if not self.teacher_provider.ensure_initialized():
            logger.error("‚ùå Failed to initialize teacher model")
            return False
        
        logger.info(f"‚úÖ Teacher model ready: {self.config.teacher_model}")
        return True
    
    def initialize_providers(self) -> Dict[str, bool]:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        """
        logger.info(f"üîß Initializing data providers: {self.config.dataset_sources}")
        
        results = {}
        
        for source in self.config.dataset_sources:
            try:
                if source == "precomputed":
                    provider = create_precomputed_provider(self.config)
                elif source == "snli":
                    provider = create_snli_provider(self.config, self.teacher_provider)
                else:
                    logger.warning(f"‚ùå Unknown data source: {source}")
                    results[source] = False
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º
                if provider.is_available() and provider.ensure_initialized():
                    self.providers[source] = provider
                    results[source] = True
                    logger.info(f"‚úÖ {source} provider ready")
                else:
                    logger.warning(f"‚ö†Ô∏è {source} provider not available")
                    results[source] = False
                    
            except Exception as e:
                logger.error(f"‚ùå Failed to initialize {source} provider: {e}")
                results[source] = False
        
        available_count = sum(results.values())
        logger.info(f"üìä Provider initialization: {available_count}/{len(self.config.dataset_sources)} available")
        
        return results
    
    def prepare_dataset(self, force_reload: bool = False) -> Optional[EnergyFlowDataset]:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        
        Args:
            force_reload: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–∂–µ –µ—Å–ª–∏ –µ—Å—Ç—å –∫—ç—à
            
        Returns:
            EnergyFlowDataset –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        if self._prepared_dataset is not None and not force_reload:
            logger.info("üìã Using cached dataset")
            return self._prepared_dataset
        
        logger.info("üîÑ Preparing unified dataset...")
        start_time = time.time()
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ teacher model –≥–æ—Ç–æ–≤
        if not self.ensure_teacher_model():
            logger.error("‚ùå Teacher model not available, cannot prepare dataset")
            return None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
        provider_results = self.initialize_providers()
        available_providers = [name for name, available in provider_results.items() if available]
        
        if not available_providers:
            logger.error("‚ùå No data providers available")
            return None
        
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
        all_text_pairs = []
        all_input_embeddings = []
        all_target_embeddings = []
        all_metadata = []
        
        for provider_name in available_providers:
            provider = self.providers[provider_name]
            
            try:
                logger.info(f"üì• Loading data from {provider_name}...")
                
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
                provider_data = provider.get_mixed_data(self.config.max_samples_per_source)
                
                if provider_data['count'] > 0:
                    # –î–æ–±–∞–≤–ª—è–µ–º –∫ –æ–±—â–∏–º –¥–∞–Ω–Ω—ã–º
                    all_text_pairs.extend(provider_data['text_pairs'])
                    all_input_embeddings.append(provider_data['input_embeddings'])
                    all_target_embeddings.append(provider_data['target_embeddings'])
                    
                    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                    provider_metadata = [{'source': provider_name} for _ in range(provider_data['count'])]
                    all_metadata.extend(provider_metadata)
                    
                    logger.info(f"‚úÖ {provider_name}: {provider_data['count']} samples loaded")
                else:
                    logger.warning(f"‚ö†Ô∏è {provider_name}: no data available")
                    
            except Exception as e:
                logger.error(f"‚ùå Failed to load data from {provider_name}: {e}")
                continue
        
        if not all_text_pairs:
            logger.error("‚ùå No data loaded from any provider")
            return None
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        combined_input_embeddings = torch.cat(all_input_embeddings, dim=0)
        combined_target_embeddings = torch.cat(all_target_embeddings, dim=0)
        
        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        if self.config.shuffle_data:
            indices = torch.randperm(len(all_text_pairs))
            all_text_pairs = [all_text_pairs[i] for i in indices]
            combined_input_embeddings = combined_input_embeddings[indices]
            combined_target_embeddings = combined_target_embeddings[indices]
            all_metadata = [all_metadata[i] for i in indices]
        
        # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        dataset = EnergyFlowDataset(
            text_pairs=all_text_pairs,
            input_embeddings=combined_input_embeddings,
            target_embeddings=combined_target_embeddings,
            metadata=all_metadata
        )
        
        preparation_time = time.time() - start_time
        
        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        self._prepared_dataset = dataset
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._dataset_statistics = self._compute_dataset_statistics(dataset, available_providers, preparation_time)
        
        logger.info(f"‚úÖ Dataset prepared: {len(dataset)} samples in {preparation_time:.2f}s")
        logger.log(DEBUG_TRAINING, f"Dataset embedding shapes: input={combined_input_embeddings.shape}, "
                                  f"target={combined_target_embeddings.shape}")
        
        return dataset
    
    def create_dataloader(self, batch_size: Optional[int] = None, 
                         shuffle: Optional[bool] = None,
                         num_workers: int = 0) -> Optional[DataLoader]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ DataLoader –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ config)
            shuffle: –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ config)
            num_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ worker –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
            
        Returns:
            DataLoader –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        dataset = self.prepare_dataset()
        if dataset is None:
            return None
        
        effective_batch_size = batch_size or self.config.batch_size
        effective_shuffle = shuffle if shuffle is not None else self.config.shuffle_data
        
        dataloader = DataLoader(
            dataset,
            batch_size=effective_batch_size,
            shuffle=effective_shuffle,
            num_workers=num_workers,
            pin_memory=torch.cuda.is_available(),
            drop_last=True  # –î–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
        )
        
        logger.info(f"üì¶ DataLoader created: batch_size={effective_batch_size}, "
                   f"shuffle={effective_shuffle}, batches={len(dataloader)}")
        
        return dataloader
    
    def get_teacher_embeddings(self, texts: List[str]) -> torch.Tensor:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –æ—Ç –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
        
        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            –¢–µ–Ω–∑–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ [len(texts), embed_dim]
        """
        if not self.ensure_teacher_model():
            raise RuntimeError("Teacher model not available")
        
        return self.teacher_provider.encode_texts(texts)
    
    def validate_setup(self) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        """
        logger.info("üîç Running comprehensive setup validation...")
        
        validation_results = {
            'teacher_model': False,
            'providers': {},
            'dataset_preparation': False,
            'overall_status': False,
            'errors': [],
            'warnings': []
        }
        
        try:
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ teacher model
            if self.ensure_teacher_model():
                validation_results['teacher_model'] = True
                logger.info("‚úÖ Teacher model validation passed")
            else:
                validation_results['errors'].append("Teacher model not available")
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
            provider_results = self.initialize_providers()
            validation_results['providers'] = provider_results
            
            available_providers = sum(provider_results.values())
            if available_providers > 0:
                logger.info(f"‚úÖ Data providers validation: {available_providers} available")
            else:
                validation_results['errors'].append("No data providers available")
            
            # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
            if validation_results['teacher_model'] and available_providers > 0:
                dataset = self.prepare_dataset()
                if dataset is not None and len(dataset) > 0:
                    validation_results['dataset_preparation'] = True
                    logger.info(f"‚úÖ Dataset preparation successful: {len(dataset)} samples")
                else:
                    validation_results['errors'].append("Dataset preparation failed")
            
            # 4. –û–±—â–∏–π —Å—Ç–∞—Ç—É—Å
            validation_results['overall_status'] = (
                validation_results['teacher_model'] and
                available_providers > 0 and
                validation_results['dataset_preparation']
            )
            
            if validation_results['overall_status']:
                logger.info("üéâ Setup validation PASSED - system ready for training")
            else:
                logger.warning("‚ö†Ô∏è Setup validation FAILED - issues need to be resolved")
            
        except Exception as e:
            logger.error(f"‚ùå Validation error: {e}")
            validation_results['errors'].append(f"Validation exception: {e}")
        
        return validation_results
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É"""
        if self._dataset_statistics is None:
            self.prepare_dataset()  # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –µ—Å–ª–∏ –µ—â–µ –Ω–µ –≥–æ—Ç–æ–≤–æ
        
        return self._dataset_statistics or {'error': 'No statistics available'}
    
    def _compute_dataset_statistics(self, dataset: EnergyFlowDataset, 
                                   providers: List[str], preparation_time: float) -> Dict[str, Any]:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É"""
        stats = {
            'total_samples': len(dataset),
            'providers_used': providers,
            'preparation_time_seconds': preparation_time,
            'embedding_dimension': dataset.input_embeddings.shape[1],
            'config': self.config.to_dict()
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –¥–∞–Ω–Ω—ã—Ö
        source_counts = {}
        for metadata in dataset.metadata:
            source = metadata.get('source', 'unknown')
            source_counts[source] = source_counts.get(source, 0) + 1
        
        stats['source_distribution'] = source_counts
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–ª–∏–Ω–∞–º —Ç–µ–∫—Å—Ç–æ–≤
        input_lengths = [len(pair[0].split()) for pair in dataset.text_pairs[:1000]]  # –í—ã–±–æ—Ä–∫–∞
        target_lengths = [len(pair[1].split()) for pair in dataset.text_pairs[:1000]]
        
        if input_lengths:
            stats['text_statistics'] = {
                'avg_input_length': sum(input_lengths) / len(input_lengths),
                'avg_target_length': sum(target_lengths) / len(target_lengths),
                'max_input_length': max(input_lengths),
                'max_target_length': max(target_lengths)
            }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º
        input_norms = torch.norm(dataset.input_embeddings[:1000], dim=1)  # –í—ã–±–æ—Ä–∫–∞
        target_norms = torch.norm(dataset.target_embeddings[:1000], dim=1)
        
        stats['embedding_statistics'] = {
            'input_norm_mean': input_norms.mean().item(),
            'input_norm_std': input_norms.std().item(),
            'target_norm_mean': target_norms.mean().item(),
            'target_norm_std': target_norms.std().item()
        }
        
        return stats
    
    def clear_cache(self):
        """–û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –∫—ç—à–µ–π"""
        self._prepared_dataset = None
        self._dataset_statistics = None
        
        if self.teacher_provider:
            self.teacher_provider.clear_cache()
        
        for provider in self.providers.values():
            if hasattr(provider, 'clear_cache'):
                provider.clear_cache()
        
        logger.info("üßπ All caches cleared")


def create_dataset_manager(config: DatasetConfig, 
                          energy_config: Optional[EnergyConfig] = None) -> DatasetManager:
    """
    –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è DatasetManager
    
    Args:
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
        energy_config: –û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è energy_flow
        
    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π DatasetManager
    """
    return DatasetManager(config, energy_config)