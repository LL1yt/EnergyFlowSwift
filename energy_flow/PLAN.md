# Energy Flow Architecture - Подробный план реализации

## Концепция

Энергетическая архитектура на основе 3D решетки, где энергия (представленная RNN-моделями) течет через простые нейроны-автоматы. Ключевая идея - параллельная обработка независимых энергетических потоков вместо последовательной обработки клеток.

## Архитектура системы

### Структура проекта

```
energy_flow/
├── config/
│   ├── __init__.py
│   ├── energy_config.py       # Конфигурация энергетической системы
│   └── base_config.py         # Базовая конфигурация (адаптированная из new_rebuild)
├── core/
│   ├── __init__.py
│   ├── energy_carrier.py      # RNN-based энергетические потоки
│   ├── simple_neuron.py       # Простой нейрон-автомат
│   ├── energy_lattice.py      # 3D решетка для потоков
│   └── flow_processor.py      # Механизм распространения энергии
├── text_bridge/              # ✅ НОВЫЙ: Двунаправленное преобразование текст↔куб
│   ├── __init__.py
│   ├── text_to_cube_encoder.py    # Текст → Surface Embeddings (~9M параметров)
│   ├── cube_to_text_decoder.py    # Surface Embeddings → Текст (~61M параметров)
│   └── text_cache.py             # LRU кэш для известных пар с персистентным хранением
├── training/
│   ├── __init__.py
│   └── energy_trainer.py      # Тренировочный цикл адаптируем из new_rebuild\core\training\embedding_trainer.py
├── utils/
│   ├── __init__.py
│   ├── logging.py            # (копируем из new_rebuild)
│   ├── device_manager.py     # (адаптируем из new_rebuild)
│   └── helpers.py            # Вспомогательные функции
└── examples/
    └── simple_training.py     # Пример использования
```

координаты и часть входного эмбединга передаются в SimpleNeuron - он на основе этого и своих весов высчитывает некоторое значение, которое мы передаем RNN и так же передаем значение входного эмбединга для этого шага - она так же на основании своих весов высчитывает определенное значение - это значение должно содержать изменение сигнала (или энергии или части эмбединга), который мы изначально запустили от обучающей модели, можно называть по разному для лучшего понимания, так же должен содержать координаты для следующего нейрона(с которым будет взаимодействовать эта RNN) и набор возможных новых RNN, которые пойдут из этого нейрона с возможностью ограничения их количества через конфиг. получается, что вывод должен быть структурированный, а размера выхода SimpleNeuron, должен соответствовать входу RNN. так же нам нужно уделить внимание и проверить размерности нейронок, что бы они сочетались по входным и выходным параметрам

## Компоненты системы

### 1. EnergyCarrier (energy_carrier.py)

**Назначение**: Представление энергии в виде GRU-модели

**Характеристики**:

- ~10M параметров
- GRU с hidden_size=1024, num_layers=3
- Входной эмбеддинг: часть от входного эмбединга обучающей модели можно посмотреть как тут реализовано new_rebuild\core\training\embedding_lattice_mapper.py, но нам не нужно состояние всех клеток, а мы работаем только с входной и выходной стороной
- Внутреннее состояние: скрытое состояние GRU
- Выход: структурированный вывод через projection head
- Общие веса для всех GRU в решетке

**Структура вывода EnergyCarrier**:

```python
{
    'energy_value': torch.Tensor,      # Текущая энергия/эмбеддинг; 768D эмбеддинг → маппер → каждый EnergyCarrier на входе получает соответствующее значение от маппера(тоже, что и соответствующий нейрон)
    'next_position': torch.Tensor,     # Координаты следующей клетки (3D)
    'spawn_info': List[SpawnInfo]      # Структурированная информация о spawn'ах
}
```

**Ключевые методы**:

- `__init__(hidden_size=1024, num_layers=3)`
- `forward(neuron_output, hidden_state)` → structured_output, new_hidden_state
- `can_spawn(energy_level)` → bool
- `spawn(parent_energy)` → новый EnergyCarrier с частью энергии

### 2. SimpleNeuron (simple_neuron.py)

**Назначение**: Простой нейрон-автомат в каждой клетке решетки

**Характеристики**:

- ~1000 параметров
- Архитектура: координаты (3D) + энергия части входного эмбединга → 64 скрытых → выход для RNN
- Общие веса для всех нейронов в решетке
- Выходной размер должен соответствовать входу GRU

**Входные данные**:

- Координаты клетки (x, y, z) - 3 значения

**Ключевые методы**:

- `__init__(coord_dim=3, extra_features=0, hidden_dim=64, output_dim=128)`
- `forward(position, extra_features=None)` → neuron_output (для передачи в GRU)
- `compute_features(position, lattice_state)` → extra_features

### 3. EnergyLattice (energy_lattice.py)

**Назначение**: 3D решетка для управления потоками

**Характеристики**:

- Размеры: width × height × depth
- Хранит активные потоки и их позиции
- Управляет бюджетом потоков
- **✅ РЕАЛИЗОВАНА буферизованная система сбора**

**Размеры по режимам**:

- DEBUG: 20×20×10 (4,000 клеток)
- EXPERIMENT: 50×50×20 (50,000 клеток)
- OPTIMIZED: 100×100×50 (500,000 клеток)

**Ключевые методы**:

- `__init__(width, height, depth, max_flows=1000)`
- `place_initial_energy(embeddings)` → размещение на входной стороне
- `get_active_flows()` → список активных потоков
- **✅ Буферизованная система сбора:**
  - `_buffer_output_flow(flow_id)` → автоматическая буферизация при достижении выхода
  - `collect_buffered_energy()` → умный сбор из буфера с взвешенным усреднением
  - `collect_output_energy()` → совместимая обертка над буферизованным сбором
  - `clear_output_buffer()` → управление жизненным циклом буфера
  - `get_buffered_flows_count()` → количество потоков в буфере

**✅ Умная обработка координат за пределами решетки:**

- Потоки за пределами (z > depth-1) автоматически корректируются к выходной стороне
- Множественные потоки в одной клетке объединяются взвешенным усреднением
- Вес = energy_magnitude × (1 + age × 0.1) - учитывает энергию и возраст потока

### 4. FlowProcessor (flow_processor.py)

**Назначение**: Механизм распространения энергии и координации компонентов

**Ключевые особенности**:

- Энергия может двигаться только вперед (по оси Z)
- ✅ **EnergyCarrier полностью определяет координаты** на основе своих весов
- При высокой энергии может создавать новые потоки
- Параллельная обработка всех потоков
- **✅ РЕАЛИЗОВАНА гибридная система координации**

**Ключевые методы**:

- `__init__(lattice, neuron, carrier, config)`
- `forward(input_embeddings, max_steps)` → полный проход с координацией компонентов
- `step(active_flows)` → один шаг распространения всех потоков
- `_process_flow_batch(flows)` → батчевая обработка с SimpleNeuron → EnergyCarrier
- **✅ Гибридная система сбора:**
  - `_collect_final_output()` → проверяет активные потоки И буфер
  - Автоматически добавляет оставшиеся потоки в буфер
  - Координирует жизненный цикл потоков
  - Очищает буфер после успешного сбора

**✅ Исправления технических проблем:**

- `.contiguous()` для исправления `rnn: hx is not contiguous`
- Правильное транспонирование hidden states: `[batch, layers, hidden] ↔ [layers, batch, hidden]`
- Координация устройств между компонентами

## Конфигурация системы

### EnergyConfig (energy_config.py)

```python
@dataclass
class EnergyConfig:
    # Размеры решетки
    lattice_width: int
    lattice_height: int
    lattice_depth: int

    # Параметры энергии
    max_active_flows: int = 1000
    energy_threshold: float = 0.1  # Минимальная энергия для продолжения
    spawn_threshold: float = 0.8   # Порог для создания новых потоков
    max_spawn_per_step: int = 10   # Максимум новых потоков за шаг

    # Параметры моделей
    carrier_hidden_size: int = 1024
    carrier_num_layers: int = 3
    neuron_hidden_dim: int = 64

    # Обучение
    learning_rate: float = 1e-4
    batch_size: int = 32
```

### Режимы работы

```python
# ✅ РЕАЛИЗОВАННЫЕ КОНФИГУРАЦИИ

DEBUG_CONFIG = EnergyConfig(
    lattice_width=20, lattice_height=20, lattice_depth=10,
    max_active_flows=1000, batch_size=8,
    energy_threshold=0.01,  # Низкий порог для отладки
    carrier_hidden_size=256, carrier_num_layers=2  # Уменьшенные размеры для отладки
)

EXPERIMENT_CONFIG = EnergyConfig(
    lattice_width=50, lattice_height=50, lattice_depth=20,
    max_active_flows=500, batch_size=16,
    carrier_hidden_size=512, carrier_num_layers=2
)

OPTIMIZED_CONFIG = EnergyConfig(
    lattice_width=100, lattice_height=100, lattice_depth=50,
    max_active_flows=1000, batch_size=32,
    carrier_hidden_size=1024, carrier_num_layers=3  # Полный размер для RTX 5090
)
```

## Механизм взаимодействия (детальный)

### Пошаговое взаимодействие для одной клетки:

1. **SimpleNeuron получает координаты**:

   ```python
   position = (x, y, z)
   neuron_output = simple_neuron(position)  # Размер: 128
   ```

2. **EnergyCarrier обрабатывает выход нейрона**:

   ```python
   structured_output, new_hidden = energy_carrier(
       neuron_output,
       current_hidden_state
   )
   ```

3. **Структурированный вывод содержит**:

   - `energy_value`: текущая энергия/эмбеддинг это допустим входной эмбединг от обучающей модели - мы его равномерно распределяем по нейронам входной стороны куба, тогда у нас от каждого нейрона отходит GRU со своей энергией. суть в том, что бы умно преобразовать размерность эмбединга обучающей модели в размерность входной стороны куба и передать соответственно каждому нейрону и GRU, которая от него пойдет, свое значение. по сути это скаляр, но умный, нормализованный скаляр
   - `next_position`: координаты следующей клетки (должны быть впереди)
   - `spawn_info`: структурированная информация о spawn'ах (связь batch_idx ↔ энергии)

4. **Создание новых потоков** (если spawn_info не пустой):
   - Каждый новый поток получает часть энергии родителя
   - Новые потоки начинают с текущей позиции
   - У каждого свое скрытое состояние GRU

## Механизм работы

### 1. Инициализация

- Создаем решетку заданного размера
- Инициализируем общий SimpleNeuron
- Подготавливаем пул для EnergyCarrier

### 2. Прямой проход

1. Размещаем входные эмбеддинги на входной стороне куба (z=0) new_rebuild\core\training\embedding_lattice_mapper.py - для примера, но нам не нужно состояние всех клеток, а мы работаем только с входной и выходной стороной (new_rebuild\core\common\embedding_transformer.py)
2. Для каждого эмбеддинга создаем EnergyCarrier
3. На каждом шаге:
   - Все активные потоки обрабатываются параллельно
   - SimpleNeuron преобразует координаты и текущий входной эмбединг на текущем шаге в features
   - EnergyCarrier принимает features и текущий входной эмбединг и выдает структурированный вывод
   - Проверяем валидность следующей позиции (только вперед по Z) - проверить, нужна ли тут нормализация координат.
   - Создаем новые потоки если необходимо (с учетом бюджета)
   - Обновляем позиции и состояния всех потоков
4. Собираем энергию с выходной стороны (z=depth-1). если координаты выходят за предели размеров куба - можно присваивать ближайшим координатам выходной стороны. если несколько значений - мжно делать умное усреднение.

### 3. Обучение

суть пиплайна обучения. мы берем модель-учителя, для простоты сначала берем DistilBERT с 768D, далее подготавливаем пары эмбедингов(вопрос-ответ) из датасета(generate_snli_embedding_dataset.py; precomputed_embedding_loader.py; unified_dataset_loader.py). эмбединг-вопрос(768D) мы должны равномерно распределить на входную поверхность куба. сейчас у нас есть реализация в виде energy_flow\core\embedding_mapper.py. в итоге у нас было 768 значений, а мы их умно преобразовали в размерность поверхности куба(например 20х20=400) и каждый нейрон на поверхности куба получил свое значение и так же от этого нейрона пошла GRU, которая получила такое же значение. далее происходит распределение энергии внутри куба по определенной логике и в итоге мы собираем энергии на выходной поверхности куба. общая размерность 400D - мы ее разумно преобразуем в 768D и сравниваем с эмбединг-ответом(768D) модели-учителя. так же мы хотим иметь возможность преобразовывать эмбединги от куба в текст и наоборот. это должна быть простая модель(а не модель, которая генерирует ответы на вопросы), которая умеет преобразовывать эмбединги куба в текст и обратно с возможностью(активировать через центральный конфиг, когда фразы будут осмысленны) кэширования известных сочетаний. она так же будет участвовать в процессе обучения и может давать вывод периодически, что бы дополнительно контролировать уровень обучения. после обучения она позволит нам общаться с моделью на обычном языке, а не эмбедингами.

- Сравниваем выходные эмбеддинги с целевыми
- Вычисляем loss (MSE или cosine similarity)
- Обратное распространение через:
  - Веса общего EnergyCarrier (GRU)
  - Веса общего SimpleNeuron
- Оптимизация через Adam

у нас основная линия тренеровки: мы берем пары вопрос(входные данные(текст и эмбединг))-ответ(выходные данные(текст и эмбединг)) от модели учителя. пары вопрос-ответ эмбедингов мы используем для обучения куба - для этого нам нужен маппинг эмбедингов модели-учителя(например 768D) на входную поверхность куба(например 20х20=400D) и обратно с выходной поверхности. для cube_to_text_decoder и text_to_cube_encoder - мы паралельно пытаемся обучать их независимо пока(полноценно они будут работать только после обучения, тогда и будем думать о такой интеграции). берем текст из пары вопрос-ответ и для text_to_cube_encoder это вопрос и преобразованный нашим маппером эмбединг под поверхность куба - эти значения используем для обучения. для cube_to_text_decoder мы берем выходной(ответ) эмбединг от модели-учителя, пропускаем его через наш маппинг(тут необычное действие) и получаем эмбединг ответ в формате выходной поверхности куба(его мы кстати можем использовать для обучения куба, сравнивая с реальным выходом куба - тут возможно нужно пересмотреть пиплайн, что бы два раза не преобразовывать выходные эмбединги) и эту пару используем для обучения cube_to_text_decoder
Исправленная архитектура:

     Основное обучение куба (эффективно):

     # 1. Генерируем random teacher embeddings для теста
     teacher_input_768D = torch.randn(batch_size, 768, device=device)
     teacher_target_768D = torch.randn(batch_size, 768, device=device)

     # 2. FlowProcessor работает с 768D как и задумано
     cube_output_surface_400D = flow_processor.forward(teacher_input_768D)  # 768D → surface 400D (внутри есть mapper)

     # 3. Маппим target в surface для сравнения
     target_surface_400D = flow_processor.mapper.input_mapper.forward(teacher_target_768D)  # 768D → surface 400D

     # 4. Energy loss - сравниваем на уровне surface (экономия!)
     energy_loss = mse_loss(cube_output_surface_400D, target_surface_400D)

     Text Bridge обучение (независимо):

     if text_bridge_enabled:
         # TextToCubeEncoder: учится текст → surface
         encoder_output = text_encoder.encode_text(input_texts)  # → 400D
         encoder_target = target_surface_400D.detach()  # Используем уже вычисленный!
         encoder_loss = mse_loss(encoder_output, encoder_target)

         # CubeToTextDecoder: учится surface → текст
         decoder_input = target_surface_400D.detach()  # Переиспользуем!
         decoder_output = text_decoder.decode_surface(decoder_input)
         decoder_loss = text_loss(decoder_output, target_texts)

         text_loss = encoder_loss + decoder_loss

## ✅ Модуль text_bridge - Связь с естественным языком

### Концепция

Text Bridge обеспечивает двунаправленное преобразование между естественным языком и эмбеддингами поверхности куба. Это позволяет:

1. Контролировать процесс обучения через текстовые описания
2. Общаться с обученной моделью на естественном языке
3. Кэшировать известные пары для ускорения работы

### Архитектура

**Surface Embeddings:** поверхность куба размерностью `lattice_width × lattice_height` (например, 20×20=400D для debug)

#### 1. TextToCubeEncoder (~9.1M параметров)

```python
class TextToCubeEncoder(nn.Module):
    # DistilBERT tokenizer + 2-layer transformer encoder
    # Input: text → Output: surface_embedding [surface_dim]
```

**Особенности:**

- Использует DistilBERT токенизатор
- 2-слойный transformer encoder (768 → 512 → surface_dim)
- Адаптивные размерности под конфигурацию куба
- Batch processing поддержка

#### 2. CubeToTextDecoder (~60.7M параметров)

```python
class CubeToTextDecoder(nn.Module):
    # T5-small backbone с адаптером для surface embeddings
    # Input: surface_embedding [surface_dim] → Output: text
```

**Особенности:**

- T5-small как основа для генерации текста
- Surface adapter: surface_dim → T5 hidden size (512)
- Итеративная коррекция (vec2text принципы)
- Замороженный T5 encoder для стабильности

#### 3. TextCache - LRU кэширование

```python
class TextCache:
    # Двунаправленный LRU кэш с персистентным хранением
    # text ↔ surface_embedding пары
```

**Возможности:**

- LRU кэширование с настраиваемым размером
- Персистентное хранение через torch.save/load (точность)
- Thread-safe доступ
- Статистика hit/miss rate
- Детерминированное хэширование тензоров

### Интеграция с основным обучением

**Ключевая идея:** CubeToTextDecoder может обучаться прямо в процессе основной тренировки!

```python
# Во время основного обучения:
surface_output = energy_processor(input_embedding)  # Выход куба
target_text = teacher_model_response               # Эталонный ответ

# Обучаем decoder одновременно:
predicted_text = cube_to_text_decoder(surface_output)
text_loss = criterion(predicted_text, target_text)
total_loss = energy_loss + λ * text_loss  # Комбинированный loss
```

**Преимущества:**

- Не нужен отдельный pre-training
- Decoder учится понимать семантику выходов куба
- Естественная интеграция в основной тренировочный цикл

### Конфигурационные параметры

```python
@dataclass
class EnergyConfig:
    # ... существующие параметры ...

    # Text Bridge параметры
    text_bridge_enabled: bool = False           # Включить text bridge
    text_cache_enabled: bool = False           # Включить кэширование
    text_cache_size: int = 10000              # Размер LRU кэша
    text_loss_weight: float = 0.1             # Вес text loss в общем loss
    iterative_correction_steps: int = 3       # Шаги итеративной коррекции
```

### Workflow обучения с text_bridge

1. **Подготовка данных:** пары (input_text, target_text) от модели-учителя
2. **Основное обучение:**
   - input_text → TextToCubeEncoder → surface_input
   - surface_input → EnergyProcessor → surface_output
   - Сравнение surface_output с эталонным surface_embedding (основной loss)
3. **Параллельное обучение decoder:**
   - surface_output → CubeToTextDecoder → predicted_text
   - Сравнение predicted_text с target_text (text loss)
4. **Комбинированная оптимизация:** total_loss = energy_loss + λ \* text_loss

### Использование после обучения

```python
# Общение с моделью на естественном языке
user_text = "What is machine learning?"
surface_input = text_encoder.encode_text(user_text)
surface_output = energy_processor(surface_input)
response = text_decoder.decode_surface(surface_output)
print(f"Model: {response}")
```

## Особенности реализации

### Параллелизм

- Все EnergyCarrier обрабатываются параллельно в батчах
- Используем torch.nn.parallel для эффективной обработки
- Векторизованные операции где возможно

### Управление памятью

- Пул предаллоцированных EnergyCarrier
- Переиспользование неактивных потоков
- Автоматическая очистка по порогу энергии

### Эмерджентность

- Минимум жестко заданных правил
- Путь энергии определяется обучением
- Естественное формирование "каналов" через решетку

## Интеграция с существующими компонентами

### Из new_rebuild переиспользуем:

1. **Система логирования** (utils/logging.py)

   - Custom debug levels
   - Контекстное логирование

2. **DeviceManager** (адаптированный)

   - Управление GPU/CPU
   - Мониторинг памяти

3. **Базовые хелперы**
   - Position3D для навигации
   - Batch processing утилиты

## Примерный API использования

```python
from energy_flow.config import create_experiment_config
from energy_flow.core import EnergyLattice, SimpleNeuron, FlowProcessor
from energy_flow.training import EnergyTrainer

# Конфигурация
config = create_experiment_config()

# Создание компонентов
lattice = EnergyLattice(config)
neuron = SimpleNeuron(config)
processor = FlowProcessor(lattice, neuron, config)

# Обучение
trainer = EnergyTrainer(processor, config)
trainer.train(input_embeddings, target_embeddings, epochs=100)
```

1.  Работаем только с входной и выходной сторонами куба (не со всеми клетками)
2.  SimpleNeuron получает координаты И часть входного эмбеддинга
3.  GRU получает выход SimpleNeuron И также часть входного эмбеддинга
4.  Размерности должны быть согласованы между компонентами

## Метрики и мониторинг

### Ключевые метрики:

- Количество активных потоков
- Средняя энергия потоков
- Процент достигших выхода
- Loss (MSE/cosine similarity)
- Утилизация GPU памяти

### Логирование:

- DEBUG_ENERGY: детали распространения энергии
- DEBUG_SPAWN: создание новых потоков
- DEBUG_CONVERGENCE: статистика достижения выхода

## ✅ Этапы реализации - СТАТУС

1. **✅ Базовая инфраструктура** (config, logging, device) - **ЗАВЕРШЕНО**
2. **✅ SimpleNeuron** - простейший компонент - **ЗАВЕРШЕНО И ПРОТЕСТИРОВАНО**
   - 3,504 параметра (близко к целевым ~1000)
   - Позиционное кодирование, нормализация координат, батчевая обработка
3. **✅ EnergyCarrier** - ядро системы - **ЗАВЕРШЕНО И ПРОТЕСТИРОВАНО**
   - 709,254 параметра для debug-конфигурации
   - Структурированный вывод, spawn механизм, энергетические пороги
4. **✅ EnergyLattice** - управление пространством - **ЗАВЕРШЕНО И ПРОТЕСТИРОВАНО**
   - Буферизованная система сбора, умное усреднение, управление жизненным циклом
5. **✅ FlowProcessor** - механизм распространения - **ЗАВЕРШЕНО И ПРОТЕСТИРОВАНО**
   - Гибридная координация, исправления технических проблем, статистика производительности
6. **✅ Text Bridge модуль** - связь с естественным языком - **ЗАВЕРШЕНО И ПРОТЕСТИРОВАНО**
   - TextToCubeEncoder (~9.1M параметров): текст → surface embeddings
   - CubeToTextDecoder (~60.7M параметров): surface embeddings → текст
   - TextCache: LRU кэширование с персистентным хранением (torch.save/load)
   - Готовность к интеграции в основной тренировочный цикл
7. **🔄 EnergyTrainer** - обучение с text_bridge интеграцией - **СЛЕДУЮЩИЙ ЭТАП**
8. **🔄 Простой пример** - проверка работоспособности - **СЛЕДУЮЩИЙ ЭТАП**

### ✅ Результаты тестирования:

**EnergyCarrier:**

- ✅ 758,406 параметров (debug config), spawn механизм работает
- ✅ Координаты округляются до целых для дискретной решетки
- ✅ Движение потоков согласно PLAN.md (EnergyCarrier определяет координаты)

**SimpleNeuron:**

- ✅ 2,448 параметров (выше целевых ~1000, но приемлемо)
- ✅ Позиционное кодирование создает различимые паттерны
- ⚠️ Dropout вызывает батчевую неконсистентность (оставлено для исследований)

**EnergyLattice:**

- ✅ Буферизованная система работает: 4 потока собраны из буфера
- ✅ Взвешенное усреднение: energy_magnitude × (1 + age × 0.1)
- ✅ Коррекция потоков за пределами решетки к выходной стороне

**FlowProcessor:**

- ✅ Гибридная координация: активные потоки + буфер
- ✅ Исправлена ошибка `rnn: hx is not contiguous`

**Text Bridge:**

- ✅ TextToCubeEncoder: 9,143,728 параметров, адаптивные размерности
- ✅ CubeToTextDecoder: 60,736,768 обучаемых + замороженный T5 encoder
- ✅ TextCache: torch.save/load обеспечивает точность float (исправлена проблема с numpy)
- ✅ Интеграция с моделями: кэшированные версии ускоряют повторные запросы
- ✅ Device management: все компоненты работают на default CUDA device

## 🔥 Ключевые доработки в процессе тестирования

### 1. **Буферизованная система сбора энергии**

**Проблема:** Потоки достигали выхода с разной скоростью, что требовало синхронизации.
**Решение:**

- Добавлен `output_buffer: Dict[(x,y), List[EnergyFlow]]` в EnergyLattice
- Автоматическая буферизация в `update_flow()` при `z >= depth-1`
- Умное взвешенное усреднение с учетом энергии и возраста потока

### 2. **Гибридная система координации**

**Проблема:** FlowProcessor не знал когда собирать энергию из буфера.
**Решение:**

- Цикл обработки проверяет `active_flows AND buffered_flows`
- `_collect_final_output()` координирует сбор из обоих источников
- Автоматическая очистка буфера после успешного сбора

### 3. **Логика движения потоков**

**Доработка:** EnergyCarrier теперь полностью определяет координаты на основе своих весов.

- Убрана принудительная логика "движения вперед"
- Потоки, не движущиеся вперед по Z, автоматически деактивируются
- Координаты округляются для дискретной решетки

### 4. **Технические исправления**

- **RNN contiguous memory:** `.contiguous()` после транспонирования
- **Device coordination:** правильное управление устройствами между компонентами
- **Edge cases:** корректная обработка потоков за пределами решетки

## Оптимизации (на будущее)

1. **Batch processing**: группировка потоков по позициям
2. **Sparse operations**: только активные клетки
3. **Multi-GPU**: распределение решетки по устройствам. вообще у нас пока что одна gpu 5090 32gb, так что для исследования мы оптимизируем под этот вариант
4. **Checkpoint/restore**: сохранение состояния обучения
5. **Адаптивный бюджет**: динамическое управление max_flows
