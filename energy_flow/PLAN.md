# Energy Flow Architecture - Подробный план реализации

## Концепция

Энергетическая архитектура на основе 3D решетки, где энергия (представленная RNN-моделями) течет через простые нейроны-автоматы. Ключевая идея - параллельная обработка независимых энергетических потоков вместо последовательной обработки клеток.

## Архитектура системы

### Структура проекта

```
energy_flow/
├── config/
│   ├── __init__.py
│   ├── energy_config.py       # Конфигурация энергетической системы
│   └── base_config.py         # Базовая конфигурация (адаптированная из new_rebuild)
├── core/
│   ├── __init__.py
│   ├── energy_carrier.py      # RNN-based энергетические потоки
│   ├── simple_neuron.py       # Простой нейрон-автомат
│   ├── energy_lattice.py      # 3D решетка для потоков
│   └── flow_processor.py      # Механизм распространения энергии
├── training/
│   ├── __init__.py
│   └── energy_trainer.py      # Тренировочный цикл адаптируем из new_rebuild\core\training\embedding_trainer.py
├── utils/
│   ├── __init__.py
│   ├── logging.py            # (копируем из new_rebuild)
│   ├── device_manager.py     # (адаптируем из new_rebuild)
│   └── helpers.py            # Вспомогательные функции
└── examples/
    └── simple_training.py     # Пример использования
```

координаты и часть входного эмбединга передаются в SimpleNeuron - он на основе этого и своих весов высчитывает некоторое значение, которое мы передаем RNN и так же передаем значение входного эмбединга для этого шага - она так же на основании своих весов высчитывает определенное значение - это значение должно содержать изменение сигнала (или энергии или части эмбединга), который мы изначально запустили от обучающей модели, можно называть по разному для лучшего понимания, так же должен содержать координаты для следующего нейрона(с которым будет взаимодействовать эта RNN) и набор возможных новых RNN, которые пойдут из этого нейрона с возможностью ограничения их количества через конфиг. получается, что вывод должен быть структурированный, а размера выхода SimpleNeuron, должен соответствовать входу RNN. так же нам нужно уделить внимание и проверить размерности нейронок, что бы они сочетались по входным и выходным параметрам

## Компоненты системы

### 1. EnergyCarrier (energy_carrier.py)

**Назначение**: Представление энергии в виде GRU-модели

**Характеристики**:

- ~10M параметров
- GRU с hidden_size=1024, num_layers=3
- Входной эмбеддинг: часть от входного эмбединга обучающей модели можно посмотреть как тут реализовано new_rebuild\core\training\embedding_lattice_mapper.py, но нам не нужно состояние всех клеток, а мы работаем только с входной и выходной стороной
- Внутреннее состояние: скрытое состояние GRU
- Выход: структурированный вывод через projection head
- Общие веса для всех GRU в решетке

**Структура вывода EnergyCarrier**:

```python
{
    'energy_value': torch.Tensor,      # Текущая энергия/эмбеддинг; 768D эмбеддинг → маппер → каждый EnergyCarrier на входе получает соответствующее значение от маппера(тоже, что и соответствующий нейрон)
    'next_position': torch.Tensor,     # Координаты следующей клетки (3D)
    'spawn_energies': List[torch.Tensor],  # Энергии для новых потоков
    'spawn_count': int                 # Количество новых потоков
}
```

**Ключевые методы**:

- `__init__(hidden_size=1024, num_layers=3)`
- `forward(neuron_output, hidden_state)` → structured_output, new_hidden_state
- `can_spawn(energy_level)` → bool
- `spawn(parent_energy)` → новый EnergyCarrier с частью энергии

### 2. SimpleNeuron (simple_neuron.py)

**Назначение**: Простой нейрон-автомат в каждой клетке решетки

**Характеристики**:

- ~1000 параметров
- Архитектура: координаты (3D) + энергия части входного эмбединга → 64 скрытых → выход для RNN
- Общие веса для всех нейронов в решетке
- Выходной размер должен соответствовать входу GRU

**Входные данные**:

- Координаты клетки (x, y, z) - 3 значения

**Ключевые методы**:

- `__init__(coord_dim=3, extra_features=0, hidden_dim=64, output_dim=128)`
- `forward(position, extra_features=None)` → neuron_output (для передачи в GRU)
- `compute_features(position, lattice_state)` → extra_features

### 3. EnergyLattice (energy_lattice.py)

**Назначение**: 3D решетка для управления потоками

**Характеристики**:

- Размеры: width × height × depth
- Хранит активные потоки и их позиции
- Управляет бюджетом потоков
- **✅ РЕАЛИЗОВАНА буферизованная система сбора**

**Размеры по режимам**:

- DEBUG: 20×20×10 (4,000 клеток)
- EXPERIMENT: 50×50×20 (50,000 клеток)
- OPTIMIZED: 100×100×50 (500,000 клеток)

**Ключевые методы**:

- `__init__(width, height, depth, max_flows=1000)`
- `place_initial_energy(embeddings)` → размещение на входной стороне
- `get_active_flows()` → список активных потоков
- **✅ Буферизованная система сбора:**
  - `_buffer_output_flow(flow_id)` → автоматическая буферизация при достижении выхода
  - `collect_buffered_energy()` → умный сбор из буфера с взвешенным усреднением
  - `collect_output_energy()` → совместимая обертка над буферизованным сбором
  - `clear_output_buffer()` → управление жизненным циклом буфера
  - `get_buffered_flows_count()` → количество потоков в буфере

**✅ Умная обработка координат за пределами решетки:**

- Потоки за пределами (z > depth-1) автоматически корректируются к выходной стороне
- Множественные потоки в одной клетке объединяются взвешенным усреднением
- Вес = energy_magnitude × (1 + age × 0.1) - учитывает энергию и возраст потока

### 4. FlowProcessor (flow_processor.py)

**Назначение**: Механизм распространения энергии и координации компонентов

**Ключевые особенности**:

- Энергия может двигаться только вперед (по оси Z)
- ✅ **EnergyCarrier полностью определяет координаты** на основе своих весов
- При высокой энергии может создавать новые потоки
- Параллельная обработка всех потоков
- **✅ РЕАЛИЗОВАНА гибридная система координации**

**Ключевые методы**:

- `__init__(lattice, neuron, carrier, config)`
- `forward(input_embeddings, max_steps)` → полный проход с координацией компонентов
- `step(active_flows)` → один шаг распространения всех потоков
- `_process_flow_batch(flows)` → батчевая обработка с SimpleNeuron → EnergyCarrier
- **✅ Гибридная система сбора:**
  - `_collect_final_output()` → проверяет активные потоки И буфер
  - Автоматически добавляет оставшиеся потоки в буфер
  - Координирует жизненный цикл потоков
  - Очищает буфер после успешного сбора

**✅ Исправления технических проблем:**

- `.contiguous()` для исправления `rnn: hx is not contiguous`
- Правильное транспонирование hidden states: `[batch, layers, hidden] ↔ [layers, batch, hidden]`
- Координация устройств между компонентами

## Конфигурация системы

### EnergyConfig (energy_config.py)

```python
@dataclass
class EnergyConfig:
    # Размеры решетки
    lattice_width: int
    lattice_height: int
    lattice_depth: int

    # Параметры энергии
    max_active_flows: int = 1000
    energy_threshold: float = 0.1  # Минимальная энергия для продолжения
    spawn_threshold: float = 0.8   # Порог для создания новых потоков
    max_spawn_per_step: int = 10   # Максимум новых потоков за шаг

    # Параметры моделей
    carrier_hidden_size: int = 1024
    carrier_num_layers: int = 3
    neuron_hidden_dim: int = 64

    # Обучение
    learning_rate: float = 1e-4
    batch_size: int = 32
```

### Режимы работы

```python
# ✅ РЕАЛИЗОВАННЫЕ КОНФИГУРАЦИИ

DEBUG_CONFIG = EnergyConfig(
    lattice_width=20, lattice_height=20, lattice_depth=10,
    max_active_flows=1000, batch_size=8,
    energy_threshold=0.01,  # Низкий порог для отладки
    carrier_hidden_size=256, carrier_num_layers=2  # Уменьшенные размеры для отладки
)

EXPERIMENT_CONFIG = EnergyConfig(
    lattice_width=50, lattice_height=50, lattice_depth=20,
    max_active_flows=500, batch_size=16,
    carrier_hidden_size=512, carrier_num_layers=2
)

OPTIMIZED_CONFIG = EnergyConfig(
    lattice_width=100, lattice_height=100, lattice_depth=50,
    max_active_flows=1000, batch_size=32,
    carrier_hidden_size=1024, carrier_num_layers=3  # Полный размер для RTX 5090
)
```

## Механизм взаимодействия (детальный)

### Пошаговое взаимодействие для одной клетки:

1. **SimpleNeuron получает координаты**:

   ```python
   position = (x, y, z)
   neuron_output = simple_neuron(position)  # Размер: 128
   ```

2. **EnergyCarrier обрабатывает выход нейрона**:

   ```python
   structured_output, new_hidden = energy_carrier(
       neuron_output,
       current_hidden_state
   )
   ```

3. **Структурированный вывод содержит**:

   - `energy_value`: текущая энергия/эмбеддинг это допустим входной эмбединг от обучающей модели - мы его равномерно распределяем по нейронам входной стороны куба, тогда у нас от каждого нейрона отходит GRU со своей энергией. суть в том, что бы умно преобразовать размерность эмбединга обучающей модели в размерность входной стороны куба и передать соответственно каждому нейрону и GRU, которая от него пойдет, свое значение. по сути это скаляр, но умный, нормализованный скаляр
   - `next_position`: координаты следующей клетки (должны быть впереди)
   - `spawn_energies`: энергии для новых потоков (если есть)
   - `spawn_count`: количество новых потоков (ограничено конфигом)

4. **Создание новых потоков** (если spawn_count > 0):
   - Каждый новый поток получает часть энергии родителя
   - Новые потоки начинают с текущей позиции
   - У каждого свое скрытое состояние GRU

## Механизм работы

### 1. Инициализация

- Создаем решетку заданного размера
- Инициализируем общий SimpleNeuron
- Подготавливаем пул для EnergyCarrier

### 2. Прямой проход

1. Размещаем входные эмбеддинги на входной стороне куба (z=0) new_rebuild\core\training\embedding_lattice_mapper.py - для примера, но нам не нужно состояние всех клеток, а мы работаем только с входной и выходной стороной (new_rebuild\core\common\embedding_transformer.py)
2. Для каждого эмбеддинга создаем EnergyCarrier
3. На каждом шаге:
   - Все активные потоки обрабатываются параллельно
   - SimpleNeuron преобразует координаты и текущий входной эмбединг на текущем шаге в features
   - EnergyCarrier принимает features и текущий входной эмбединг и выдает структурированный вывод
   - Проверяем валидность следующей позиции (только вперед по Z) - проверить, нужна ли тут нормализация координат.
   - Создаем новые потоки если необходимо (с учетом бюджета)
   - Обновляем позиции и состояния всех потоков
4. Собираем энергию с выходной стороны (z=depth-1). если координаты выходят за предели размеров куба - можно присваивать ближайшим координатам выходной стороны. если несколько значений - мжно делать умное усреднение.

### 3. Обучение

суть пиплайна обучения. мы берем модель-учителя, для простоты сначала берем DistilBERT с 768D, далее подготавливаем пары эмбедингов(вопрос-ответ) из датасета(archive\240725\generate_snli_embedding_dataset.py). эмбединг-вопрос(768D) мы должны равномерно распределить на входную поверхность куба. сейчас у нас есть реализация в виде energy_flow\core\embedding_mapper.py. в итоге у нас было 768 значений, а мы их умно преобразовали в размерность поверхности куба(например 20х20=400) и каждый нейрон на поверхности куба получил свое значение и так же от этого нейрона пошла GRU, которая получила такое же значение. далее происходит распределение энергии внутри куба по определенной логике и в итоге мы собираем энергии на выходной поверхности куба. общая размерность 400D - мы е

- Сравниваем выходные эмбеддинги с целевыми
- Вычисляем loss (MSE или cosine similarity)
- Обратное распространение через:
  - Веса общего EnergyCarrier (GRU)
  - Веса общего SimpleNeuron
- Оптимизация через Adam
- для примера можно посмотреть new_rebuild\core\training\embedding_trainer.py. так же там реализовано преобразование выходного эмбединга в текст, что бы дополнительно проверять, насколько продвинулось обучение

## Особенности реализации

### Параллелизм

- Все EnergyCarrier обрабатываются параллельно в батчах
- Используем torch.nn.parallel для эффективной обработки
- Векторизованные операции где возможно

### Управление памятью

- Пул предаллоцированных EnergyCarrier
- Переиспользование неактивных потоков
- Автоматическая очистка по порогу энергии

### Эмерджентность

- Минимум жестко заданных правил
- Путь энергии определяется обучением
- Естественное формирование "каналов" через решетку

## Интеграция с существующими компонентами

### Из new_rebuild переиспользуем:

1. **Система логирования** (utils/logging.py)

   - Custom debug levels
   - Контекстное логирование

2. **DeviceManager** (адаптированный)

   - Управление GPU/CPU
   - Мониторинг памяти

3. **Базовые хелперы**
   - Position3D для навигации
   - Batch processing утилиты

## Примерный API использования

```python
from energy_flow.config import create_experiment_config
from energy_flow.core import EnergyLattice, SimpleNeuron, FlowProcessor
from energy_flow.training import EnergyTrainer

# Конфигурация
config = create_experiment_config()

# Создание компонентов
lattice = EnergyLattice(config)
neuron = SimpleNeuron(config)
processor = FlowProcessor(lattice, neuron, config)

# Обучение
trainer = EnergyTrainer(processor, config)
trainer.train(input_embeddings, target_embeddings, epochs=100)
```

1.  Работаем только с входной и выходной сторонами куба (не со всеми клетками)
2.  SimpleNeuron получает координаты И часть входного эмбеддинга
3.  GRU получает выход SimpleNeuron И также часть входного эмбеддинга
4.  Размерности должны быть согласованы между компонентами

## Метрики и мониторинг

### Ключевые метрики:

- Количество активных потоков
- Средняя энергия потоков
- Процент достигших выхода
- Loss (MSE/cosine similarity)
- Утилизация GPU памяти

### Логирование:

- DEBUG_ENERGY: детали распространения энергии
- DEBUG_SPAWN: создание новых потоков
- DEBUG_CONVERGENCE: статистика достижения выхода

## ✅ Этапы реализации - СТАТУС

1. **✅ Базовая инфраструктура** (config, logging, device) - **ЗАВЕРШЕНО**
2. **✅ SimpleNeuron** - простейший компонент - **ЗАВЕРШЕНО И ПРОТЕСТИРОВАНО**
   - 3,504 параметра (близко к целевым ~1000)
   - Позиционное кодирование, нормализация координат, батчевая обработка
3. **✅ EnergyCarrier** - ядро системы - **ЗАВЕРШЕНО И ПРОТЕСТИРОВАНО**
   - 709,254 параметра для debug-конфигурации
   - Структурированный вывод, spawn механизм, энергетические пороги
4. **✅ EnergyLattice** - управление пространством - **ЗАВЕРШЕНО И ПРОТЕСТИРОВАНО**
   - Буферизованная система сбора, умное усреднение, управление жизненным циклом
5. **✅ FlowProcessor** - механизм распространения - **ЗАВЕРШЕНО И ПРОТЕСТИРОВАНО**
   - Гибридная координация, исправления технических проблем, статистика производительности
6. **🔄 EnergyTrainer** - обучение - **СЛЕДУЮЩИЙ ЭТАП**
7. **🔄 Простой пример** - проверка работоспособности - **СЛЕДУЮЩИЙ ЭТАП**

### ✅ Созданные тесты:

- `test_energy_carrier.py` - тестирование RNN-based энергетических потоков
- `test_simple_neuron.py` - тестирование простого нейрона-автомата
- `test_energy_lattice.py` - тестирование 3D решетки и буферизованной системы
- `test_flow_processor.py` - тестирование механизма распространения и координации

### ✅ Результаты тестирования:

**EnergyCarrier:**

- ✅ 758,406 параметров (debug config), spawn механизм работает
- ✅ Координаты округляются до целых для дискретной решетки
- ✅ Движение потоков согласно PLAN.md (EnergyCarrier определяет координаты)

**SimpleNeuron:**

- ✅ 2,448 параметров (выше целевых ~1000, но приемлемо)
- ✅ Позиционное кодирование создает различимые паттерны
- ⚠️ Dropout вызывает батчевую неконсистентность (оставлено для исследований)

**EnergyLattice:**

- ✅ Буферизованная система работает: 4 потока собраны из буфера
- ✅ Взвешенное усреднение: energy_magnitude × (1 + age × 0.1)
- ✅ Коррекция потоков за пределами решетки к выходной стороне

**FlowProcessor:**

- тут основная проблема в том, что не завершаются и не буфиризируются правильно потоки. лучше простестировать на реальном обучени и добавить логов для отладки. (energy_flow.core.flow_processor - DEBUG - Final collection: 363 active flows, 0 buffered flows energy_flow.core.energy_lattice - DEBUG - No flows in output buffer 🏁 Финальный сбор: 0 потоков 📦 Размер выхода: torch.Size([0, 1]))
- ✅ Гибридная координация: активные потоки + буфер
- ✅ Исправлена ошибка `rnn: hx is not contiguous`

## 🔥 Ключевые доработки в процессе тестирования

### 1. **Буферизованная система сбора энергии**

**Проблема:** Потоки достигали выхода с разной скоростью, что требовало синхронизации.
**Решение:**

- Добавлен `output_buffer: Dict[(x,y), List[EnergyFlow]]` в EnergyLattice
- Автоматическая буферизация в `update_flow()` при `z >= depth-1`
- Умное взвешенное усреднение с учетом энергии и возраста потока

### 2. **Гибридная система координации**

**Проблема:** FlowProcessor не знал когда собирать энергию из буфера.
**Решение:**

- Цикл обработки проверяет `active_flows AND buffered_flows`
- `_collect_final_output()` координирует сбор из обоих источников
- Автоматическая очистка буфера после успешного сбора

### 3. **Логика движения потоков**

**Доработка:** EnergyCarrier теперь полностью определяет координаты на основе своих весов.

- Убрана принудительная логика "движения вперед"
- Потоки, не движущиеся вперед по Z, автоматически деактивируются
- Координаты округляются для дискретной решетки

### 4. **Технические исправления**

- **RNN contiguous memory:** `.contiguous()` после транспонирования
- **Device coordination:** правильное управление устройствами между компонентами
- **Edge cases:** корректная обработка потоков за пределами решетки

## Оптимизации (на будущее)

1. **Batch processing**: группировка потоков по позициям
2. **Sparse operations**: только активные клетки
3. **Multi-GPU**: распределение решетки по устройствам. вообще у нас пока что одна gpu 5090 32gb, так что для исследования мы оптимизируем под этот вариант
4. **Checkpoint/restore**: сохранение состояния обучения
5. **Адаптивный бюджет**: динамическое управление max_flows
