#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ Connection Classification —á–µ—Ä–µ–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
==========================================================

–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–Ω–∏—Ü—É –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É:
1. –û–±—ã—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π —Å–≤—è–∑–µ–π (fallback)
2. Pre-computed –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Å–≤—è–∑–µ–π

–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç speedup –∏ memory usage –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ —Ä–µ—à–µ—Ç–∫–∏.
"""

import torch
import time
import numpy as np
from typing import Dict, Any

from new_rebuild.core.moe.connection_classifier import UnifiedConnectionClassifier
from new_rebuild.config.project_config import get_project_config
from utils.centralized_config import CentralizedConfig

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
CentralizedConfig()


def benchmark_connection_classification(
    lattice_dimensions: tuple = (15, 15, 15), num_tests: int = 100, batch_size: int = 32
) -> Dict[str, Any]:
    """
    –ë–µ–Ω—á–º–∞—Ä–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–±—ã—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ vs –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–π

    Args:
        lattice_dimensions: –†–∞–∑–º–µ—Ä—ã —Ä–µ—à–µ—Ç–∫–∏ (x, y, z)
        num_tests: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤ –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è
        batch_size: –†–∞–∑–º–µ—Ä batch –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞ —Å –≤—Ä–µ–º–µ–Ω–∞–º–∏ –∏ speedup
    """
    print(f"\nüîç Benchmarking Connection Classification")
    print(f"üìê –†–µ—à–µ—Ç–∫–∞: {lattice_dimensions}")
    print(f"üîÑ –¢–µ—Å—Ç—ã: {num_tests}")
    print(f"üì¶ Batch size: {batch_size}")
    print("=" * 60)

    total_cells = np.prod(lattice_dimensions)
    config = get_project_config()
    state_size = config.gnn.state_size
    max_neighbors = config.max_neighbors

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    print("üìä –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ...")

    # –°–ª—É—á–∞–π–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∫–ª–µ—Ç–æ–∫
    all_states = torch.randn(total_cells, state_size)

    # –°–ª—É—á–∞–π–Ω—ã–µ batch –∏–Ω–¥–µ–∫—Å—ã
    test_batches = []
    for _ in range(num_tests):
        cell_indices = torch.randint(0, total_cells, (batch_size,))
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π (—Å padding -1)
        neighbor_indices = torch.randint(-1, total_cells, (batch_size, max_neighbors))
        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π
        for i in range(batch_size):
            valid_count = torch.randint(5, max_neighbors // 2, (1,)).item()
            neighbor_indices[i, :valid_count] = torch.randint(
                0, total_cells, (valid_count,)
            )
            neighbor_indices[i, valid_count:] = -1

        test_batches.append((cell_indices, neighbor_indices))

    results = {}

    # ==========================================
    # 1. –¢–ï–°–¢ –ë–ï–ó –ö–≠–®–ê (Fallback —Ä–µ–∂–∏–º)
    # ==========================================
    print("\nüîÑ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ë–ï–ó –∫—ç—à–∞ (fallback —Ä–µ–∂–∏–º)...")

    classifier_no_cache = UnifiedConnectionClassifier(
        lattice_dimensions=lattice_dimensions, enable_cache=False  # –û—Ç–∫–ª—é—á–∞–µ–º –∫—ç—à
    )

    # –ü—Ä–æ–≥—Ä–µ–≤
    for i in range(3):
        cell_indices, neighbor_indices = test_batches[0]
        _ = classifier_no_cache.classify_connections_batch(
            cell_indices, neighbor_indices, all_states
        )

    # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è
    start_time = time.time()

    for cell_indices, neighbor_indices in test_batches:
        _ = classifier_no_cache.classify_connections_batch(
            cell_indices, neighbor_indices, all_states
        )

    fallback_time = time.time() - start_time
    fallback_avg = fallback_time / num_tests

    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –ë–ï–ó –∫—ç—à–∞: {fallback_time:.4f}s")
    print(f"üìä –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {fallback_avg:.6f}s/batch")

    results["fallback"] = {
        "total_time": fallback_time,
        "avg_time": fallback_avg,
        "stats": classifier_no_cache.get_classification_stats(),
    }

    # ==========================================
    # 2. –¢–ï–°–¢ –° –ö–≠–®–ï–ú
    # ==========================================
    print("\nüöÄ –¢–µ—Å—Ç–∏—Ä—É–µ–º –° –∫—ç—à–µ–º...")

    classifier_with_cache = UnifiedConnectionClassifier(
        lattice_dimensions=lattice_dimensions, enable_cache=True  # –í–∫–ª—é—á–∞–µ–º –∫—ç—à
    )

    # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –∫—ç—à–∞
    print("‚åõ –û–∂–∏–¥–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –∫—ç—à–∞...")
    time.sleep(2)

    # –ü—Ä–æ–≥—Ä–µ–≤ –∫—ç—à–∞
    for i in range(5):
        cell_indices, neighbor_indices = test_batches[0]
        _ = classifier_with_cache.classify_connections_batch(
            cell_indices, neighbor_indices, all_states
        )

    # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è —Å –∫—ç—à–µ–º
    start_time = time.time()

    for cell_indices, neighbor_indices in test_batches:
        _ = classifier_with_cache.classify_connections_batch(
            cell_indices, neighbor_indices, all_states
        )

    cached_time = time.time() - start_time
    cached_avg = cached_time / num_tests

    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –° –∫—ç—à–µ–º: {cached_time:.4f}s")
    print(f"üìä –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {cached_avg:.6f}s/batch")

    results["cached"] = {
        "total_time": cached_time,
        "avg_time": cached_avg,
        "stats": classifier_with_cache.get_classification_stats(),
    }

    # ==========================================
    # 3. –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
    # ==========================================
    print("\nüìà –ê–ù–ê–õ–ò–ó –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò")
    print("=" * 60)

    if cached_time > 0:
        speedup = fallback_time / cached_time
        speedup_percent = ((fallback_time - cached_time) / fallback_time) * 100

        print(f"‚ö° Speedup: {speedup:.2f}x")
        print(f"üìâ –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {speedup_percent:.1f}%")
        print(f"‚è±Ô∏è  –≠–∫–æ–Ω–æ–º–∏—è –≤—Ä–µ–º–µ–Ω–∏: {fallback_time - cached_time:.4f}s")

        results["performance"] = {
            "speedup": speedup,
            "speedup_percent": speedup_percent,
            "time_saved": fallback_time - cached_time,
        }
    else:
        print("‚ö†Ô∏è  Cached –≤—Ä–µ–º—è —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è")
        results["performance"] = {"speedup": float("inf")}

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
    cache_stats = classifier_with_cache.get_cache_stats()
    if cache_stats["status"] == "active":
        print(f"\nüíæ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ö–≠–®–ê:")
        print(f"üî¢ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–µ—Ç–æ–∫: {cache_stats['cached_cells']}")
        print(f"üîó –í—Å–µ–≥–æ —Å–≤—è–∑–µ–π: {cache_stats['total_connections']}")
        print(f"üíΩ –†–∞–∑–º–µ—Ä –∫—ç—à–∞: {cache_stats['cache_size_mb']:.1f} MB")
        print(f"üéØ LOCAL: {cache_stats['local_connections']}")
        print(f"üéØ FUNCTIONAL candidates: {cache_stats['functional_candidates']}")
        print(f"üéØ DISTANT: {cache_stats['distant_connections']}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫—ç—à–∞
    perf_stats = results["cached"]["stats"].get("cache_performance", {})
    if perf_stats.get("cache_enabled", False):
        print(f"\n‚ö° –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –ö–≠–®–ê:")
        print(f"üéØ Hit rate: {perf_stats['cache_hit_rate']:.1%}")
        print(f"‚úÖ Cache hits: {perf_stats['cache_hits']}")
        print(f"‚ùå Cache misses: {perf_stats['cache_misses']}")
        print(f"‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∫—ç—à–∞: {perf_stats['avg_cache_time']:.6f}s")

    return results


def test_different_lattice_sizes():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–∞—Ö —Ä–µ—à–µ—Ç–∫–∏"""
    print("\nüî¨ –¢–ï–°–¢ –ú–ê–°–®–¢–ê–ë–ò–†–£–ï–ú–û–°–¢–ò")
    print("=" * 80)

    lattice_sizes = [
        (10, 10, 10),  # 1K –∫–ª–µ—Ç–æ–∫
        (15, 15, 15),  # 3.4K –∫–ª–µ—Ç–æ–∫
        (20, 20, 15),  # 6K –∫–ª–µ—Ç–æ–∫
        (25, 25, 15),  # 9.4K –∫–ª–µ—Ç–æ–∫
    ]

    for dimensions in lattice_sizes:
        total_cells = np.prod(dimensions)
        print(f"\nüìê –†–µ—à–µ—Ç–∫–∞ {dimensions} ({total_cells:,} –∫–ª–µ—Ç–æ–∫)")
        print("-" * 50)

        try:
            results = benchmark_connection_classification(
                lattice_dimensions=dimensions,
                num_tests=20,  # –ú–µ–Ω—å—à–µ —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ä–µ—à–µ—Ç–æ–∫
                batch_size=16,
            )

            if "performance" in results:
                speedup = results["performance"].get("speedup", 0)
                print(f"üöÄ –†–µ–∑—É–ª—å—Ç–∞—Ç: {speedup:.2f}x speedup")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            continue

        print("\n" + "=" * 30)


def demonstrate_cache_persistence():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∫—ç—à–∞ –º–µ–∂–¥—É –∑–∞–ø—É—Å–∫–∞–º–∏"""
    print("\nüíæ –¢–ï–°–¢ –ü–ï–†–°–ò–°–¢–ï–ù–¢–ù–û–°–¢–ò –ö–≠–®–ê")
    print("=" * 60)

    lattice_dims = (12, 12, 12)

    print("1Ô∏è‚É£  –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ (—Å–æ–∑–¥–∞–Ω–∏–µ –∫—ç—à–∞)...")
    start_time = time.time()
    classifier1 = UnifiedConnectionClassifier(
        lattice_dimensions=lattice_dims, enable_cache=True
    )
    first_init_time = time.time() - start_time
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {first_init_time:.2f}s")

    # –£–Ω–∏—á—Ç–æ–∂–∞–µ–º –æ–±—ä–µ–∫—Ç
    del classifier1

    print("\n2Ô∏è‚É£  –í—Ç–æ—Ä–æ–π –∑–∞–ø—É—Å–∫ (–∑–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞ —Å –¥–∏—Å–∫–∞)...")
    start_time = time.time()
    classifier2 = UnifiedConnectionClassifier(
        lattice_dimensions=lattice_dims, enable_cache=True
    )
    second_init_time = time.time() - start_time
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {second_init_time:.2f}s")

    if second_init_time > 0:
        cache_speedup = first_init_time / second_init_time
        print(f"üöÄ –ö—ç—à –∑–∞–≥—Ä—É–∑–∫–∞ –±—ã—Å—Ç—Ä–µ–µ –≤ {cache_speedup:.1f}x")

    return classifier2


if __name__ == "__main__":
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï CONNECTION CACHE OPTIMIZATION")
    print("=" * 80)

    try:
        # –û—Å–Ω–æ–≤–Ω–æ–π –±–µ–Ω—á–º–∞—Ä–∫
        print("\n1Ô∏è‚É£  –û–°–ù–û–í–ù–û–ô –ë–ï–ù–ß–ú–ê–†–ö")
        main_results = benchmark_connection_classification(
            lattice_dimensions=(15, 15, 15), num_tests=50, batch_size=32
        )

        # –¢–µ—Å—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏
        print("\n2Ô∏è‚É£  –¢–ï–°–¢ –ú–ê–°–®–¢–ê–ë–ò–†–£–ï–ú–û–°–¢–ò")
        test_different_lattice_sizes()

        # –¢–µ—Å—Ç –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        print("\n3Ô∏è‚É£  –¢–ï–°–¢ –ü–ï–†–°–ò–°–¢–ï–ù–¢–ù–û–°–¢–ò")
        final_classifier = demonstrate_cache_persistence()

        print("\n‚úÖ –í–°–ï –¢–ï–°–¢–´ –ó–ê–í–ï–†–®–ï–ù–´")
        print("=" * 80)

        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if "performance" in main_results:
            speedup = main_results["performance"]["speedup"]
            print(f"üéØ –ò–¢–û–ì–û–í–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢: {speedup:.2f}x —É—Å–∫–æ—Ä–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ")

    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  –¢–µ—Å—Ç –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback

        traceback.print_exc()
