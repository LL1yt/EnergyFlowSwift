#!/usr/bin/env python3
"""
–î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è gradient flow –≤ energy_flow training
===========================================================================

–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏:
- FlowProcessor gradient flow
- Individual components testing  
- Loss computation analysis
- In-place operations detection
"""

import torch
import torch.nn as nn
import sys
from pathlib import Path
import traceback

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from energy_flow.config import create_debug_config, set_energy_config
from energy_flow.core import FlowProcessor, EnergyLattice, SimpleNeuron, EnergyCarrier
from energy_flow.text_bridge import TextToCubeEncoder, CubeToTextDecoder
from energy_flow.utils.logging import get_logger, DEBUG_TRAINING

logger = get_logger(__name__)

def setup_test_environment():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    print("üîß Setting up test environment...")
    
    # Debug –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    config = create_debug_config()
    set_energy_config(config)
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º CUDA –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
    if torch.cuda.is_available():
        torch.set_default_device('cuda')
        print(f"‚úÖ Using CUDA device: {torch.cuda.get_device_name()}")
    else:
        print("‚ö†Ô∏è CUDA not available, using CPU")
    
    return config

def test_flow_processor_gradients(config):
    """–î–µ—Ç–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ gradient flow —á–µ—Ä–µ–∑ FlowProcessor"""
    print("\nüî¨ Testing FlowProcessor gradient flow...")
    
    batch_size = 2  # –ú–∞–ª–µ–Ω—å–∫–∏–π batch –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    try:
        # –°–æ–∑–¥–∞–µ–º FlowProcessor
        flow_processor = FlowProcessor(config).to(device)
        
        # –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏
        input_embeddings = torch.randn(batch_size, 768, device=device, requires_grad=True)
        print(f"üìä Input embeddings: {input_embeddings.shape}, requires_grad={input_embeddings.requires_grad}")
        
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
        print("üîÑ Forward pass through FlowProcessor...")
        output_surface = flow_processor.forward(input_embeddings, max_steps=5)  # –ö–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ—Ö–æ–¥
        
        print(f"üìä Output surface: {output_surface.shape}, requires_grad={output_surface.requires_grad}")
        print(f"üìä Output stats: mean={output_surface.mean():.4f}, std={output_surface.std():.4f}")
        
        # –ü—Ä–æ—Å—Ç–æ–π loss –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
        loss = output_surface.sum()
        print(f"üìä Loss: {loss:.4f}, requires_grad={loss.requires_grad}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ loss –∏–º–µ–µ—Ç grad_fn
        if loss.grad_fn is not None:
            print(f"‚úÖ Loss has grad_fn: {type(loss.grad_fn).__name__}")
        else:
            print("‚ùå Loss has no grad_fn!")
            return {"FlowProcessor": "‚ùå No grad_fn in loss"}
        
        # –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ
        print("üîÑ Backward pass...")
        loss.backward()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö
        components_with_grads = {}
        
        # FlowProcessor parameters
        fp_params = sum(1 for p in flow_processor.parameters() if p.grad is not None)
        fp_total = sum(1 for p in flow_processor.parameters())
        components_with_grads['FlowProcessor'] = f"{fp_params}/{fp_total}"
        
        # Neuron parameters
        neuron_params = sum(1 for p in flow_processor.neuron.parameters() if p.grad is not None)
        neuron_total = sum(1 for p in flow_processor.neuron.parameters())
        components_with_grads['SimpleNeuron'] = f"{neuron_params}/{neuron_total}"
        
        # Carrier parameters
        carrier_params = sum(1 for p in flow_processor.carrier.parameters() if p.grad is not None)
        carrier_total = sum(1 for p in flow_processor.carrier.parameters())
        components_with_grads['EnergyCarrier'] = f"{carrier_params}/{carrier_total}"
        
        # Mapper parameters
        mapper_params = sum(1 for p in flow_processor.mapper.parameters() if p.grad is not None)
        mapper_total = sum(1 for p in flow_processor.mapper.parameters())
        components_with_grads['EmbeddingMapper'] = f"{mapper_params}/{mapper_total}"
        
        print("üìä Components with gradients:")
        for comp, ratio in components_with_grads.items():
            print(f"  {comp}: {ratio}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º input gradients
        input_grad_norm = 0
        if input_embeddings.grad is not None:
            input_grad_norm = input_embeddings.grad.norm().item()
            print(f"‚úÖ Input gradients: norm={input_grad_norm:.6f}")
        else:
            print("‚ùå No gradients in input_embeddings")
        
        return {
            "FlowProcessor": "‚úÖ Gradient flow successful", 
            "components": components_with_grads,
            "input_grad_norm": input_grad_norm
        }
        
    except Exception as e:
        print(f"‚ùå FlowProcessor gradient test failed: {e}")
        traceback.print_exc()
        return {"FlowProcessor": f"‚ùå Error: {e}"}

def debug_gradient_flow(config):
    """–ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ gradient flow –≤ —Ä–µ–∞–ª—å–Ω–æ–º training setup"""
    print("\nüêõ Debugging real training setup...")
    
    batch_size = 2
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º training
        flow_processor = FlowProcessor(config).to(device)
        text_encoder = TextToCubeEncoder(config).to(device)
        
        # Teacher embeddings (–∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º training)
        teacher_input = torch.randn(batch_size, 768, device=device, requires_grad=False)  # Teacher –±–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤!
        teacher_target = torch.randn(batch_size, 768, device=device, requires_grad=False)
        
        # –¢–µ–∫—Å—Ç—ã
        input_texts = ["Test input text", "Another input"]
        target_texts = ["Target output text", "Another target"]
        
        print(f"üìä Teacher embeddings: input={teacher_input.requires_grad}, target={teacher_target.requires_grad}")
        
        # 1. –û—Å–Ω–æ–≤–Ω–æ–π energy flow
        print("üîÑ Energy flow forward pass...")
        cube_output = flow_processor.forward(teacher_input, max_steps=3)
        print(f"üìä Cube output: {cube_output.shape}, requires_grad={cube_output.requires_grad}")
        
        # ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: –ü–æ—á–µ–º—É cube_output –ù–ï –∏–º–µ–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤?
        if not cube_output.requires_grad:
            print("üö® –ü–†–û–ë–õ–ï–ú–ê –ù–ê–ô–î–ï–ù–ê: FlowProcessor.forward() –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã!")
            print("üîç –≠—Ç–æ –æ–±—ä—è—Å–Ω—è–µ—Ç –æ—à–∏–±–∫—É 'element 0 of tensors does not require grad'")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
            print("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –≤–Ω—É—Ç—Ä–∏ FlowProcessor:")
            
            # –ü—Ä–æ–≤–µ—Ä–∏–º mapper
            target_surface = flow_processor.mapper.input_mapper.forward(teacher_target)
            print(f"  üìä Mapper output: requires_grad={target_surface.requires_grad}")
            
            # –ü—Ä–æ–≤–µ—Ä–∏–º lattice
            print("  üìä Checking EnergyLattice operations...")
            
            return {
                "status": "üö® CRITICAL: FlowProcessor breaks gradient flow",
                "cube_output_has_grad": cube_output.requires_grad,
                "investigation": "FlowProcessor.forward() –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã"
            }
        
        # 2. Target mapping 
        print("üîÑ Target mapping...")
        target_surface = flow_processor.mapper.input_mapper.forward(teacher_target)
        if target_surface.dim() == 3:
            target_surface = target_surface.view(batch_size, -1)
        print(f"üìä Target surface: {target_surface.shape}, requires_grad={target_surface.requires_grad}")
        
        # 3. Energy loss
        print("üîÑ Computing energy loss...")
        energy_loss = nn.functional.mse_loss(cube_output, target_surface)
        print(f"üìä Energy loss: {energy_loss:.4f}, requires_grad={energy_loss.requires_grad}")
        
        # 4. Text encoding
        print("üîÑ Text encoding...")
        encoder_outputs = text_encoder.encode_text(input_texts)
        print(f"üìä Encoder outputs: {encoder_outputs.shape}, requires_grad={encoder_outputs.requires_grad}")
        
        # 5. Text loss
        print("üîÑ Computing text loss...")
        text_loss = nn.functional.mse_loss(encoder_outputs, target_surface)
        print(f"üìä Text loss: {text_loss:.4f}, requires_grad={text_loss.requires_grad}")
        
        # 6. Combined loss
        print("üîÑ Computing combined loss...")
        total_loss = energy_loss + 0.1 * text_loss
        print(f"üìä Total loss: {total_loss:.4f}, requires_grad={total_loss.requires_grad}")
        
        # 7. –ü—Ä–æ–≤–µ—Ä—è–µ–º grad_fn —Ü–µ–ø–æ—á–∫—É
        print("üîó Gradient function chain:")
        if total_loss.grad_fn:
            print(f"  total_loss.grad_fn: {type(total_loss.grad_fn).__name__}")
        else:
            print("  ‚ùå No grad_fn in total_loss!")
        
        # 8. Backward pass
        print("üîÑ Backward pass...")
        total_loss.backward()
        
        return {
            "status": "‚úÖ Debug successful",
            "energy_loss": energy_loss.item(),
            "text_loss": text_loss.item(),
            "total_loss": total_loss.item()
        }
        
    except Exception as e:
        print(f"‚ùå Debug failed: {e}")
        traceback.print_exc()
        return {"status": f"‚ùå Error: {e}"}

def investigate_flow_processor_internals(config):
    """–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π FlowProcessor"""
    print("\nüîç Investigating FlowProcessor internals...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    batch_size = 1
    
    try:
        flow_processor = FlowProcessor(config).to(device)
        input_embeddings = torch.randn(batch_size, 768, device=device, requires_grad=True)
        
        print(f"üìä Input: requires_grad={input_embeddings.requires_grad}")
        
        # –ü–æ—à–∞–≥–æ–≤–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
        print("üîÑ Step 1: mapper.map_to_surface")
        cell_energies = flow_processor.mapper.map_to_surface(input_embeddings)
        print(f"  üìä Cell energies: {len(cell_energies)} cells")
        for i, (pos, energy, batch_idx) in enumerate(cell_energies[:3]):  # –ü–µ—Ä–≤—ã–µ 3
            print(f"    Cell {i}: energy.requires_grad={energy.requires_grad}")
        
        print("üîÑ Step 2: lattice.place_initial_energy")
        flow_ids = flow_processor.lattice.place_initial_energy(input_embeddings, flow_processor.mapper)
        print(f"  üìä Created {len(flow_ids)} flows")
        
        print("üîÑ Step 3: _collect_final_surface_output")
        output_surface, completed_flows = flow_processor._collect_final_surface_output()
        print(f"  üìä Output surface: requires_grad={output_surface.requires_grad}")
        
        if not output_surface.requires_grad:
            print("üö® –ü–†–û–ë–õ–ï–ú–ê: _collect_final_surface_output –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã!")
            print("üîç –ù—É–∂–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å collect_buffered_surface_energy")
        
        return {
            "input_has_grad": input_embeddings.requires_grad,
            "output_has_grad": output_surface.requires_grad,
            "problem_location": "_collect_final_surface_output" if not output_surface.requires_grad else "unknown"
        }
        
    except Exception as e:
        print(f"‚ùå Investigation failed: {e}")
        traceback.print_exc()
        return {"error": str(e)}

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    print("üî¨ Energy Flow Gradient Diagnostics")
    print("=" * 50)
    
    config = setup_test_environment()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Ç–µ—Å—Ç—ã
    tests = [
        ("FlowProcessor Gradients", lambda: test_flow_processor_gradients(config)),
        ("Gradient Flow Debug", lambda: debug_gradient_flow(config)),
        ("FlowProcessor Internals", lambda: investigate_flow_processor_internals(config))
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            results[test_name] = result
        except Exception as e:
            print(f"‚ùå Test '{test_name}' crashed: {e}")
            results[test_name] = {"error": str(e)}
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print(f"\n{'='*20} SUMMARY {'='*20}")
    for test_name, result in results.items():
        print(f"üìã {test_name}:")
        if isinstance(result, dict):
            for key, value in result.items():
                print(f"  {key}: {value}")
        else:
            print(f"  {result}")
    
    print(f"\nüèÅ Diagnostics completed!")

if __name__ == "__main__":
    main()