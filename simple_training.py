#!/usr/bin/env python3
"""
Simple Training Example - –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è EnergyTrainer
====================================================

–ü–æ–ª–Ω—ã–π workflow –æ–±—É—á–µ–Ω–∏—è energy_flow –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:
1. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è debug —Ä–µ–∂–∏–º–∞
2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö
3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è EnergyTrainer —Å text_bridge
4. –û–±—É—á–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è
5. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
python energy_flow/examples/simple_training.py
"""

import torch
from torch.utils.data import Dataset, DataLoader
import sys
from pathlib import Path
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from energy_flow.config import create_debug_config, set_energy_config
from energy_flow.training.energy_trainer import EnergyTrainer
from energy_flow.utils.logging import get_logger, DEBUG_TRAINING

logger = get_logger(__name__)


class SimpleTextDataset(Dataset):
    """
    –ü—Ä–æ—Å—Ç–æ–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –±–∞–∑–æ–≤—ã–µ –ø–∞—Ä—ã –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è text_bridge
    """
    
    def __init__(self, max_samples: int = 50):
        """
        Args:
            max_samples: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤
        """
        # –ü—Ä–æ—Å—Ç—ã–µ –ø–∞—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–≤–æ–ø—Ä–æ—Å -> –æ—Ç–≤–µ—Ç)
        self.data_pairs = [
            ("What is AI?", "Artificial Intelligence is the simulation of human intelligence."),
            ("How does machine learning work?", "Machine learning uses algorithms to find patterns in data."),
            ("What is deep learning?", "Deep learning uses neural networks with multiple layers."),
            ("What is a neural network?", "A neural network is inspired by biological neural systems."),
            ("How do computers learn?", "Computers learn by processing data and adjusting parameters."),
            ("What is training data?", "Training data is used to teach machine learning models."),
            ("What is an algorithm?", "An algorithm is a set of rules for solving problems."),
            ("How does AI work?", "AI works by processing information and making decisions."),
            ("What is data science?", "Data science extracts insights from structured and unstructured data."),
            ("What is natural language processing?", "NLP helps computers understand and process human language."),
            ("What is computer vision?", "Computer vision enables machines to interpret visual information."),
            ("What is reinforcement learning?", "Reinforcement learning learns through interaction and rewards."),
            ("What is supervised learning?", "Supervised learning uses labeled examples to train models."),
            ("What is unsupervised learning?", "Unsupervised learning finds patterns in data without labels."),
            ("What is a model?", "A model is a mathematical representation of a process."),
            ("What is prediction?", "Prediction is forecasting future outcomes based on data."),
            ("What is classification?", "Classification assigns data points to predefined categories."),
            ("What is regression?", "Regression predicts continuous numerical values."),
            ("What is feature extraction?", "Feature extraction identifies relevant data characteristics."),
            ("What is optimization?", "Optimization finds the best solution to a problem."),
        ]
        
        # –î—É–±–ª–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –ø—Ä–∏–º–µ—Ä–æ–≤
        while len(self.data_pairs) < max_samples:
            self.data_pairs.extend(self.data_pairs[:min(20, max_samples - len(self.data_pairs))])
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ max_samples
        self.data_pairs = self.data_pairs[:max_samples]
        
        logger.log(DEBUG_TRAINING, f"SimpleTextDataset initialized with {len(self.data_pairs)} pairs")
    
    def __len__(self):
        return len(self.data_pairs)
    
    def __getitem__(self, idx):
        input_text, target_text = self.data_pairs[idx]
        return input_text, target_text


def create_simple_dataloader(batch_size: int = 4, max_samples: int = 50) -> DataLoader:
    """–°–æ–∑–¥–∞–Ω–∏–µ DataLoader —Å –ø—Ä–æ—Å—Ç—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    dataset = SimpleTextDataset(max_samples=max_samples)
    
    # –°–æ–∑–¥–∞–µ–º CUDA generator –∑–∞—Ä–∞–Ω–µ–µ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã shuffle
    cuda_generator = torch.Generator(device='cuda') if torch.cuda.is_available() else None
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        generator=cuda_generator,  # –ü–µ—Ä–µ–¥–∞–µ–º CUDA generator –Ω–∞–ø—Ä—è–º—É—é!
        num_workers=0,  # –ò–∑–±–µ–≥–∞–µ–º multiprocessing –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
        pin_memory=False  # –û—Ç–∫–ª—é—á–∞–µ–º –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –æ—Ç–ª–∞–¥–∫–∏
    )
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    if torch.cuda.is_available() and hasattr(dataloader, 'generator') and dataloader.generator:
        print(f"‚úÖ DataLoader generator device: {dataloader.generator.device}")
    
    return dataloader


def create_teacher_embeddings_loader(batch_size: int = 4, max_samples: int = 50):
    """–°–æ–∑–¥–∞–µ—Ç –∏—Ç–µ—Ä–∞—Ç–æ—Ä —Å –ø–∞—Ä–∞–º–∏ teacher embeddings –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∫—É–±–∞"""
    
    class TeacherEmbeddingsDataset(Dataset):
        def __init__(self, max_samples: int):
            self.max_samples = max_samples
        
        def __len__(self):
            return self.max_samples
        
        def __getitem__(self, idx):
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–∞—Ä—ã teacher embeddings (768D)
            input_embedding = torch.randn(768, dtype=torch.float32)
            target_embedding = torch.randn(768, dtype=torch.float32)
            return input_embedding, target_embedding
    
    dataset = TeacherEmbeddingsDataset(max_samples)
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        generator=torch.Generator(device='cuda') if torch.cuda.is_available() else None,
        num_workers=0,
        pin_memory=False  # –û—Ç–∫–ª—é—á–∞–µ–º –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –æ—Ç–ª–∞–¥–∫–∏
    )
    
    if torch.cuda.is_available() and hasattr(dataloader, 'generator') and dataloader.generator:
        print(f"‚úÖ Teacher embeddings DataLoader generator device: {dataloader.generator.device}")
    
    return dataloader


def run_simple_training():
    """–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Å—Ç–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("üöÄ Starting Simple Energy Flow Training Demo")
    print("=" * 50)
    
    # 1. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è debug —Ä–µ–∂–∏–º–∞
    config = create_debug_config()
    set_energy_config(config)
    
    print(f"üìä Configuration:")
    print(f"  - Lattice size: {config.lattice_width}x{config.lattice_height}x{config.lattice_depth}")
    print(f"  - Text bridge: {config.text_bridge_enabled}")
    print(f"  - Batch size: {config.batch_size}")
    print(f"  - Device: {config.device}")
    print()
    
    # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("üìÅ Preparing data...")
    train_dataloader = create_simple_dataloader(
        batch_size=config.batch_size, 
        max_samples=40  # –ù–µ–±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è debug
    )
    val_dataloader = create_simple_dataloader(
        batch_size=config.batch_size,
        max_samples=10  # –ï—â–µ –º–µ–Ω—å—à–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    )
    
    # Teacher embeddings –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∫—É–±–∞
    train_teacher_loader = create_teacher_embeddings_loader(
        batch_size=config.batch_size,
        max_samples=40
    )
    val_teacher_loader = create_teacher_embeddings_loader(
        batch_size=config.batch_size,
        max_samples=10
    )
    
    print(f"  - Training batches: {len(train_dataloader)}")
    print(f"  - Validation batches: {len(val_dataloader)}")
    print(f"  - Teacher embeddings batches: {len(train_teacher_loader)}")
    print()
    
    # 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞
    print("ü§ñ Initializing EnergyTrainer...")
    try:
        trainer = EnergyTrainer(config)
        model_info = trainer.get_model_info()
        
        print(f"  - Flow processor parameters: {model_info.get('flow_processor_parameters', 0):,}")
        if config.text_bridge_enabled:
            print(f"  - Text encoder parameters: {model_info.get('text_encoder_parameters', 0):,}")
            print(f"  - Text decoder parameters: {model_info.get('text_decoder_parameters', 0):,}")
        print(f"  - Device: {model_info['device']}")
        print()
        
    except Exception as e:
        print(f"‚ùå Trainer initialization failed: {e}")
        return False
    
    # 4. –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º
    print("üîç Initial validation...")
    try:
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π batch –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        val_batch = next(iter(val_dataloader))
        val_teacher_batch = next(iter(val_teacher_loader))
        val_metrics = trainer.validate(val_batch[0], val_batch[1], val_teacher_batch[0], val_teacher_batch[1])
        
        print(f"  - Initial loss: {val_metrics.get('total_loss', 0):.4f}")
        if val_metrics.get('examples'):
            example = val_metrics['examples'][0]
            print(f"  - Example input: '{example['input'][:40]}...'")
            if config.text_bridge_enabled:
                print(f"  - Example predicted: '{example.get('predicted', 'N/A')[:40]}...'")
        print()
        
    except Exception as e:
        print(f"‚ö†Ô∏è Initial validation failed: {e}")
        val_metrics = None
    
    # 5. –û–±—É—á–µ–Ω–∏–µ
    print("üéØ Starting training...")
    try:
        num_epochs = 3  # –ù–µ–±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –¥–ª—è demo
        training_history = trainer.train(train_dataloader, train_teacher_loader, num_epochs=num_epochs)
        
        print(f"‚úÖ Training completed!")
        print(f"  - Epochs: {num_epochs}")
        print(f"  - Final loss: {training_history.get('total_loss', [0])[-1]:.4f}")
        print(f"  - Best loss: {trainer.best_loss:.4f}")
        print()
        
    except Exception as e:
        print(f"‚ùå Training failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 6. –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
    print("üîç Final validation...")
    try:
        final_val_metrics = trainer.validate(val_batch[0], val_batch[1], val_teacher_batch[0], val_teacher_batch[1])
        
        print(f"  - Final loss: {final_val_metrics.get('total_loss', 0):.4f}")
        print(f"  - Energy loss: {final_val_metrics.get('energy_loss', 0):.4f}")
        print(f"  - Text loss: {final_val_metrics.get('text_loss', 0):.4f}")
        
        if final_val_metrics.get('examples') and config.text_bridge_enabled:
            example = final_val_metrics['examples'][0]
            print(f"\nüìù Example after training:")
            print(f"  Input:     '{example['input']}'")
            print(f"  Target:    '{example['target']}'")
            print(f"  Predicted: '{example.get('predicted', 'N/A')}'")
        print()
        
    except Exception as e:
        print(f"‚ö†Ô∏è Final validation failed: {e}")
    
    # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("üíæ Saving model...")
    try:
        checkpoint_path = "simple_training_demo.pt"
        trainer.save_checkpoint(checkpoint_path)
        print(f"  - Model saved: {checkpoint_path}")
        print()
        
    except Exception as e:
        print(f"‚ö†Ô∏è Model saving failed: {e}")
    
    # 8. –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("üìä Training Summary:")
    print("=" * 50)
    if training_history:
        print(f"Total losses: {[f'{loss:.4f}' for loss in training_history.get('total_loss', [])]}")
        print(f"Energy losses: {[f'{loss:.4f}' for loss in training_history.get('energy_loss', [])]}")
        if config.text_bridge_enabled:
            print(f"Text losses: {[f'{loss:.4f}' for loss in training_history.get('text_loss', [])]}")
    
    print(f"Best loss achieved: {trainer.best_loss:.4f}")
    print(f"Configuration used: {config.lattice_width}x{config.lattice_height}x{config.lattice_depth}")
    print("‚úÖ Demo completed successfully!")
    
    return True


def run_interactive_demo():
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º –≤–≤–æ–¥–æ–º"""
    print("\nüéÆ Interactive Demo Mode")
    print("=" * 30)
    
    # –ë—ã—Å—Ç—Ä–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    config = create_debug_config()
    config.lattice_width = 10  # –ï—â–µ –º–µ–Ω—å—à–µ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
    config.lattice_height = 10
    config.lattice_depth = 5
    set_energy_config(config)
    
    try:
        trainer = EnergyTrainer(config)
        print("ü§ñ EnergyTrainer initialized!")
        
        while True:
            print("\nEnter input text (or 'quit' to exit):")
            user_input = input("> ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'q']:
                break
            
            if not user_input:
                continue
            
            try:
                # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ forward pass
                result = trainer.validate([user_input], ["Sample target response"])
                
                print(f"‚úÖ Processing completed!")
                print(f"  - Loss: {result.get('total_loss', 0):.4f}")
                if result.get('examples') and config.text_bridge_enabled:
                    predicted = result['examples'][0].get('predicted', 'N/A')
                    print(f"  - Model output: '{predicted}'")
                
            except Exception as e:
                print(f"‚ùå Processing failed: {e}")
    
    except Exception as e:
        print(f"‚ùå Interactive demo initialization failed: {e}")
    
    print("üëã Interactive demo ended!")


if __name__ == "__main__":
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞"""
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("üåü Energy Flow Training Demo")
    print("=" * 40)
    print("Choose mode:")
    print("1. Simple Training Demo (recommended)")
    print("2. Interactive Demo")
    print("3. Both")
    
    try:
        choice = input("Enter choice (1-3): ").strip()
        
        if choice in ['1', '3']:
            success = run_simple_training()
            if not success:
                print("‚ùå Simple training demo failed!")
        
        if choice in ['2', '3']:
            run_interactive_demo()
        
        if choice not in ['1', '2', '3']:
            print("Invalid choice, running simple training demo...")
            run_simple_training()
            
    except KeyboardInterrupt:
        print("\nüëã Demo interrupted by user")
    except Exception as e:
        print(f"‚ùå Demo failed: {e}")
        import traceback
        traceback.print_exc()