#!/usr/bin/env python3
"""
üéØ –¢–ï–°–¢ –§–ê–ó–´ 4: –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏

–¶–µ–ª—å: –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è —Å –Ω–æ–≤—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –§–∞–∑—ã 4:
- –†–µ–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –º–∞–ª—ã—Ö —Ä–µ—à–µ—Ç–∫–∞—Ö (16√ó16√ó16 ‚Üí 24√ó24√ó24)
- –ò–∑–º–µ—Ä–µ–Ω–∏–µ memory reduction –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è emergent behavior
- –í–∞–ª–∏–¥–∞—Ü–∏—è quality metrics

–≠—Ç–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –ù–ï–î–ï–õ–ò 1 —Å–æ–≥–ª–∞—Å–Ω–æ –ø–ª–∞–Ω—É –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏.
"""

import sys
import os
import time
import json
import psutil
import torch
from pathlib import Path
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ Python path
sys.path.append(str(Path(__file__).parent))

from training.automated_training.types import StageConfig
from training.automated_training.progressive_config import ProgressiveConfigManager
from training.automated_training.stage_runner import TrainingStageRunner
from training.automated_training.automated_trainer import AutomatedTrainer


class FullCycleMemoryMonitor:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä –ø–∞–º—è—Ç–∏ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—É—á–µ–Ω–∏—è"""

    def __init__(self):
        self.measurements = []
        self.start_time = None

    def start_monitoring(self):
        """–ù–∞—á–∞—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞"""
        self.start_time = time.time()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        initial_measurement = {
            "timestamp": 0,
            "ram_mb": psutil.Process().memory_info().rss / 1024 / 1024,
            "gpu_mb": (
                torch.cuda.memory_allocated(0) / 1024 / 1024
                if torch.cuda.is_available()
                else 0
            ),
            "event": "start",
        }
        self.measurements.append(initial_measurement)
        print(
            f"üìä Monitoring started: {initial_measurement['ram_mb']:.1f}MB RAM, {initial_measurement['gpu_mb']:.1f}MB GPU"
        )

    def record_measurement(self, event: str):
        """–ó–∞–ø–∏—Å–∞—Ç—å –∏–∑–º–µ—Ä–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏"""
        if self.start_time is None:
            return

        current_time = time.time() - self.start_time
        measurement = {
            "timestamp": current_time,
            "ram_mb": psutil.Process().memory_info().rss / 1024 / 1024,
            "gpu_mb": (
                torch.cuda.memory_allocated(0) / 1024 / 1024
                if torch.cuda.is_available()
                else 0
            ),
            "event": event,
        }
        self.measurements.append(measurement)
        print(
            f"üìä {event}: {measurement['ram_mb']:.1f}MB RAM, {measurement['gpu_mb']:.1f}MB GPU"
        )

    def get_peak_usage(self):
        """–ü–æ–ª—É—á–∏—Ç—å –ø–∏–∫–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏"""
        if not self.measurements:
            return 0, 0

        peak_ram = max(m["ram_mb"] for m in self.measurements)
        peak_gpu = max(m["gpu_mb"] for m in self.measurements)
        return peak_ram, peak_gpu

    def get_memory_efficiency(self):
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        if len(self.measurements) < 2:
            return {}

        start = self.measurements[0]
        peak_ram, peak_gpu = self.get_peak_usage()

        return {
            "start_ram_mb": start["ram_mb"],
            "start_gpu_mb": start["gpu_mb"],
            "peak_ram_mb": peak_ram,
            "peak_gpu_mb": peak_gpu,
            "ram_growth_mb": peak_ram - start["ram_mb"],
            "gpu_growth_mb": peak_gpu - start["gpu_mb"],
            "total_measurements": len(self.measurements),
        }


def create_test_stage_config(stage: int, mode: str = "optimized") -> StageConfig:
    """–°–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å—Ç–∞–¥–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""

    if mode == "optimized":
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –§–∞–∑—ã 4
        configs = {
            1: {
                "dataset_limit": 50,  # –ú–∞–ª–µ–Ω—å–∫–∏–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞
                "epochs": 3,
                "plasticity_profile": "discovery",
                "clustering_enabled": False,
                "activity_threshold": 0.01,
                "memory_optimizations": True,
                "emergence_tracking": True,
            },
            2: {
                "dataset_limit": 100,
                "epochs": 2,
                "plasticity_profile": "learning",
                "clustering_enabled": True,
                "activity_threshold": 0.025,
                "memory_optimizations": True,
                "emergence_tracking": True,
                "sparse_connection_ratio": 0.1,
            },
        }
    else:
        # –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
        configs = {
            1: {
                "dataset_limit": 50,
                "epochs": 3,
                "plasticity_profile": "balanced",
                "clustering_enabled": False,
                "activity_threshold": 0.05,
                "memory_optimizations": False,
                "emergence_tracking": False,
            },
            2: {
                "dataset_limit": 100,
                "epochs": 2,
                "plasticity_profile": "balanced",
                "clustering_enabled": False,
                "activity_threshold": 0.05,
                "memory_optimizations": False,
                "emergence_tracking": False,
            },
        }

    config = configs.get(stage, configs[1])

    return StageConfig(
        stage=stage,
        dataset_limit=config["dataset_limit"],
        epochs=config["epochs"],
        batch_size=8,  # –ú–∞–ª–µ–Ω—å–∫–∏–π batch –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        description=f"Full Cycle Test Stage {stage} ({mode})",
        plasticity_profile=config["plasticity_profile"],
        clustering_enabled=config["clustering_enabled"],
        activity_threshold=config["activity_threshold"],
        memory_optimizations=config["memory_optimizations"],
        emergence_tracking=config["emergence_tracking"],
        sparse_connection_ratio=config.get("sparse_connection_ratio", 0.0),
        progressive_scaling=True,
    )


def run_training_stage_with_monitoring(
    stage_config: StageConfig, monitor: FullCycleMemoryMonitor
) -> dict:
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å —Å—Ç–∞–¥–∏—é –æ–±—É—á–µ–Ω–∏—è —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º"""

    monitor.record_measurement(f"stage_{stage_config.stage}_start")

    # –°–æ–∑–¥–∞–µ–º runner
    runner = TrainingStageRunner(
        mode="development",
        scale=0.01,  # –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–π –º–∞—Å—à—Ç–∞–± –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        timeout_multiplier=1.5,
        verbose=True,
    )

    # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
    config_manager = ProgressiveConfigManager()
    estimated_time = config_manager.estimate_stage_time(
        stage_config, mode="development"
    )

    monitor.record_measurement(f"stage_{stage_config.stage}_config_ready")

    # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
    print(f"üèÉ‚Äç‚ôÇÔ∏è –ó–∞–ø—É—Å–∫ Stage {stage_config.stage}: {stage_config.description}")
    print(f"   Dataset: {stage_config.dataset_limit}, Epochs: {stage_config.epochs}")
    print(
        f"   Plasticity: {stage_config.plasticity_profile}, Memory opt: {stage_config.memory_optimizations}"
    )

    start_time = time.time()

    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)
        result = runner.run_stage(stage_config, estimated_time)

        actual_time = (time.time() - start_time) / 60
        monitor.record_measurement(f"stage_{stage_config.stage}_complete")

        if result and result.success:
            print(f"‚úÖ Stage {stage_config.stage} completed in {actual_time:.1f}min")
            return {
                "success": True,
                "actual_time_minutes": actual_time,
                "final_similarity": result.final_similarity,
                "stage_result": result,
            }
        else:
            print(f"‚ùå Stage {stage_config.stage} failed after {actual_time:.1f}min")
            return {
                "success": False,
                "actual_time_minutes": actual_time,
                "error": result.error if result else "Unknown error",
            }

    except Exception as e:
        actual_time = (time.time() - start_time) / 60
        monitor.record_measurement(f"stage_{stage_config.stage}_error")
        print(
            f"‚ùå Stage {stage_config.stage} exception after {actual_time:.1f}min: {e}"
        )
        return {"success": False, "actual_time_minutes": actual_time, "error": str(e)}


def test_optimized_vs_baseline_training():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –±–∞–∑–æ–≤—ã–º"""
    print("üÜö –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ vs –±–∞–∑–æ–≤–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è...")

    results = {"optimized": {}, "baseline": {}}

    # === –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï ===
    print("\nüöÄ === –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï (Phase 4) ===")

    monitor_opt = FullCycleMemoryMonitor()
    monitor_opt.start_monitoring()

    # –°—Ç–∞–¥–∏—è 1: Discovery —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
    stage1_opt = create_test_stage_config(1, "optimized")
    result1_opt = run_training_stage_with_monitoring(stage1_opt, monitor_opt)

    # –°—Ç–∞–¥–∏—è 2: Learning —Å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–µ–π
    stage2_opt = create_test_stage_config(2, "optimized")
    result2_opt = run_training_stage_with_monitoring(stage2_opt, monitor_opt)

    opt_efficiency = monitor_opt.get_memory_efficiency()
    results["optimized"] = {
        "stage1": result1_opt,
        "stage2": result2_opt,
        "memory_efficiency": opt_efficiency,
        "total_time": result1_opt["actual_time_minutes"]
        + result2_opt["actual_time_minutes"],
    }

    print(f"üöÄ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ:")
    print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {results['optimized']['total_time']:.1f}min")
    print(f"   Peak RAM: {opt_efficiency['peak_ram_mb']:.1f}MB")
    print(f"   Peak GPU: {opt_efficiency['peak_gpu_mb']:.1f}MB")

    # === –ë–ê–ó–û–í–û–ï –û–ë–£–ß–ï–ù–ò–ï ===
    print("\nüìä === –ë–ê–ó–û–í–û–ï –û–ë–£–ß–ï–ù–ò–ï (–±–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π) ===")

    monitor_base = FullCycleMemoryMonitor()
    monitor_base.start_monitoring()

    # –°—Ç–∞–¥–∏—è 1: –ë–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
    stage1_base = create_test_stage_config(1, "baseline")
    result1_base = run_training_stage_with_monitoring(stage1_base, monitor_base)

    # –°—Ç–∞–¥–∏—è 2: –ë–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
    stage2_base = create_test_stage_config(2, "baseline")
    result2_base = run_training_stage_with_monitoring(stage2_base, monitor_base)

    base_efficiency = monitor_base.get_memory_efficiency()
    results["baseline"] = {
        "stage1": result1_base,
        "stage2": result2_base,
        "memory_efficiency": base_efficiency,
        "total_time": result1_base["actual_time_minutes"]
        + result2_base["actual_time_minutes"],
    }

    print(f"üìä –ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ:")
    print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {results['baseline']['total_time']:.1f}min")
    print(f"   Peak RAM: {base_efficiency['peak_ram_mb']:.1f}MB")
    print(f"   Peak GPU: {base_efficiency['peak_gpu_mb']:.1f}MB")

    # === –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
    print("\nüìä === –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===")

    if base_efficiency["peak_ram_mb"] > 0:
        ram_savings = (
            (base_efficiency["peak_ram_mb"] - opt_efficiency["peak_ram_mb"])
            / base_efficiency["peak_ram_mb"]
            * 100
        )
        print(f"üíæ –≠–∫–æ–Ω–æ–º–∏—è RAM: {ram_savings:.1f}%")

    if base_efficiency["peak_gpu_mb"] > 0:
        gpu_savings = (
            (base_efficiency["peak_gpu_mb"] - opt_efficiency["peak_gpu_mb"])
            / base_efficiency["peak_gpu_mb"]
            * 100
        )
        print(f"üéÆ –≠–∫–æ–Ω–æ–º–∏—è GPU: {gpu_savings:.1f}%")

    time_diff = results["baseline"]["total_time"] - results["optimized"]["total_time"]
    print(
        f"‚è±Ô∏è  –†–∞–∑–Ω–∏—Ü–∞ –≤–æ –≤—Ä–µ–º–µ–Ω–∏: {time_diff:.1f}min ({'–±—ã—Å—Ç—Ä–µ–µ' if time_diff > 0 else '–º–µ–¥–ª–µ–Ω–Ω–µ–µ'})"
    )

    return results


def test_progressive_scaling_training():
    """–¢–µ—Å—Ç –æ–±—É—á–µ–Ω–∏—è —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    print("üìê –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º...")

    monitor = FullCycleMemoryMonitor()
    monitor.start_monitoring()

    scaling_results = []

    # –¢–µ—Å—Ç 3 —Å—Ç–∞–¥–∏–π —Å —É–≤–µ–ª–∏—á–∏–≤–∞—é—â–∏–º–∏—Å—è —Ä–∞–∑–º–µ—Ä–∞–º–∏ —Ä–µ—à–µ—Ç–∫–∏
    for stage in [1, 2, 3]:
        stage_config = StageConfig(
            stage=stage,
            dataset_limit=30,  # –ú–∞–ª–µ–Ω—å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞
            epochs=1,
            batch_size=4,
            description=f"Progressive Scaling Test Stage {stage}",
            plasticity_profile="learning",
            clustering_enabled=(stage >= 2),
            activity_threshold=0.02 + stage * 0.01,
            memory_optimizations=True,
            emergence_tracking=True,
            progressive_scaling=True,  # –ö–ª—é—á–µ–≤–∞—è –æ–ø—Ü–∏—è
        )

        print(f"\nüìê Stage {stage} - Progressive Scaling Test")
        result = run_training_stage_with_monitoring(stage_config, monitor)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ä–µ—à–µ—Ç–∫–∏
        runner = TrainingStageRunner(mode="development")
        expected_dims = runner._get_adaptive_dimensions(stage)

        stage_summary = {
            "stage": stage,
            "expected_dimensions": expected_dims,
            "training_result": result,
            "total_cells": expected_dims[0] * expected_dims[1] * expected_dims[2],
        }

        scaling_results.append(stage_summary)
        print(
            f"   Expected dimensions: {expected_dims[0]}√ó{expected_dims[1]}√ó{expected_dims[2]} = {stage_summary['total_cells']:,} cells"
        )
        print(f"   Training success: {'‚úÖ' if result['success'] else '‚ùå'}")

    efficiency = monitor.get_memory_efficiency()

    print(f"\nüìä Progressive Scaling Summary:")
    print(
        f"   Stages completed: {len([r for r in scaling_results if r['training_result']['success']])}/{len(scaling_results)}"
    )
    print(f"   Memory efficiency: {efficiency['peak_ram_mb']:.1f}MB peak RAM")
    print(
        f"   Scaling range: {scaling_results[0]['total_cells']:,} ‚Üí {scaling_results[-1]['total_cells']:,} cells"
    )

    return scaling_results, efficiency


def save_test_results(results: dict, filename: str = None):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"phase4_full_cycle_results_{timestamp}.json"

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    results_dir = Path("results/phase4_tests")
    results_dir.mkdir(parents=True, exist_ok=True)

    filepath = results_dir / filename

    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)

    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filepath}")
    return filepath


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞"""
    print("üéØ –¢–ï–°–¢ –§–ê–ó–´ 4: –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏")
    print("=" * 80)
    print("üéØ –¶–µ–ª—å: –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ù–ï–î–ï–õ–ò 1 —Å–æ–≥–ª–∞—Å–Ω–æ –ø–ª–∞–Ω—É –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏")
    print("‚è±Ô∏è  –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: 10-20 –º–∏–Ω—É—Ç")
    print()

    all_results = {
        "test_info": {
            "timestamp": datetime.now().isoformat(),
            "phase": "Phase 4 Integration",
            "week": "Week 1 Final Test",
            "python_version": sys.version,
            "cuda_available": torch.cuda.is_available(),
            "gpu_name": (
                torch.cuda.get_device_name(0) if torch.cuda.is_available() else "None"
            ),
        }
    }

    try:
        # 1. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ vs –±–∞–∑–æ–≤–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        comparison_results = test_optimized_vs_baseline_training()
        all_results["comparison"] = comparison_results

        print("\n" + "=" * 50)

        # 2. –¢–µ—Å—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
        scaling_results, scaling_efficiency = test_progressive_scaling_training()
        all_results["progressive_scaling"] = {
            "results": scaling_results,
            "memory_efficiency": scaling_efficiency,
        }

        # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results_file = save_test_results(all_results)

        print("\n" + "=" * 80)
        print("üéâ –ü–û–õ–ù–´–ô –¶–ò–ö–õ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
        print()

        # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        print("üìä –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ù–ï–î–ï–õ–ò 1:")
        print()

        opt_success = (
            comparison_results["optimized"]["stage1"]["success"]
            and comparison_results["optimized"]["stage2"]["success"]
        )
        base_success = (
            comparison_results["baseline"]["stage1"]["success"]
            and comparison_results["baseline"]["stage2"]["success"]
        )

        print(
            f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ: {'–£—Å–ø–µ—à–Ω–æ' if opt_success else '–ù–µ—É–¥–∞—á–Ω–æ'}"
        )
        print(f"üìä –ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ: {'–£—Å–ø–µ—à–Ω–æ' if base_success else '–ù–µ—É–¥–∞—á–Ω–æ'}")

        scaling_success_count = len(
            [r for r in scaling_results if r["training_result"]["success"]]
        )
        print(
            f"üìê –ü—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ: {scaling_success_count}/{len(scaling_results)} —Å—Ç–∞–¥–∏–π"
        )

        print()
        print("üöÄ –ì–û–¢–û–í–ù–û–°–¢–¨ –ö –ù–ï–î–ï–õ–ï 2:")
        if opt_success and scaling_success_count >= 2:
            print("   ‚úÖ –í—Å–µ —Å–∏—Å—Ç–µ–º—ã –≥–æ—Ç–æ–≤—ã –∫ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—é")
            print("   ‚úÖ Memory optimizations —Ä–∞–±–æ—Ç–∞—é—Ç")
            print("   ‚úÖ Progressive scaling —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä—É–µ—Ç")
            print("   ‚úÖ Plasticity profiles –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω—ã")
            print()
            print("‚û°Ô∏è  –°–õ–ï–î–£–Æ–©–ò–ô –≠–¢–ê–ü: Progressive Scaling (Week 2)")
            print("     - Scaling –¥–æ 32√ó32√ó24 —Ä–µ—à–µ—Ç–æ–∫")
            print("     - Real-time decoder monitoring")
            print("     - Advanced memory budget management")
        else:
            print("   ‚ö†Ô∏è  –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞")
            print("   ‚ö†Ô∏è  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –æ—à–∏–±–æ–∫")

        print(f"\nüìÑ –ü–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {results_file}")

        return opt_success and scaling_success_count >= 2

    except Exception as e:
        print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
