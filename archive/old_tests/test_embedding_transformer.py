#!/usr/bin/env python3
"""
–¢–µ—Å—Ç EmbeddingTransformer
========================

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—è —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –º–µ–∂–¥—É Teacher –º–æ–¥–µ–ª—å—é –∏ –∫—É–±–æ–º.
"""

import logging
import torch

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

from new_rebuild.config.simple_config import get_project_config
from new_rebuild.core.common.embedding_transformer import (
    create_embedding_transformer, 
    test_embedding_transformer
)
from new_rebuild.utils.logging import get_logger

logger = get_logger(__name__)


def test_basic_transformer():
    """–¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–≥–æ –ª–∏–Ω–µ–π–Ω–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—è"""
    logger.info("=== –¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—è ===")
    
    config = get_project_config()
    config.embedding.transformation_type = "linear"
    config.embedding.use_residual_connections = True
    
    transformer, metrics = test_embedding_transformer(config, batch_size=8)
    
    logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–∞–∑–æ–≤–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—è:")
    logger.info(f"  MSE Loss: {metrics['mse_loss']:.6f}")
    logger.info(f"  Cosine Similarity: {metrics['cosine_similarity']:.6f}")
    logger.info(f"  Parameters: {metrics['parameter_count']:,}")
    
    return metrics


def test_hierarchical_transformer():
    """–¢–µ—Å—Ç –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—è"""
    logger.info("\n=== –¢–µ—Å—Ç –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—è ===")
    
    config = get_project_config()
    config.embedding.transformation_type = "hierarchical"
    config.embedding.use_residual_connections = True
    config.embedding.use_layer_norm = True
    
    transformer, metrics = test_embedding_transformer(config, batch_size=8)
    
    logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—è:")
    logger.info(f"  MSE Loss: {metrics['mse_loss']:.6f}")
    logger.info(f"  Cosine Similarity: {metrics['cosine_similarity']:.6f}")
    logger.info(f"  Parameters: {metrics['parameter_count']:,}")
    
    return metrics


def test_different_cube_sizes():
    """–¢–µ—Å—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –∫—É–±–æ–≤"""
    logger.info("\n=== –¢–µ—Å—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –∫—É–±–æ–≤ ===")
    
    cube_sizes = [27, 37, 50]  # 27√ó27=729, 37√ó37=1369, 50√ó50=2500
    results = {}
    
    for size in cube_sizes:
        logger.info(f"\n–¢–µ—Å—Ç–∏—Ä—É–µ–º –∫—É–± {size}√ó{size}√ó{size}:")
        
        config = get_project_config()
        config.embedding.cube_surface_dim = size
        config.embedding.cube_embedding_dim = size * size
        config.embedding.transformation_type = "hierarchical"
        
        transformer, metrics = test_embedding_transformer(config, batch_size=4)
        results[size] = metrics
        
        logger.info(f"  Compression ratio: {transformer.get_compression_ratio():.2f}")
    
    return results


def test_batch_sizes():
    """–¢–µ—Å—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –±–∞—Ç—á–µ–π"""
    logger.info("\n=== –¢–µ—Å—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –±–∞—Ç—á–µ–π ===")
    
    config = get_project_config()
    config.embedding.transformation_type = "hierarchical"
    
    transformer = create_embedding_transformer(config)
    
    batch_sizes = [1, 4, 16, 32]
    
    for batch_size in batch_sizes:
        logger.info(f"\n–ë–∞—Ç—á —Ä–∞–∑–º–µ—Ä: {batch_size}")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        teacher_embeddings = torch.randn(batch_size, config.embedding.teacher_embedding_dim)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
        cube_embeddings = transformer.transform_to_cube(teacher_embeddings)
        reconstructed = transformer.transform_from_cube(cube_embeddings)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        assert teacher_embeddings.shape == reconstructed.shape
        assert cube_embeddings.shape == (batch_size, config.embedding.cube_surface_dim, 
                                       config.embedding.cube_surface_dim)
        
        mse = torch.nn.functional.mse_loss(reconstructed, teacher_embeddings)
        logger.info(f"  ‚úì MSE: {mse:.6f}")


def compare_transformation_types():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π"""
    logger.info("\n=== –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π ===")
    
    types = ["linear", "hierarchical"]
    results = {}
    
    for transform_type in types:
        logger.info(f"\n–¢–∏–ø: {transform_type}")
        
        config = get_project_config()
        config.embedding.transformation_type = transform_type
        config.embedding.use_residual_connections = True
        
        transformer, metrics = test_embedding_transformer(config, batch_size=16)
        results[transform_type] = metrics
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    logger.info("\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    for transform_type, metrics in results.items():
        logger.info(f"  {transform_type}:")
        logger.info(f"    MSE: {metrics['mse_loss']:.6f}")
        logger.info(f"    Cosine Similarity: {metrics['cosine_similarity']:.6f}")
        logger.info(f"    Parameters: {metrics['parameter_count']:,}")
    
    return results


if __name__ == "__main__":
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ EmbeddingTransformer")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Ç–µ—Å—Ç—ã
    basic_results = test_basic_transformer()
    hierarchical_results = test_hierarchical_transformer()
    cube_size_results = test_different_cube_sizes()
    test_batch_sizes()
    comparison_results = compare_transformation_types()
    
    logger.info("\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã EmbeddingTransformer –∑–∞–≤–µ—Ä—à–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
    
    # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    logger.info("\nüìà –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    logger.info(f"  –õ—É—á—à–∞—è cosine similarity: {max(basic_results['cosine_similarity'], hierarchical_results['cosine_similarity']):.6f}")
    logger.info(f"  –ù–∞–∏–º–µ–Ω—å—à–∏–π MSE: {min(basic_results['mse_loss'], hierarchical_results['mse_loss']):.6f}")