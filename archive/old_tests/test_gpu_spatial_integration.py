#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ GPU Spatial Optimization –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
==================================================

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:
- GPU Spatial Hashing (GPUMortonEncoder, GPUSpatialHashGrid, AdaptiveGPUSpatialHash)
- Adaptive Chunking (AdaptiveGPUChunker)
- Integrated Spatial Processor (GPUSpatialProcessor)

–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏:
1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
2. GPU Memory management
3. Spatial query performance
4. Component integration
5. Performance benchmarks
"""

import sys
import os

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import torch
import numpy as np
import time
from typing import List, Dict, Tuple
import traceback

from new_rebuild.config import get_project_config
from new_rebuild.utils.device_manager import get_device_manager
from new_rebuild.utils.logging import get_logger

# –ò–º–ø–æ—Ä—Ç—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ GPU Spatial Optimization
from new_rebuild.core.lattice.gpu_spatial_hashing import (
    GPUMortonEncoder,
    GPUSpatialHashGrid,
    AdaptiveGPUSpatialHash,
)
from new_rebuild.core.lattice.spatial_optimization.adaptive_chunker import (
    AdaptiveGPUChunker,
    AdaptiveChunkInfo,
)
from new_rebuild.core.lattice.spatial_optimization.gpu_spatial_processor import (
    GPUSpatialProcessor,
    SpatialQuery,
    SpatialQueryResult,
)

logger = get_logger(__name__)


class GPUSpatialIntegrationTester:
    """–¢–µ—Å—Ç–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ GPU Spatial Optimization –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""

    def __init__(self):
        self.config = get_project_config()
        self.device_manager = get_device_manager()
        self.device = self.device_manager.get_device()

        # –¢–µ—Å—Ç–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã —Ä–µ—à–µ—Ç–æ–∫
        self.test_dimensions = [
            (10, 10, 10),  # –ú–∞–ª–µ–Ω—å–∫–∞—è
            (25, 25, 25),  # –°—Ä–µ–¥–Ω—è—è
            (50, 50, 50),  # –ë–æ–ª—å—à–∞—è
        ]

        self.results = {}

    def run_all_tests(self) -> Dict[str, bool]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Ç–µ—Å—Ç—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ GPU Spatial Optimization –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏")

        tests = [
            ("GPU Morton Encoder", self.test_gpu_morton_encoder),
            ("GPU Spatial Hash Grid", self.test_gpu_spatial_hash_grid),
            ("Adaptive GPU Spatial Hash", self.test_adaptive_gpu_spatial_hash),
            ("Adaptive GPU Chunker", self.test_adaptive_gpu_chunker),
            ("GPU Spatial Processor", self.test_gpu_spatial_processor),
            ("Integration Performance", self.test_integration_performance),
            ("Memory Management", self.test_memory_management),
        ]

        results = {}
        for test_name, test_func in tests:
            try:
                logger.info(f"üìä –¢–µ—Å—Ç: {test_name}")
                start_time = time.time()
                success = test_func()
                elapsed = (time.time() - start_time) * 1000

                results[test_name] = success
                status = "‚úÖ –ü–†–û–ô–î–ï–ù" if success else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
                logger.info(f"   {status} –∑–∞ {elapsed:.2f}ms")

            except Exception as e:
                logger.error(f"   ‚ùå –û–®–ò–ë–ö–ê: {e}")
                logger.error(f"   Traceback: {traceback.format_exc()}")
                results[test_name] = False

        return results

    def test_gpu_morton_encoder(self) -> bool:
        """–¢–µ—Å—Ç GPU Morton Encoder"""
        try:
            dimensions = (64, 64, 64)
            encoder = GPUMortonEncoder(dimensions)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            test_coords = torch.tensor(
                [[10, 20, 30], [40, 50, 60], [5, 15, 25]],
                dtype=torch.long,
                device=self.device,
            )

            # –ö–æ–¥–∏—Ä—É–µ–º –≤ Morton –∫–æ–¥—ã
            morton_codes = encoder.encode_batch(test_coords)
            assert morton_codes.shape == (3,), f"–ù–µ–≤–µ—Ä–Ω–∞—è —Ñ–æ—Ä–º–∞: {morton_codes.shape}"

            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ
            decoded_coords = encoder.decode_batch(morton_codes)
            assert torch.allclose(
                test_coords.float(), decoded_coords.float()
            ), "–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç"

            logger.debug(
                f"   Morton –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ: {test_coords.tolist()} -> {morton_codes.tolist()}"
            )
            return True

        except Exception as e:
            logger.error(f"Morton Encoder –æ—à–∏–±–∫–∞: {e}")
            return False

    def test_gpu_spatial_hash_grid(self) -> bool:
        """–¢–µ—Å—Ç GPU Spatial Hash Grid"""
        try:
            dimensions = (32, 32, 32)
            hash_grid = GPUSpatialHashGrid(dimensions, cell_size=8)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            num_points = 100
            coordinates = torch.randint(
                0, 32, (num_points, 3), dtype=torch.long, device=self.device
            )
            indices = torch.arange(num_points, device=self.device)

            # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
            hash_grid.insert_batch(coordinates, indices)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
            query_points = torch.tensor(
                [[16, 16, 16]], dtype=torch.float32, device=self.device
            )
            neighbors = hash_grid.query_radius_batch(query_points, radius=5.0)

            assert (
                len(neighbors) == 1
            ), f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(neighbors)}"
            assert len(neighbors[0]) > 0, "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ—Å–µ–¥–µ–π"

            logger.debug(f"   –ù–∞–π–¥–µ–Ω–æ —Å–æ—Å–µ–¥–µ–π: {len(neighbors[0])}")
            return True

        except Exception as e:
            logger.error(f"Spatial Hash Grid –æ—à–∏–±–∫–∞: {e}")
            return False

    def test_adaptive_gpu_spatial_hash(self) -> bool:
        """–¢–µ—Å—Ç Adaptive GPU Spatial Hash"""
        try:
            dimensions = (50, 50, 50)
            adaptive_hash = AdaptiveGPUSpatialHash(dimensions, target_memory_mb=512.0)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
            num_points = 500
            coordinates = torch.randint(
                0, 50, (num_points, 3), dtype=torch.float32, device=self.device
            )
            indices = torch.arange(num_points, device=self.device)

            # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
            adaptive_hash.insert_batch(coordinates, indices)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
            for i in range(3):
                query_points = torch.rand(5, 3, device=self.device) * 50
                neighbors = adaptive_hash.query_radius_batch(query_points, radius=8.0)
                assert (
                    len(neighbors) == 5
                ), f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(neighbors)}"

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats = adaptive_hash.get_comprehensive_stats()
            assert "hash_grid" in stats, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ hash_grid"
            assert "adaptations" in stats, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ adaptations"

            logger.debug(f"   –ê–¥–∞–ø—Ç–∞—Ü–∏–∏: {stats['adaptations']}")
            return True

        except Exception as e:
            logger.error(f"Adaptive Spatial Hash –æ—à–∏–±–∫–∞: {e}")
            return False

    def test_adaptive_gpu_chunker(self) -> bool:
        """–¢–µ—Å—Ç Adaptive GPU Chunker"""
        try:
            dimensions = (40, 40, 40)
            chunker = AdaptiveGPUChunker(dimensions)

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ chunk'–∞—Ö
            total_chunks = len(chunker.chunks)
            assert total_chunks > 0, "–ù–µ —Å–æ–∑–¥–∞–Ω–æ chunk'–æ–≤"

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ chunk'–∞ –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º
            test_coords = (20, 20, 20)
            chunk_info = chunker.get_chunk_by_coords(test_coords)
            assert chunk_info is not None, "–ù–µ –Ω–∞–π–¥–µ–Ω chunk –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç"

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º schedule –ø–æ–ª—É—á–µ–Ω–∏—è
            schedule = chunker.get_adaptive_processing_schedule()
            assert len(schedule) > 0, "–ü—É—Å—Ç–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏"

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            chunk_id = chunk_info.chunk_id
            future = chunker.process_chunk_async(chunk_id, "load")
            assert future is not None, "–ù–µ —Å–æ–∑–¥–∞–Ω–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞"

            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats = chunker.get_comprehensive_stats()
            assert "chunks" in stats, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ chunks"
            assert (
                "total_chunks" in stats["chunks"]
            ), "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ total_chunks"

            logger.debug(f"   –°–æ–∑–¥–∞–Ω–æ chunk'–æ–≤: {total_chunks}")
            logger.debug(f"   –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats['chunks']['total_chunks']} chunk'–æ–≤")
            return True

        except Exception as e:
            logger.error(f"Adaptive Chunker –æ—à–∏–±–∫–∞: {e}")
            return False

    def test_gpu_spatial_processor(self) -> bool:
        """–¢–µ—Å—Ç GPU Spatial Processor (–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç)"""
        try:
            dimensions = (30, 30, 30)
            processor = GPUSpatialProcessor(dimensions)

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            test_coordinates = torch.tensor(
                [[15, 15, 15], [10, 10, 10], [20, 20, 20]],
                dtype=torch.float32,
                device=self.device,
            )

            # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            result = processor.query_neighbors_sync(
                coordinates=test_coordinates, radius=5.0, timeout=10.0
            )

            assert result is not None, "–ù–µ –ø–æ–ª—É—á–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"
            assert (
                len(result.neighbor_lists) == 3
            ), f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(result.neighbor_lists)}"
            assert result.processing_time_ms > 0, "–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ –∑–∞–ø–∏—Å–∞–Ω–æ"

            # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            query_id = processor.query_neighbors_async(
                coordinates=test_coordinates, radius=8.0, priority=10
            )

            assert query_id is not None, "–ù–µ –ø–æ–ª—É—á–µ–Ω ID –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"

            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            max_wait = 50  # 5 —Å–µ–∫—É–Ω–¥
            completed = False
            for _ in range(max_wait):
                if processor.is_query_complete(query_id):
                    completed = True
                    break
                time.sleep(0.1)

            assert completed, "–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è"

            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            async_result = processor.get_query_result(query_id)
            assert async_result is not None, "–ù–µ –ø–æ–ª—É—á–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            stats = processor.get_performance_stats()
            assert "processor" in stats, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ processor"
            assert (
                stats["processor"]["total_queries"] >= 2
            ), "–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ"

            logger.debug(f"   –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {result.processing_time_ms:.2f}ms")
            logger.debug(
                f"   –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {async_result.processing_time_ms:.2f}ms"
            )
            logger.debug(f"   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['processor']['total_queries']}")

            # –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É
            processor.shutdown()
            return True

        except Exception as e:
            logger.error(f"Spatial Processor –æ—à–∏–±–∫–∞: {e}")
            return False

    def test_integration_performance(self) -> bool:
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
        try:
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–∞—Ö
            performance_results = {}

            for dimensions in self.test_dimensions:
                logger.debug(f"   –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {dimensions}")

                processor = GPUSpatialProcessor(dimensions)

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                num_queries = 10
                max_coord = max(dimensions)
                coordinates = torch.rand(num_queries, 3, device=self.device) * max_coord

                # –ò–∑–º–µ—Ä—è–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                start_time = time.time()

                result = processor.query_neighbors_sync(
                    coordinates=coordinates,
                    radius=max_coord * 0.1,  # 10% –æ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
                    timeout=30.0,
                )

                elapsed_ms = (time.time() - start_time) * 1000

                performance_results[dimensions] = {
                    "time_ms": elapsed_ms,
                    "queries_per_second": num_queries / (elapsed_ms / 1000),
                    "processing_time_ms": result.processing_time_ms,
                    "memory_usage_mb": result.memory_usage_mb,
                }

                processor.shutdown()

            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            for dims, perf in performance_results.items():
                logger.debug(
                    f"   {dims}: {perf['time_ms']:.2f}ms, "
                    f"{perf['queries_per_second']:.1f} q/s, "
                    f"{perf['memory_usage_mb']:.2f}MB"
                )

            return True

        except Exception as e:
            logger.error(f"Performance —Ç–µ—Å—Ç –æ—à–∏–±–∫–∞: {e}")
            return False

    def test_memory_management(self) -> bool:
        """–¢–µ—Å—Ç —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–∞–º—è—Ç–∏
            initial_stats = self.device_manager.get_memory_stats()

            dimensions = (60, 60, 60)  # –ë–æ–ª—å—à–∞—è —Ä–µ—à–µ—Ç–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞–º—è—Ç–∏

            # –°–æ–∑–¥–∞–µ–º –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º processor
            processor = GPUSpatialProcessor(dimensions)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–ø–µ—Ä–∞—Ü–∏–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞–º—è—Ç–∏
            for i in range(5):
                coordinates = torch.rand(20, 3, device=self.device) * 60
                result = processor.query_neighbors_sync(coordinates, radius=10.0)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
                current_stats = self.device_manager.get_memory_stats()
                logger.debug(
                    f"     –ò—Ç–µ—Ä–∞—Ü–∏—è {i+1}: {current_stats.get('used_mb', 0):.2f}MB –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ"
                )

            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            processor.optimize_performance()

            # –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ—á–∏—Å—Ç–∫—É –ø–∞–º—è—Ç–∏
            processor.shutdown()

            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
            self.device_manager.cleanup()

            final_stats = self.device_manager.get_memory_stats()

            logger.debug(
                f"   –ù–∞—á–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å: {initial_stats.get('used_mb', 0):.2f}MB"
            )
            logger.debug(f"   –§–∏–Ω–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å: {final_stats.get('used_mb', 0):.2f}MB")

            return True

        except Exception as e:
            logger.error(f"Memory management —Ç–µ—Å—Ç –æ—à–∏–±–∫–∞: {e}")
            return False


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–æ–≤"""
    print("=" * 60)
    print("GPU Spatial Optimization Integration Test")
    print("=" * 60)

    tester = GPUSpatialIntegrationTester()
    results = tester.run_all_tests()

    # –ü–æ–¥–≤–æ–¥–∏–º –∏—Ç–æ–≥–∏
    print("\n" + "=" * 60)
    print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    print("=" * 60)

    passed = 0
    total = len(results)

    for test_name, success in results.items():
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if success else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        print(f"{test_name:<30} {status}")
        if success:
            passed += 1

    print("-" * 60)
    print(f"–ü—Ä–æ–π–¥–µ–Ω–æ: {passed}/{total} —Ç–µ—Å—Ç–æ–≤ ({passed/total*100:.1f}%)")

    if passed == total:
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´! GPU Spatial Optimization —É—Å–ø–µ—à–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω!")
        return 0
    else:
        print("‚ö†Ô∏è –ù–ï–ö–û–¢–û–†–´–ï –¢–ï–°–¢–´ –ü–†–û–í–ê–õ–ï–ù–´. –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞.")
        return 1


if __name__ == "__main__":
    exit(main())
