#!/usr/bin/env python3
"""
PHASE 2.7.2 - PhraseBankDecoder Stage 1.2 Optimization Test
==========================================================

Testing Stage 1.2 optimizations:
- Context-aware phrase selection 
- Improved text assembly
- Post-processing capabilities
- Session management
- Enhanced quality metrics

Author: AI Assistant
Date: 6 –¥–µ–∫–∞–±—Ä—è 2024
"""

import time
import torch
import sys
import os
import numpy as np

# [CONFIG] CUDA COMPATIBILITY FIX –¥–ª—è RTX 5090
os.environ['CUDA_VISIBLE_DEVICES'] = ''
torch.backends.cudnn.enabled = False
torch.set_default_device('cpu')

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ PATH
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_context_aware_decoding():
    """–¢–µ—Å—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-–æ—Å–≤–µ–¥–æ–º–ª–µ–Ω–Ω–æ–≥–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("\n[BRAIN] Testing context-aware decoding...")
    
    try:
        from inference.lightweight_decoder.phrase_bank_decoder import (
            PhraseBankDecoder, DecodingConfig
        )
        from data.embedding_loader import EmbeddingLoader
        
        # –°–æ–∑–¥–∞–Ω–∏–µ decoder —Å context-aware —Ä–µ–∂–∏–º–æ–º
        config = DecodingConfig(
            assembly_method="context_aware",
            context_weight=0.4,
            length_preference="medium",
            enable_grammar_fix=True,
            enable_coherence_boost=True
        )
        
        decoder = PhraseBankDecoder(
            embedding_dim=768,
            phrase_bank_size=50000,
            similarity_threshold=0.75,
            config=config
        )
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ phrase bank
        embedding_loader = EmbeddingLoader(cache_dir="./cache")
        decoder.load_phrase_bank(embedding_loader=embedding_loader)
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        test_sequences = [
            ["Hello, how are you?", "I'm doing great!", "Thank you for asking"],
            ["Good morning", "Have a nice day", "See you later"],
            ["What's the weather?", "It's sunny today", "Perfect for a walk"]
        ]
        
        print("   [TARGET] Testing context awareness across sequences...")
        
        for seq_idx, sequence in enumerate(test_sequences):
            print(f"   \n   Sequence {seq_idx + 1}: {' -> '.join(sequence)}")
            
            # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
            decoder.start_new_session()
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            for step, text in enumerate(sequence):
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–∏–Ω–≥
                embedding = embedding_loader.load_from_llm(
                    texts=[text],
                    model_key="distilbert",
                    use_cache=True
                )[0]
                
                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º
                decoded_text = decoder.decode(embedding)
                context_info = decoder.get_context_info()
                
                print(f"     Step {step + 1}: '{decoded_text}' (history: {context_info['phrase_history_length']})")
        
        return True
        
    except Exception as e:
        print(f"   [ERROR] Context-aware decoding failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_post_processing():
    """–¢–µ—Å—Ç –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞"""
    print("\n‚ú® Testing text post-processing...")
    
    try:
        from inference.lightweight_decoder.phrase_bank_decoder import (
            TextPostProcessor, DecodingConfig
        )
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å –≤–∫–ª—é—á–µ–Ω–Ω–æ–π –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–æ–π
        config = DecodingConfig(
            enable_grammar_fix=True,
            enable_coherence_boost=True,
            enable_redundancy_removal=True
        )
        
        post_processor = TextPostProcessor(config)
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ —Å–ª—É—á–∞–∏ –¥–ª—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏
        test_cases = [
            ("hello  world  test", "Hello world test"),  # –ì—Ä–∞–º–º–∞—Ç–∏–∫–∞
            ("test test repeat repeat", "Test repeat"),   # –ò–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç—å  
            ("uncertain response", "It seems uncertain response"),  # –ö–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
        ]
        
        print("   [WRITE] Testing grammar fixes, redundancy removal, coherence boost...")
        
        for raw_text, expected_pattern in test_cases:
            processed = post_processor.process_text(raw_text, confidence=0.5)
            print(f"     '{raw_text}' -> '{processed}'")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
            assert len(processed.strip()) > 0, "Processed text should not be empty"
            assert processed[0].isupper(), "Should start with capital letter"
        
        print("   [OK] Post-processing works correctly")
        return True
        
    except Exception as e:
        print(f"   [ERROR] Post-processing failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_session_management():
    """–¢–µ—Å—Ç —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–µ—Å—Å–∏—è–º–∏"""
    print("\n[INFO] Testing session management...")
    
    try:
        from inference.lightweight_decoder.phrase_bank_decoder import (
            PhraseBankDecoder, DecodingConfig
        )
        from data.embedding_loader import EmbeddingLoader
        
        # –°–æ–∑–¥–∞–Ω–∏–µ decoder
        config = DecodingConfig(assembly_method="context_aware")
        decoder = PhraseBankDecoder(config=config)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ phrase bank
        embedding_loader = EmbeddingLoader(cache_dir="./cache")
        decoder.load_phrase_bank(embedding_loader=embedding_loader)
        
        # –¢–µ—Å—Ç –Ω–∞—á–∞–ª—å–Ω–æ–π —Å–µ—Å—Å–∏–∏
        print("   [START] Testing session start/reset...")
        initial_context = decoder.get_context_info()
        assert initial_context['phrase_history_length'] == 0, "Initial context should be empty"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–π
        test_texts = ["Hello world", "Good morning", "Thank you"]
        embeddings_batch = embedding_loader.load_from_llm(
            texts=test_texts,
            model_key="distilbert",
            use_cache=True
        )
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —ç–º–±–µ–¥–∏–Ω–≥ –æ—Ç–¥–µ–ª—å–Ω–æ
        for i in range(len(test_texts)):
            embedding = embeddings_batch[i]  # –ü–æ–ª—É—á–∞–µ–º i-–π —ç–º–±–µ–¥–∏–Ω–≥
            decoder.decode(embedding)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context_with_history = decoder.get_context_info()
        assert context_with_history['phrase_history_length'] > 0, "Context should have history"
        
        # –°–±—Ä–æ—Å —Å–µ—Å—Å–∏–∏
        decoder.start_new_session()
        reset_context = decoder.get_context_info()
        assert reset_context['phrase_history_length'] == 0, "Context should be reset"
        
        print("   [OK] Session management works correctly")
        
        # –¢–µ—Å—Ç batch –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Å —Å–µ—Å—Å–∏—è–º–∏
        print("   [PACKAGE] Testing batch decoding with session boundaries...")
        
        # embeddings_batch —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è —Ç–µ–Ω–∑–æ—Ä–æ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º—ã (N, 768)
        session_boundaries = [0, 2]  # –°–±—Ä–æ—Å –Ω–∞ –ø–æ–∑–∏—Ü–∏—è—Ö 0 –∏ 2
        
        results = decoder.batch_decode_with_sessions(
            embeddings_batch,
            session_boundaries=session_boundaries
        )
        
        assert len(results) == len(test_texts), "Should return result for each input"
        print(f"     Batch results: {results}")
        
        return True
        
    except Exception as e:
        print(f"   [ERROR] Session management failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_assembly_methods_comparison():
    """–¢–µ—Å—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤ —Å–±–æ—Ä–∫–∏"""
    print("\n‚öñÔ∏è  Testing assembly methods comparison...")
    
    try:
        from inference.lightweight_decoder.phrase_bank_decoder import (
            PhraseBankDecoder, DecodingConfig
        )
        from data.embedding_loader import EmbeddingLoader
        
        embedding_loader = EmbeddingLoader(cache_dir="./cache")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã —Å–±–æ—Ä–∫–∏
        assembly_methods = ["weighted", "greedy", "beam_search", "context_aware"]
        
        test_text = "Hello, how are you today?"
        test_embedding = embedding_loader.load_from_llm(
            texts=[test_text],
            model_key="distilbert",
            use_cache=True
        )[0]
        
        results = {}
        
        for method in assembly_methods:
            print(f"   [CONFIG] Testing {method} method...")
            
            config = DecodingConfig(assembly_method=method)
            decoder = PhraseBankDecoder(config=config)
            decoder.load_phrase_bank(embedding_loader=embedding_loader)
            
            # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
            decoded_text, metrics = decoder.decode_with_metrics(test_embedding)
            
            results[method] = {
                'text': decoded_text,
                'confidence': metrics['confidence'],
                'quality_score': metrics['quality_score']
            }
            
            print(f"     Result: '{decoded_text}' (confidence: {metrics['confidence']:.3f})")
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("\n   [DATA] Assembly methods comparison:")
        for method, result in results.items():
            print(f"     {method:15}: confidence={result['confidence']:.3f}, quality={result['quality_score']:.3f}")
        
        return True
        
    except Exception as e:
        print(f"   [ERROR] Assembly methods comparison failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_performance_optimization():
    """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π"""
    print("\n[FAST] Testing performance optimizations...")
    
    try:
        from inference.lightweight_decoder.phrase_bank_decoder import (
            PhraseBankDecoder, DecodingConfig
        )
        from data.embedding_loader import EmbeddingLoader
        
        # –°–æ–∑–¥–∞–Ω–∏–µ decoder —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        config = DecodingConfig(
            assembly_method="context_aware",
            max_candidates=5,  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            similarity_threshold=0.7
        )
        
        decoder = PhraseBankDecoder(config=config)
        embedding_loader = EmbeddingLoader(cache_dir="./cache")
        decoder.load_phrase_bank(embedding_loader=embedding_loader)
        
        # –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –±–∞—Ç—á–µ
        print("   ‚è±Ô∏è  Testing batch performance...")
        
        test_texts = [f"Test sentence number {i}" for i in range(20)]
        batch_embeddings = embedding_loader.load_from_llm(
            texts=test_texts,
            model_key="distilbert",
            use_cache=True
        )
        
        # batch_embeddings —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è —Ç–µ–Ω–∑–æ—Ä–æ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º—ã (N, 768)
        
        # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è
        start_time = time.time()
        results = decoder.batch_decode(batch_embeddings)
        end_time = time.time()
        
        total_time = (end_time - start_time) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
        avg_time = total_time / len(results)
        
        print(f"     Batch size: {len(results)}")
        print(f"     Total time: {total_time:.2f} ms")
        print(f"     Average per item: {avg_time:.2f} ms")
        print(f"     Throughput: {len(results) / (total_time / 1000):.1f} items/sec")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–ª–µ–≤—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        target_time_per_item = 50  # 50ms –Ω–∞ —ç–ª–µ–º–µ–Ω—Ç
        if avg_time <= target_time_per_item:
            print(f"   [OK] Performance target met: {avg_time:.2f}ms <= {target_time_per_item}ms")
        else:
            print(f"   [WARNING]  Performance target missed: {avg_time:.2f}ms > {target_time_per_item}ms")
        
        return True
        
    except Exception as e:
        print(f"   [ERROR] Performance optimization test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_quality_metrics():
    """–¢–µ—Å—Ç —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞"""
    print("\n[CHART] Testing enhanced quality metrics...")
    
    try:
        from inference.lightweight_decoder.phrase_bank_decoder import (
            PhraseBankDecoder, DecodingConfig
        )
        from data.embedding_loader import EmbeddingLoader
        
        config = DecodingConfig(assembly_method="context_aware")
        decoder = PhraseBankDecoder(config=config)
        
        embedding_loader = EmbeddingLoader(cache_dir="./cache")
        decoder.load_phrase_bank(embedding_loader=embedding_loader)
        
        # –¢–µ—Å—Ç —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        test_cases = [
            "Clear and simple sentence",          # –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ–∂–∏–¥–∞–µ—Ç—Å—è
            "Ambiguous unclear meaning text",     # –°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            "Xyztabc random nonsense words"       # –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ–∂–∏–¥–∞–µ—Ç—Å—è
        ]
        
        print("   [DATA] Testing quality assessment for different input types...")
        
        quality_results = []
        
        for test_text in test_cases:
            embedding = embedding_loader.load_from_llm(
                texts=[test_text],
                model_key="distilbert", 
                use_cache=True
            )[0]
            
            decoded_text, metrics = decoder.decode_with_metrics(embedding)
            
            quality_results.append({
                'input': test_text,
                'output': decoded_text,
                'quality_score': metrics['quality_score'],
                'confidence': metrics['confidence'],
                'coherence': metrics.get('coherence', 0.0),
                'num_candidates': metrics['num_candidates']
            })
            
            print(f"     Input: '{test_text}'")
            print(f"     Output: '{decoded_text}'")
            print(f"     Quality: {metrics['quality_score']:.3f}, Confidence: {metrics['confidence']:.3f}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç—Ä–µ–Ω–¥—ã –∫–∞—á–µ—Å—Ç–≤–∞
        qualities = [r['quality_score'] for r in quality_results]
        print(f"\n   [CHART] Quality trend: {qualities}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–µ–∫–æ–¥–µ—Ä–∞
        stats = decoder.get_statistics()
        print(f"   [DATA] Decoder statistics:")
        print(f"     Success rate: {stats['success_rate']}")
        print(f"     Average confidence: {stats['avg_confidence']:.3f}")
        print(f"     Average quality: {stats['avg_quality']:.3f}")
        
        return True
        
    except Exception as e:
        print(f"   [ERROR] Quality metrics test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Stage 1.2"""
    print("[START] PHASE 2.7.2 - PhraseBankDecoder Stage 1.2 Optimization Test")
    print("="*70)
    
    test_results = []
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ —Ç–µ—Å—Ç—ã
    tests = [
        ("Context-Aware Decoding", test_context_aware_decoding),
        ("Text Post-Processing", test_post_processing),
        ("Session Management", test_session_management), 
        ("Assembly Methods Comparison", test_assembly_methods_comparison),
        ("Performance Optimization", test_performance_optimization),
        ("Quality Metrics", test_quality_metrics),
    ]
    
    for test_name, test_func in tests:
        try:
            print(f"\n[INFO] Running {test_name}...")
            result = test_func()
            test_results.append((test_name, result))
            
            if result:
                print(f"[OK] {test_name}: PASSED")
            else:
                print(f"[ERROR] {test_name}: FAILED")
                
        except Exception as e:
            print(f"üí• {test_name}: CRASHED - {e}")
            test_results.append((test_name, False))
    
    # –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "="*70)
    print("[TARGET] STAGE 1.2 OPTIMIZATION RESULTS")
    print("="*70)
    
    passed = sum(1 for _, result in test_results if result)
    total = len(test_results)
    success_rate = (passed / total) * 100 if total > 0 else 0
    
    for test_name, result in test_results:
        status = "[OK] PASS" if result else "[ERROR] FAIL"
        print(f"{status} {test_name}")
    
    print(f"\n[TARGET] Stage 1.2: {passed}/{total} tests passed ({success_rate:.1f}%)")
    
    if success_rate >= 80:
        print("\n[SUCCESS] STAGE 1.2 OPTIMIZATION: SUCCESS!")
        print("[INFO] Ready for Stage 1.3: Production readiness")
        
        # Checkpoint 1.2 summary
        print("\n[DATA] CHECKPOINT 1.2 ACHIEVEMENTS:")
        print("[OK] Context-aware phrase selection implemented")
        print("[OK] Advanced text post-processing working")
        print("[OK] Session management system operational")
        print("[OK] Multiple assembly methods available")
        print("[OK] Performance optimizations effective")
        print("[OK] Enhanced quality metrics functional")
        
    else:
        print(f"\n[WARNING]  STAGE 1.2 NEEDS IMPROVEMENT: {success_rate:.1f}% < 80%")
        print("[CONFIG] Review failed tests and optimize implementation")

if __name__ == "__main__":
    main() 