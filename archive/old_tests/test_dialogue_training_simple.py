#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç Dialogue Training –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ dialogue training
–±–µ–∑ —Å–ª–æ–∂–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.
"""

import torch
import torch.nn as nn
import logging
from typing import List, Dict

# –ò–º–ø–æ—Ä—Ç—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
from training.embedding_trainer.cube_trainer import CubeTrainer, TrainingConfig
from training.embedding_trainer.dialogue_dataset import create_dialogue_dataset

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def create_simple_dialogue_data() -> List[Dict]:
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç—ã–µ –¥–∏–∞–ª–æ–≥–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    return [
        {"question": "What is AI?", "answer": "AI is artificial intelligence."},
        {"question": "How are you?", "answer": "I am doing well, thank you."},
        {"question": "What is Python?", "answer": "Python is a programming language."},
        {"question": "Hello there", "answer": "Hello! How can I help you today?"},
        {"question": "Good morning", "answer": "Good morning! Hope you have a great day."},
    ]


def test_components():
    """–¢–µ—Å—Ç –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
    logger.info("=== TESTING COMPONENTS ===")
    
    # 1. –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è dataset
    logger.info("1. Testing DialogueDataset creation...")
    dialogue_pairs = create_simple_dialogue_data()
    
    try:
        dataset = create_dialogue_dataset(
            dialogue_pairs=dialogue_pairs,
            teacher_model="distilbert",
            validation_split=0.4,  # –ë–æ–ª—å—à–µ –¥–ª—è validation –ø—Ä–∏ –º–∞–ª–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
            embedding_dim=768,
            enable_quality_filter=False,  # –û—Ç–∫–ª—é—á–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
            use_cache=True
        )
        logger.info(f"‚úÖ Dataset created: {len(dataset)} pairs")
        
        # –¢–µ—Å—Ç DataLoader
        dataloader = dataset.get_dataloader(batch_size=2, shuffle=False)
        for i, (q_emb, a_emb) in enumerate(dataloader):
            logger.info(f"   Batch {i}: Q={q_emb.shape}, A={a_emb.shape}")
            if i >= 1:  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2 batch'–∞
                break
                
    except Exception as e:
        logger.error(f"‚ùå Dataset creation failed: {e}")
        return False
    
    # 2. –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è CubeTrainer
    logger.info("2. Testing CubeTrainer creation...")
    
    try:
        config = TrainingConfig(
            mode="dialogue",
            device="cpu",
            lattice_size=[8, 8, 12],  # 768D —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
            embedding_dim=768,
            batch_size=2,
            learning_rate=0.01,  # –í—ã—à–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
            epochs=3,
            target_similarity=0.70  # –ü–æ–Ω–∏–∂–µ–Ω–Ω–∞—è —Ü–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∞
        )
        
        trainer = CubeTrainer(config=config)
        trainer.initialize_components()
        logger.info("‚úÖ CubeTrainer created and initialized")
        
    except Exception as e:
        logger.error(f"‚ùå CubeTrainer creation failed: {e}")
        return False
    
    # 3. –¢–µ—Å—Ç forward pass
    logger.info("3. Testing forward pass...")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –æ–¥–∏–Ω —ç–º–±–µ–¥–∏–Ω–≥ –∏–∑ dataset
        sample_q, sample_a = next(iter(dataloader))
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º forward –¥–ª—è –æ–¥–Ω–æ–≥–æ —ç–º–±–µ–¥–∏–Ω–≥–∞
        single_q = sample_q[0]  # [768]
        logger.info(f"   Input shape: {single_q.shape}")
        
        with torch.no_grad():  # –ë–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞
            output = trainer.forward(single_q)
            logger.info(f"   Output shape: {output.shape}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            similarity = torch.nn.functional.cosine_similarity(
                single_q.unsqueeze(0), output.unsqueeze(0), dim=1
            ).item()
            logger.info(f"   Identity similarity: {similarity:.4f}")
            
        logger.info("‚úÖ Forward pass successful")
        
    except Exception as e:
        logger.error(f"‚ùå Forward pass failed: {e}")
        return False
    
    return True


def test_simple_training():
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –æ–±—É—á–µ–Ω–∏—è"""
    logger.info("=== TESTING SIMPLE TRAINING ===")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    dialogue_pairs = create_simple_dialogue_data()
    dataset = create_dialogue_dataset(
        dialogue_pairs=dialogue_pairs,
        teacher_model="distilbert",
        validation_split=0.4,
        embedding_dim=768,
        enable_quality_filter=False,
        use_cache=True
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ trainer
    config = TrainingConfig(
        mode="dialogue",
        device="cpu",
        lattice_size=[8, 8, 12],
        embedding_dim=768,
        batch_size=1,  # –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–π batch
        learning_rate=0.01,
        epochs=2,
        target_similarity=0.60
    )
    
    trainer = CubeTrainer(config=config)
    trainer.initialize_components()
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    dataloader = dataset.get_dataloader(batch_size=1, shuffle=False, validation=False)
    
    logger.info("Starting simplified training...")
    
    try:
        for epoch in range(2):
            logger.info(f"Epoch {epoch + 1}/2")
            
            for batch_idx, (question_emb, answer_emb) in enumerate(dataloader):
                if batch_idx >= 2:  # –¢–æ–ª—å–∫–æ 2 batch'–∞ –¥–ª—è —Ç–µ—Å—Ç–∞
                    break
                
                # –ü–æ–ª—É—á–∞–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ —ç–º–±–µ–¥–∏–Ω–≥–∏
                q_emb = question_emb[0]  # [768]
                a_emb = answer_emb[0]    # [768]
                
                logger.info(f"   Batch {batch_idx}: Q={q_emb.shape}, A={a_emb.shape}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç–º–±–µ–¥–∏–Ω–≥–∏ –Ω–µ NaN
                if torch.isnan(q_emb).any() or torch.isnan(a_emb).any():
                    logger.error("‚ùå NaN detected in embeddings")
                    return False
                
                # –ü—Ä–æ—Å—Ç–æ–π forward –±–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
                with torch.no_grad():
                    processed = trainer.forward(q_emb)
                    similarity = torch.nn.functional.cosine_similarity(
                        processed.unsqueeze(0), a_emb.unsqueeze(0), dim=1
                    ).item()
                    logger.info(f"      Similarity: {similarity:.4f}")
        
        logger.info("‚úÖ Simplified training completed")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Simplified training failed: {e}")
        return False


def main():
    """Main function"""
    logger.info("SIMPLE DIALOGUE TRAINING TEST")
    logger.info("=" * 50)
    
    # –¢–µ—Å—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    if not test_components():
        logger.error("‚ùå Component tests failed")
        return 1
    
    # –¢–µ—Å—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    if not test_simple_training():
        logger.error("‚ùå Simple training test failed")
        return 1
    
    logger.info("‚úÖ ALL TESTS PASSED!")
    logger.info("üöÄ Components are ready for full dialogue training")
    return 0


if __name__ == "__main__":
    exit(main()) 