#!/usr/bin/env python3
"""
PHASE 2.7.1 - PhraseBankDecoder Infrastructure Test
=================================================

Checkpoint 1.1 Verification:
- Phrase bank loading and indexing 
- Similarity search functionality
- Performance testing (<10ms target)
- PhraseBankDecoder functionality
- Integration with Modules 1 & 2

Author: AI Assistant
Date: 6 –∏—é–Ω—è 2025
"""

import time
import torch
import sys
import os

# [CONFIG] CUDA COMPATIBILITY FIX –¥–ª—è RTX 5090
# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
import os
os.environ['CUDA_VISIBLE_DEVICES'] = ''
torch.backends.cudnn.enabled = False

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º CPU –∫–∞–∫ default device
if torch.cuda.is_available():
    print("[WARNING]  CUDA detected but forcing CPU mode for RTX 5090 compatibility")
torch.set_default_device('cpu')

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ PATH
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_phrase_bank_loading():
    """–¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è phrase bank"""
    print("\nüè¶ Testing phrase bank loading and indexing...")
    
    try:
        from inference.lightweight_decoder.phrase_bank import PhraseBank, PhraseLoader
        from data.embedding_loader import EmbeddingLoader
        
        # –°–æ–∑–¥–∞–Ω–∏–µ embedding loader –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API)
        embedding_loader = EmbeddingLoader(cache_dir="./cache")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ phrase bank
        phrase_bank = PhraseBank(embedding_dim=768, index_type="linear")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ—Ä–∞–∑ —á–µ—Ä–µ–∑ LLM
        print("   [WRITE] Creating sample phrases using LLM...")
        test_texts = [
            "Hello, how are you?",
            "Thank you very much", 
            "Good morning everyone",
            "Have a nice day",
            "See you later"
        ]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏ –¥–ª—è —Ñ—Ä–∞–∑
        test_embeddings = embedding_loader.load_from_llm(
            texts=test_texts,
            model_key="distilbert",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª—é—á –º–æ–¥–µ–ª–∏
            use_cache=True
        )
        
        # –°–æ–∑–¥–∞–µ–º phrase entries
        from inference.lightweight_decoder.phrase_bank import PhraseEntry
        sample_phrases = []
        for i, text in enumerate(test_texts):
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
            category = "greeting" if "hello" in text.lower() or "good morning" in text.lower() else "general"
            
            phrase_entry = PhraseEntry(
                text=text,
                embedding=test_embeddings[i],
                frequency=1,
                category=category
            )
            sample_phrases.append(phrase_entry)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ—Ä–∞–∑—ã –≤ –±–∞–Ω–∫
        phrase_bank.add_phrases(sample_phrases)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥—Ä—É–∑–∫—É
        stats = phrase_bank.get_statistics()
        print(f"   [OK] Loaded {stats['total_phrases']} phrases")
        print(f"   [DATA] Index type: {stats['index_type']}")
        print(f"   [FAST] Average search time: {stats['avg_search_time_ms']} ms")
        print(f"   [CONFIG] FAISS available: {stats['faiss_available']}")
        
        return True
        
    except Exception as e:
        print(f"   [ERROR] Phrase bank loading failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_similarity_search():
    """–¢–µ—Å—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞ –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É"""
    print("\n[MAGNIFY] Testing similarity search...")
    
    try:
        from inference.lightweight_decoder.phrase_bank import PhraseBank, PhraseEntry
        from data.embedding_loader import EmbeddingLoader
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API)
        embedding_loader = EmbeddingLoader(cache_dir="./cache")
        
        phrase_bank = PhraseBank(embedding_dim=768, index_type="linear")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ—Ä–∞–∑
        test_texts = [
            "Hello, how are you?",
            "Hi there, how's it going?",
            "Good morning everyone",
            "Thank you very much",
            "See you later"
        ]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏
        test_embeddings = embedding_loader.load_from_llm(
            texts=test_texts,
            model_key="distilbert",
            use_cache=True
        )
        
        # –°–æ–∑–¥–∞–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ñ—Ä–∞–∑—ã
        sample_phrases = []
        for i, text in enumerate(test_texts):
            phrase_entry = PhraseEntry(
                text=text,
                embedding=test_embeddings[i],
                frequency=1,
                category="test"
            )
            sample_phrases.append(phrase_entry)
        
        phrase_bank.add_phrases(sample_phrases)
        
        # –¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ —Å –∏–∑–≤–µ—Å—Ç–Ω–æ–π —Ñ—Ä–∞–∑–æ–π
        print("   [TARGET] Testing search with known phrase...")
        test_query = "Hello, how are you?"
        query_embedding = embedding_loader.load_from_llm(
            texts=[test_query],
            model_key="distilbert",
            use_cache=True
        )[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        
        # –ü–æ–∏—Å–∫
        results = phrase_bank.search_phrases(query_embedding, k=3)
        
        if len(results) == 0:
            print("   [ERROR] No search results returned")
            return False
        
        print(f"   [OK] Found {len(results)} similar phrases")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        top_phrase, top_similarity = results[0]
        print(f"   [DATA] Top result: '{top_phrase.text}' (similarity: {top_similarity:.3f})")
        
        # –¢–µ—Å—Ç —Å –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–º —ç–º–±–µ–¥–∏–Ω–≥–æ–º
        print("   [DICE] Testing search with random embedding...")
        random_embedding = torch.randn(768)
        random_results = phrase_bank.search_phrases(random_embedding, k=3)
        
        print(f"   [OK] Random search returned {len(random_results)} results")
        
        return True
        
    except Exception as e:
        print(f"   [ERROR] Similarity search failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_performance():
    """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: <10ms –Ω–∞ –ø–æ–∏—Å–∫ —Ñ—Ä–∞–∑—ã"""
    print("\n[FAST] Testing search performance...")
    
    try:
        from inference.lightweight_decoder.phrase_bank import PhraseBank, PhraseEntry
        from data.embedding_loader import EmbeddingLoader
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API)
        embedding_loader = EmbeddingLoader(cache_dir="./cache")
        
        phrase_bank = PhraseBank(embedding_dim=768, index_type="linear")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –±–æ–ª—å—à–µ–≥–æ –Ω–∞–±–æ—Ä–∞ —Ñ—Ä–∞–∑ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        test_texts = [f"Test phrase number {i}" for i in range(20)]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏
        test_embeddings = embedding_loader.load_from_llm(
            texts=test_texts,
            model_key="distilbert",
            use_cache=True
        )
        
        # –°–æ–∑–¥–∞–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ñ—Ä–∞–∑—ã
        sample_phrases = []
        for i, text in enumerate(test_texts):
            phrase_entry = PhraseEntry(
                text=text,
                embedding=test_embeddings[i],
                frequency=1,
                category="test"
            )
            sample_phrases.append(phrase_entry)
        
        phrase_bank.add_phrases(sample_phrases)
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        query_texts = ["Test phrase", "Random query", "Hello world"]
        query_embeddings = embedding_loader.load_from_llm(
            texts=query_texts,
            model_key="distilbert",
            use_cache=True
        )
        
        # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        print("   ‚è±Ô∏è  Measuring search performance...")
        
        total_time = 0
        num_searches = len(query_embeddings)
        
        for embedding in query_embeddings:
            start_time = time.time()
            results = phrase_bank.search_phrases(embedding, k=5)
            end_time = time.time()
            
            search_time = (end_time - start_time) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
            total_time += search_time
        
        avg_time = total_time / num_searches
        print(f"   [DATA] Average search time: {avg_time:.2f}ms")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–µ—Ä–∏—è <10ms
        if avg_time < 10.0:
            print("   [OK] Performance target met (<10ms)")
            performance_ok = True
        else:
            print(f"   [WARNING]  Performance target missed (target: <10ms, actual: {avg_time:.2f}ms)")
            performance_ok = False
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ phrase bank
        stats = phrase_bank.get_statistics()
        print(f"   [CHART] Cache hit rate: {stats.get('cache_hit_rate', 'N/A')}")
        print(f"   [MAGNIFY] Total searches: {stats.get('total_searches', 0)}")
        
        return performance_ok
        
    except Exception as e:
        print(f"   [ERROR] Performance test failed: {e}")
        return False

def test_phrase_bank_decoder():
    """–¢–µ—Å—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ PhraseBankDecoder"""
    print("\nüî§ Testing PhraseBankDecoder...")
    
    try:
        from inference.lightweight_decoder.phrase_bank_decoder import PhraseBankDecoder
        from data.embedding_loader import EmbeddingLoader
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–∫–æ–¥–µ—Ä–∞
        decoder = PhraseBankDecoder(
            embedding_dim=768,
            similarity_threshold=0.5,  # –ù–µ–º–Ω–æ–≥–æ –Ω–∏–∂–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        )
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ phrase bank (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API)
        embedding_loader = EmbeddingLoader(cache_dir="./cache")
        
        print("   [BOOKS] Loading phrase bank...")
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é phrase bank –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        test_texts = [
            "Thank you very much.",
            "Hello, how are you?",
            "Good morning everyone.",
            "Have a great day!",
            "See you later."
        ]
        
        test_embeddings = embedding_loader.load_from_llm(
            texts=test_texts,
            model_key="distilbert",
            use_cache=True
        )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º phrase bank –≤ –¥–µ–∫–æ–¥–µ—Ä (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–±)
        decoder.load_phrase_bank(embedding_loader=embedding_loader)
        
        # –¢–µ—Å—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
        print("   üî§ Testing basic decoding...")
        test_query = "Thank you very much."
        test_embedding = embedding_loader.load_from_llm(
            texts=[test_query],
            model_key="distilbert",
            use_cache=True
        )[0]
        
        decoded_text = decoder.decode(test_embedding)
        print(f"   [WRITE] Decoded: '{decoded_text}'")
        
        # –¢–µ—Å—Ç batch –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
        print("   [PACKAGE] Testing batch decoding...")
        batch_queries = ["Hello there", "Good day"]
        batch_embeddings = embedding_loader.load_from_llm(
            texts=batch_queries,
            model_key="distilbert",
            use_cache=True
        )
        
        batch_results = decoder.batch_decode(batch_embeddings)
        print(f"   [WRITE] Batch decoded {len(batch_results)} texts")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–µ–∫–æ–¥–µ—Ä–∞
        decoder_stats = decoder.get_statistics()
        print(f"   [DATA] Decoder stats:")
        print(f"      - Decode attempts: {decoder_stats.get('decode_attempts', 0)}")
        print(f"      - Success count: {decoder_stats.get('success_count', 0)}")
        
        return True
        
    except Exception as e:
        print(f"   [ERROR] PhraseBankDecoder test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_integration_with_modules():
    """–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Modules 1 & 2"""
    print("\n[LINK] Testing integration with existing modules...")
    
    try:
        from data.embedding_loader import EmbeddingLoader
        from inference.lightweight_decoder.phrase_bank_decoder import PhraseBankDecoder
        
        # Module 1: Teacher LLM Encoder (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API)
        print("   üî¥ Setting up Module 1 (Teacher LLM Encoder)...")
        encoder = EmbeddingLoader(cache_dir="./cache")
        
        # Module 3: Lightweight Decoder
        print("   üü° Setting up Module 3 (PhraseBankDecoder)...")
        decoder = PhraseBankDecoder(embedding_dim=768)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ phrase bank
        test_texts = [
            "Hello, how are you today?",
            "Thank you for your help.",
            "Good morning everyone.",
            "Have a wonderful day!"
        ]
        
        test_embeddings = encoder.load_from_llm(
            texts=test_texts,
            model_key="distilbert",
            use_cache=True
        )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º phrase bank –≤ –¥–µ–∫–æ–¥–µ—Ä (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–±)
        decoder.load_phrase_bank(embedding_loader=encoder)
        
        # –¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
        print("   üåä Testing Module 1 ‚Üí Module 3 pipeline...")
        
        test_text = "Hello, how are you today?"
        
        # –¢–µ–∫—Å—Ç ‚Üí –≠–º–±–µ–¥–∏–Ω–≥ (Module 1)
        embedding = encoder.load_from_llm(
            texts=[test_text],
            model_key="distilbert",
            use_cache=True
        )[0]
        
        print(f"   üìè Embedding shape: {embedding.shape}")
        
        # –≠–º–±–µ–¥–∏–Ω–≥ ‚Üí –¢–µ–∫—Å—Ç (Module 3)
        decoded_text = decoder.decode(embedding)
        print(f"   [WRITE] Decoded text: '{decoded_text}'")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if decoded_text and len(decoded_text) > 0:
            print("   [OK] Integration successful")
            return True
        else:
            print("   [ERROR] Integration failed - empty result")
            return False
        
    except Exception as e:
        print(f"   [ERROR] Integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("[START] PHASE 2.7.1 - PhraseBankDecoder Infrastructure Test")
    print("=" * 70)
    print("Checkpoint 1.1 Verification\n")
    
    # –°–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤
    tests = [
        ("Phrase Bank Loading", test_phrase_bank_loading),
        ("Similarity Search", test_similarity_search),
        ("Performance (<10ms)", test_performance),
        ("PhraseBankDecoder", test_phrase_bank_decoder),
        ("Module Integration", test_integration_with_modules),
    ]
    
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
    results = []
    for test_name, test_func in tests:
        print(f"\n{'=' * 70}")
        result = test_func()
        results.append((test_name, result))
    
    # –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "=" * 70)
    print("[DATA] CHECKPOINT 1.1 RESULTS")
    print("=" * 70)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "[OK] PASS" if result else "[ERROR] FAIL"
        print(f"{status} {test_name}")
        if result:
            passed += 1
    
    success_rate = (passed / total) * 100
    print(f"\n[TARGET] Checkpoint 1.1: {passed}/{total} tests passed ({success_rate:.1f}%)")
    
    if success_rate == 100:
        print("\n[SUCCESS] ALL TESTS PASSED! Ready for ETAP 1.2")
        print("[INFO] Next: PhraseBankDecoder refinement and optimization")
    elif success_rate >= 80:
        print("\n[WARNING]  MOSTLY SUCCESSFUL - Minor issues to fix")
    else:
        print("\n[ERROR] MULTIPLE FAILURES - Need debugging before proceeding")
    
    return success_rate == 100

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 