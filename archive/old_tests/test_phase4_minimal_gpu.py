#!/usr/bin/env python3
"""
–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç GPU –∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –¥–ª—è Phase 4
"""

import torch
import tempfile
import yaml
from pathlib import Path


def test_gpu_detection():
    """–¢–µ—Å—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è GPU"""
    print("üîç –ü–†–û–í–ï–†–ö–ê GPU")
    print("=" * 40)

    cuda_available = torch.cuda.is_available()
    print(f"CUDA –¥–æ—Å—Ç—É–ø–µ–Ω: {cuda_available}")

    if cuda_available:
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(
            f"GPU –ø–∞–º—è—Ç–∏: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB"
        )

        # –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ–Ω–∑–æ—Ä–∞ –Ω–∞ GPU
        try:
            test_tensor = torch.randn(100, 100).cuda()
            print(f"‚úÖ –¢–µ–Ω–∑–æ—Ä –Ω–∞ GPU —Å–æ–∑–¥–∞–Ω: {test_tensor.device}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
            memory_allocated = torch.cuda.memory_allocated(0) / 1024**2
            print(f"GPU –ø–∞–º—è—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞: {memory_allocated:.1f} MB")

            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ–Ω–∑–æ—Ä–∞ –Ω–∞ GPU: {e}")
            return False
    else:
        print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return False


def test_lattice_gpu_config():
    """–¢–µ—Å—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ GPU –¥–ª—è lattice"""
    print("\nüß± –ü–†–û–í–ï–†–ö–ê LATTICE GPU –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò")
    print("=" * 40)

    try:
        from core.lattice_3d.config import LatticeConfig

        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config = LatticeConfig(
            dimensions=(4, 4, 4),  # –ú–∞–ª–µ–Ω—å–∫–∞—è —Ä–µ—à–µ—Ç–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∞
            gpu_enabled=True,
            parallel_processing=True,
        )

        print(f"gpu_enabled: {config.gpu_enabled}")
        print(f"parallel_processing: {config.parallel_processing}")
        print(f"total_cells: {config.total_cells}")

        # –°–æ–∑–¥–∞–µ–º —Ä–µ—à–µ—Ç–∫—É
        from core.lattice_3d.lattice import Lattice3D

        lattice = Lattice3D(config)
        print(f"Lattice device: {lattice.device}")
        print(f"States shape: {lattice.states.shape}")
        print(f"States device: {lattice.states.device}")

        if torch.cuda.is_available():
            expected_device = "cuda"
        else:
            expected_device = "cpu"

        if str(lattice.device) == expected_device:
            print("‚úÖ Lattice –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ")
            return True
        else:
            print(f"‚ùå Lattice –Ω–∞ {lattice.device}, –æ–∂–∏–¥–∞–ª–æ—Å—å {expected_device}")
            return False

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è lattice: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_minimal_training_config():
    """–¢–µ—Å—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è"""
    print("\n‚öôÔ∏è –ü–†–û–í–ï–†–ö–ê –ú–ò–ù–ò–ú–ê–õ–¨–ù–û–ô –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò –û–ë–£–ß–ï–ù–ò–Ø")
    print("=" * 40)

    try:
        from utils.config_manager.dynamic_config import DynamicConfigGenerator

        # –°–æ–∑–¥–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
        generator = DynamicConfigGenerator()
        config = generator.generate_config("development")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–µ–∫—Ü–∏–∏
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ–∫—Ü–∏–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:")

        # Architecture
        architecture = config.get("architecture", {})
        print(f"  architecture.hybrid_mode: {architecture.get('hybrid_mode')}")
        print(
            f"  architecture.neuron_architecture: {architecture.get('neuron_architecture')}"
        )

        # Lattice_3d
        lattice_3d = config.get("lattice_3d", {})
        print(f"  lattice_3d.gpu_enabled: {lattice_3d.get('gpu_enabled')}")
        print(
            f"  lattice_3d.parallel_processing: {lattice_3d.get('parallel_processing')}"
        )

        # Training
        training = config.get("training", {})
        print(f"  training.device: {training.get('device')}")
        print(f"  training.mixed_precision: {training.get('mixed_precision')}")

        # Emergent training
        emergent = config.get("emergent_training", {})
        print(
            f"  emergent_training.cell_architecture: {emergent.get('cell_architecture')}"
        )

        # Lattice —Ä–∞–∑–º–µ—Ä—ã
        lattice = config.get("lattice", {})
        print(
            f"  lattice —Ä–∞–∑–º–µ—Ä—ã: {lattice.get('xs')}√ó{lattice.get('ys')}√ó{lattice.get('zs')}"
        )

        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_simple_embedding_creation():
    """–¢–µ—Å—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–∏–Ω–≥–æ–≤"""
    print("\nüìä –ü–†–û–í–ï–†–ö–ê –ü–†–û–°–¢–´–• –≠–ú–ë–ï–î–ò–ù–ì–û–í")
    print("=" * 40)

    try:
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_texts = ["Hello world", "Test sentence", "Simple example"]

        # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ—Å—Ç—ã–µ —ç–º–±–µ–¥–∏–Ω–≥–∏
        from sentence_transformers import SentenceTransformer

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å
        model = SentenceTransformer("all-MiniLM-L6-v2")

        if torch.cuda.is_available():
            model = model.cuda()
            print("‚úÖ –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–º–µ—â–µ–Ω–∞ –Ω–∞ GPU")

        embeddings = model.encode(test_texts)
        print(f"‚úÖ –≠–º–±–µ–¥–∏–Ω–≥–∏ —Å–æ–∑–¥–∞–Ω—ã: {embeddings.shape}")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ torch tensor
        embeddings_tensor = torch.tensor(embeddings)
        if torch.cuda.is_available():
            embeddings_tensor = embeddings_tensor.cuda()

        print(
            f"‚úÖ Tensor —ç–º–±–µ–¥–∏–Ω–≥–æ–≤: {embeddings_tensor.shape}, device: {embeddings_tensor.device}"
        )

        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–∏–Ω–≥–æ–≤: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ô –¢–ï–°–¢ GPU –ò –≠–ú–ë–ï–î–ò–ù–ì–û–í - PHASE 4")
    print("=" * 60)

    results = []

    # –¢–µ—Å—Ç 1: GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ
    results.append(("GPU Detection", test_gpu_detection()))

    # –¢–µ—Å—Ç 2: Lattice GPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    results.append(("Lattice GPU Config", test_lattice_gpu_config()))

    # –¢–µ—Å—Ç 3: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    results.append(("Training Config", test_minimal_training_config()))

    # –¢–µ—Å—Ç 4: –ü—Ä–æ—Å—Ç—ã–µ —ç–º–±–µ–¥–∏–Ω–≥–∏
    results.append(("Simple Embeddings", test_simple_embedding_creation()))

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "=" * 60)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–û–í:")
    print("=" * 60)

    passed = 0
    for name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"  {status} | {name}")
        if result:
            passed += 1

    print(f"\nüéØ –ò–¢–û–ì–û: {passed}/{len(results)} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ—à–ª–∏")

    if passed == len(results):
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–®–õ–ò! GPU –ì–û–¢–û–í –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ!")
    else:
        print("‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ—à–ª–∏. –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞.")


if __name__ == "__main__":
    main()
