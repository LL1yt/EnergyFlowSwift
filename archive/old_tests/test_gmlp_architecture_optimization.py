#!/usr/bin/env python3
"""
Test Suite: gMLP Architecture Optimization (15√ó15√ó11)
====================================================

–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ revolutionary –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:
- gMLP Spatial Gating Units
- 15√ó15√ó11 area-focused scaling  
- Parameter budget optimization
- Memory efficiency validation
- Integration compatibility

–¶–µ–ª—å: –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å breakthrough >50% Q‚ÜíA similarity
"""

import sys
import os
import torch
import logging
import traceback
import numpy as np
import time
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ path
sys.path.append(str(Path(__file__).parent))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_gmlp_cell_architecture():
    """
    –¢–µ—Å—Ç 1: –ë–∞–∑–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å gMLP –∫–ª–µ—Ç–∫–∏
    """
    print("\nüß™ –¢–ï–°–¢ 1: gMLP Cell Architecture")
    print("=" * 50)
    
    try:
        from core.cell_prototype.architectures.gmlp_cell import (
            GatedMLPCell, 
            SpatialGatingUnit,
            create_gmlp_cell_from_config,
            test_gmlp_cell_basic
        )
        
        # 1.1: –°–æ–∑–¥–∞–Ω–∏–µ gMLP –∫–ª–µ—Ç–∫–∏
        print("[INFO] 1.1: –°–æ–∑–¥–∞–Ω–∏–µ GatedMLPCell...")
        cell = GatedMLPCell(
            state_size=32,
            neighbor_count=6,
            hidden_dim=256,
            external_input_size=12,
            activation="gelu",
            use_memory=True
        )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        info = cell.get_info()
        print(f"   [OK] –ö–ª–µ—Ç–∫–∞ —Å–æ–∑–¥–∞–Ω–∞: {info['total_parameters']:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        print(f"   [DATA] Target: 25K, Actual: {info['total_parameters']:,}")
        print(f"   [CHART] Efficiency: {info['parameter_efficiency']:.2f}")
        
        # 1.2: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ forward pass
        print("\n[INFO] 1.2: Forward Pass Testing...")
        batch_size = 4
        neighbor_states = torch.randn(batch_size, 6, 32)
        own_state = torch.randn(batch_size, 32)
        external_input = torch.randn(batch_size, 12)
        
        # Forward pass
        start_time = time.time()
        new_state = cell(neighbor_states, own_state, external_input)
        forward_time = time.time() - start_time
        
        print(f"   [OK] Forward pass: {neighbor_states.shape} + {own_state.shape} ‚Üí {new_state.shape}")
        print(f"   [FAST] –í—Ä–µ–º—è: {forward_time*1000:.2f}ms")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        assert new_state.shape == (batch_size, 32), f"Wrong shape: {new_state.shape}"
        assert not torch.isnan(new_state).any(), "NaN values detected"
        assert not torch.isinf(new_state).any(), "Inf values detected"
        
        # 1.3: Memory component testing
        print("\n[INFO] 1.3: Memory Component Testing...")
        initial_memory = cell.memory_state
        print(f"   [WRITE] Initial memory state: {initial_memory is not None}")
        
        # Second forward pass (memory should persist)
        new_state_2 = cell(neighbor_states, own_state, external_input)
        second_memory = cell.memory_state
        print(f"   [WRITE] Memory after second pass: {second_memory is not None}")
        print(f"   [WRITE] Memory shape: {second_memory.shape if second_memory is not None else 'None'}")
        
        # Memory reset test
        cell.reset_memory()
        assert cell.memory_state is None, "Memory not properly reset"
        print(f"   [OK] Memory reset successful")
        
        # 1.4: Built-in test
        print("\n[INFO] 1.4: Built-in Test Suite...")
        success = test_gmlp_cell_basic()
        assert success, "Built-in tests failed"
        print(f"   [OK] Built-in tests passed")
        
        print("\n[TARGET] –¢–ï–°–¢ 1 –†–ï–ó–£–õ–¨–¢–ê–¢: [OK] SUCCESS")
        return True
        
    except Exception as e:
        print(f"\n[ERROR] –¢–ï–°–¢ 1 FAILED: {e}")
        traceback.print_exc()
        return False


def test_15x15x11_lattice_configuration():
    """
    –¢–µ—Å—Ç 2: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è 15√ó15√ó11 —Ä–µ—à–µ—Ç–∫–∏
    """
    print("\nüß™ –¢–ï–°–¢ 2: 15√ó15√ó11 Lattice Configuration")
    print("=" * 50)
    
    try:
        import yaml
        
        # 2.1: –ó–∞–≥—Ä—É–∑–∫–∞ optimized –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        print("[INFO] 2.1: –ó–∞–≥—Ä—É–∑–∫–∞ optimized –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
        config_path = Path("config/optimized_architecture_15x15x11.yaml")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        lattice_config = config['lattice_3d']
        cell_config = config['cell_prototype']
        
        print(f"   [OK] –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {config_path}")
        print(f"   [DATA] Lattice —Ä–∞–∑–º–µ—Ä—ã: {lattice_config['dimensions']}")
        print(f"   [DATA] Total cells: {lattice_config['total_cells']}")
        print(f"   [BRAIN] Cell architecture: {cell_config['architecture_type']}")
        
        # 2.2: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        print("\n[INFO] 2.2: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏...")
        dimensions = lattice_config['dimensions']
        total_cells = dimensions[0] * dimensions[1] * dimensions[2]
        
        assert dimensions == [15, 15, 11], f"Wrong dimensions: {dimensions}"
        assert total_cells == 2475, f"Wrong total cells: {total_cells}"
        
        print(f"   [OK] –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞: {dimensions} = {total_cells} –∫–ª–µ—Ç–æ–∫")
        print(f"   [CHART] –£–≤–µ–ª–∏—á–µ–Ω–∏–µ: {total_cells / 512:.1f}x vs 8√ó8√ó8")
        
        # 2.3: Golden Ratio –ø—Ä–æ–≤–µ—Ä–∫–∞
        print("\n[INFO] 2.3: Golden Ratio Analysis...")
        x, y, z = dimensions
        ratio_xy = y / x  # Should be ~1.0
        ratio_z = z / x   # Should be ~0.5-0.73
        
        print(f"   üìè X:Y ratio: {ratio_xy:.3f} (target: ~1.0)")
        print(f"   üìè Z:X ratio: {ratio_z:.3f} (target: 0.5-0.73)")
        
        # Area-focused validation
        area_cells = x * y  # 15 √ó 15 = 225
        volume_ratio = area_cells / total_cells
        print(f"   üìè Area-focused ratio: {volume_ratio:.3f} (higher = better)")
        
        assert 0.5 <= ratio_z <= 0.8, f"Z ratio out of range: {ratio_z}"
        print(f"   [OK] Golden Ratio compliance verified")
        
        # 2.4: Memory estimation
        print("\n[INFO] 2.4: Memory Estimation...")
        cells_per_param = cell_config['architecture']['target_parameters']
        total_params = total_cells * cells_per_param
        memory_mb = total_params * 4 / (1024 * 1024)  # float32
        
        print(f"   [DATA] –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –∫–ª–µ—Ç–∫—É: {cells_per_param:,}")
        print(f"   [DATA] Total –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {total_params:,}")
        print(f"   [SAVE] Estimated memory: {memory_mb:.1f} MB")
        
        # Warning –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
        if memory_mb > 1000:  # 1GB
            print(f"   [WARNING]  Large memory requirement: {memory_mb:.1f} MB")
        
        print("\n[TARGET] –¢–ï–°–¢ 2 –†–ï–ó–£–õ–¨–¢–ê–¢: [OK] SUCCESS")
        return True
        
    except Exception as e:
        print(f"\n[ERROR] –¢–ï–°–¢ 2 FAILED: {e}")
        traceback.print_exc()
        return False


def test_embedding_processor_compatibility():
    """
    –¢–µ—Å—Ç 3: –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å EmbeddingProcessor –¥–ª—è 15√ó15√ó11
    """
    print("\nüß™ –¢–ï–°–¢ 3: EmbeddingProcessor Compatibility")
    print("=" * 50)
    
    try:
        # 3.1: –ü—Ä–æ–≤–µ—Ä–∫–∞ EmbeddingReshaper –¥–ª—è 2,475 elements
        print("[INFO] 3.1: EmbeddingReshaper Adaptation...")
        
        from data.embedding_reshaper import EmbeddingReshaper
        
        # –°–æ–∑–¥–∞–µ–º reshaper –¥–ª—è –Ω–æ–≤—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
        reshaper = EmbeddingReshaper(
            input_dim=768,
            cube_shape=(15, 15, 11),  # 2,475 elements
            reshaping_method="adaptive"
        )
        
        print(f"   [OK] EmbeddingReshaper —Å–æ–∑–¥–∞–Ω –¥–ª—è 15√ó15√ó11")
        print(f"   [DATA] Input dim: 768")
        print(f"   [DATA] Cube shape: {reshaper.cube_shape}")
        print(f"   [DATA] Total elements: {np.prod(reshaper.cube_shape)}")
        
        # 3.2: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ reshape –æ–ø–µ—Ä–∞—Ü–∏–π
        print("\n[INFO] 3.2: Reshape Operations Testing...")
        
        # –¢–µ—Å—Ç–æ–≤—ã–π embedding
        test_embedding = torch.randn(768)
        
        # 768D ‚Üí 15√ó15√ó11 (2,475 elements)
        try:
            matrix_3d = reshaper.vector_to_matrix(test_embedding)
            print(f"   [OK] Vector to matrix: {test_embedding.shape} ‚Üí {matrix_3d.shape}")
            
            # 15√ó15√ó11 ‚Üí 768D 
            reconstructed = reshaper.matrix_to_vector(matrix_3d)
            print(f"   [OK] Matrix to vector: {matrix_3d.shape} ‚Üí {reconstructed.shape}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
            assert matrix_3d.shape == (15, 15, 11), f"Wrong matrix shape: {matrix_3d.shape}"
            assert reconstructed.shape == (768,), f"Wrong vector shape: {reconstructed.shape}"
            
        except Exception as reshape_error:
            print(f"   [WARNING]  Reshape operations —Ç—Ä–µ–±—É—é—Ç –∞–¥–∞–ø—Ç–∞—Ü–∏–∏: {reshape_error}")
            # –≠—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ - EmbeddingReshaper –ø–æ—Ç—Ä–µ–±—É–µ—Ç –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è 768‚Üí2475 mapping
            
        # 3.3: Parameter scaling analysis
        print("\n[INFO] 3.3: Parameter Scaling Analysis...")
        
        old_cells = 8 * 8 * 8  # 512
        new_cells = 15 * 15 * 11  # 2,475
        scaling_factor = new_cells / old_cells
        
        old_params_total = 512 * 1000  # 512K
        new_params_total = 2475 * 25000  # 61.875M
        param_scaling = new_params_total / old_params_total
        
        print(f"   [DATA] Cell scaling: {old_cells} ‚Üí {new_cells} ({scaling_factor:.1f}x)")
        print(f"   [DATA] Parameter scaling: {old_params_total:,} ‚Üí {new_params_total:,} ({param_scaling:.0f}x)")
        print(f"   [DATA] Per-cell improvement: {1000} ‚Üí {25000} (25x richer)")
        
        # Efficiency analysis
        efficiency_gain = (scaling_factor * 25) ** 0.5  # Approximation
        print(f"   [CHART] Estimated capacity gain: ~{efficiency_gain:.1f}x")
        
        print("\n[TARGET] –¢–ï–°–¢ 3 –†–ï–ó–£–õ–¨–¢–ê–¢: [OK] SUCCESS (—Å –∞–¥–∞–ø—Ç–∞—Ü–∏—è–º–∏)")
        return True
        
    except Exception as e:
        print(f"\n[ERROR] –¢–ï–°–¢ 3 FAILED: {e}")
        traceback.print_exc()
        return False


def test_training_configuration():
    """
    –¢–µ—Å—Ç 4: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è optimized architecture
    """
    print("\nüß™ –¢–ï–°–¢ 4: Training Configuration")
    print("=" * 50)
    
    try:
        # 4.1: –ó–∞–≥—Ä—É–∑–∫–∞ training config
        print("[INFO] 4.1: Training Configuration Validation...")
        
        import yaml
        config_path = Path("config/optimized_architecture_15x15x11.yaml")
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        training_config = config['training']
        performance_config = config['performance']
        
        print(f"   [OK] Training config loaded")
        print(f"   [TARGET] Target similarity: {training_config['target_similarity']}")
        print(f"   [DATA] Batch size: {training_config['batch_size']}")
        print(f"   [DATA] Learning rate: {training_config['learning_rate']}")
        
        # 4.2: Memory requirements validation
        print("\n[INFO] 4.2: Memory Requirements Analysis...")
        
        batch_size = training_config['batch_size']
        max_memory_gb = performance_config['max_memory_gb']
        gradient_checkpointing = performance_config['gradient_checkpointing']
        
        # Estimate memory usage
        total_params = 2475 * 25000  # 61.875M parameters
        param_memory_gb = total_params * 4 / (1024**3)  # float32
        gradient_memory_gb = param_memory_gb * 2  # gradients + params
        
        if gradient_checkpointing:
            gradient_memory_gb *= 0.5  # Gradient checkpointing reduces memory
        
        estimated_memory = param_memory_gb + gradient_memory_gb
        
        print(f"   [DATA] Parameter memory: {param_memory_gb:.2f} GB")
        print(f"   [DATA] Gradient memory: {gradient_memory_gb:.2f} GB")
        print(f"   [DATA] Total estimated: {estimated_memory:.2f} GB")
        print(f"   [DATA] Memory limit: {max_memory_gb} GB")
        print(f"   [CONFIG] Gradient checkpointing: {gradient_checkpointing}")
        
        if estimated_memory > max_memory_gb:
            print(f"   [WARNING]  Memory requirement exceeds limit!")
            print(f"   [IDEA] Suggestions:")
            print(f"      - Reduce batch size to 1")
            print(f"      - Enable gradient checkpointing")
            print(f"      - Use mixed precision training")
        
        # 4.3: Performance optimization validation
        print("\n[INFO] 4.3: Performance Optimization Checks...")
        
        checks = {
            'gradient_checkpointing': performance_config.get('gradient_checkpointing', False),
            'gradient_clipping': performance_config.get('gradient_clipping', 0) > 0,
            'memory_monitoring': performance_config.get('memory_monitoring', False),
            'mixed_precision': config['embedding_processor'].get('mixed_precision', False)
        }
        
        for check, enabled in checks.items():
            status = "[OK]" if enabled else "[WARNING]"
            print(f"   {status} {check}: {enabled}")
        
        # 4.4: Target metrics validation
        print("\n[INFO] 4.4: Target Metrics Analysis...")
        
        target_similarity = training_config['target_similarity']
        current_best = 0.385  # Current plateau
        improvement_needed = target_similarity - current_best
        
        print(f"   [DATA] Current best: {current_best:.1%}")
        print(f"   [TARGET] Target: {target_similarity:.1%}")
        print(f"   [CHART] Improvement needed: {improvement_needed:.1%}")
        print(f"   [START] Architecture improvements:")
        print(f"      - 4.8x more cells (better representation)")
        print(f"      - 25x richer cells (gMLP vs simple MLP)")
        print(f"      - Spatial Gating Units (attention-like processing)")
        print(f"      - Memory components (emergent behavior)")
        
        print("\n[TARGET] –¢–ï–°–¢ 4 –†–ï–ó–£–õ–¨–¢–ê–¢: [OK] SUCCESS")
        return True
        
    except Exception as e:
        print(f"\n[ERROR] –¢–ï–°–¢ 4 FAILED: {e}")
        traceback.print_exc()
        return False


def test_memory_and_computational_feasibility():
    """
    –¢–µ—Å—Ç 5: –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –æ—Å—É—â–µ—Å—Ç–≤–∏–º–æ—Å—Ç—å –ø–æ –ø–∞–º—è—Ç–∏ –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º
    """
    print("\nüß™ –¢–ï–°–¢ 5: Memory & Computational Feasibility")
    print("=" * 50)
    
    try:
        # 5.1: Hardware requirements
        print("[INFO] 5.1: Hardware Requirements Analysis...")
        
        # Current system info
        print(f"   [COMPUTER] PyTorch version: {torch.__version__}")
        print(f"   [COMPUTER] CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   [COMPUTER] CUDA device: {torch.cuda.get_device_name()}")
            memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            print(f"   [COMPUTER] GPU memory: {memory_gb:.1f} GB")
        
        # 5.2: –°–æ–∑–¥–∞–Ω–∏–µ mini-–≤–µ—Ä—Å–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        print("\n[INFO] 5.2: Mini Architecture Test...")
        
        from core.cell_prototype.architectures.gmlp_cell import GatedMLPCell
        
        # –°–æ–∑–¥–∞–µ–º —É–º–µ–Ω—å—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è memory scaling
        mini_cells = 10  # –í–º–µ—Å—Ç–æ 2,475
        cells = []
        
        print(f"   üî¨ –°–æ–∑–¥–∞–Ω–∏–µ {mini_cells} gMLP –∫–ª–µ—Ç–æ–∫...")
        
        start_time = time.time()
        for i in range(mini_cells):
            cell = GatedMLPCell(
                state_size=32,
                hidden_dim=128,  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                use_memory=True
            )
            cells.append(cell)
        
        creation_time = time.time() - start_time
        
        # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        total_params = sum(sum(p.numel() for p in cell.parameters()) for cell in cells)
        avg_params = total_params / mini_cells
        
        print(f"   [OK] {mini_cells} –∫–ª–µ—Ç–æ–∫ —Å–æ–∑–¥–∞–Ω—ã –∑–∞ {creation_time:.3f}s")
        print(f"   [DATA] Average parameters per cell: {avg_params:,.0f}")
        print(f"   [DATA] Total parameters: {total_params:,}")
        
        # –≠–∫—Å—Ç—Ä–∞–ø–æ–ª—è—Ü–∏—è –¥–ª—è –ø–æ–ª–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
        full_system_params = avg_params * 2475
        full_memory_gb = full_system_params * 4 / (1024**3)
        
        print(f"\n   [CHART] Full system extrapolation:")
        print(f"      [DATA] Total parameters: {full_system_params:,.0f}")
        print(f"      [SAVE] Memory requirement: {full_memory_gb:.2f} GB")
        
        # 5.3: Forward pass timing
        print("\n[INFO] 5.3: Forward Pass Performance...")
        
        cell = cells[0]
        batch_sizes = [1, 2, 4]
        
        for batch_size in batch_sizes:
            neighbor_states = torch.randn(batch_size, 6, 32)
            own_state = torch.randn(batch_size, 32)
            external_input = torch.randn(batch_size, 12)
            
            # Timing test
            start_time = time.time()
            for _ in range(10):  # 10 forward passes
                output = cell(neighbor_states, own_state, external_input)
            end_time = time.time()
            
            avg_time_ms = (end_time - start_time) * 1000 / 10
            print(f"   [FAST] Batch {batch_size}: {avg_time_ms:.2f}ms per forward pass")
        
        # Extrapolation –¥–ª—è –ø–æ–ª–Ω–æ–π —Ä–µ—à–µ—Ç–∫–∏
        single_cell_time = avg_time_ms  # –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        full_lattice_time = single_cell_time * 2475 / 1000  # –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        
        print(f"\n   [CHART] Full lattice extrapolation:")
        print(f"      [FAST] Est. time per step: {full_lattice_time:.2f}s")
        print(f"      [FAST] Est. time per epoch: {full_lattice_time * 100:.1f}s (100 steps)")
        
        # 5.4: Feasibility assessment
        print("\n[INFO] 5.4: Feasibility Assessment...")
        
        feasible = True
        recommendations = []
        
        # Memory check
        if full_memory_gb > 8:
            feasible = False
            recommendations.append("Use gradient checkpointing")
            recommendations.append("Reduce batch size to 1")
            recommendations.append("Consider parameter sharing")
        
        # Timing check
        if full_lattice_time > 10:
            recommendations.append("Optimize cell implementation")
            recommendations.append("Use GPU acceleration")
            recommendations.append("Consider parallel processing")
        
        print(f"   [TARGET] Feasibility: {'[OK] FEASIBLE' if feasible else '[WARNING] CHALLENGING'}")
        
        if recommendations:
            print(f"   [IDEA] Recommendations:")
            for rec in recommendations:
                print(f"      - {rec}")
        
        print("\n[TARGET] –¢–ï–°–¢ 5 –†–ï–ó–£–õ–¨–¢–ê–¢: [OK] SUCCESS")
        return True
        
    except Exception as e:
        print(f"\n[ERROR] –¢–ï–°–¢ 5 FAILED: {e}")
        traceback.print_exc()
        return False


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    print("[START] GMLP ARCHITECTURE OPTIMIZATION TEST SUITE")
    print("=" * 60)
    print("Testing revolutionary 15√ó15√ó11 + gMLP architecture")
    print("Goal: Breakthrough >50% Q‚ÜíA similarity\n")
    
    tests = [
        ("gMLP Cell Architecture", test_gmlp_cell_architecture),
        ("15√ó15√ó11 Lattice Config", test_15x15x11_lattice_configuration),
        ("EmbeddingProcessor Compatibility", test_embedding_processor_compatibility),
        ("Training Configuration", test_training_configuration),
        ("Memory & Computational Feasibility", test_memory_and_computational_feasibility)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"\n[ERROR] CRITICAL ERROR in {test_name}: {e}")
            results.append((test_name, False))
    
    # –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "=" * 60)
    print("[TARGET] –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print("=" * 60)
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "[OK] PASSED" if success else "[ERROR] FAILED"
        print(f"{status} {test_name}")
    
    print(f"\n[DATA] –û–ë–©–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢: {passed}/{total} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    
    if passed == total:
        print("[SUCCESS] –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´! –ì–æ—Ç–æ–≤—ã –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ optimized architecture!")
        print("\n[START] –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:")
        print("1. –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å EmbeddingReshaper –¥–ª—è 768‚Üí2475 mapping")
        print("2. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å gMLP –∫–ª–µ—Ç–∫–∏ –≤ Lattice3D")
        print("3. –û–±–Ω–æ–≤–∏—Ç—å CubeTrainer –¥–ª—è –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã")
        print("4. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É —Å gradient checkpointing")
        print("5. Monitoring memory usage –∏ performance")
    else:
        print("[WARNING]  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã failed. –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ–¥ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ–º.")
    
    return passed == total


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 