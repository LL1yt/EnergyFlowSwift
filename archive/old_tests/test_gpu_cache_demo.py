#!/usr/bin/env python3
"""
GPU Cache Demo - –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è GPU —É—Å–∫–æ—Ä–µ–Ω–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
======================================================

–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã GPU-—É—Å–∫–æ—Ä–µ–Ω–Ω–æ–≥–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
—Å–≤—è–∑–µ–π –¥–ª—è RTX 5090.
"""

import torch
import time
import sys
import os
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    stream=sys.stdout,
)

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from new_rebuild.config import get_project_config, set_project_config, ProjectConfig
from new_rebuild.core.moe import create_connection_classifier
from new_rebuild.utils.logging import get_logger

logger = get_logger(__name__)


def run_full_test():
    """–ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è, –≤–∫–ª—é—á–∞—è —Å–æ–∑–¥–∞–Ω–∏–µ –∏ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ"""

    print("üöÄ GPU Cache Acceleration Demo")
    print("=" * 50)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
    if not torch.cuda.is_available():
        print("‚ùå CUDA –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞, —Ç–µ—Å—Ç –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ CPU")
        return

    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    print(f"üéÆ GPU: {gpu_name}")
    print(f"üíæ GPU Memory: {gpu_memory:.1f}GB")

    # ==================================================================
    # –¢–µ—Å—Ç 1: –ú–∞–ª–∞—è —Ä–µ—à–µ—Ç–∫–∞ (–¥–æ–ª–∂–Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CPU)
    # ==================================================================
    print(f"\n1Ô∏è‚É£ –ú–∞–ª–∞—è —Ä–µ—à–µ—Ç–∫–∞ (8x8x8 = 512 –∫–ª–µ—Ç–æ–∫) - –æ–∂–∏–¥–∞–µ—Ç—Å—è CPU")
    config_small = ProjectConfig()
    config_small.lattice.dimensions = (8, 8, 8)
    config_small.cache.enabled = True
    config_small.cache.use_gpu_acceleration = True
    config_small.cache.enable_performance_monitoring = True
    set_project_config(config_small)

    should_use_cache = (
        config_small.cache.enabled
        and config_small.total_cells >= config_small.cache.auto_enable_threshold
    )
    print(f"   Should use cache: {should_use_cache}")

    if should_use_cache:
        start_time = time.time()
        classifier = create_connection_classifier(lattice_dimensions=(8, 8, 8))
        init_time = time.time() - start_time

        print(f"   Cache enabled: {classifier.enable_cache}")
        if classifier.cache_manager:
            print(f"   GPU acceleration: {classifier.cache_manager.use_gpu}")
            print(f"   Device: {classifier.cache_manager.device}")
        print(f"   Initialization time: {init_time:.2f}s")

    # ==================================================================
    # –¢–µ—Å—Ç 2: –°—Ä–µ–¥–Ω—è—è —Ä–µ—à–µ—Ç–∫–∞ (–¥–æ–ª–∂–Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU) - –°–û–ó–î–ê–ù–ò–ï –ö–≠–®–ê
    # ==================================================================
    print(f"\n2Ô∏è‚É£ –°—Ä–µ–¥–Ω—è—è —Ä–µ—à–µ—Ç–∫–∞ (15x15x15 = 3375 –∫–ª–µ—Ç–æ–∫) - –æ–∂–∏–¥–∞–µ—Ç—Å—è GPU")
    config_medium = ProjectConfig()
    config_medium.lattice.dimensions = (15, 15, 15)
    config_medium.cache.enabled = True
    config_medium.cache.use_gpu_acceleration = True
    config_medium.cache.enable_performance_monitoring = True
    config_medium.cache.auto_enable_threshold = 3000
    set_project_config(config_medium)

    should_use_cache = (
        config_medium.cache.enabled
        and config_medium.total_cells >= config_medium.cache.auto_enable_threshold
    )
    print(f"   Should use cache: {should_use_cache}")

    if should_use_cache:
        print("   üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫—ç—à–∞ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)...")
        start_time = time.time()
        classifier = create_connection_classifier(lattice_dimensions=(15, 15, 15))
        init_time = time.time() - start_time

        print(f"   Cache enabled: {classifier.enable_cache}")
        if classifier.cache_manager:
            print(f"   GPU acceleration: {classifier.cache_manager.use_gpu}")
            print(f"   Device: {classifier.cache_manager.device}")
            print(f"   GPU batch size: {classifier.cache_manager.gpu_batch_size}")
        print(f"   Initialization time: {init_time:.2f}s")

        cache_stats = classifier.get_cache_stats()
        print(f"   Cache status: {cache_stats.get('status', 'unknown')}")
        if cache_stats.get("cached_cells"):
            print(f"   Cached cells: {cache_stats['cached_cells']}")
            print(f"   Cache size: {cache_stats.get('cache_size_mb', 0):.1f}MB")

    # ==================================================================
    # –¢–µ—Å—Ç 3: –ë–æ–ª—å—à–∞—è —Ä–µ—à–µ—Ç–∫–∞ (–¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ–π –º–æ—â–Ω–æ—Å—Ç–∏)
    # ==================================================================
    if gpu_memory >= 8.0:
        print(f"\n3Ô∏è‚É£ –ë–æ–ª—å—à–∞—è —Ä–µ—à–µ—Ç–∫–∞ (20x20x20 = 8000 –∫–ª–µ—Ç–æ–∫) - –ø–æ–ª–Ω–∞—è –º–æ—â–Ω–æ—Å—Ç—å GPU")
        config_large = ProjectConfig()
        config_large.lattice.dimensions = (20, 20, 20)
        config_large.cache.enabled = True
        config_large.cache.use_gpu_acceleration = True
        config_large.cache.enable_performance_monitoring = True
        config_large.cache.auto_enable_threshold = 3000
        config_large.cache.gpu_batch_size = 5000
        set_project_config(config_large)

        should_use_cache = (
            config_large.cache.enabled
            and config_large.total_cells >= config_large.cache.auto_enable_threshold
        )
        print(f"   Should use cache: {should_use_cache}")

        if should_use_cache:
            print("   üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ–ª—å—à–æ–≥–æ –∫—ç—à–∞ –Ω–∞ GPU...")
            print("   ‚è±Ô∏è  –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è...")

            start_time = time.time()
            classifier = create_connection_classifier(lattice_dimensions=(20, 20, 20))
            init_time = time.time() - start_time

            print(f"   ‚úÖ Cache enabled: {classifier.enable_cache}")
            if classifier.cache_manager:
                print(f"   üöÄ GPU acceleration: {classifier.cache_manager.use_gpu}")
                print(f"   üíæ Device: {classifier.cache_manager.device}")
                print(
                    f"   üì¶ GPU batch size: {classifier.cache_manager.gpu_batch_size}"
                )
            print(f"   ‚è±Ô∏è  Total initialization time: {init_time:.2f}s")

            cache_stats = classifier.get_cache_stats()
            print(f"   üìä Cache status: {cache_stats.get('status', 'unknown')}")
            if cache_stats.get("cached_cells"):
                print(f"   üéØ Cached cells: {cache_stats['cached_cells']}")
                print(f"   üíæ Cache size: {cache_stats.get('cache_size_mb', 0):.1f}MB")
                print(f"   üíΩ Cache saved to disk for future reuse")
        else:
            print("   ‚ö†Ô∏è  Cache disabled for this lattice size")
    else:
        print(
            f"\n3Ô∏è‚É£ –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–æ–ª—å—à—É—é —Ä–µ—à–µ—Ç–∫—É (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ GPU –ø–∞–º—è—Ç–∏: {gpu_memory:.1f}GB < 8GB)"
        )

    print(f"\n‚úÖ GPU Cache Demo –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"üîÑ –ü—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º –∑–∞–ø—É—Å–∫–µ –∫—ç—à –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω —Å –¥–∏—Å–∫–∞ –º–æ–º–µ–Ω—Ç–∞–ª—å–Ω–æ!")

    # ==================================================================
    # –¢–µ—Å—Ç 4: –ü–ï–†–ï–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï –ö–≠–®–ê –¥–ª—è —Å—Ä–µ–¥–Ω–µ–π —Ä–µ—à–µ—Ç–∫–∏
    # ==================================================================
    print(f"\nüîÑ –¢–µ—Å—Ç –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫—ç—à–∞ (15x15x15)")
    print("=" * 45)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é, —á—Ç–æ –∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫—ç—à–∞
    set_project_config(config_medium)

    print("   üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫—ç—à...")
    start_time = time.time()
    classifier = create_connection_classifier(lattice_dimensions=(15, 15, 15))
    reuse_time = time.time() - start_time

    print(f"   ‚ö° –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏: {reuse_time:.2f}s")

    if reuse_time < 2.0:  # –£–≤–µ–ª–∏—á–∏–º –ø–æ—Ä–æ–≥ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        print("   ‚úÖ –ö—ç—à —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω (–±—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)!")
    else:
        print("   üîÑ –ö—ç—à –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω (–ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –∏–ª–∏ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)")

    cache_stats = classifier.get_cache_stats()
    if cache_stats.get("cached_cells"):
        print(f"   üìä Cached cells: {cache_stats['cached_cells']}")


if __name__ == "__main__":
    run_full_test()
