"""
–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤
=================================

–°–æ–¥–µ—Ä–∂–∏—Ç —Ç—Ä–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏:
1. LinearReshaper - –ø—Ä–æ—Å—Ç–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º—ã
2. AdaptiveReshaper - —É–º–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
3. SemanticReshaper - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
"""

import torch
import numpy as np
from typing import Union, Tuple, Dict, Any, Optional, List
import logging
from abc import ABC, abstractmethod

from .utils import calculate_similarity_metrics, validate_semantic_preservation


class BaseReshaper(ABC):
    """
    –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è.
    """
    
    def __init__(
        self,
        input_dim: int = 768,
        cube_shape: Tuple[int, int, int] = (8, 8, 12),
        preserve_semantics: bool = True,
        semantic_threshold: float = 0.95
    ):
        self.input_dim = input_dim
        self.cube_shape = cube_shape
        self.preserve_semantics = preserve_semantics
        self.semantic_threshold = semantic_threshold
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
        cube_size = np.prod(cube_shape)
        if cube_size != input_dim:
            raise ValueError(
                f"–†–∞–∑–º–µ—Ä—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç: input_dim={input_dim}, "
                f"cube_shape={cube_shape} (–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ={cube_size})"
            )
        
        self.logger = logging.getLogger(self.__class__.__name__)
    
    @abstractmethod
    def vector_to_matrix(
        self, 
        embedding_1d: Union[torch.Tensor, np.ndarray]
    ) -> Union[torch.Tensor, np.ndarray]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ 1D ‚Üí 3D"""
        pass
    
    @abstractmethod
    def matrix_to_vector(
        self, 
        embedding_3d: Union[torch.Tensor, np.ndarray]
    ) -> Union[torch.Tensor, np.ndarray]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ 3D ‚Üí 1D"""
        pass


class LinearReshaper(BaseReshaper):
    """
    –ü—Ä–æ—Å—Ç–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –ª–∏–Ω–µ–π–Ω–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ–æ—Ä–º—ã.
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä—è–º–æ–µ reshape –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π.
    –ë—ã—Å—Ç—Ä–∞—è, –Ω–æ –º–æ–∂–µ—Ç –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ.
    """
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.logger.info(f"LinearReshaper –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.input_dim}D ‚Üî {self.cube_shape}")
    
    def vector_to_matrix(
        self, 
        embedding_1d: Union[torch.Tensor, np.ndarray]
    ) -> Union[torch.Tensor, np.ndarray]:
        """
        –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ 1D ‚Üí 3D —á–µ—Ä–µ–∑ reshape.
        
        Args:
            embedding_1d: –í—Ö–æ–¥–Ω–æ–π 1D —ç–º–±–µ–¥–∏–Ω–≥
            
        Returns:
            3D –º–∞—Ç—Ä–∏—Ü–∞ —Ç–æ–π –∂–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        """
        if isinstance(embedding_1d, torch.Tensor):
            if embedding_1d.shape != (self.input_dim,):
                raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {self.input_dim}, –ø–æ–ª—É—á–µ–Ω–æ {embedding_1d.shape}")
            result = embedding_1d.reshape(self.cube_shape)
        elif isinstance(embedding_1d, np.ndarray):
            if embedding_1d.shape != (self.input_dim,):
                raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {self.input_dim}, –ø–æ–ª—É—á–µ–Ω–æ {embedding_1d.shape}")
            result = embedding_1d.reshape(self.cube_shape)
        else:
            raise TypeError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ torch.Tensor –∏ np.ndarray")
        
        # –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞
        if self.preserve_semantics:
            similarity = calculate_similarity_metrics(embedding_1d, result)
            if similarity < self.semantic_threshold:
                self.logger.warning(
                    f"LinearReshaper: –∫–∞—á–µ—Å—Ç–≤–æ {similarity:.3f} < {self.semantic_threshold}"
                )
        
        return result
    
    def matrix_to_vector(
        self, 
        embedding_3d: Union[torch.Tensor, np.ndarray]
    ) -> Union[torch.Tensor, np.ndarray]:
        """
        –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ 3D ‚Üí 1D —á–µ—Ä–µ–∑ reshape.
        
        Args:
            embedding_3d: –í—Ö–æ–¥–Ω–∞—è 3D –º–∞—Ç—Ä–∏—Ü–∞
            
        Returns:
            1D –≤–µ–∫—Ç–æ—Ä —Ç–æ–π –∂–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        """
        if isinstance(embedding_3d, torch.Tensor):
            if embedding_3d.shape != self.cube_shape:
                raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {self.cube_shape}, –ø–æ–ª—É—á–µ–Ω–æ {embedding_3d.shape}")
            result = embedding_3d.reshape(self.input_dim)
        elif isinstance(embedding_3d, np.ndarray):
            if embedding_3d.shape != self.cube_shape:
                raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {self.cube_shape}, –ø–æ–ª—É—á–µ–Ω–æ {embedding_3d.shape}")
            result = embedding_3d.reshape(self.input_dim)
        else:
            raise TypeError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ torch.Tensor –∏ np.ndarray")
        
        # –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞
        if self.preserve_semantics:
            similarity = calculate_similarity_metrics(result, embedding_3d)
            if similarity < self.semantic_threshold:
                self.logger.warning(
                    f"LinearReshaper: –∫–∞—á–µ—Å—Ç–≤–æ {similarity:.3f} < {self.semantic_threshold}"
                )
        
        return result


class AdaptiveReshaper(BaseReshaper):
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º >98%.
    
    PHASE 2.3 –î–µ–Ω—å 3-4: –†–µ–∞–ª–∏–∑—É–µ—Ç –∞–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏–µ
    –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
    """
    
    def __init__(self, adaptation_method: str = "enhanced_variance", **kwargs):
        super().__init__(**kwargs)
        self.adaptation_method = adaptation_method
        self.adaptation_cache = {}  # –ö—ç—à –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
        self.importance_cache = {}  # –ö—ç—à –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏
        self.placement_maps = {}   # –ö—ç—à –∫–∞—Ä—Ç —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
        from .utils import (
            calculate_enhanced_similarity_metrics,
            analyze_embedding_importance,
            create_adaptive_transformation_strategy
        )
        self._enhanced_similarity = calculate_enhanced_similarity_metrics
        self._analyze_importance = analyze_embedding_importance
        self._create_strategy = create_adaptive_transformation_strategy
        
        self.logger.info(
            f"Enhanced AdaptiveReshaper –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.input_dim}D ‚Üî {self.cube_shape}, "
            f"–º–µ—Ç–æ–¥={adaptation_method}, target_quality=98%"
        )
    
    def vector_to_matrix(
        self, 
        embedding_1d: Union[torch.Tensor, np.ndarray]
    ) -> Union[torch.Tensor, np.ndarray]:
        """
        –£–ª—É—á—à–µ–Ω–Ω–æ–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ 1D ‚Üí 3D —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º >98%.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏–µ –≤ 3D –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ.
        """
        if isinstance(embedding_1d, torch.Tensor):
            if embedding_1d.shape != (self.input_dim,):
                raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {self.input_dim}, –ø–æ–ª—É—á–µ–Ω–æ {embedding_1d.shape}")
            embedding_np = embedding_1d.detach().cpu().numpy()
            is_torch = True
        elif isinstance(embedding_1d, np.ndarray):
            if embedding_1d.shape != (self.input_dim,):
                raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {self.input_dim}, –ø–æ–ª—É—á–µ–Ω–æ {embedding_1d.shape}")
            embedding_np = embedding_1d
            is_torch = False
        else:
            raise TypeError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ torch.Tensor –∏ np.ndarray")
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
        cache_key = hash(embedding_np.tobytes())
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π
        if cache_key in self.adaptation_cache:
            result_np = self.adaptation_cache[cache_key]
        else:
            # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
            if self.adaptation_method == "enhanced_variance":
                result_np, placement_map = self._enhanced_variance_transform(embedding_np)
                self.placement_maps[cache_key] = placement_map
            elif self.adaptation_method == "importance_weighted":
                result_np, placement_map = self._enhanced_importance_transform(embedding_np)
                self.placement_maps[cache_key] = placement_map
            elif self.adaptation_method == "adaptive_placement":
                result_np, placement_map = self._adaptive_placement_transform(embedding_np)
                self.placement_maps[cache_key] = placement_map
            elif self.adaptation_method == "variance_based":
                # –û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Å—Ç–∞—Ä—ã–º –º–µ—Ç–æ–¥–æ–º
                result_np = self._variance_based_transform(embedding_np)
            else:
                # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É reshape
                result_np = embedding_np.reshape(self.cube_shape)
            
            # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.adaptation_cache[cache_key] = result_np
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        if is_torch:
            result = torch.from_numpy(result_np)
        else:
            result = result_np
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞
        if self.preserve_semantics:
            similarity = calculate_similarity_metrics(embedding_1d, result)
            if similarity < self.semantic_threshold:
                self.logger.warning(
                    f"AdaptiveReshaper: –∫–∞—á–µ—Å—Ç–≤–æ {similarity:.3f} < {self.semantic_threshold}"
                )
        
        return result
    
    def matrix_to_vector(
        self, 
        embedding_3d: Union[torch.Tensor, np.ndarray]
    ) -> Union[torch.Tensor, np.ndarray]:
        """
        –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ 3D ‚Üí 1D.
        
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º –≤–∞–∂–Ω–æ—Å—Ç–∏.
        """
        if isinstance(embedding_3d, torch.Tensor):
            if embedding_3d.shape != self.cube_shape:
                raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {self.cube_shape}, –ø–æ–ª—É—á–µ–Ω–æ {embedding_3d.shape}")
            embedding_np = embedding_3d.detach().cpu().numpy()
            is_torch = True
        elif isinstance(embedding_3d, np.ndarray):
            if embedding_3d.shape != self.cube_shape:
                raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {self.cube_shape}, –ø–æ–ª—É—á–µ–Ω–æ {embedding_3d.shape}")
            embedding_np = embedding_3d
            is_torch = False
        else:
            raise TypeError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ torch.Tensor –∏ np.ndarray")
        
        # –ü–æ–∏—Å–∫ –∫–∞—Ä—Ç—ã —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        original_cache_key = None
        placement_map = None
        
        # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∫–∞—Ä—Ç—É —Ä–∞–∑–º–µ—â–µ–Ω–∏—è
        for cached_key, cached_map in self.placement_maps.items():
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
                cached_embedding = None
                for cache_key, cached_result in self.adaptation_cache.items():
                    if np.allclose(cached_result, embedding_np, rtol=1e-10):
                        original_cache_key = cache_key
                        placement_map = self.placement_maps.get(cache_key)
                        break
                if placement_map is not None:
                    break
            except:
                continue
        
        # –¢–æ—á–Ω–æ–µ –æ–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–∞—Ä—Ç—ã —Ä–∞–∑–º–µ—â–µ–Ω–∏—è
        if placement_map is not None:
            result_np = self._precise_inverse_transform(embedding_np, placement_map)
            self.logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ—á–Ω–æ–µ –æ–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å –∫–∞—Ä—Ç–æ–π —Ä–∞–∑–º–µ—â–µ–Ω–∏—è")
        else:
            # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (fallback)
            if self.adaptation_method == "variance_based":
                result_np = self._variance_based_inverse_transform(embedding_np)
            elif self.adaptation_method == "importance_weighted":
                result_np = self._enhanced_importance_inverse_transform(embedding_np)
            elif self.adaptation_method == "enhanced_variance":
                result_np = self._enhanced_variance_inverse_transform(embedding_np)
            elif self.adaptation_method == "adaptive_placement":
                result_np = self._adaptive_placement_inverse_transform(embedding_np)
            else:
                # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É reshape
                result_np = embedding_np.reshape(self.input_dim)
            self.logger.warning(f"–ö–∞—Ä—Ç–∞ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        if is_torch:
            result = torch.from_numpy(result_np)
        else:
            result = result_np
        
        # –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞
        if self.preserve_semantics:
            similarity = calculate_similarity_metrics(result, embedding_3d)
            if similarity < self.semantic_threshold:
                self.logger.warning(
                    f"AdaptiveReshaper: –∫–∞—á–µ—Å—Ç–≤–æ {similarity:.3f} < {self.semantic_threshold}"
                )
        
        return result
    
    def _variance_based_transform(self, embedding_1d: np.ndarray) -> np.ndarray:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –∑–Ω–∞—á–µ–Ω–∏–π.
        
        –†–∞–∑–º–µ—â–∞–µ—Ç —ç–ª–µ–º–µ–Ω—Ç—ã —Å –≤—ã—Å–æ–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π –≤ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π —á–∞—Å—Ç–∏ –∫—É–±–∞.
        """
        # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é
        indices = np.argsort(np.abs(embedding_1d))[::-1]  # –û—Ç –±–æ–ª—å—à–µ–≥–æ –∫ –º–µ–Ω—å—à–µ–º—É
        sorted_values = embedding_1d[indices]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º 3D —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        result = sorted_values.reshape(self.cube_shape)
        
        return result
    
    def _variance_based_inverse_transform(self, embedding_3d: np.ndarray) -> np.ndarray:
        """–û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è variance_based."""
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π reshape
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫
        return embedding_3d.reshape(self.input_dim)
    
    def _importance_weighted_transform(self, embedding_1d: np.ndarray) -> np.ndarray:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å –≤–µ—Å–∞–º–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç –∏–ª–∏ –¥—Ä—É–≥–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–∞–∑–º–µ—â–µ–Ω–∏—è.
        """
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ (–ø—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)
        importance_weights = np.abs(embedding_1d) / (np.abs(embedding_1d).sum() + 1e-8)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
        weighted_indices = np.argsort(importance_weights)[::-1]
        weighted_values = embedding_1d[weighted_indices]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º 3D —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        result = weighted_values.reshape(self.cube_shape)
        
        return result
    
    def _importance_weighted_inverse_transform(self, embedding_3d: np.ndarray) -> np.ndarray:
        """–û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è importance_weighted."""
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π reshape
        return embedding_3d.reshape(self.input_dim)
    
    # ==========================================
    # üöÄ –ù–û–í–´–ï –£–õ–£–ß–®–ï–ù–ù–´–ï –ú–ï–¢–û–î–´ –î–õ–Ø –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ì–û –°–û–•–†–ê–ù–ï–ù–ò–Ø >98%
    # ==========================================
    
    def _enhanced_variance_transform(self, embedding_1d: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        –£–ª—É—á—à–µ–Ω–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç PCA –∞–Ω–∞–ª–∏–∑ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —ç–º–±–µ–¥–∏–Ω–≥–∞
        –∏ —Ä–∞–∑–º–µ—â–∞–µ—Ç –∏—Ö –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –≤ 3D –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ.
        """
        try:
            # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ PCA
            importance_weights = self._analyze_importance(embedding_1d, method="variance_pca")
            
            # –°–æ–∑–¥–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–∞–∑–º–µ—â–µ–Ω–∏—è
            strategy = self._create_strategy(embedding_1d, self.cube_shape, "variance_pca")
            placement_map = strategy['placement_map']
            
            # –°–æ–∑–¥–∞–µ–º 3D –º–∞—Å—Å–∏–≤ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º —Ä–∞–∑–º–µ—â–µ–Ω–∏–µ–º
            result_3d = np.zeros(self.cube_shape)
            embedding_flat = embedding_1d.flatten()
            
            # –†–∞–∑–º–µ—â–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å–æ–≥–ª–∞—Å–Ω–æ –∫–∞—Ä—Ç–µ –≤–∞–∂–Ω–æ—Å—Ç–∏
            for original_idx, spatial_idx in enumerate(placement_map):
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ª–∏–Ω–µ–π–Ω—ã–π –∏–Ω–¥–µ–∫—Å –≤ 3D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                z = spatial_idx // (self.cube_shape[1] * self.cube_shape[2])
                y = (spatial_idx % (self.cube_shape[1] * self.cube_shape[2])) // self.cube_shape[2]
                x = spatial_idx % self.cube_shape[2]
                
                if z < self.cube_shape[0] and y < self.cube_shape[1] and x < self.cube_shape[2]:
                    result_3d[z, y, x] = embedding_flat[original_idx]
            
            self.logger.debug(f"Enhanced variance transform: importance analysis completed")
            return result_3d, placement_map
            
        except Exception as e:
            self.logger.warning(f"Enhanced variance transform failed: {e}, fallback to simple")
            # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É –º–µ—Ç–æ–¥—É
            simple_result = self._variance_based_transform(embedding_1d)
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –∫–∞—Ä—Ç—É —Ä–∞–∑–º–µ—â–µ–Ω–∏—è (–ª–∏–Ω–µ–π–Ω–∞—è)
            simple_map = np.arange(len(embedding_1d))
            return simple_result, simple_map
    
    def _enhanced_importance_transform(self, embedding_1d: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        –£–ª—É—á—à–µ–Ω–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º –≤–∞–∂–Ω–æ—Å—Ç–∏.
        
        –ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Ç–æ–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ
        —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã.
        """
        try:
            # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏
            importance_pca = self._analyze_importance(embedding_1d, method="variance_pca")
            importance_clustering = self._analyze_importance(embedding_1d, method="clustering")
            importance_magnitude = self._analyze_importance(embedding_1d, method="magnitude")
            
            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ (–≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ)
            combined_importance = (
                0.5 * importance_pca +
                0.3 * importance_clustering +
                0.2 * importance_magnitude
            )
            
            # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–∞–∂–Ω–æ—Å—Ç–∏
            sorted_indices = np.argsort(combined_importance)[::-1]  # –û—Ç –≤–∞–∂–Ω—ã—Ö –∫ –º–µ–Ω–µ–µ –≤–∞–∂–Ω—ã–º
            
            # –°–æ–∑–¥–∞–µ–º 3D —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ-—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º —Ä–∞–∑–º–µ—â–µ–Ω–∏–µ–º
            result_3d = np.zeros(self.cube_shape)
            embedding_flat = embedding_1d.flatten()
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ—Ç —Ü–µ–Ω—Ç—Ä–∞ –∫ –∫—Ä–∞—è–º
            center_coords = self._generate_center_to_edge_coordinates()
            
            # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É —Ä–∞–∑–º–µ—â–µ–Ω–∏—è: original_idx -> spatial_idx
            placement_map = np.zeros(len(embedding_flat), dtype=int)
            
            for i, original_idx in enumerate(sorted_indices):
                if i < len(center_coords):
                    z, y, x = center_coords[i]
                    result_3d[z, y, x] = embedding_flat[original_idx]
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º 3D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –ª–∏–Ω–µ–π–Ω—ã–π –∏–Ω–¥–µ–∫—Å
                    spatial_idx = z * (self.cube_shape[1] * self.cube_shape[2]) + y * self.cube_shape[2] + x
                    placement_map[original_idx] = spatial_idx
            
            self.logger.debug(f"Enhanced importance transform: multi-level analysis completed")
            return result_3d, placement_map
            
        except Exception as e:
            self.logger.warning(f"Enhanced importance transform failed: {e}, fallback to simple")
            simple_result = self._importance_weighted_transform(embedding_1d)
            simple_map = np.arange(len(embedding_1d))
            return simple_result, simple_map
    
    def _adaptive_placement_transform(self, embedding_1d: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏–µ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞–∏–ª—É—á—à–µ–≥–æ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è
        —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ 3D –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ.
        """
        try:
            # –°–æ–∑–¥–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è
            candidates = []
            placement_maps = []
            similarities = []
            
            # –í–∞—Ä–∏–∞–Ω—Ç 1: –ù–∞ –æ—Å–Ω–æ–≤–µ PCA
            candidate1, map1 = self._enhanced_variance_transform(embedding_1d)
            sim1 = self._enhanced_similarity(embedding_1d, candidate1)['weighted_similarity']
            candidates.append(candidate1)
            placement_maps.append(map1)
            similarities.append(sim1)
            
            # –í–∞—Ä–∏–∞–Ω—Ç 2: –ù–∞ –æ—Å–Ω–æ–≤–µ –≤–∞–∂–Ω–æ—Å—Ç–∏
            candidate2, map2 = self._enhanced_importance_transform(embedding_1d)
            sim2 = self._enhanced_similarity(embedding_1d, candidate2)['weighted_similarity']
            candidates.append(candidate2)
            placement_maps.append(map2)
            similarities.append(sim2)
            
            # –í–∞—Ä–∏–∞–Ω—Ç 3: –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥
            candidate3, map3 = self._hybrid_placement_transform(embedding_1d)
            sim3 = self._enhanced_similarity(embedding_1d, candidate3)['weighted_similarity']
            candidates.append(candidate3)
            placement_maps.append(map3)
            similarities.append(sim3)
            
            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
            best_idx = np.argmax(similarities)
            best_candidate = candidates[best_idx]
            best_placement_map = placement_maps[best_idx]
            best_similarity = similarities[best_idx]
            
            self.logger.info(
                f"Adaptive placement: selected variant {best_idx+1} with similarity {best_similarity:.6f}"
            )
            
            return best_candidate, best_placement_map
            
        except Exception as e:
            self.logger.warning(f"Adaptive placement failed: {e}, fallback to enhanced variance")
            return self._enhanced_variance_transform(embedding_1d)
    
    def _hybrid_placement_transform(self, embedding_1d: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥, –∫–æ–º–±–∏–Ω–∏—Ä—É—é—â–∏–π —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è.
        """
        # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏
        importance = self._analyze_importance(embedding_1d, method="variance_pca")
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ –∑–æ–Ω–∞–º
        result_3d = np.zeros(self.cube_shape)
        embedding_flat = embedding_1d.flatten()
        
        # –ó–æ–Ω–∞ 1: –¶–µ–Ω—Ç—Ä (20% —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤)
        n_center = len(embedding_flat) // 5
        center_indices = np.argsort(importance)[-n_center:]
        center_coords = self._get_center_coordinates(n_center)
        
        for i, idx in enumerate(center_indices):
            if i < len(center_coords):
                z, y, x = center_coords[i]
                result_3d[z, y, x] = embedding_flat[idx]
        
        # –ó–æ–Ω–∞ 2: –°—Ä–µ–¥–Ω—è—è –æ–±–ª–∞—Å—Ç—å (60% —Å—Ä–µ–¥–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤)
        n_middle = (len(embedding_flat) * 3) // 5
        start_idx = len(embedding_flat) // 5
        middle_indices = np.argsort(importance)[start_idx:start_idx + n_middle]
        middle_coords = self._get_middle_coordinates(n_middle)
        
        for i, idx in enumerate(middle_indices):
            if i < len(middle_coords):
                z, y, x = middle_coords[i]
                result_3d[z, y, x] = embedding_flat[idx]
        
        # –ó–æ–Ω–∞ 3: –ü–µ—Ä–∏—Ñ–µ—Ä–∏—è (20% –Ω–∞–∏–º–µ–Ω–µ–µ –≤–∞–∂–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤)
        remaining_indices = np.argsort(importance)[:len(embedding_flat) // 5]
        edge_coords = self._get_edge_coordinates(len(remaining_indices))
        
        for i, idx in enumerate(remaining_indices):
            if i < len(edge_coords):
                z, y, x = edge_coords[i]
                result_3d[z, y, x] = embedding_flat[idx]
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É —Ä–∞–∑–º–µ—â–µ–Ω–∏—è: original_idx -> spatial_idx
        placement_map = np.zeros(len(embedding_flat), dtype=int)
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –∫–∞—Ä—Ç—É –¥–ª—è —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        for i, idx in enumerate(center_indices):
            if i < len(center_coords):
                z, y, x = center_coords[i]
                spatial_idx = z * (self.cube_shape[1] * self.cube_shape[2]) + y * self.cube_shape[2] + x
                placement_map[idx] = spatial_idx
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –∫–∞—Ä—Ç—É –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        for i, idx in enumerate(middle_indices):
            if i < len(middle_coords):
                z, y, x = middle_coords[i]
                spatial_idx = z * (self.cube_shape[1] * self.cube_shape[2]) + y * self.cube_shape[2] + x
                placement_map[idx] = spatial_idx
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –∫–∞—Ä—Ç—É –¥–ª—è –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        for i, idx in enumerate(remaining_indices):
            if i < len(edge_coords):
                z, y, x = edge_coords[i]
                spatial_idx = z * (self.cube_shape[1] * self.cube_shape[2]) + y * self.cube_shape[2] + x
                placement_map[idx] = spatial_idx
        
        return result_3d, placement_map
    
    def _generate_center_to_edge_coordinates(self) -> List[Tuple[int, int, int]]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ—Ç —Ü–µ–Ω—Ç—Ä–∞ –∫ –∫—Ä–∞—è–º –∫—É–±–∞."""
        d, h, w = self.cube_shape
        center_z, center_y, center_x = d // 2, h // 2, w // 2
        
        coords = []
        for z in range(d):
            for y in range(h):
                for x in range(w):
                    coords.append((z, y, x))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é –æ—Ç —Ü–µ–Ω—Ç—Ä–∞
        coords.sort(key=lambda coord: 
                   (coord[0] - center_z)**2 + (coord[1] - center_y)**2 + (coord[2] - center_x)**2)
        
        return coords
    
    def _get_center_coordinates(self, count: int) -> List[Tuple[int, int, int]]:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏."""
        all_coords = self._generate_center_to_edge_coordinates()
        return all_coords[:count]
    
    def _get_middle_coordinates(self, count: int) -> List[Tuple[int, int, int]]:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å—Ä–µ–¥–Ω–µ–π –æ–±–ª–∞—Å—Ç–∏."""
        all_coords = self._generate_center_to_edge_coordinates()
        center_count = len(all_coords) // 5
        return all_coords[center_count:center_count + count]
    
    def _get_edge_coordinates(self, count: int) -> List[Tuple[int, int, int]]:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏."""
        all_coords = self._generate_center_to_edge_coordinates()
        return all_coords[-count:] if count > 0 else []
    
    # ==========================================
    # üîÑ –û–ë–†–ê–¢–ù–´–ï –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–Ø –î–õ–Ø ENHANCED –ú–ï–¢–û–î–û–í
    # ==========================================
    
    def _enhanced_variance_inverse_transform(self, embedding_3d: np.ndarray) -> np.ndarray:
        """
        –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è enhanced_variance –º–µ—Ç–æ–¥–∞.
        
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—Ä—Ç—ã —Ä–∞–∑–º–µ—â–µ–Ω–∏—è.
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —ç–º–±–µ–¥–∏–Ω–≥ (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏) –∏–∑ –∫—ç—à–∞
            # –ü–æ—Å–∫–æ–ª—å–∫—É —É –Ω–∞—Å –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —ç–º–±–µ–¥–∏–Ω–≥—É, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ
            embedding_flat = embedding_3d.flatten()
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω—É—é –≤–∞–∂–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∑–∏—Ü–∏–∏ –≤ 3D –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ
            # –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å—á–∏—Ç–∞–µ–º –±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–º–∏
            d, h, w = self.cube_shape
            center_z, center_y, center_x = d / 2, h / 2, w / 2
            
            # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è
            result_1d = np.zeros(self.input_dim)
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –æ—Ç —Ü–µ–Ω—Ç—Ä–∞
            distance_importance = []
            element_positions = []
            
            idx = 0
            for z in range(d):
                for y in range(h):
                    for x in range(w):
                        dist = np.sqrt((z - center_z)**2 + (y - center_y)**2 + (x - center_x)**2)
                        distance_importance.append(1.0 / (1.0 + dist))  # –ò–Ω–≤–µ—Ä—Å–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
                        element_positions.append((z, y, x, embedding_3d[z, y, x]))
                        idx += 1
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ (–æ–±—Ä–∞—Ç–Ω–æ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ä–∞–∑–º–µ—â–µ–Ω–∏—é)
            sorted_elements = sorted(zip(distance_importance, element_positions), 
                                   key=lambda x: x[0], reverse=True)
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫
            for i, (importance, (z, y, x, value)) in enumerate(sorted_elements):
                if i < self.input_dim:
                    result_1d[i] = value
            
            return result_1d
            
        except Exception as e:
            self.logger.warning(f"Enhanced variance inverse transform failed: {e}, fallback to simple")
            return embedding_3d.reshape(self.input_dim)
    
    def _enhanced_importance_inverse_transform(self, embedding_3d: np.ndarray) -> np.ndarray:
        """
        –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è enhanced_importance –º–µ—Ç–æ–¥–∞.
        """
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ –ª–æ–≥–∏–∫—É, —á—Ç–æ –∏ –¥–ª—è enhanced_variance
            return self._enhanced_variance_inverse_transform(embedding_3d)
            
        except Exception as e:
            self.logger.warning(f"Enhanced importance inverse transform failed: {e}, fallback to simple")
            return embedding_3d.reshape(self.input_dim)
    
    def _adaptive_placement_inverse_transform(self, embedding_3d: np.ndarray) -> np.ndarray:
        """
        –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è adaptive_placement –º–µ—Ç–æ–¥–∞.
        """
        try:
            # –î–ª—è adaptive_placement –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
            return self._enhanced_variance_inverse_transform(embedding_3d)
            
        except Exception as e:
            self.logger.warning(f"Adaptive placement inverse transform failed: {e}, fallback to simple")
            return embedding_3d.reshape(self.input_dim)
    
    def _precise_inverse_transform(self, embedding_3d: np.ndarray, placement_map: np.ndarray) -> np.ndarray:
        """
        –¢–û–ß–ù–û–ï –æ–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–∞—Ä—Ç—ã —Ä–∞–∑–º–µ—â–µ–Ω–∏—è.
        
        –≠—Ç–æ –∫–ª—é—á–µ–≤–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è >98% —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¢–û–ß–ù–û –ø–æ –∫–∞—Ä—Ç–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è.
        """
        try:
            result_1d = np.zeros(self.input_dim)
            embedding_flat = embedding_3d.flatten()
            
            if len(placement_map) != len(embedding_flat):
                self.logger.error(
                    f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç: placement_map={len(placement_map)}, "
                    f"embedding_flat={len(embedding_flat)}"
                )
                return embedding_3d.reshape(self.input_dim)
            
            # –¢–û–ß–ù–û–ï –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ä—Ç–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è
            for original_idx, spatial_idx in enumerate(placement_map):
                if spatial_idx < len(embedding_flat) and original_idx < self.input_dim:
                    result_1d[original_idx] = embedding_flat[spatial_idx]
            
            self.logger.debug(
                f"–¢–æ—á–Ω–æ–µ –æ–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {len(placement_map)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤"
            )
            
            return result_1d
            
        except Exception as e:
            self.logger.error(f"–¢–æ—á–Ω–æ–µ –æ–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ failed: {e}")
            # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π fallback
            return embedding_3d.reshape(self.input_dim)


class SemanticReshaper(BaseReshaper):
    """
    –°—Ç—Ä–∞—Ç–µ–≥–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤.
    
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —ç–º–±–µ–¥–∏–Ω–≥–∞ –∏ —Ä–∞–∑–º–µ—â–∞–µ—Ç –ø–æ—Ö–æ–∂–∏–µ
    —ç–ª–µ–º–µ–Ω—Ç—ã –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏ –≤ 3D –∫—É–±–µ.
    """
    
    def __init__(self, clustering_method: str = "kmeans", n_clusters: int = 8, **kwargs):
        super().__init__(**kwargs)
        self.clustering_method = clustering_method
        self.n_clusters = n_clusters
        self.cluster_cache = {}
        
        self.logger.info(
            f"SemanticReshaper –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.input_dim}D ‚Üî {self.cube_shape}, "
            f"–∫–ª–∞—Å—Ç–µ—Ä—ã={n_clusters}, –º–µ—Ç–æ–¥={clustering_method}"
        )
    
    def vector_to_matrix(
        self, 
        embedding_1d: Union[torch.Tensor, np.ndarray]
    ) -> Union[torch.Tensor, np.ndarray]:
        """
        –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ 1D ‚Üí 3D.
        
        –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–æ—Ö–æ–∂–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã.
        """
        if isinstance(embedding_1d, torch.Tensor):
            if embedding_1d.shape != (self.input_dim,):
                raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {self.input_dim}, –ø–æ–ª—É—á–µ–Ω–æ {embedding_1d.shape}")
            embedding_np = embedding_1d.detach().cpu().numpy()
            is_torch = True
        elif isinstance(embedding_1d, np.ndarray):
            if embedding_1d.shape != (self.input_dim,):
                raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {self.input_dim}, –ø–æ–ª—É—á–µ–Ω–æ {embedding_1d.shape}")
            embedding_np = embedding_1d
            is_torch = False
        else:
            raise TypeError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ torch.Tensor –∏ np.ndarray")
        
        # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –∫–ª–∞—Å—Ç–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ
        if self.clustering_method == "kmeans":
            result_np = self._kmeans_transform(embedding_np)
        elif self.clustering_method == "hierarchical":
            result_np = self._hierarchical_transform(embedding_np)
        else:
            # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É reshape
            result_np = embedding_np.reshape(self.cube_shape)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        if is_torch:
            result = torch.from_numpy(result_np)
        else:
            result = result_np
        
        # –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞
        if self.preserve_semantics:
            similarity = calculate_similarity_metrics(embedding_1d, result)
            if similarity < self.semantic_threshold:
                self.logger.warning(
                    f"SemanticReshaper: –∫–∞—á–µ—Å—Ç–≤–æ {similarity:.3f} < {self.semantic_threshold}"
                )
        
        return result
    
    def matrix_to_vector(
        self, 
        embedding_3d: Union[torch.Tensor, np.ndarray]
    ) -> Union[torch.Tensor, np.ndarray]:
        """
        –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ 3D ‚Üí 1D.
        
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—É—é —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É.
        """
        if isinstance(embedding_3d, torch.Tensor):
            if embedding_3d.shape != self.cube_shape:
                raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {self.cube_shape}, –ø–æ–ª—É—á–µ–Ω–æ {embedding_3d.shape}")
            embedding_np = embedding_3d.detach().cpu().numpy()
            is_torch = True
        elif isinstance(embedding_3d, np.ndarray):
            if embedding_3d.shape != self.cube_shape:
                raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {self.cube_shape}, –ø–æ–ª—É—á–µ–Ω–æ {embedding_3d.shape}")
            embedding_np = embedding_3d
            is_torch = False
        else:
            raise TypeError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ torch.Tensor –∏ np.ndarray")
        
        # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        if self.clustering_method == "kmeans":
            result_np = self._kmeans_inverse_transform(embedding_np)
        elif self.clustering_method == "hierarchical":
            result_np = self._hierarchical_inverse_transform(embedding_np)
        else:
            # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É reshape
            result_np = embedding_np.reshape(self.input_dim)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        if is_torch:
            result = torch.from_numpy(result_np)
        else:
            result = result_np
        
        # –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞
        if self.preserve_semantics:
            similarity = calculate_similarity_metrics(result, embedding_3d)
            if similarity < self.semantic_threshold:
                self.logger.warning(
                    f"SemanticReshaper: –∫–∞—á–µ—Å—Ç–≤–æ {similarity:.3f} < {self.semantic_threshold}"
                )
        
        return result
    
    def _kmeans_transform(self, embedding_1d: np.ndarray) -> np.ndarray:
        """
        K-means –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–∏—è.
        
        –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è - –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º.
        """
        # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º –∑–Ω–∞—á–µ–Ω–∏–π
        n_groups = min(self.n_clusters, len(embedding_1d))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏ –∏–Ω–¥–µ–∫—Å—ã
        sorted_indices = np.argsort(embedding_1d)
        group_size = len(embedding_1d) // n_groups
        
        # –ü–µ—Ä–µ—É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –ø–æ –≥—Ä—É–ø–ø–∞–º
        reordered_values = np.zeros_like(embedding_1d)
        for i, group_start in enumerate(range(0, len(embedding_1d), group_size)):
            group_end = min(group_start + group_size, len(embedding_1d))
            group_indices = sorted_indices[group_start:group_end]
            reordered_values[group_start:group_end] = embedding_1d[group_indices]
        
        return reordered_values.reshape(self.cube_shape)
    
    def _kmeans_inverse_transform(self, embedding_3d: np.ndarray) -> np.ndarray:
        """–û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è kmeans."""
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π reshape
        return embedding_3d.reshape(self.input_dim)
    
    def _hierarchical_transform(self, embedding_1d: np.ndarray) -> np.ndarray:
        """–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è."""
        # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É
        return np.sort(embedding_1d).reshape(self.cube_shape)
    
    def _hierarchical_inverse_transform(self, embedding_3d: np.ndarray) -> np.ndarray:
        """–û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è hierarchical."""
        return embedding_3d.reshape(self.input_dim) 