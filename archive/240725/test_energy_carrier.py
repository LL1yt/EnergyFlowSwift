"""
Ð¢ÐµÑÑ‚ Ð´Ð»Ñ EnergyCarrier - RNN-based ÑÐ½ÐµÑ€Ð³ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¸
========================================================

ÐŸÑ€Ð¾ÑÑ‚Ñ‹Ðµ Ñ‚ÐµÑÑ‚Ñ‹ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ñ€Ð°Ð±Ð¾Ñ‚Ð¾ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸ EnergyCarrier:
- Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ 
- ÐŸÑ€ÑÐ¼Ð¾Ð¹ Ð¿Ñ€Ð¾Ñ…Ð¾Ð´ Ñ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¼Ð¸ Ð²Ñ…Ð¾Ð´Ð°Ð¼Ð¸
- ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ€Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚ÐµÐ¹ Ð²Ñ‹Ñ…Ð¾Ð´Ð¾Ð²
- Ð¢ÐµÑÑ‚ Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼Ð° Ð¿Ð¾Ñ€Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²
"""

import torch
import torch.nn as nn
import sys
import os

# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿ÑƒÑ‚Ð¸ Ð´Ð»Ñ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²
sys.path.append('/mnt/c/Users/n0n4a/projects/AA')

from energy_flow.core.energy_carrier import EnergyCarrier, EnergyOutput, create_energy_carrier
from energy_flow.config import create_debug_config, set_energy_config

def test_energy_carrier_init():
    """Ð¢ÐµÑÑ‚ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ EnergyCarrier"""
    print("\n=== Ð¢ÐµÑÑ‚ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ EnergyCarrier ===")
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³
    config = create_debug_config()
    set_energy_config(config)
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
    carrier = create_energy_carrier(config)
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹
    total_params = sum(p.numel() for p in carrier.parameters())
    print(f"âœ… EnergyCarrier ÑÐ¾Ð·Ð´Ð°Ð½ Ñ {total_params:,} Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸")
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ
    print(f"âœ… GRU: input_size={carrier.input_dim}, hidden_size={carrier.hidden_size}, layers={carrier.num_layers}")
    print(f"âœ… Embedding dim: {carrier.embedding_dim}")
    
    return carrier

def test_energy_carrier_forward():
    """Ð¢ÐµÑÑ‚ Ð¿Ñ€ÑÐ¼Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ñ…Ð¾Ð´Ð°"""
    print("\n=== Ð¢ÐµÑÑ‚ Ð¿Ñ€ÑÐ¼Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ñ…Ð¾Ð´Ð° EnergyCarrier ===")
    
    config = create_debug_config()
    set_energy_config(config)
    carrier = create_energy_carrier(config)
    
    # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð²Ñ…Ð¾Ð´Ñ‹
    batch_size = 4
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    carrier = carrier.to(device)
    
    # Ð’Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
    neuron_output = torch.randn(batch_size, config.neuron_output_dim, device=device)
    embedding_part = torch.randn(batch_size, config.embedding_per_cell, device=device)
    current_position = torch.randint(0, 10, (batch_size, 3), dtype=torch.float32, device=device)
    
    print(f"ðŸ“ Ð’Ñ…Ð¾Ð´Ñ‹: neuron_output={neuron_output.shape}, embedding_part={embedding_part.shape}")
    print(f"ðŸ“ ÐŸÐ¾Ð·Ð¸Ñ†Ð¸Ð¸: {current_position.shape}")
    
    # ÐŸÑ€ÑÐ¼Ð¾Ð¹ Ð¿Ñ€Ð¾Ñ…Ð¾Ð´
    with torch.no_grad():
        output, new_hidden = carrier(neuron_output, embedding_part, None, current_position)
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð²Ñ‹Ñ…Ð¾Ð´Ñ‹
    print(f"âœ… Energy value: {output.energy_value.shape}")
    print(f"âœ… Next position: {output.next_position.shape}")
    print(f"âœ… Spawn count: {output.spawn_count}")
    print(f"âœ… Spawn energies: {len(output.spawn_energies)}")
    print(f"âœ… Hidden state: {new_hidden.shape}")
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ñ‹ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹
    energy_norm = torch.norm(output.energy_value, dim=-1).mean()
    print(f"ðŸ“Š Ð¡Ñ€ÐµÐ´Ð½ÑÑ Ð½Ð¾Ñ€Ð¼Ð° ÑÐ½ÐµÑ€Ð³Ð¸Ð¸: {energy_norm:.4f}")
    
    pos_delta = (output.next_position - current_position).abs().mean()
    print(f"ðŸ“Š Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ ÑÐ¼ÐµÑ‰ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸: {pos_delta:.4f}")
    
    return carrier, output

def test_energy_spawn_mechanism():
    """Ð¢ÐµÑÑ‚ Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼Ð° Ð¿Ð¾Ñ€Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²"""
    print("\n=== Ð¢ÐµÑÑ‚ Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼Ð° Ð¿Ð¾Ñ€Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð² ===")
    
    config = create_debug_config()
    # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð½Ð¸Ð·ÐºÐ¸Ð¹ Ð¿Ð¾Ñ€Ð¾Ð³ Ð´Ð»Ñ Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ ÑÐ¿Ð°Ð²Ð½Ð°
    config.spawn_threshold = 0.1
    config.max_spawn_per_step = 3
    set_energy_config(config)
    
    carrier = create_energy_carrier(config)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    carrier = carrier.to(device)
    
    batch_size = 2
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ "Ð²Ñ‹ÑÐ¾ÐºÐ¾ÑÐ½ÐµÑ€Ð³ÐµÑ‚Ð¸Ñ‡Ð½Ñ‹Ðµ" Ð²Ñ…Ð¾Ð´Ñ‹
    neuron_output = torch.ones(batch_size, config.neuron_output_dim, device=device) * 2.0
    embedding_part = torch.ones(batch_size, config.embedding_per_cell, device=device) * 1.5
    current_position = torch.tensor([[5, 5, 2], [3, 7, 1]], dtype=torch.float32, device=device)
    
    # ÐÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¾Ñ…Ð¾Ð´Ð¾Ð² Ð´Ð»Ñ Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½Ð¸Ñ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ
    hidden_state = carrier.init_hidden(batch_size, device)
    
    spawn_counts = []
    
    for step in range(5):
        with torch.no_grad():
            output, hidden_state = carrier(neuron_output, embedding_part, hidden_state, current_position)
        
        spawn_counts.append(output.spawn_count)
        
        if output.spawn_count > 0:
            print(f"âœ… Ð¨Ð°Ð³ {step}: ÑÐ¾Ð·Ð´Ð°Ð½Ð¾ {output.spawn_count} Ð½Ð¾Ð²Ñ‹Ñ… Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²")
            print(f"   ðŸ“ Ð­Ð½ÐµÑ€Ð³Ð¸Ð¸ Ð´Ð»Ñ ÑÐ¿Ð°Ð²Ð½Ð°: {len(output.spawn_energies)}")
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸
            for i, energy in enumerate(output.spawn_energies):
                energy_norm = torch.norm(energy).item()
                print(f"   ðŸ”‹ Ð¡Ð¿Ð°Ð²Ð½ {i}: Ð½Ð¾Ñ€Ð¼Ð° ÑÐ½ÐµÑ€Ð³Ð¸Ð¸ = {energy_norm:.4f}")
        else:
            print(f"âšª Ð¨Ð°Ð³ {step}: ÑÐ¿Ð°Ð²Ð½Ð° Ð½ÐµÑ‚")
        
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ Ð´Ð»Ñ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ ÑˆÐ°Ð³Ð°
        current_position = output.next_position
    
    total_spawns = sum(spawn_counts)
    print(f"ðŸ“Š Ð’ÑÐµÐ³Ð¾ ÑÐ¾Ð·Ð´Ð°Ð½Ð¾ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð² Ð·Ð° 5 ÑˆÐ°Ð³Ð¾Ð²: {total_spawns}")
    
    return spawn_counts

def test_energy_threshold_check():
    """Ð¢ÐµÑÑ‚ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÑƒÑ€Ð¾Ð²Ð½Ñ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸"""
    print("\n=== Ð¢ÐµÑÑ‚ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÑƒÑ€Ð¾Ð²Ð½Ñ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸ ===")
    
    config = create_debug_config()
    carrier = create_energy_carrier(config)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    carrier = carrier.to(device)
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸ Ñ€Ð°Ð·Ð½Ñ‹Ñ… ÑƒÑ€Ð¾Ð²Ð½ÐµÐ¹
    high_energy = torch.ones(1, config.embedding_per_cell, device=device) * 2.0
    low_energy = torch.ones(1, config.embedding_per_cell, device=device) * 0.01
    zero_energy = torch.zeros(1, config.embedding_per_cell, device=device)
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¶Ð¸Ð·Ð½ÐµÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚ÑŒ
    with torch.no_grad():
        high_alive = carrier.check_energy_level(high_energy)
        low_alive = carrier.check_energy_level(low_energy)
        zero_alive = carrier.check_energy_level(zero_energy)
    
    print(f"ðŸ”‹ Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ ÑÐ½ÐµÑ€Ð³Ð¸Ñ (Ð½Ð¾Ñ€Ð¼Ð°={torch.norm(high_energy):.4f}): Ð¶Ð¸Ð² = {high_alive[0]}")
    print(f"ðŸª« ÐÐ¸Ð·ÐºÐ°Ñ ÑÐ½ÐµÑ€Ð³Ð¸Ñ (Ð½Ð¾Ñ€Ð¼Ð°={torch.norm(low_energy):.4f}): Ð¶Ð¸Ð² = {low_alive[0]}")
    print(f"ðŸ’€ ÐÑƒÐ»ÐµÐ²Ð°Ñ ÑÐ½ÐµÑ€Ð³Ð¸Ñ (Ð½Ð¾Ñ€Ð¼Ð°={torch.norm(zero_energy):.4f}): Ð¶Ð¸Ð² = {zero_alive[0]}")
    
    print(f"ðŸ“Š ÐŸÐ¾Ñ€Ð¾Ð³ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸: {config.energy_threshold}")
    
    return high_alive, low_alive, zero_alive

def test_position_constraints():
    """Ð¢ÐµÑÑ‚ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ð¹ Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ñ"""
    print("\n=== Ð¢ÐµÑÑ‚ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ð¹ Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ñ ===")
    
    config = create_debug_config()
    carrier = create_energy_carrier(config)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    carrier = carrier.to(device)
    
    # Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ Ð½Ð° Ð³Ñ€Ð°Ð½Ð¸Ñ†Ð°Ñ… Ñ€ÐµÑˆÐµÑ‚ÐºÐ¸
    test_positions = torch.tensor([
        [0, 0, 0],  # Ð›ÐµÐ²Ñ‹Ð¹ Ð½Ð¸Ð¶Ð½Ð¸Ð¹ ÑƒÐ³Ð¾Ð»
        [config.lattice_width-1, config.lattice_height-1, config.lattice_depth-2],  # ÐŸÑ€Ð°Ð²Ñ‹Ð¹ Ð²ÐµÑ€Ñ…Ð½Ð¸Ð¹
        [config.lattice_width//2, config.lattice_height//2, config.lattice_depth//2],  # Ð¦ÐµÐ½Ñ‚Ñ€
    ], dtype=torch.float32, device=device)
    
    batch_size = test_positions.shape[0]
    neuron_output = torch.randn(batch_size, config.neuron_output_dim, device=device)
    embedding_part = torch.randn(batch_size, config.embedding_per_cell, device=device)
    
    with torch.no_grad():
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð´Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
        combined_input = torch.cat([neuron_output, embedding_part], dim=-1).unsqueeze(1)
        gru_output, _ = carrier.gru(combined_input, None)
        gru_output = gru_output.squeeze(1)
        raw_predictions = carrier.position_projection(gru_output)
        
        output, _ = carrier(neuron_output, embedding_part, None, test_positions)
    
    print(f"ðŸ“ Ð˜ÑÑ…Ð¾Ð´Ð½Ñ‹Ðµ pozÐ¸Ñ†Ð¸Ð¸:")
    for i, pos in enumerate(test_positions):
        print(f"   {i}: {pos.cpu().numpy()}")
    
    print(f"ðŸ“ Ð¡Ñ‹Ñ€Ñ‹Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸:")
    for i, pos in enumerate(raw_predictions):
        print(f"   {i}: {pos.cpu().numpy()}")
    
    print(f"ðŸ“ Ð¡Ð»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ (Ð¿Ð¾ÑÐ»Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸):")
    for i, pos in enumerate(output.next_position):
        print(f"   {i}: {pos.cpu().numpy()}")
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Z ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ð° Ð²ÑÐµÐ³Ð´Ð° ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ð²Ð°ÐµÑ‚ÑÑ
    z_increases = output.next_position[:, 2] > test_positions[:, 2]
    print(f"âœ… Z ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ð° ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ð»Ð°ÑÑŒ Ð²Ð¾ Ð²ÑÐµÑ… ÑÐ»ÑƒÑ‡Ð°ÑÑ…: {z_increases.all()}")
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð³Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ Ñ€ÐµÑˆÐµÑ‚ÐºÐ¸
    within_bounds = (
        (output.next_position[:, 0] >= 0) & (output.next_position[:, 0] < config.lattice_width) &
        (output.next_position[:, 1] >= 0) & (output.next_position[:, 1] < config.lattice_height) &
        (output.next_position[:, 2] >= 0) & (output.next_position[:, 2] < config.lattice_depth)
    )
    print(f"âœ… Ð’ÑÐµ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ Ð² Ð³Ñ€Ð°Ð½Ð¸Ñ†Ð°Ñ… Ñ€ÐµÑˆÐµÑ‚ÐºÐ¸: {within_bounds.all()}")
    
    return output.next_position

def main():
    """Ð—Ð°Ð¿ÑƒÑÐº Ð²ÑÐµÑ… Ñ‚ÐµÑÑ‚Ð¾Ð²"""
    print("ðŸ§ª Ð—Ð°Ð¿ÑƒÑÐº Ñ‚ÐµÑÑ‚Ð¾Ð² Ð´Ð»Ñ EnergyCarrier")
    print("=" * 50)
    
    try:
        # Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ñ‚ÐµÑÑ‚Ñ‹
        carrier = test_energy_carrier_init()
        carrier, output = test_energy_carrier_forward()
        
        # Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ‚ÐµÑÑ‚Ñ‹
        spawn_counts = test_energy_spawn_mechanism()
        alive_states = test_energy_threshold_check()
        positions = test_position_constraints()
        
        print("\n" + "=" * 50)
        print("âœ… Ð’ÑÐµ Ñ‚ÐµÑÑ‚Ñ‹ EnergyCarrier Ð¿Ñ€Ð¾ÑˆÐ»Ð¸ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾!")
        print(f"ðŸ“Š Ð£ÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾: {next(carrier.parameters()).device}")
        
        # Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
        total_params = sum(p.numel() for p in carrier.parameters())
        print(f"ðŸ“Š ÐžÐ±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²: {total_params:,}")
        print(f"ðŸ“Š ÐžÐ±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð² Ð² Ñ‚ÐµÑÑ‚Ð°Ñ…: {sum(spawn_counts)}")
        
    except Exception as e:
        print(f"\nâŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² Ñ‚ÐµÑÑ‚Ð°Ñ…: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)