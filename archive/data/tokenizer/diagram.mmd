graph TD
    %% Tokenizer Module Architecture - 3D Cellular Neural Network
    %% Enhanced Mermaid diagram following @instructions.md guidelines
    
    subgraph "üéØ INPUT LAYER"
        TXT["Text Input<br/>Hello world!"]
        BTXT["Batch Texts<br/>Multiple texts"]
        USER_EVENTS[("üë§ User Events<br/>‚Ä¢ text_input<br/>‚Ä¢ batch_submit")]
    end
    
    subgraph "üìù TEXT PROCESSING LAYER"
        TP["TextProcessor<br/>‚Ä¢ normalize_unicode()<br/>‚Ä¢ clean_text()<br/>‚Ä¢ remove_punctuation()"]
        TXT --> TP
        BTXT --> TP
        USER_EVENTS -.->|"on_text_input"| TP
    end
    
    subgraph "üîß TOKENIZER MANAGER LAYER"
        TM["TokenizerManager<br/>‚Ä¢ encode()<br/>‚Ä¢ decode()<br/>‚Ä¢ tokenize()<br/>‚Ä¢ batch_encode()"]
        CONFIG["YAML Config<br/>‚Ä¢ tokenizer_type<br/>‚Ä¢ max_length<br/>‚Ä¢ padding"]
        
        TP --> TM
        CONFIG --> TM
    end
    
    subgraph "üèóÔ∏è ADAPTER FACTORY LAYER"
        FACTORY["TokenizerFactory<br/>create_adapter()"]
        TM --> FACTORY
    end
    
    subgraph "üîå TOKENIZER ADAPTERS LAYER"
        BERT["BertTokenizerAdapter<br/>‚Ä¢ huggingface/bert<br/>‚Ä¢ CLS, SEP tokens<br/>‚Ä¢ subword tokenization"]
        GPT["GPTTokenizerAdapter<br/>‚Ä¢ gpt2/gpt2-medium<br/>‚Ä¢ BPE encoding<br/>‚Ä¢ byte-level"]
        SP["SentencePieceAdapter<br/>‚Ä¢ custom models<br/>‚Ä¢ subword units<br/>‚Ä¢ multilingual"]
        BASIC["BasicTokenizerAdapter<br/>‚Ä¢ whitespace split<br/>‚Ä¢ punctuation handling<br/>‚Ä¢ simple fallback"]
        
        FACTORY --> BERT
        FACTORY --> GPT
        FACTORY --> SP
        FACTORY --> BASIC
    end
    
    subgraph "üíæ CACHING LAYER"
        CACHE["TokenCache<br/>‚Ä¢ LRU eviction<br/>‚Ä¢ configurable TTL<br/>‚Ä¢ memory efficient"]
        CACHE_EVENTS[("üîÑ Cache Events<br/>‚Ä¢ cache_hit<br/>‚Ä¢ cache_miss<br/>‚Ä¢ cache_evict")]
        
        BERT --> CACHE
        GPT --> CACHE
        SP --> CACHE
        BASIC --> CACHE
        CACHE -.->|"cache_events"| CACHE_EVENTS
    end
    
    subgraph "üöÄ OUTPUT PROCESSING LAYER"
        TOKENS["Token IDs<br/>[101, 7592, 2088, 102]"]
        BATCH_TOKENS["Batch Token IDs<br/>Multiple sequences"]
        OUTPUT_EVENTS[("üì§ Output Events<br/>‚Ä¢ tokens_ready<br/>‚Ä¢ batch_complete")]
        
        CACHE --> TOKENS
        CACHE --> BATCH_TOKENS
        TOKENS -.->|"tokens_ready"| OUTPUT_EVENTS
        BATCH_TOKENS -.->|"batch_complete"| OUTPUT_EVENTS
    end
    
    subgraph "üîó INTEGRATION LAYER"
        EMBED["EmbeddingLoader<br/>Integration"]
        LATTICE["Lattice3D<br/>Input Preparation"]
        INTEGRATION_EVENTS[("üîÑ Integration Events<br/>‚Ä¢ embed_request<br/>‚Ä¢ lattice_prepare")]
        
        TOKENS --> EMBED
        BATCH_TOKENS --> LATTICE
        EMBED -.->|"embed_request"| INTEGRATION_EVENTS
        LATTICE -.->|"lattice_prepare"| INTEGRATION_EVENTS
    end
    
    %% Special handling flows with DOM-like events
    subgraph "‚ö†Ô∏è SPECIAL HANDLING LAYER"
        OOV["OOV Tokens<br/>Out-of-Vocabulary"]
        SPECIAL["Special Tokens<br/>CLS, SEP, PAD"]
        TRUNCATE["Truncation<br/>Max Length Handling"]
        ERROR_EVENTS[("‚ö†Ô∏è Error Events<br/>‚Ä¢ oov_detected<br/>‚Ä¢ truncation_needed")]
        
        TM --> OOV
        TM --> SPECIAL
        TM --> TRUNCATE
        OOV -.->|"oov_detected"| ERROR_EVENTS
        TRUNCATE -.->|"truncation_needed"| ERROR_EVENTS
    end
    
    %% Error handling with event flows
    subgraph "üõ°Ô∏è ERROR HANDLING LAYER"
        FALLBACK["Fallback to Basic<br/>if model fails"]
        VALIDATION["Input Validation<br/>‚Ä¢ type checking<br/>‚Ä¢ length limits"]
        ERROR_HANDLER[("üö® Error Handler<br/>‚Ä¢ model_failure<br/>‚Ä¢ validation_error")]
        
        FACTORY --> FALLBACK
        TM --> VALIDATION
        FALLBACK -.->|"model_failure"| ERROR_HANDLER
        VALIDATION -.->|"validation_error"| ERROR_HANDLER
    end
    
    %% Performance monitoring with metrics events
    subgraph "üìä PERFORMANCE MONITORING"
        METRICS["Performance Metrics<br/>‚Ä¢ tokens/sec<br/>‚Ä¢ memory usage<br/>‚Ä¢ cache hit rate"]
        PERF_EVENTS[("üìà Performance Events<br/>‚Ä¢ metrics_update<br/>‚Ä¢ threshold_exceeded")]
        
        CACHE --> METRICS
        TM --> METRICS
        METRICS -.->|"metrics_update"| PERF_EVENTS
    end
    
    %% User Interaction Sequence (Numbered Steps)
    subgraph "üë§ USER SEQUENCE"
        STEP1["1. User inputs text"]
        STEP2["2. Text preprocessing"]
        STEP3["3. Tokenizer selection"]
        STEP4["4. Token generation"]
        STEP5["5. Cache storage"]
        STEP6["6. Output delivery"]
        
        STEP1 --> STEP2
        STEP2 --> STEP3
        STEP3 --> STEP4
        STEP4 --> STEP5
        STEP5 --> STEP6
    end
    
    %% Critical paths with bold styling
    TXT ==>|"CRITICAL PATH"| TM
    TM ==>|"CRITICAL PATH"| TOKENS
    TOKENS ==>|"CRITICAL PATH"| EMBED
    
    %% Enhanced data flow styles
    classDef inputClass fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef processingClass fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef adapterClass fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
    classDef outputClass fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef integrationClass fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    classDef errorClass fill:#ffebee,stroke:#b71c1c,stroke-width:2px
    classDef eventClass fill:#f1f8e9,stroke:#33691e,stroke-width:1px,stroke-dasharray: 5 5
    classDef criticalClass fill:#ffcdd2,stroke:#d32f2f,stroke-width:3px
    
    class TXT,BTXT inputClass
    class TP,TM,FACTORY processingClass
    class BERT,GPT,SP,BASIC adapterClass
    class TOKENS,BATCH_TOKENS outputClass
    class EMBED,LATTICE integrationClass
    class FALLBACK,VALIDATION,OOV,SPECIAL,TRUNCATE errorClass
    class USER_EVENTS,CACHE_EVENTS,OUTPUT_EVENTS,INTEGRATION_EVENTS,ERROR_EVENTS,PERF_EVENTS eventClass
    class STEP1,STEP2,STEP3,STEP4,STEP5,STEP6 criticalClass 