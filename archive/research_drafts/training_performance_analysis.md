# üìä Training Performance Analysis

–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—É—á–µ–Ω–∏—è 3D –∫–ª–µ—Ç–æ—á–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏

## üéØ –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è–Ω–∏—è

### 1. üöÄ Batch Size

**–í–ª–∏—è–Ω–∏–µ –Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å:**

- ‚úÖ **–ë–æ–ª—å—à–∏–π batch = –±—ã—Å—Ç—Ä–µ–µ –æ–±—É—á–µ–Ω–∏–µ** (–º–µ–Ω—å—à–µ –∏—Ç–µ—Ä–∞—Ü–∏–π –Ω–∞ —ç–ø–æ—Ö—É)
- ‚úÖ –õ—É—á—à–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU/–≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
- ‚ùå –ù–æ –µ—Å—Ç—å –ø—Ä–µ–¥–µ–ª –ø–æ—Å–ª–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –ø—Ä–∏—Ä–æ—Å—Ç –º–∏–Ω–∏–º–∞–ª–µ–Ω

**–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ø–∞–º—è—Ç—å:**

- ‚ùå **–ö–≤–∞–¥—Ä–∞—Ç–∏—á–Ω—ã–π —Ä–æ—Å—Ç –ø–∞–º—è—Ç–∏** —Å —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º batch size
- GPU memory = batch_size √ó embedding_dim √ó lattice_neurons
- –ü—Ä–∏–º–µ—Ä: batch=128 vs batch=32 = 4x –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏

**–í–ª–∏—è–Ω–∏–µ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ:**

- üìà –ú–∞–ª—ã–µ batch (16-32): –ª—É—á—à–µ –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è, –±–æ–ª–µ–µ —à—É–º–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç
- üìâ –ë–æ–ª—å—à–∏–µ batch (128+): –º–æ–∂–µ—Ç –∑–∞—Å—Ç—Ä–µ–≤–∞—Ç—å –≤ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–∞—Ö
- üéØ **–û–ø—Ç–∏–º—É–º: 32-64** –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∑–∞–¥–∞—á

### 2. üíæ Dataset Size

**–ü–∞–º—è—Ç—å –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:**

- ‚úÖ **–ü–æ—á—Ç–∏ –Ω–µ –≤–ª–∏—è–µ—Ç** - DataLoader –∑–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ batch-–∞–º
- –¢–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã–π batch –≤ –ø–∞–º—è—Ç–∏

**–ü–∞–º—è—Ç—å –Ω–∞ –¥–∏—Å–∫–µ:**

- ‚ùå **–ü—Ä—è–º–æ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–∞** —Ä–∞–∑–º–µ—Ä—É –¥–∞—Ç–∞—Å–µ—Ç–∞
- SNLI 109k –ø—Ä–∏–º–µ—Ä–æ–≤ = 643 MB precomputed embeddings
- –ü–æ–ª–Ω—ã–π SNLI 549k –ø—Ä–∏–º–µ—Ä–æ–≤ ‚âà 3.2 GB

**–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:**

- ‚ùå **–õ–∏–Ω–µ–π–Ω–æ —Ä–∞—Å—Ç–µ—Ç** —Å —Ä–∞–∑–º–µ—Ä–æ–º –¥–∞—Ç–∞—Å–µ—Ç–∞
- 1000 –ø—Ä–∏–º–µ—Ä–æ–≤ ‚âà 2 –º–∏–Ω—É—Ç—ã
- 10000 –ø—Ä–∏–º–µ—Ä–æ–≤ ‚âà 20 –º–∏–Ω—É—Ç
- 50000 –ø—Ä–∏–º–µ—Ä–æ–≤ ‚âà 100 –º–∏–Ω—É—Ç

### 3. üß† Lattice Dimensions

**–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ø–∞–º—è—Ç—å:**

- ‚ùå **–ö—É–±–∏—á–µ—Å–∫–∏–π —Ä–æ—Å—Ç**: xs √ó ys √ó zs
- Small (10√ó10√ó10) = 1,000 neurons
- Medium (20√ó15√ó15) = 4,500 neurons
- Large (30√ó20√ó20) = 12,000 neurons

**–í–ª–∏—è–Ω–∏–µ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ:**

- üìà –ë–æ–ª—å—à–µ –Ω–µ–π—Ä–æ–Ω–æ–≤ = –±–æ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ = –±–æ–ª—å—à–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
- üìâ –ù–æ —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ –º–∞–ª—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö
- üéØ **–ü—Ä–∞–≤–∏–ª–æ**: neurons ‚âà dataset_size / 10

### 4. üìê Embedding Dimensions

**–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã:**

- sentence-transformers/all-MiniLM-L6-v2: **384** (–ª–µ–≥–∫–∏–π)
- sentence-transformers/all-mpnet-base-v2: **768** (—Å—Ç–∞–Ω–¥–∞—Ä—Ç)
- text-embedding-ada-002: **1536** (—Ç—è–∂–µ–ª—ã–π)

**–í–ª–∏—è–Ω–∏–µ:**

- üíæ –ü–∞–º—è—Ç—å: –ª–∏–Ω–µ–π–Ω–æ —Ä–∞—Å—Ç–µ—Ç —Å —Ä–∞–∑–º–µ—Ä–æ–º
- üéØ –ö–∞—á–µ—Å—Ç–≤–æ: –±–æ–ª—å—à–µ dimension = –ª—É—á—à–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
- ‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: –±–æ–ª—å—à–µ dimension = –º–µ–¥–ª–µ–Ω–Ω–µ–µ

### 5. üå°Ô∏è Learning Rate & Warm-up

**Learning Rate:**

- üéØ **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–µ–Ω** –¥–ª—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
- –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: divergence, NaN loss
- –°–ª–∏—à–∫–æ–º –º–∞–ª—ã–π: –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- **–û–ø—Ç–∏–º—É–º**: 1e-4 to 1e-3 –¥–ª—è AdamW

**Warm-up (–Ω–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è):**

- ‚úÖ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è** –ø—Ä–∏ resume
- üìà –≠–ø–æ—Ö–∏ 1-3: –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º LR –æ—Ç 20% –¥–æ 100%
- üõ°Ô∏è –ó–∞—â–∏—â–∞–µ—Ç –æ—Ç "–∑–∞–±—ã–≤–∞–Ω–∏—è" –≤–µ—Å–æ–≤ –ø—Ä–∏ resume

## üìà –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### üéÆ –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:

```bash
# –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
--mode development      # –ú–∞–ª–µ–Ω—å–∫–∞—è —Ä–µ—à–µ—Ç–∫–∞
--dataset-limit 1000    # –ë—ã—Å—Ç—Ä—ã–π –¥–∞—Ç–∞—Å–µ—Ç
--batch-size 64         # –•–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å
--additional-epochs 5   # –ö–æ—Ä–æ—Ç–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ
```

### üß™ –î–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤:

```bash
# –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
--mode research         # –°—Ä–µ–¥–Ω—è—è —Ä–µ—à–µ—Ç–∫–∞
--dataset-limit 5000    # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
--batch-size 32         # –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
--additional-epochs 15  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —ç–ø–æ—Ö
```

### üöÄ –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞:

```bash
# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
--mode production       # –ë–æ–ª—å—à–∞—è —Ä–µ—à–µ—Ç–∫–∞
--dataset-limit 50000   # –ú–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö
--batch-size 64         # –ö–æ–º–ø—Ä–æ–º–∏—Å—Å
--additional-epochs 30  # –î–æ–ª–≥–æ–µ –æ–±—É—á–µ–Ω–∏–µ
```

## ‚öñÔ∏è Memory vs Speed vs Quality

### Memory-Constrained (–º–∞–ª–æ RAM/GPU):

```
Lattice: development mode (small)
Batch Size: 16-32
Dataset: 1000-5000 examples
Embedding: 384-dim (MiniLM)
```

### Speed-Focused (–±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ):

```
Lattice: development mode
Batch Size: 128 (–µ—Å–ª–∏ –≤–ª–µ–∑–∞–µ—Ç)
Dataset: 2000-5000 examples
Embedding: 384-dim
Epochs: 5-10
```

### Quality-Focused (–ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç):

```
Lattice: research/production mode
Batch Size: 32-64
Dataset: 20000-50000 examples
Embedding: 768-dim (mpnet)
Epochs: 20-50 with automated training
```

## üîß –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

### ü§ñ Automated Training:

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é:

**Stage 1: Foundation** (–±—ã—Å—Ç—Ä–æ–µ –∏–∑—É—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤)

- Small dataset, many epochs
- Focus –Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

**Stage 2-3: Consolidation** (–∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∑–Ω–∞–Ω–∏–π)

- Medium dataset, balanced epochs
- Focus –Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ

**Stage 4-5: Mastery** (—Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø–æ–ª–∏—Ä–æ–≤–∫–∞)

- Large dataset, few epochs
- Focus –Ω–∞ –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—é –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### üìä Smart Resume:

- ‚úÖ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π warm-up** –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ checkpoint
- üéØ **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π** –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- üîÑ **–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π learning rate** –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

## üö® –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –∏ –ª–∏–º–∏—Ç—ã

### Memory Limits:

```
Windows 32GB RAM:
- Max batch size ‚âà 128-256 (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç lattice)
- Max dataset ‚âà 100k examples (–≤ –ø–∞–º—è—Ç–∏ –ø–æ batch-–∞–º)
- Max lattice ‚âà 50√ó30√ó30 neurons

GPU 8GB VRAM:
- Max batch size ‚âà 64-128
- Embedding dim ‚â§ 768 recommended
```

### Performance Bottlenecks:

```
–ì–ª–∞–≤–Ω—ã–µ —É–∑–∫–∏–µ –º–µ—Å—Ç–∞:
1. Lattice size (cubic growth)
2. Embedding forward pass
3. Surface projection operations
4. Loss computation and backprop

–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:
- Gradient clipping (max_norm=1.0)
- Memory cleanup –∫–∞–∂–¥—ã–µ 10 —ç–ø–æ—Ö
- Mixed precision (–±—É–¥—É—â–∞—è —Ñ–∏—á–∞)
```

## üìã Checklist –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

### –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º:

- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω—É—é –ø–∞–º—è—Ç—å (RAM/GPU)
- [ ] –í—ã–±—Ä–∞—Ç—å —Ä–µ–∂–∏–º –ø–æ–¥ —Ä–∞–∑–º–µ—Ä —Ä–µ—à–µ—Ç–∫–∏
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å batch size –ø–æ–¥ –ø–∞–º—è—Ç—å
- [ ] –û—Ü–µ–Ω–∏—Ç—å –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è

### –í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:

- [ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å loss –∏ similarity
- [ ] –°–ª–µ–¥–∏—Ç—å –∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–∞–º—è—Ç–∏
- [ ] –ü—Ä–æ–≤–µ—Ä—è—Ç—å warm-up –ª–æ–≥–∏ –ø—Ä–∏ resume
- [ ] –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è:

- [ ] –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å final vs best similarity
- [ ] –ü—Ä–æ–≤–µ—Ä—è—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ checkpoints
- [ ] –ü–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

---

**üéØ –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–Ω—Ü–∏–ø:** –ù–∞—á–∏–Ω–∞—Ç—å —Å –º–∞–ª–æ–≥–æ, –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é –¥–ª—è –¥–æ–ª–≥–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è!
