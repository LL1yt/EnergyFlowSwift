#!/usr/bin/env python3
"""
DEPRECATED: GNN Cell - –∑–∞–º–µ–Ω–∞ gMLP –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏
=================================================================

üö® –£–°–¢–ê–†–ï–õ: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `new_rebuild.core.cells.vectorized_gnn_cell.VectorizedGNNCell` –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏!

–ó–ê–ú–ï–ù–ï–ù –ù–ê: `vectorized_gnn_cell.py`
–ü–†–ò–ß–ò–ù–ê: `VectorizedGNNCell` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏, —á—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–µ–µ.
DEPRECATED —Å 27 –∏—é–Ω—è 2025. –ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω –≤ –≤–µ—Ä—Å–∏–∏ 2.0.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, Dict, Any, Tuple

from .base_cell import BaseCell
from ...config import get_project_config
from ...utils.logging import (
    get_logger,
    log_cell_init,
    log_cell_forward,
    log_cell_component_params,
)

logger = get_logger(__name__)


class MessageNetwork(nn.Module):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-–∑–∞–≤–∏—Å–∏–º—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –º–µ–∂–¥—É –∫–ª–µ—Ç–∫–∞–º–∏

    –ö–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–π –û–ë–ï–ò–• —Å—Ç–æ—Ä–æ–Ω:
    sender_state + receiver_state ‚Üí meaningful_message
    """

    def __init__(self, state_size: int, message_dim: int, hidden_dim: int):
        super().__init__()

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –∏ –ø–æ–ª—É—á–∞—Ç–µ–ª—è
        combined_size = state_size * 2  # sender + receiver

        self.message_creator = nn.Sequential(
            nn.Linear(combined_size, hidden_dim, bias=True),
            nn.GELU(),
            nn.Linear(hidden_dim, message_dim, bias=True),
        )

    def forward(
        self, sender_state: torch.Tensor, receiver_state: torch.Tensor
    ) -> torch.Tensor:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –∫ –ø–æ–ª—É—á–∞—Ç–µ–ª—é

        Args:
            sender_state: [batch, state_size] - —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è
            receiver_state: [batch, state_size] - —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—É—á–∞—Ç–µ–ª—è

        Returns:
            message: [batch, message_dim] - –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        """
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        combined = torch.cat([sender_state, receiver_state], dim=-1)
        message = self.message_creator(combined)
        return message


class AttentionAggregator(nn.Module):
    """
    Attention mechanism –¥–ª—è —Å–µ–ª–µ–∫—Ç–∏–≤–Ω–æ–π –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π

    –ö–ª–µ—Ç–∫–∞ "–≤—ã–±–∏—Ä–∞–µ—Ç" –Ω–∞ –∫–∞–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ
    ‚Üí —ç–º–µ—Ä–¥–∂–µ–Ω—Ç–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç —Å–µ–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è
    """

    def __init__(self, message_dim: int, state_size: int):
        super().__init__()

        # Attention weights –∑–∞–≤–∏—Å—è—Ç –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∫–ª–µ—Ç–∫–∏
        self.attention_network = nn.Sequential(
            nn.Linear(message_dim + state_size, message_dim, bias=True),
            nn.Tanh(),
            nn.Linear(message_dim, 1, bias=True),
        )

    def forward(
        self, messages: torch.Tensor, receiver_state: torch.Tensor
    ) -> torch.Tensor:
        """
        –°–µ–ª–µ–∫—Ç–∏–≤–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π —á–µ—Ä–µ–∑ attention

        Args:
            messages: [batch, num_neighbors, message_dim] - –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            receiver_state: [batch, state_size] - —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—É—á–∞—Ç–µ–ª—è

        Returns:
            aggregated: [batch, message_dim] - –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        """
        batch_size, num_neighbors, message_dim = messages.shape

        # –†–∞—Å—à–∏—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—É—á–∞—Ç–µ–ª—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        receiver_expanded = receiver_state.unsqueeze(1).expand(-1, num_neighbors, -1)

        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –¥–ª—è attention
        attention_input = torch.cat([messages, receiver_expanded], dim=-1)

        # –í—ã—á–∏—Å–ª—è–µ–º attention weights
        attention_logits = self.attention_network(
            attention_input
        )  # [batch, num_neighbors, 1]
        attention_weights = F.softmax(
            attention_logits, dim=1
        )  # [batch, num_neighbors, 1]

        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
        aggregated = torch.sum(
            messages * attention_weights, dim=1
        )  # [batch, message_dim]

        return aggregated


class StateUpdater(nn.Module):
    """
    GRU-style –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç gates –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
    ‚Üí –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –≤–∑—Ä—ã–≤—ã –∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
    """

    def __init__(self, state_size: int, message_dim: int, external_input_size: int):
        super().__init__()

        input_size = message_dim + external_input_size

        # Update gate: "–Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ"
        self.update_gate = nn.Linear(state_size + input_size, state_size, bias=True)

        # Reset gate: "—á—Ç–æ –∑–∞–±—ã—Ç—å –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è"
        self.reset_gate = nn.Linear(state_size + input_size, state_size, bias=True)

        # Candidate state: "–Ω–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"
        self.candidate_network = nn.Linear(
            state_size + input_size, state_size, bias=True
        )

    def forward(
        self,
        current_state: torch.Tensor,
        aggregated_message: torch.Tensor,
        external_input: torch.Tensor,
    ) -> torch.Tensor:
        """
        –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —á–µ—Ä–µ–∑ GRU-style gates

        Args:
            current_state: [batch, state_size] - —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            aggregated_message: [batch, message_dim] - –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            external_input: [batch, external_input_size] - –≤–Ω–µ—à–Ω–∏–π –≤—Ö–æ–¥

        Returns:
            new_state: [batch, state_size] - –Ω–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        """
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –≤—Å–µ –≤—Ö–æ–¥—ã
        combined_input = torch.cat([aggregated_message, external_input], dim=-1)
        full_input = torch.cat([current_state, combined_input], dim=-1)

        # –í—ã—á–∏—Å–ª—è–µ–º gates
        update = torch.sigmoid(self.update_gate(full_input))
        reset = torch.sigmoid(self.reset_gate(full_input))

        # Candidate state —Å reset gate
        reset_state = reset * current_state
        candidate_input = torch.cat([reset_state, combined_input], dim=-1)
        candidate = torch.tanh(self.candidate_network(candidate_input))

        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        new_state = (1 - update) * current_state + update * candidate

        return new_state


class GNNCell(BaseCell):
    """
    Graph Neural Network Cell –¥–ª—è —ç–º–µ—Ä–¥–∂–µ–Ω—Ç–Ω–æ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏

    –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
    1. MessageNetwork: —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-–∑–∞–≤–∏—Å–∏–º—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    2. AttentionAggregator: —Å–µ–ª–µ–∫—Ç–∏–≤–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
    3. StateUpdater: —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è

    –ü–†–ï–ò–ú–£–©–ï–°–¢–í–ê:
    - –ù–∞–º–Ω–æ–≥–æ –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —á–µ–º gMLP (8k vs 113k)
    - –ë–æ–≥–∞—Ç–∞—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    - –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å STDP –≤–µ—Å–∞–º–∏
    - –ë–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
    """

    def __init__(
        self,
        state_size: Optional[int] = None,
        neighbor_count: Optional[int] = None,
        message_dim: Optional[int] = None,
        hidden_dim: Optional[int] = None,
        external_input_size: Optional[int] = None,
        activation: Optional[str] = None,
        target_params: Optional[int] = None,
        use_attention: Optional[bool] = None,
        **kwargs,
    ):
        """
        GNN –∫–ª–µ—Ç–∫–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–µ–π

        Args:
            –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã - –±–µ—Ä—É—Ç—Å—è –∏–∑ ProjectConfig –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã
        """
        super().__init__()

        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config = get_project_config()
        gnn_config = config.get_gnn_config()

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã
        self.state_size = state_size or gnn_config["state_size"]
        self.neighbor_count = neighbor_count or gnn_config["neighbor_count"]
        self.message_dim = message_dim or gnn_config["message_dim"]
        self.hidden_dim = hidden_dim or gnn_config["hidden_dim"]
        self.external_input_size = (
            external_input_size or gnn_config["external_input_size"]
        )
        self.target_params = target_params or gnn_config["target_params"]
        self.use_attention = (
            use_attention if use_attention is not None else gnn_config["use_attention"]
        )

        # === GNN –ê–†–•–ò–¢–ï–ö–¢–£–†–ê ===

        # 1. Message Network - —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        self.message_network = MessageNetwork(
            state_size=self.state_size,
            message_dim=self.message_dim,
            hidden_dim=self.hidden_dim,
        )

        # 2. Aggregation - —Å–µ–ª–µ–∫—Ç–∏–≤–Ω–∞—è –∏–ª–∏ –ø—Ä–æ—Å—Ç–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è
        if self.use_attention:
            self.aggregator = AttentionAggregator(
                message_dim=self.message_dim,
                state_size=self.state_size,
            )
        else:
            # –ü—Ä–æ—Å—Ç–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Å—Ä–µ–¥–Ω–µ–µ
            self.aggregator = None

        # 3. State Update - —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.state_updater = StateUpdater(
            state_size=self.state_size,
            message_dim=self.message_dim,
            external_input_size=self.external_input_size,
        )

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if config.logging.debug_mode:
            self._log_parameter_count()

    def _log_parameter_count(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —á–µ—Ä–µ–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É"""
        total_params = sum(p.numel() for p in self.parameters())

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∫–ª–µ—Ç–æ–∫
        log_cell_init(
            cell_type="GNN",
            total_params=total_params,
            target_params=self.target_params,
            state_size=self.state_size,
            hidden_dim=self.hidden_dim,
            neighbor_count=self.neighbor_count,
            external_input_size=self.external_input_size,
            message_dim=self.message_dim,
            use_attention=self.use_attention,
        )

        # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º
        component_params = {}
        for name, param in self.named_parameters():
            component = name.split(".")[0] if "." in name else name
            if component not in component_params:
                component_params[component] = 0
            component_params[component] += param.numel()

        log_cell_component_params(component_params, total_params)

    def forward(
        self,
        neighbor_states: torch.Tensor,
        own_state: torch.Tensor,
        external_input: Optional[torch.Tensor] = None,
        connection_weights: Optional[torch.Tensor] = None,  # STDP –≤–µ—Å–∞
        flexible_neighbor_count: bool = False,  # NEW: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ—Å–µ–¥–µ–π
        **kwargs,
    ) -> torch.Tensor:
        """
        Forward pass —Å message passing

        Args:
            neighbor_states: [batch, neighbor_count, state_size] - —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ—Å–µ–¥–µ–π
            own_state: [batch, state_size] - —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            external_input: [batch, external_input_size] - –≤–Ω–µ—à–Ω–∏–π –≤—Ö–æ–¥
            connection_weights: [batch, neighbor_count] - STDP –≤–µ—Å–∞ –¥–ª—è –º–æ–¥—É–ª—è—Ü–∏–∏

        Returns:
            new_state: [batch, state_size] - –Ω–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        """
        batch_size = own_state.shape[0]
        device = own_state.device

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π neighbor_states
        if neighbor_states.dim() == 2:
            # [num_neighbors, state_size] -> [1, num_neighbors, state_size]
            neighbor_states = neighbor_states.unsqueeze(0)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ forward pass (—Ç–æ–ª—å–∫–æ –≤ debug —Ä–µ–∂–∏–º–µ)
        config = get_project_config()
        if config.logging.debug_mode:
            input_shapes = {
                "neighbor_states": neighbor_states.shape,
                "own_state": own_state.shape,
                "external_input": (
                    external_input.shape if external_input is not None else None
                ),
                "connection_weights": (
                    connection_weights.shape if connection_weights is not None else None
                ),
            }
            log_cell_forward("GNN", input_shapes)

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ external_input
        if external_input is None:
            external_input = torch.zeros(
                batch_size, self.external_input_size, device=device
            )
        elif external_input.shape[-1] != self.external_input_size:
            # –ê–¥–∞–ø—Ç–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ external_input –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if external_input.shape[-1] < self.external_input_size:
                padding = torch.zeros(
                    batch_size,
                    self.external_input_size - external_input.shape[-1],
                    device=device,
                )
                external_input = torch.cat([external_input, padding], dim=-1)
            else:
                external_input = external_input[:, : self.external_input_size]

        # === MESSAGE PASSING ===

        # 1. –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç –∫–∞–∂–¥–æ–≥–æ —Å–æ—Å–µ–¥–∞ –∫ —Ç–µ–∫—É—â–µ–π –∫–ª–µ—Ç–∫–µ
        messages = []
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π –µ—Å–ª–∏ flexible_neighbor_count=True
        actual_neighbor_count = (
            neighbor_states.shape[1] if flexible_neighbor_count else self.neighbor_count
        )

        for i in range(actual_neighbor_count):
            neighbor_state = neighbor_states[:, i, :]  # [batch, state_size]

            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-–∑–∞–≤–∏—Å–∏–º–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            message = self.message_network(neighbor_state, own_state)
            messages.append(message)

        messages = torch.stack(
            messages, dim=1
        )  # [batch, actual_neighbor_count, message_dim]

        # 2. –ú–æ–¥—É–ª—è—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π —á–µ—Ä–µ–∑ STDP –≤–µ—Å–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if connection_weights is not None:
            # connection_weights: [batch, actual_neighbor_count] ‚Üí [batch, actual_neighbor_count, 1]
            stdp_weights = connection_weights.unsqueeze(-1)
            messages = messages * stdp_weights

        # 3. –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
        if self.use_attention:
            # –°–µ–ª–µ–∫—Ç–∏–≤–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —á–µ—Ä–µ–∑ attention
            aggregated_message = self.aggregator(messages, own_state)
        else:
            # –ü—Ä–æ—Å—Ç–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Å—Ä–µ–¥–Ω–µ–µ
            aggregated_message = torch.mean(messages, dim=1)  # [batch, message_dim]

        # 4. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        new_state = self.state_updater(own_state, aggregated_message, external_input)

        return new_state

    def get_message_statistics(
        self,
        neighbor_states: torch.Tensor,
        own_state: torch.Tensor,
    ) -> Dict[str, torch.Tensor]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–º–µ—Ä–¥–∂–µ–Ω—Ç–Ω–æ—Å—Ç–∏

        Returns:
            Dict —Å –∫–ª—é—á–∞–º–∏:
            - message_diversity: —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π
            - attention_entropy: —ç–Ω—Ç—Ä–æ–ø–∏—è attention (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
            - message_magnitudes: –≤–µ–ª–∏—á–∏–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        with torch.no_grad():
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π
            messages = []
            for i in range(self.neighbor_count):
                neighbor_state = neighbor_states[:, i, :]
                message = self.message_network(neighbor_state, own_state)
                messages.append(message)

            messages = torch.stack(
                messages, dim=1
            )  # [batch, neighbor_count, message_dim]

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            stats = {
                "message_diversity": torch.std(messages, dim=1).mean(dim=-1),  # [batch]
                "message_magnitudes": torch.norm(
                    messages, dim=-1
                ),  # [batch, neighbor_count]
            }

            # Attention entropy –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
            if self.use_attention:
                # –ü–æ–≤—Ç–æ—Ä–Ω–æ –≤—ã—á–∏—Å–ª—è–µ–º attention –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                batch_size, num_neighbors, message_dim = messages.shape
                receiver_expanded = own_state.unsqueeze(1).expand(-1, num_neighbors, -1)
                attention_input = torch.cat([messages, receiver_expanded], dim=-1)
                attention_logits = self.aggregator.attention_network(
                    attention_input
                ).squeeze(-1)
                attention_weights = F.softmax(attention_logits, dim=1)

                # Entropy: -sum(p * log(p))
                attention_entropy = -torch.sum(
                    attention_weights * torch.log(attention_weights + 1e-8), dim=1
                )
                stats["attention_entropy"] = attention_entropy

            return stats
