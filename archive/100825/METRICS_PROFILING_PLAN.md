# üìä Metrics & Profiling System - –î–µ—Ç–∞–ª—å–Ω—ã–π –ü–ª–∞–Ω –†–µ–∞–ª–∏–∑–∞—Ü–∏–∏

## üéØ **–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã**

- **–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π overhead** - –º–µ—Ç—Ä–∏–∫–∏ –Ω–µ –¥–æ–ª–∂–Ω—ã –∑–∞–º–µ–¥–ª—è—Ç—å –æ–±—É—á–µ–Ω–∏–µ 
- **–õ–µ–≥–∫–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ** - –ø—Ä–æ—Å—Ç—ã–µ boolean —Ñ–ª–∞–≥–∏ –≤ –∫–æ–Ω—Ñ–∏–≥–µ
- **–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è** - –≤—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è** - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å DEBUG_PERFORMANCE/DEBUG_PROFILING
- **–ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** - –æ—Ç–¥–µ–ª—å–Ω—ã–π –º–æ–¥—É–ª—å, –Ω–µ –≤–ª–∏—è—é—â–∏–π –Ω–∞ core –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

## üèóÔ∏è **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥—É–ª—è**

```
energy_flow/
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ metrics/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ collector.py      # MetricsCollector - —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —Å–±–æ—Ä –º–µ—Ç—Ä–∏–∫
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ profiler.py       # ProfilerManager - torch.profiler integration  
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gpu_monitor.py    # GPUMonitor - lightweight GPU tracking
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py         # MetricsConfig - –≤—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–µ—Ç—Ä–∏–∫
‚îÇ   ‚îî‚îÄ‚îÄ logging.py           # –°—É—â–µ—Å—Ç–≤—É—é—â–∞—è —Å–∏—Å—Ç–µ–º–∞ (—Ä–∞—Å—à–∏—Ä–∏–º –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
```

## üìã **1. MetricsConfig - –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è**

**–§–∞–π–ª**: `energy_flow/utils/metrics/config.py`

```python
@dataclass
class MetricsConfig:
    # === MASTER SWITCHES ===
    enable_metrics: bool = False          # –ì–ª–∞–≤–Ω—ã–π –≤—ã–∫–ª—é—á–∞—Ç–µ–ª—å –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫
    enable_profiler: bool = False         # PyTorch Profiler (—Ç—è–∂–µ–ª—ã–π)
    enable_gpu_monitoring: bool = False   # GPU utilization tracking
    
    # === LIGHTWEIGHT METRICS ===
    collect_timing: bool = True           # –ë–∞–∑–æ–≤—ã–µ timing –º–µ—Ç—Ä–∏–∫–∏ (–ø–æ—á—Ç–∏ –±–µ—Å–ø–ª–∞—Ç–Ω–æ)
    collect_throughput: bool = True       # samples/sec, flows/sec (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π overhead)
    collect_memory_basic: bool = True     # torch.cuda.memory_allocated() —Ç–æ–ª—å–∫–æ
    
    # === ADVANCED METRICS (–±–æ–ª—å—à–∏–π overhead) ===
    collect_gpu_utilization: bool = False     # –¢—Ä–µ–±—É–µ—Ç nvidia-ml-py3 –∏–ª–∏ polling
    collect_memory_detailed: bool = False     # Fragmentation, peak usage
    collect_component_profiling: bool = False # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    
    # === PROFILER SETTINGS ===
    profiler_record_shapes: bool = False      # –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä traces
    profiler_profile_memory: bool = False     # Memory profiling (–æ—á–µ–Ω—å —Ç—è–∂–µ–ª—ã–π)
    profiler_with_stack: bool = False         # Stack traces (—Ç—è–∂–µ–ª—ã–π)
    profiler_export_interval: int = 1000      # –≠–∫—Å–ø–æ—Ä—Ç –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤
    profiler_trace_dir: str = "traces"        # –ü–∞–ø–∫–∞ –¥–ª—è Chrome traces
    
    # === COLLECTION INTERVALS ===
    metrics_log_interval: int = 10           # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤  
    gpu_monitor_interval: float = 1.0        # GPU polling –∏–Ω—Ç–µ—Ä–≤–∞–ª (—Å–µ–∫—É–Ω–¥—ã)
    memory_cleanup_check_interval: int = 50  # –ü—Ä–æ–≤–µ—Ä–∫–∞ memory leaks
    
    # === AUTOMATIC CONTROLS ===
    auto_disable_on_slow: bool = True        # –ê–≤—Ç–æ–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –∑–∞–º–µ–¥–ª–µ–Ω–∏–∏ >5%
    performance_threshold: float = 0.05      # 5% overhead threshold
```

## üîß **2. MetricsCollector - –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —Å–±–æ—Ä**

**–§–∞–π–ª**: `energy_flow/utils/metrics/collector.py`

### –ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- **Thread-safe** collections —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º locking'–æ–º
- **Conditional collection** - –º–µ—Ç—Ä–∏–∫–∏ —Å–æ–±–∏—Ä–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã
- **Lightweight storage** - –∏—Å–ø–æ–ª—å–∑—É–µ–º deque —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
- **Integration —Å existing logging** - –∏—Å–ø–æ–ª—å–∑—É–µ–º DEBUG_PERFORMANCE —É—Ä–æ–≤–Ω–∏

```python
class MetricsCollector:
    def __init__(self, config: MetricsConfig):
        self.config = config
        self.enabled = config.enable_metrics
        
        # Lightweight storage (fixed size –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è memory leaks)
        self.timing_metrics = deque(maxlen=1000) if config.collect_timing else None
        self.throughput_metrics = deque(maxlen=1000) if config.collect_throughput else None
        self.memory_metrics = deque(maxlen=500) if config.collect_memory_basic else None
        
        # Thread safety —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        self._lock = threading.Lock() if config.enable_gpu_monitoring else None
        
    @contextmanager
    def time_component(self, component_name: str):
        \"\"\"Lightweight timing context manager\"\"\"
        if not self.config.collect_timing:
            yield  # No-op –µ—Å–ª–∏ timing –æ—Ç–∫–ª—é—á–µ–Ω
            return
            
        start_time = time.perf_counter()
        yield
        elapsed = time.perf_counter() - start_time
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ overhead –ø—Ä–∏–µ–º–ª–µ–º—ã–π
        if elapsed > 0.001:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º < 1ms –∏–∑–º–µ—Ä–µ–Ω–∏—è
            self.timing_metrics.append((component_name, elapsed, time.time()))
```

## ‚ö° **3. GPUMonitor - –õ–µ–≥–∫–æ–≤–µ—Å–Ω—ã–π GPU tracking**

**–§–∞–π–ª**: `energy_flow/utils/metrics/gpu_monitor.py`

### –°—Ç—Ä–∞—Ç–µ–≥–∏—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ overhead:
- **Polling –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º thread** —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
- **Graceful fallback** –µ—Å–ª–∏ nvidia-ml-py3 –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
- **Smart caching** - –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ä–∞–∑ –≤ —Å–µ–∫—É–Ω–¥—É –º–∞–∫—Å–∏–º—É–º

```python
class GPUMonitor:
    def __init__(self, config: MetricsConfig):
        self.enabled = config.enable_gpu_monitoring
        self.interval = config.gpu_monitor_interval
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        if self.enabled:
            self._init_monitoring()
        
    def _init_monitoring(self):
        \"\"\"Lazy initialization —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏\"\"\"
        try:
            import pynvml
            pynvml.nvmlInit()
            self.nvml_available = True
        except ImportError:
            self.nvml_available = False
            logger.log(DEBUG_PERFORMANCE, \"GPU monitoring: pynvml –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º torch fallback\")
    
    @property  
    def gpu_utilization(self) -> float:
        \"\"\"Cached GPU utilization —Å smart polling\"\"\"
        if not self.enabled:
            return 0.0
            
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º cached –∑–Ω–∞—á–µ–Ω–∏–µ –µ—Å–ª–∏ –ø—Ä–æ—à–ª–æ < interval —Å–µ–∫—É–Ω–¥
        now = time.time()
        if hasattr(self, '_last_poll') and now - self._last_poll < self.interval:
            return getattr(self, '_cached_utilization', 0.0)
            
        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ
        self._last_poll = now
        self._cached_utilization = self._poll_gpu_utilization()
        return self._cached_utilization
```

## üî¨ **4. ProfilerManager - torch.profiler integration**

**–§–∞–π–ª**: `energy_flow/utils/metrics/profiler.py`

### –£–º–Ω–æ–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ:
- **Context manager** –¥–ª—è easy integration
- **Conditional activation** - –ø—Ä–æ—Ñ–∏–ª–µ—Ä –≤–∫–ª—é—á–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ
- **Automatic export** —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
- **Chrome Trace format** –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏

```python
class ProfilerManager:
    def __init__(self, config: MetricsConfig):
        self.config = config
        self.enabled = config.enable_profiler
        self.step_count = 0
        
    @contextmanager
    def profile_step(self, step_name: str = \"train_step\"):
        \"\"\"Context manager –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è –æ–¥–Ω–æ–≥–æ —à–∞–≥–∞\"\"\"
        if not self.enabled:
            yield  # No-op –µ—Å–ª–∏ –ø—Ä–æ—Ñ–∏–ª–µ—Ä –æ—Ç–∫–ª—é—á–µ–Ω
            return
            
        with torch.profiler.profile(
            activities=[
                torch.profiler.ProfilerActivity.CPU,
                torch.profiler.ProfilerActivity.CUDA,
            ],
            record_shapes=self.config.profiler_record_shapes,
            profile_memory=self.config.profiler_profile_memory,
            with_stack=self.config.profiler_with_stack,
        ) as prof:
            yield prof
            
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —ç–∫—Å–ø–æ—Ä—Ç –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤
        self.step_count += 1
        if self.step_count % self.config.profiler_export_interval == 0:
            self._export_trace(prof, step_name)
            
    def _export_trace(self, prof, step_name: str):
        \"\"\"–≠–∫—Å–ø–æ—Ä—Ç trace –≤ Chrome format\"\"\"
        trace_path = f\"{self.config.profiler_trace_dir}/{step_name}_step_{self.step_count}.json\"
        prof.export_chrome_trace(trace_path)
        logger.log(DEBUG_PROFILING, f\"Exported profiler trace: {trace_path}\")
```

## üîó **5. Integration —Å EnergyTrainer**

### –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ existing –∫–æ–¥–µ:

```python
# –í EnergyTrainer.__init__()
from ..utils.metrics import MetricsCollector, ProfilerManager, GPUMonitor, MetricsConfig

self.metrics_config = MetricsConfig()  # –ò–ª–∏ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ config'–∞
self.metrics = MetricsCollector(self.metrics_config)
self.profiler = ProfilerManager(self.metrics_config) 
self.gpu_monitor = GPUMonitor(self.metrics_config)

# –í train_step()
def train_step(self, ...):
    with self.profiler.profile_step(\"train_step\"):
        with self.metrics.time_component(\"total_step\"):
            
            # Existing –∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
            with self.metrics.time_component(\"flow_processor\"):
                cube_output_surface = self.flow_processor.forward(teacher_input_embeddings)
            
            with self.metrics.time_component(\"loss_computation\"):
                # Loss computation –∫–æ–¥
                
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
    if self.metrics.enabled and self.global_step % self.metrics_config.metrics_log_interval == 0:
        self._log_performance_metrics()
```

## üìä **6. Configuration Integration**

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ EnergyConfig:

```python
@dataclass
class EnergyConfig:
    # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ...
    
    # === METRICS & PROFILING ===
    # –ü—Ä–æ—Å—Ç–æ–µ –≤–∫–ª—é—á–µ–Ω–∏–µ/–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ–¥–Ω–∏–º —Ñ–ª–∞–≥–æ–º
    enable_performance_monitoring: bool = False    # Master switch
    
    # –î–µ—Ç–∞–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ (–¥–ª—è advanced users)
    metrics_config: Optional[MetricsConfig] = None
    
    def __post_init__(self):
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–µ—Ç—Ä–∏–∫
        if self.metrics_config is None:
            self.metrics_config = MetricsConfig()
            self.metrics_config.enable_metrics = self.enable_performance_monitoring
            
            # –í DEBUG —Ä–µ–∂–∏–º–µ –≤–∫–ª—é—á–∞–µ–º –±–æ–ª—å—à–µ –º–µ—Ç—Ä–∏–∫
            if self.debug_mode:
                self.metrics_config.enable_gpu_monitoring = True
                self.metrics_config.collect_component_profiling = True
```

## üöÄ **7. –ü–ª–∞–Ω –ø–æ—ç—Ç–∞–ø–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**

### **Phase 1: Core Infrastructure (Priority: HIGH)**
1. –°–æ–∑–¥–∞—Ç—å `MetricsConfig` —Å –≤—Å–µ–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
2. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `MetricsCollector` —Å basic timing/throughput
3. –î–æ–±–∞–≤–∏—Ç—å integration points –≤ `EnergyTrainer`
4. **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: —É–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ overhead < 1%

### **Phase 2: GPU Monitoring (Priority: MEDIUM)**  
1. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `GPUMonitor` —Å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π
2. –î–æ–±–∞–≤–∏—Ç—å real-time GPU utilization tracking
3. Integration —Å conditional logging
4. **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ polling –Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ performance

### **Phase 3: Advanced Profiling (Priority: LOW)**
1. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `ProfilerManager` —Å torch.profiler
2. Chrome Trace export functionality  
3. Automatic bottleneck detection
4. **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –±–æ–ª—å—à–∏—Ö batch'–∞—Ö

### **Phase 4: Polish & Optimization**
1. Automatic performance regression detection
2. Optimization recommendations –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
3. TensorBoard integration (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
4. Documentation –∏ examples

## ‚ö†Ô∏è **–í–∞–∂–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**

1. **Zero overhead –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é** - –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã unless explicitly enabled
2. **Fail-safe** - –æ—à–∏–±–∫–∏ –≤ –º–µ—Ç—Ä–∏–∫–∞—Ö –Ω–µ –¥–æ–ª–∂–Ω—ã –ø—Ä–µ—Ä—ã–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ
3. **Minimal dependencies** - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ torch –∏ standard library
4. **Graceful fallback** - –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å
5. **Thread safety** —Ç–æ–ª—å–∫–æ –≥–¥–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ - –∏–∑–±–µ–≥–∞–µ–º –ª–∏—à–Ω–µ–≥–æ locking'–∞

## üéØ **Expected Results**

- **< 1% overhead** –ø—Ä–∏ –≤–∫–ª—é—á–µ–Ω–Ω—ã—Ö –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫–∞—Ö
- **Easy on/off** —á–µ—Ä–µ–∑ –ø—Ä–æ—Å—Ç—ã–µ boolean —Ñ–ª–∞–≥–∏
- **Rich insights** –∫–æ–≥–¥–∞ –º–µ—Ç—Ä–∏–∫–∏ –≤–∫–ª—é—á–µ–Ω—ã
- **Production ready** –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥–ª—è deployment
- **Chrome Profiler integration** –¥–ª—è deep performance analysis