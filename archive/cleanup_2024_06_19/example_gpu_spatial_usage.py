#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU Spatial Optimization
============================================

–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:
- GPU Morton Encoder –¥–ª—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
- GPU Spatial Hash Grid –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å–æ—Å–µ–¥–µ–π
- Adaptive GPU Spatial Hash –¥–ª—è —Å–∞–º–æ–æ–ø—Ç–∏–º–∏–∑–∏—Ä—É—é—â–µ–≥–æ—Å—è –ø–æ–∏—Å–∫–∞
- Adaptive GPU Chunker –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–æ–ª—å—à–∏–º–∏ —Ä–µ—à–µ—Ç–∫–∞–º–∏
- GPU Spatial Processor –∫–∞–∫ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ

–û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ new_rebuild/GPU_SPATIAL_OPTIMIZATION_GUIDE.md
"""

import sys
import os

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import torch
import numpy as np
import time

from config.project_config import get_project_config
from utils.device_manager import get_device_manager
from utils.logging import get_logger

# –ò–º–ø–æ—Ä—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ GPU Spatial Optimization
from core.lattice.spatial_optimization import (
    GPUSpatialProcessor,
    AdaptiveGPUChunker,
    GPUMortonEncoder,
    GPUSpatialHashGrid,
    AdaptiveGPUSpatialHash,
)

logger = get_logger(__name__)


def example_basic_usage():
    """–ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPUSpatialProcessor"""
    print("üìç –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")

    # –°–æ–∑–¥–∞–µ–º processor –¥–ª—è —Ä–µ—à–µ—Ç–∫–∏ 100x100x100
    processor = GPUSpatialProcessor((100, 100, 100))

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å
    query_coordinates = torch.tensor(
        [[25, 25, 25], [50, 50, 50], [75, 75, 75]], dtype=torch.float32
    )

    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Å–æ—Å–µ–¥–µ–π
    result = processor.query_neighbors_sync(
        coordinates=query_coordinates, radius=8.0, timeout=30.0
    )

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"–ù–∞–π–¥–µ–Ω–æ —Å–æ—Å–µ–¥–µ–π: {[len(neighbors) for neighbors in result.neighbor_lists]}")
    print(f"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.processing_time_ms:.2f}ms")
    print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {result.memory_usage_mb:.2f}MB")

    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    stats = processor.get_performance_stats()
    print(f"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['processor']['total_queries']}")
    print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {stats['processor']['avg_query_time_ms']:.2f}ms")

    # –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É
    processor.shutdown()
    print("‚úÖ –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω\n")


async def example_advanced_async():
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø—Ä–∏–º–µ—Ä —Å async –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
    print("üöÄ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø—Ä–∏–º–µ—Ä —Å async")

    processor = GPUSpatialProcessor((200, 200, 200))

    # –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    def process_result(result):
        print(
            f"Query {result.query_id} completed: {len(result.neighbor_lists)} results"
        )

    # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    query_ids = []
    for i in range(5):
        coords = torch.randint(0, 200, (10, 3), dtype=torch.float32)
        query_id = processor.query_neighbors_async(
            coordinates=coords, radius=12.0, priority=i * 10, callback=process_result
        )
        query_ids.append(query_id)

    # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    completed = 0
    max_wait = 50  # 5 —Å–µ–∫—É–Ω–¥
    wait_count = 0

    while completed < len(query_ids) and wait_count < max_wait:
        new_completed = 0
        for query_id in query_ids:
            if processor.is_query_complete(query_id):
                new_completed += 1

        if new_completed > completed:
            completed = new_completed
            print(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {completed}/{len(query_ids)}")

        time.sleep(0.1)
        wait_count += 1

    processor.shutdown()
    print("‚úÖ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø—Ä–∏–º–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω\n")


def example_morton_encoding():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU Morton Encoder"""
    print("üî¢ –ü—Ä–∏–º–µ—Ä Morton Encoding")

    device_manager = get_device_manager()
    device = device_manager.get_device()

    # –°–æ–∑–¥–∞–µ–º encoder
    encoder = GPUMortonEncoder((128, 128, 128))

    # –¢–µ—Å—Ç–æ–≤—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
    coordinates = torch.tensor(
        [[10, 20, 30], [64, 32, 96], [100, 50, 75]], dtype=torch.long, device=device
    )

    # –ö–æ–¥–∏—Ä—É–µ–º –≤ Morton –∫–æ–¥—ã
    morton_codes = encoder.encode_batch(coordinates)
    print(f"–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: {coordinates.tolist()}")
    print(f"Morton –∫–æ–¥—ã: {morton_codes.tolist()}")

    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ
    decoded = encoder.decode_batch(morton_codes)
    print(f"–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ: {decoded.tolist()}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å
    matches = torch.allclose(coordinates.float(), decoded.float())
    print(f"–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ—á–Ω–æ–µ: {'‚úÖ' if matches else '‚ùå'}")
    print("‚úÖ Morton encoding –ø—Ä–∏–º–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω\n")


def example_spatial_hash_grid():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU Spatial Hash Grid"""
    print("üèéÔ∏è –ü—Ä–∏–º–µ—Ä Spatial Hash Grid")

    device_manager = get_device_manager()
    device = device_manager.get_device()

    # –°–æ–∑–¥–∞–µ–º hash grid
    hash_grid = GPUSpatialHashGrid((64, 64, 64), cell_size=8)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Ç–æ—á–∫–∏
    num_points = 200
    coordinates = torch.randint(0, 64, (num_points, 3), dtype=torch.long, device=device)
    indices = torch.arange(num_points, device=device)

    # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
    print(f"–í—Å—Ç–∞–≤–ª—è–µ–º {num_points} —Ç–æ—á–µ–∫...")
    hash_grid.insert_batch(coordinates, indices)

    # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å—ã
    query_points = torch.tensor(
        [
            [32, 32, 32],  # –¶–µ–Ω—Ç—Ä
            [16, 16, 16],  # –ü–µ—Ä–≤–∞—è —á–µ—Ç–≤–µ—Ä—Ç—å
            [48, 48, 48],  # –¢—Ä–µ—Ç—å—è —á–µ—Ç–≤–µ—Ä—Ç—å
        ],
        dtype=torch.float32,
        device=device,
    )

    neighbors = hash_grid.query_radius_batch(query_points, radius=10.0)

    for i, neighbors_list in enumerate(neighbors):
        print(f"–¢–æ—á–∫–∞ {query_points[i].tolist()}: {len(neighbors_list)} —Å–æ—Å–µ–¥–µ–π")

    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = hash_grid.get_stats()
    print(
        f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats.total_queries} –∑–∞–ø—Ä–æ—Å–æ–≤, "
        f"{stats.avg_query_time_ms:.2f}ms —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è"
    )
    print("‚úÖ Spatial Hash Grid –ø—Ä–∏–º–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω\n")


def example_adaptive_chunker():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Adaptive GPU Chunker"""
    print("üì¶ –ü—Ä–∏–º–µ—Ä Adaptive Chunker")

    # –°–æ–∑–¥–∞–µ–º chunker –¥–ª—è –±–æ–ª—å—à–æ–π —Ä–µ—à–µ—Ç–∫–∏
    chunker = AdaptiveGPUChunker((80, 80, 80))

    print(f"–°–æ–∑–¥–∞–Ω–æ chunk'–æ–≤: {len(chunker.chunks)}")

    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º chunk'–µ
    test_coords = (40, 40, 40)
    chunk_info = chunker.get_chunk_by_coords(test_coords)

    if chunk_info:
        print(f"Chunk –¥–ª—è {test_coords}:")
        print(f"  ID: {chunk_info.chunk_id}")
        print(f"  –†–∞–∑–º–µ—Ä—ã: {chunk_info.start_coords} -> {chunk_info.end_coords}")
        print(f"  –ö–ª–µ—Ç–æ–∫: {len(chunk_info.cell_indices)}")
        print(f"  –ü–∞–º—è—Ç—å: {chunk_info.gpu_memory_usage_mb:.2f}MB")

    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    schedule = chunker.get_adaptive_processing_schedule()
    print(f"–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(schedule)} —ç—Ç–∞–ø–æ–≤")

    for i, stage in enumerate(schedule[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 —ç—Ç–∞–ø–∞
        print(f"  –≠—Ç–∞–ø {i+1}: {len(stage)} chunk'–æ–≤")

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
    if chunk_info:
        future = chunker.process_chunk_async(chunk_info.chunk_id, "load")
        print(f"–ó–∞–ø—É—â–µ–Ω–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ chunk {chunk_info.chunk_id}")

    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = chunker.get_comprehensive_stats()
    print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ chunker: {stats}")

    print("‚úÖ Adaptive Chunker –ø—Ä–∏–º–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω\n")


def example_performance_comparison():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤"""
    print("‚ö° –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")

    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    dimensions = (50, 50, 50)
    num_queries = 20
    radius = 8.0

    device_manager = get_device_manager()
    device = device_manager.get_device()

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
    test_coordinates = torch.rand(num_queries, 3, device=device) * 50

    results = {}

    # 1. GPU Spatial Hash Grid
    print("  –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU Spatial Hash Grid...")
    start_time = time.time()

    hash_grid = GPUSpatialHashGrid(dimensions, cell_size=8)
    # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    sample_coords = torch.randint(0, 50, (100, 3), dtype=torch.long, device=device)
    sample_indices = torch.arange(100, device=device)
    hash_grid.insert_batch(sample_coords, sample_indices)

    neighbors = hash_grid.query_radius_batch(test_coordinates, radius)

    results["SpatialHashGrid"] = (time.time() - start_time) * 1000

    # 2. Adaptive GPU Spatial Hash
    print("  –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Adaptive GPU Spatial Hash...")
    start_time = time.time()

    adaptive_hash = AdaptiveGPUSpatialHash(dimensions, target_memory_mb=256.0)
    adaptive_hash.insert_batch(sample_coords.float(), sample_indices)
    neighbors = adaptive_hash.query_radius_batch(test_coordinates, radius)

    results["AdaptiveSpatialHash"] = (time.time() - start_time) * 1000

    # 3. GPU Spatial Processor (–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ)
    print("  –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU Spatial Processor...")
    start_time = time.time()

    processor = GPUSpatialProcessor(dimensions)
    result = processor.query_neighbors_sync(test_coordinates, radius, timeout=10.0)
    processor.shutdown()

    results["SpatialProcessor"] = (time.time() - start_time) * 1000

    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:")
    for method, time_ms in results.items():
        print(f"  {method:<20}: {time_ms:.2f}ms")

    fastest = min(results, key=results.get)
    print(f"–°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π: {fastest} ({results[fastest]:.2f}ms)")
    print("‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ\n")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤—Å–µ—Ö –ø—Ä–∏–º–µ—Ä–æ–≤"""
    print("=" * 60)
    print("GPU Spatial Optimization - –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
    print("=" * 60)

    config = get_project_config()
    device_manager = get_device_manager()

    print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device_manager.get_device()}")
    print(f"CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {'‚úÖ' if device_manager.is_cuda() else '‚ùå'}")
    print(f"–†–∞–∑–º–µ—Ä —Ä–µ—à–µ—Ç–∫–∏: {config.lattice_dimensions}")
    print()

    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
        example_morton_encoding()
        example_spatial_hash_grid()
        example_adaptive_chunker()
        example_basic_usage()
        example_performance_comparison()

        # Async –ø—Ä–∏–º–µ—Ä —Ç—Ä–µ–±—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
        print("üîÑ –ó–∞–ø—É—Å–∫ async –ø—Ä–∏–º–µ—Ä–∞...")
        import asyncio

        asyncio.run(example_advanced_async())

        print("=" * 60)
        print("üéâ –í–°–ï –ü–†–ò–ú–ï–†–´ –£–°–ü–ï–®–ù–û –í–´–ü–û–õ–ù–ï–ù–´!")
        print(
            "GPU Spatial Optimization –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é."
        )
        print("=" * 60)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö: {e}")
        import traceback

        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
