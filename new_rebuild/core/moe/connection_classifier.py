#!/usr/bin/env python3
"""
Connection Classifier - –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∫–ª–µ—Ç–∫–∞–º–∏
=========================================================

–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–≤—è–∑–µ–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –º–æ–¥—É–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
–¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ —Å–≤—è–∑–µ–π –≤ 3D –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Ä–µ—à–µ—Ç–∫–µ.

–ù–û–í–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
- ConnectionCacheManager –¥–ª—è pre-computed –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- Fallback –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–µ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∫—ç—à–∞
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
"""

import torch
import torch.nn as nn
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import asdict

from .connection_types import ConnectionCategory, ConnectionInfo
from .distance_calculator import DistanceCalculator
from .functional_similarity import FunctionalSimilarityAnalyzer
from .connection_cache import ConnectionCacheManager
from ...config import get_project_config
from ...utils.logging import get_logger

logger = get_logger(__name__)


class UnifiedConnectionClassifier(nn.Module):
    """
    –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–≤—è–∑–µ–π —Å pre-computed –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º

    –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:
    - ConnectionCacheManager –¥–ª—è pre-computed —Å—Ç—Ä—É–∫—Ç—É—Ä
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫—ç—à–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
    - Fallback –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    - –ë—ã—Å—Ç—Ä–∞—è batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ –∫—ç—à

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
    - DistanceCalculator –¥–ª—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (fallback)
    - FunctionalSimilarityAnalyzer –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏ (fallback)
    - Learnable –ø–æ—Ä–æ–≥–∏ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    """

    def __init__(
        self, lattice_dimensions: Tuple[int, int, int], enable_cache: bool = None
    ):
        super().__init__()

        config = get_project_config()

        self.lattice_dimensions = lattice_dimensions
        self.state_size = config.model.state_size

        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        cache_config = asdict(config.cache) if config.cache else {}
        self.enable_cache = (
            cache_config.get("enabled", True) if enable_cache is None else enable_cache
        )
        self.enable_performance_monitoring = cache_config.get(
            "enable_performance_monitoring", False
        )
        self.enable_detailed_stats = cache_config.get("enable_detailed_stats", False)

        # –ú–æ–¥—É–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–¥–ª—è fallback)
        self.distance_calculator = DistanceCalculator(lattice_dimensions)
        self.similarity_analyzer = FunctionalSimilarityAnalyzer(self.state_size)

        # Pre-computed –∫—ç—à –º–µ–Ω–µ–¥–∂–µ—Ä
        if self.enable_cache:
            self.cache_manager = ConnectionCacheManager(
                lattice_dimensions, cache_config
            )
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫—ç—à
            self._initialize_cache()
        else:
            self.cache_manager = None

        # Learnable –ø–æ—Ä–æ–≥–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.local_distance_threshold = nn.Parameter(
            torch.tensor(config.model.local_distance_threshold)
        )
        self.functional_distance_threshold = nn.Parameter(
            torch.tensor(config.model.functional_distance_threshold)
        )
        self.distant_distance_threshold = nn.Parameter(
            torch.tensor(config.model.distant_distance_threshold)
        )
        self.functional_similarity_threshold = nn.Parameter(
            torch.tensor(config.model.functional_similarity_threshold)
        )

        # –¶–µ–ª–µ–≤—ã–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        self.target_ratios = {
            "local": config.model.local_tier_ratio,
            "functional": config.model.functional_tier_ratio,
            "distant": config.model.distant_tier_ratio,
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        self.reset_stats()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–≤–∫–ª—é—á–∞–µ—Ç—Å—è –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º)
        if self.enable_performance_monitoring:
            self.performance_stats = {
                "cache_hits": 0,
                "cache_misses": 0,
                "total_classifications": 0,
                "avg_cache_speedup": 0.0,
                "total_fallback_time": 0.0,
                "total_cache_time": 0.0,
            }
        else:
            self.performance_stats = {}

        cache_status = "enabled" if self.enable_cache else "disabled"
        performance_status = (
            "enabled" if self.enable_performance_monitoring else "disabled"
        )
        logger.info(
            f"UnifiedConnectionClassifier initialized for {lattice_dimensions}, cache: {cache_status}, performance monitoring: {performance_status}"
        )

    def _initialize_cache(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è pre-computed –∫—ç—à–∞"""
        try:
            if self.cache_manager is not None:
                logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è connection cache...")
                self.cache_manager.precompute_all_connections()

                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞
                stats = self.cache_manager.get_cache_stats()
                if stats["status"] == "active":
                    logger.info(
                        f"‚úÖ Cache –≥–æ—Ç–æ–≤: {stats['cached_cells']} –∫–ª–µ—Ç–æ–∫, {stats['total_connections']} —Å–≤—è–∑–µ–π, {stats['cache_size_mb']:.1f}MB"
                    )
                else:
                    logger.warning("‚ö†Ô∏è Cache –ø—É—Å—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–µ–∂–∏–º")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫—ç—à–∞: {e}")
            logger.info("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ fallback —Ä–µ–∂–∏–º –±–µ–∑ –∫—ç—à–∞")
            self.cache_manager = None

    def classify_connections_batch(
        self,
        cell_indices: torch.Tensor,
        neighbor_indices: torch.Tensor,
        states: torch.Tensor,
    ) -> Dict[str, torch.Tensor]:
        """
        Batch –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–≤—è–∑–µ–π —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π —á–µ—Ä–µ–∑ –∫—ç—à

        Args:
            cell_indices: [batch] - –∏–Ω–¥–µ–∫—Å—ã –∫–ª–µ—Ç–æ–∫
            neighbor_indices: [batch, max_neighbors] - –∏–Ω–¥–µ–∫—Å—ã —Å–æ—Å–µ–¥–µ–π
            states: [total_cells, state_size] - —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤—Å–µ—Ö –∫–ª–µ—Ç–æ–∫

        Returns:
            Dict —Å –º–∞—Å–∫–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ —Å–≤—è–∑–µ–π
        """
        if self.enable_performance_monitoring:
            self.performance_stats["total_classifications"] += 1

        # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à
        if self.cache_manager is not None:
            try:
                if self.enable_performance_monitoring:
                    import time

                    start_time = time.time()

                result = self.cache_manager.get_batch_cached_connections(
                    cell_indices=cell_indices,
                    neighbor_indices=neighbor_indices,
                    states=states,
                    functional_similarity_threshold=self.functional_similarity_threshold.item(),
                )

                if self.enable_performance_monitoring:
                    cache_time = time.time() - start_time
                    self.performance_stats["cache_hits"] += 1
                    self.performance_stats["total_cache_time"] += cache_time

                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É speedup
                    self.performance_stats["avg_cache_speedup"] = (
                        self.performance_stats["avg_cache_speedup"] * 0.9
                        + cache_time * 0.1
                    )

                    if self.enable_detailed_stats:
                        logger.debug(
                            f"‚úÖ Cache hit: {cache_time:.4f}s –¥–ª—è batch_size={cell_indices.shape[0]}"
                        )
                return result

            except Exception as e:
                if self.enable_detailed_stats:
                    logger.warning(f"Cache miss, fallback: {e}")
                if self.enable_performance_monitoring:
                    self.performance_stats["cache_misses"] += 1

        # Fallback –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–µ
        if self.enable_performance_monitoring:
            import time

            start_time = time.time()

        result = self._classify_connections_batch_original(
            cell_indices, neighbor_indices, states
        )

        if self.enable_performance_monitoring:
            fallback_time = time.time() - start_time
            self.performance_stats["total_fallback_time"] += fallback_time

        return result

    def _classify_connections_batch_original(
        self,
        cell_indices: torch.Tensor,
        neighbor_indices: torch.Tensor,
        states: torch.Tensor,
    ) -> Dict[str, torch.Tensor]:
        """
        –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è batch –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (fallback —Ä–µ–∂–∏–º)
        """
        try:
            logger.debug(
                f"üîç classify_connections_batch_original: –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ - cell_indices.shape={cell_indices.shape}, neighbor_indices.shape={neighbor_indices.shape}, states.shape={states.shape}"
            )

            batch_size, max_neighbors = neighbor_indices.shape
            device = cell_indices.device

            # –°–æ–∑–¥–∞–µ–º –≤–∞–ª–∏–¥–Ω—É—é –º–∞—Å–∫—É (–∏—Å–∫–ª—é—á–∞–µ–º -1 padding)
            valid_mask = neighbor_indices >= 0

        except Exception as e:
            import traceback

            logger.error(
                f"‚ùå –û–®–ò–ë–ö–ê –≤ classify_connections_batch_original (–Ω–∞—á–∞–ª–æ): {e}"
            )
            logger.error(f"üìç Traceback:\n{traceback.format_exc()}")
            raise

        if valid_mask.sum().item() == 0:
            return self._empty_classification_result(batch_size, max_neighbors, device)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ –ø–∞—Ä—ã
        valid_cells = cell_indices.unsqueeze(1).expand(-1, max_neighbors)[valid_mask]
        valid_neighbors = neighbor_indices[valid_mask]

        # 1. –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        euclidean_distances = self.distance_calculator.euclidean_distance_batch(
            valid_cells, valid_neighbors
        )

        # 2. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é
        local_mask_flat = euclidean_distances <= self.local_distance_threshold
        distant_mask_flat = euclidean_distances >= self.distant_distance_threshold
        # –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–≤—è–∑–∏: –º–µ–∂–¥—É local –∏ functional_distance_threshold
        functional_candidate_mask = (
            euclidean_distances > self.local_distance_threshold
        ) * (euclidean_distances <= self.functional_distance_threshold)
        # –°—Ä–µ–¥–Ω–∏–µ —Å–≤—è–∑–∏: –º–µ–∂–¥—É functional_distance –∏ distant_threshold (–±—É–¥—É—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –Ω–∞ similarity)
        middle_mask = (euclidean_distances > self.functional_distance_threshold) * (
            euclidean_distances < self.distant_distance_threshold
        )

        # 3. –£—Ç–æ—á–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π
        # –ü—Ä—è–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ (–±–ª–∏–∑–∫–∏–µ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é)
        functional_mask_flat = functional_candidate_mask.clone()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ —Å–≤—è–∑–∏ –Ω–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –±–ª–∏–∑–æ—Å—Ç—å
        if middle_mask.sum().item() > 0:
            middle_cells = valid_cells[middle_mask]
            middle_neighbors = valid_neighbors[middle_mask]

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤ –ø–µ—Ä–µ–¥ –¥–æ—Å—Ç—É–ø–æ–º –∫ states
            max_index = states.shape[0] - 1
            valid_middle_cells = middle_cells <= max_index
            valid_middle_neighbors = middle_neighbors <= max_index

            if not (valid_middle_cells.all() and valid_middle_neighbors.all()):
                logger.warning(
                    f"‚ö†Ô∏è –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã: cells max={middle_cells.max().item()}, neighbors max={middle_neighbors.max().item()}, states size={states.shape[0]}"
                )
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
                valid_pairs = valid_middle_cells & valid_middle_neighbors
                if valid_pairs.sum().item() == 0:
                    logger.warning("‚ö†Ô∏è –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–∞—Ä –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏")
                else:
                    middle_cells = middle_cells[valid_pairs]
                    middle_neighbors = middle_neighbors[valid_pairs]
                    cell_states = states[middle_cells]
                    neighbor_states = states[middle_neighbors]

                    similarities = self.similarity_analyzer(
                        cell_states, neighbor_states
                    )
                    high_similarity = (
                        similarities > self.functional_similarity_threshold
                    )

                    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ —Å–≤—è–∑–∏ —Å –≤—ã—Å–æ–∫–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç—å—é –∫ functional
                    middle_indices = torch.where(middle_mask)[0]
                    valid_middle_indices = middle_indices[valid_pairs]
                    functional_additions = valid_middle_indices[high_similarity]
                    functional_mask_flat[functional_additions] = True
            else:
                cell_states = states[middle_cells]
                neighbor_states = states[middle_neighbors]

                similarities = self.similarity_analyzer(cell_states, neighbor_states)
                high_similarity = similarities > self.functional_similarity_threshold

                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ —Å–≤—è–∑–∏ —Å –≤—ã—Å–æ–∫–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç—å—é –∫ functional
                middle_indices = torch.where(middle_mask)[0]
                functional_additions = middle_indices[high_similarity]
                functional_mask_flat[functional_additions] = True

        # 4. –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–æ—Ä–º—É –º–∞—Å–æ–∫
        local_mask = torch.zeros(
            batch_size, max_neighbors, dtype=torch.bool, device=device
        )
        functional_mask = torch.zeros(
            batch_size, max_neighbors, dtype=torch.bool, device=device
        )
        distant_mask = torch.zeros(
            batch_size, max_neighbors, dtype=torch.bool, device=device
        )

        local_mask[valid_mask] = local_mask_flat
        functional_mask[valid_mask] = functional_mask_flat
        distant_mask[valid_mask] = distant_mask_flat

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._update_stats_batch(local_mask, functional_mask, distant_mask)

        return self._create_batch_classification_result(
            batch_size,
            max_neighbors,
            valid_mask,
            local_mask,
            functional_mask,
            distant_mask,
            device,
        )

    def classify_connections(
        self,
        cell_idx: int,
        neighbor_indices: List[int],
        cell_state: torch.Tensor,
        neighbor_states: torch.Tensor,
    ) -> Dict[ConnectionCategory, List[ConnectionInfo]]:
        """–ï–¥–∏–Ω–∏—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–≤—è–∑–µ–π —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Å—Ç—ã–µ neighbor_indices
        if torch.is_tensor(neighbor_indices):
            if neighbor_indices.numel() == 0:
                return {cat: [] for cat in ConnectionCategory}
        else:
            if not neighbor_indices:
                return {cat: [] for cat in ConnectionCategory}

        # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à
        if self.cache_manager is not None:
            try:
                # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è –∫—ç—à –º–µ–Ω–µ–¥–∂–µ—Ä–∞
                cell_state_normalized = (
                    cell_state.unsqueeze(0) if cell_state.dim() == 1 else cell_state
                )
                neighbor_states_normalized = (
                    neighbor_states
                    if neighbor_states.dim() == 2
                    else neighbor_states.unsqueeze(0)
                )

                all_states = torch.cat(
                    [cell_state_normalized, neighbor_states_normalized], dim=0
                )

                result = self.cache_manager.get_cached_connections(
                    cell_idx=cell_idx,
                    neighbor_indices=(
                        neighbor_indices
                        if isinstance(neighbor_indices, list)
                        else neighbor_indices.tolist()
                    ),
                    states=all_states,
                    functional_similarity_threshold=self.functional_similarity_threshold.item(),
                )

                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–∏ cache hit
                self._update_stats_from_result(result)

                self.performance_stats["cache_hits"] += 1
                logger.debug(f"‚úÖ Cache hit –¥–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx}")
                logger.debug(
                    f"üìä Cache result: LOCAL={len(result.get(ConnectionCategory.LOCAL, []))}, FUNCTIONAL={len(result.get(ConnectionCategory.FUNCTIONAL, []))}, DISTANT={len(result.get(ConnectionCategory.DISTANT, []))}"
                )
                return result

            except Exception as e:
                logger.debug(f"Cache miss –¥–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx}: {e}")
                self.performance_stats["cache_misses"] += 1

        # Fallback –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–µ
        return self._classify_connections_original(
            cell_idx, neighbor_indices, cell_state, neighbor_states
        )

    def _classify_connections_original(
        self,
        cell_idx: int,
        neighbor_indices: List[int],
        cell_state: torch.Tensor,
        neighbor_states: torch.Tensor,
    ) -> Dict[ConnectionCategory, List[ConnectionInfo]]:
        """–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –µ–¥–∏–Ω–∏—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (fallback)"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ batch —Ñ–æ—Ä–º–∞—Ç
        cell_tensor = torch.tensor([cell_idx], device=cell_state.device)
        if torch.is_tensor(neighbor_indices):
            neighbor_tensor = neighbor_indices.unsqueeze(0)  # [1, num_neighbors]
        else:
            neighbor_tensor = torch.tensor([neighbor_indices], device=cell_state.device)

        # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏–π
        try:
            logger.debug(
                f"üîç concat debug: cell_state.shape={cell_state.shape}, neighbor_states.shape={neighbor_states.shape}"
            )

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏
            if cell_state.dim() == 0:
                raise ValueError(
                    f"cell_state –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–∫–∞–ª—è—Ä–æ–º, –ø–æ–ª—É—á–µ–Ω–æ: {cell_state.shape}"
                )
            elif cell_state.dim() == 1:
                cell_state_normalized = cell_state.unsqueeze(0)
            elif cell_state.dim() == 2 and cell_state.shape[0] == 1:
                cell_state_normalized = cell_state
            else:
                raise ValueError(
                    f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å cell_state: {cell_state.shape}, –æ–∂–∏–¥–∞–ª–æ—Å—å [state_size] –∏–ª–∏ [1, state_size]"
                )

            # neighbor_states –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å [num_neighbors, state_size]
            if neighbor_states.dim() == 1:
                # [state_size] -> [1, state_size] (—Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å–æ—Å–µ–¥)
                neighbor_states_normalized = neighbor_states.unsqueeze(0)
            elif neighbor_states.dim() == 2:
                # [num_neighbors, state_size] - —É–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                neighbor_states_normalized = neighbor_states
            else:
                raise ValueError(
                    f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å neighbor_states: {neighbor_states.shape}, –æ–∂–∏–¥–∞–ª–æ—Å—å [state_size] –∏–ª–∏ [num_neighbors, state_size]"
                )

            # –ö–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ–º states: [1, state_size] + [num_neighbors, state_size] = [1+num_neighbors, state_size]
            all_states = torch.cat(
                [cell_state_normalized, neighbor_states_normalized], dim=0
            )
            logger.debug(f"üîç all_states.shape –ø–æ—Å–ª–µ concat: {all_states.shape}")

        except Exception as e:
            logger.error(f"‚ùå concat error: {e}")
            logger.error(
                f"üîç cell_state.shape={cell_state.shape}, neighbor_states.shape={neighbor_states.shape}"
            )
            logger.error(
                f"üîç cell_state_normalized.shape={locals().get('cell_state_normalized', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')}"
            )
            logger.error(
                f"üîç neighbor_states_normalized.shape={locals().get('neighbor_states_normalized', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')}"
            )
            raise

        # –í—ã–∑—ã–≤–∞–µ–º batch –≤–µ—Ä—Å–∏—é
        batch_result = self._classify_connections_batch_original(
            cell_tensor, neighbor_tensor, all_states
        )

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞—Ç–Ω–æ
        result = {cat: [] for cat in ConnectionCategory}

        for i, neighbor_idx in enumerate(neighbor_indices):
            if batch_result["local_mask"][0, i].item():
                category = ConnectionCategory.LOCAL
            elif batch_result["functional_mask"][0, i].item():
                category = ConnectionCategory.FUNCTIONAL
            elif batch_result["distant_mask"][0, i].item():
                category = ConnectionCategory.DISTANT
            else:
                continue  # –ò—Å–∫–ª—é—á–µ–Ω–Ω—ã–π —Å–æ—Å–µ–¥

            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
            euclidean_dist = self.distance_calculator.euclidean_distance(
                cell_idx, neighbor_idx
            )
            manhattan_dist = self.distance_calculator.manhattan_distance(
                cell_idx, neighbor_idx
            )

            connection_info = ConnectionInfo(
                source_idx=cell_idx,
                target_idx=neighbor_idx,
                euclidean_distance=euclidean_dist,
                manhattan_distance=manhattan_dist,
                category=category,
            )

            result[category].append(connection_info)

        return result

    def _empty_classification_result(
        self, batch_size: int, max_neighbors: int, device: torch.device
    ) -> Dict[str, torch.Tensor]:
        """–ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        return {
            "local_mask": torch.zeros(
                batch_size, max_neighbors, dtype=torch.bool, device=device
            ),
            "functional_mask": torch.zeros(
                batch_size, max_neighbors, dtype=torch.bool, device=device
            ),
            "distant_mask": torch.zeros(
                batch_size, max_neighbors, dtype=torch.bool, device=device
            ),
            "valid_mask": torch.zeros(
                batch_size, max_neighbors, dtype=torch.bool, device=device
            ),
        }

    def _create_batch_classification_result(
        self,
        batch_size: int,
        max_neighbors: int,
        valid_mask: torch.Tensor,
        local_mask: torch.Tensor,
        functional_mask: torch.Tensor,
        distant_mask: torch.Tensor,
        device: torch.device,
    ) -> Dict[str, torch.Tensor]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ batch –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        return {
            "local_mask": local_mask,
            "functional_mask": functional_mask,
            "distant_mask": distant_mask,
            "valid_mask": valid_mask,
        }

    def _update_stats_batch(
        self,
        local_mask: torch.Tensor,
        functional_mask: torch.Tensor,
        distant_mask: torch.Tensor,
    ):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        self.usage_stats["local_count"] += local_mask.sum().item()
        self.usage_stats["functional_count"] += functional_mask.sum().item()
        self.usage_stats["distant_count"] += distant_mask.sum().item()
        self.usage_stats["total_classifications"] += 1

    def get_classification_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤–∫–ª—é—á–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫—ç—à–∞"""
        total = max(
            1,
            self.usage_stats["local_count"]
            + self.usage_stats["functional_count"]
            + self.usage_stats["distant_count"],
        )

        stats = {
            "local_ratio": self.usage_stats["local_count"] / total,
            "functional_ratio": self.usage_stats["functional_count"] / total,
            "distant_ratio": self.usage_stats["distant_count"] / total,
            "total_connections": total,
            "total_classifications": self.usage_stats["total_classifications"],
            "thresholds": {
                "local_distance": self.local_distance_threshold.item(),
                "functional_distance": self.functional_distance_threshold.item(),
                "distant_distance": self.distant_distance_threshold.item(),
                "functional_similarity": self.functional_similarity_threshold.item(),
            },
        }

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫—ç—à–∞ (–µ—Å–ª–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤–∫–ª—é—á–µ–Ω)
        if self.cache_manager is not None:
            cache_stats = self.cache_manager.get_cache_stats()

            stats["cache_performance"] = {
                "cache_enabled": True,
                "performance_monitoring": self.enable_performance_monitoring,
                "detailed_stats": self.enable_detailed_stats,
                "cache_size_mb": cache_stats.get("cache_size_mb", 0),
                "cached_cells": cache_stats.get("cached_cells", 0),
            }

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤–∫–ª—é—á–µ–Ω
            if self.enable_performance_monitoring and self.performance_stats:
                total_requests = self.performance_stats.get(
                    "cache_hits", 0
                ) + self.performance_stats.get("cache_misses", 0)
                hit_rate = self.performance_stats.get("cache_hits", 0) / max(
                    1, total_requests
                )

                stats["cache_performance"].update(
                    {
                        "cache_hit_rate": hit_rate,
                        "cache_hits": self.performance_stats.get("cache_hits", 0),
                        "cache_misses": self.performance_stats.get("cache_misses", 0),
                        "avg_cache_time": self.performance_stats.get(
                            "avg_cache_speedup", 0.0
                        ),
                        "total_cache_time": self.performance_stats.get(
                            "total_cache_time", 0.0
                        ),
                        "total_fallback_time": self.performance_stats.get(
                            "total_fallback_time", 0.0
                        ),
                        "total_classifications": self.performance_stats.get(
                            "total_classifications", 0
                        ),
                    }
                )

                # –í—ã—á–∏—Å–ª—è–µ–º speedup –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
                if (
                    self.performance_stats.get("total_fallback_time", 0) > 0
                    and self.performance_stats.get("total_cache_time", 0) > 0
                ):
                    avg_fallback_time = self.performance_stats[
                        "total_fallback_time"
                    ] / max(1, self.performance_stats.get("cache_misses", 1))
                    avg_cache_time = self.performance_stats["total_cache_time"] / max(
                        1, self.performance_stats.get("cache_hits", 1)
                    )
                    speedup = avg_fallback_time / max(0.001, avg_cache_time)
                    stats["cache_performance"]["speedup_ratio"] = speedup

        else:
            stats["cache_performance"] = {
                "cache_enabled": False,
                "fallback_mode": True,
                "performance_monitoring": self.enable_performance_monitoring,
                "detailed_stats": self.enable_detailed_stats,
                "cache_size_mb": 0,
                "cached_cells": 0,
                "cache_hit_rate": 0.0,
                "cache_hits": 0,
                "cache_misses": 0,
                "avg_cache_time": 0.0,
                "total_cache_time": 0.0,
                "total_fallback_time": 0.0,
                "total_classifications": 0,
                "speedup_ratio": 1.0,
            }

        return stats

    def reset_stats(self):
        """–°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        self.usage_stats = {
            "local_count": 0,
            "functional_count": 0,
            "distant_count": 0,
            "total_classifications": 0,
        }

        if self.enable_performance_monitoring:
            self.performance_stats = {
                "cache_hits": 0,
                "cache_misses": 0,
                "total_classifications": 0,
                "avg_cache_speedup": 0.0,
                "total_fallback_time": 0.0,
                "total_cache_time": 0.0,
            }
        else:
            self.performance_stats = {}

    def rebuild_cache(self, force: bool = True):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∞ –∫—ç—à–∞"""
        if self.cache_manager is not None:
            logger.info("üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∞ –∫—ç—à–∞...")
            self.cache_manager.clear_cache()
            self.cache_manager.precompute_all_connections(force_rebuild=force)
            logger.info("‚úÖ –ö—ç—à –ø–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω")
        else:
            logger.warning("Cache manager –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")

    def get_cache_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞"""
        if self.cache_manager is not None:
            return self.cache_manager.get_cache_stats()
        else:
            return {"status": "disabled"}

    def _update_stats_from_result(
        self, result: Dict[ConnectionCategory, List[ConnectionInfo]]
    ):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        local_count = len(result.get(ConnectionCategory.LOCAL, []))
        functional_count = len(result.get(ConnectionCategory.FUNCTIONAL, []))
        distant_count = len(result.get(ConnectionCategory.DISTANT, []))

        self.usage_stats["local_count"] += local_count
        self.usage_stats["functional_count"] += functional_count
        self.usage_stats["distant_count"] += distant_count
        self.usage_stats["total_classifications"] += 1

        logger.debug(
            f"üìä Stats updated: LOCAL+{local_count}, FUNCTIONAL+{functional_count}, DISTANT+{distant_count}"
        )
