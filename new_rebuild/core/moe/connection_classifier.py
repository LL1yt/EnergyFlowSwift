#!/usr/bin/env python3
"""
Connection Classifier - –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∫–ª–µ—Ç–∫–∞–º–∏
=========================================================

–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–≤—è–∑–µ–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –º–æ–¥—É–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
–¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ —Å–≤—è–∑–µ–π –≤ 3D –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Ä–µ—à–µ—Ç–∫–µ.

–ù–û–í–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
- ConnectionCacheManager –¥–ª—è pre-computed –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- Fallback –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–µ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∫—ç—à–∞
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
"""

import torch
import torch.nn as nn
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import asdict

from typing import Optional, TYPE_CHECKING

from .connection_types import ConnectionCategory, ConnectionInfo
from .distance_calculator import DistanceCalculator
from .functional_similarity import FunctionalSimilarityAnalyzer
from .connection_cache import ConnectionCacheManager
from .unified_cache_adapter import UnifiedCacheAdapter
from ...config import get_project_config
from ...utils.logging import get_logger

if TYPE_CHECKING:
    from ...core.lattice.spatial_optimization import UnifiedSpatialOptimizer

logger = get_logger(__name__)


class UnifiedConnectionClassifier(nn.Module):
    """
    –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–≤—è–∑–µ–π —Å pre-computed –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º

    –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:
    - ConnectionCacheManager –¥–ª—è pre-computed —Å—Ç—Ä—É–∫—Ç—É—Ä
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫—ç—à–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
    - Fallback –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    - –ë—ã—Å—Ç—Ä–∞—è batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ –∫—ç—à

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
    - DistanceCalculator –¥–ª—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (fallback)
    - FunctionalSimilarityAnalyzer –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏ (fallback)
    - Learnable –ø–æ—Ä–æ–≥–∏ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    """

    def __init__(
        self, lattice_dimensions: Tuple[int, int, int], enable_cache: bool = None
    ):
        super().__init__()

        config = get_project_config()

        self.lattice_dimensions = lattice_dimensions
        self.state_size = config.model.state_size

        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        cache_config = asdict(config.cache) if config.cache else {}
        self.enable_cache = (
            cache_config.get("enabled", True) if enable_cache is None else enable_cache
        )
        self.enable_performance_monitoring = cache_config.get(
            "enable_performance_monitoring", False
        )
        self.enable_detailed_stats = cache_config.get("enable_detailed_stats", False)
        
        logger.debug(f"Cache config: {cache_config}")
        logger.debug(f"Enable cache param: {enable_cache}")
        logger.debug(f"Final enable_cache: {self.enable_cache}")

        # –ú–æ–¥—É–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–¥–ª—è fallback)
        self.distance_calculator = DistanceCalculator(lattice_dimensions)
        self.similarity_analyzer = FunctionalSimilarityAnalyzer(self.state_size)

        # Pre-computed –∫—ç—à –º–µ–Ω–µ–¥–∂–µ—Ä
        if self.enable_cache:
            logger.info(f"–°–æ–∑–¥–∞–µ–º ConnectionCacheManager –¥–ª—è —Ä–µ—à–µ—Ç–∫–∏ {lattice_dimensions}")
            try:
                self.cache_manager = ConnectionCacheManager(
                    lattice_dimensions, cache_config
                )
                # –°–æ–∑–¥–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å spatial optimizer
                self.cache_adapter = UnifiedCacheAdapter(self.cache_manager)
                logger.info("ConnectionCacheManager –∏ –∞–¥–∞–ø—Ç–µ—Ä —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
                # –ù–ï –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫—ç—à –∑–¥–µ—Å—å - –∂–¥–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫–∏ spatial optimizer
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è ConnectionCacheManager: {e}")
                import traceback
                logger.error(traceback.format_exc())
                self.cache_manager = None
                self.cache_adapter = None
        else:
            logger.warning(f"Cache –æ—Ç–∫–ª—é—á–µ–Ω (enable_cache={self.enable_cache})")
            self.cache_manager = None
            self.cache_adapter = None

        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ—Ä–æ–≥–∏ —Ç–µ–ø–µ—Ä—å –Ω–µ –æ–±—É—á–∞–µ–º—ã–µ, –∞ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        # –≠—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Å ConnectionCacheManager
        self.adaptive_radius = config.calculate_adaptive_radius()
        self.local_distance_threshold = (
            self.adaptive_radius * config.lattice.local_distance_ratio
        )
        self.functional_distance_threshold = (
            self.adaptive_radius * config.lattice.functional_distance_ratio
        )
        self.distant_distance_threshold = (
            self.adaptive_radius * config.lattice.distant_distance_ratio
        )
        self.functional_similarity_threshold = (
            config.lattice.functional_similarity_threshold
        )

        # –ó–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ: learnable-–ø–æ—Ä–æ–≥–∏ –∏ target-ratios —É—Å—Ç–∞—Ä–µ–ª–∏
        # self.local_distance_threshold = nn.Parameter(
        #     torch.tensor(1.8) # –ü—Ä–∏–º–µ—Ä –∑–Ω–∞—á–µ–Ω–∏—è
        # )
        # self.functional_distance_threshold = nn.Parameter(
        #     torch.tensor(4.0) # –ü—Ä–∏–º–µ—Ä –∑–Ω–∞—á–µ–Ω–∏—è
        # )
        # self.distant_distance_threshold = nn.Parameter(
        #     torch.tensor(5.5) # –ü—Ä–∏–º–µ—Ä –∑–Ω–∞—á–µ–Ω–∏—è
        # )
        # self.functional_similarity_threshold = nn.Parameter(
        #     torch.tensor(0.3) # –ü—Ä–∏–º–µ—Ä –∑–Ω–∞—á–µ–Ω–∏—è
        # )
        #
        # # –¶–µ–ª–µ–≤—ã–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ (–£–°–¢–ê–†–ï–õ–û)
        # self.target_ratios = {
        #     "local": 0.1,
        #     "functional": 0.55,
        #     "distant": 0.35,
        # }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        self.reset_stats()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–≤–∫–ª—é—á–∞–µ—Ç—Å—è –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º)
        if self.enable_performance_monitoring:
            self.performance_stats = {
                "cache_hits": 0,
                "cache_misses": 0,
                "total_classifications": 0,
                "avg_cache_speedup": 0.0,
                "total_fallback_time": 0.0,
                "total_cache_time": 0.0,
            }
        else:
            self.performance_stats = {}

        cache_status = "enabled" if self.enable_cache else "disabled"
        performance_status = (
            "enabled" if self.enable_performance_monitoring else "disabled"
        )
        logger.info(
            f"UnifiedConnectionClassifier initialized for {lattice_dimensions}, cache: {cache_status}, performance monitoring: {performance_status}"
        )
        
    def set_spatial_optimizer(self, spatial_optimizer: Optional['UnifiedSpatialOptimizer']):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç spatial optimizer –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ª–æ–≥–∏–∫–∏ –ø–æ–∏—Å–∫–∞ —Å–æ—Å–µ–¥–µ–π"""
        if self.cache_adapter is not None:
            self.cache_adapter.spatial_optimizer = spatial_optimizer
            logger.info("Spatial optimizer —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ connection classifier")
            
            # –ï—Å–ª–∏ –∫—ç—à –µ—â–µ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –µ–≥–æ —Å–µ–π—á–∞—Å
            if self.cache_manager is not None and not self.cache_manager.is_precomputed:
                logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫—ç—à–∞ —Å spatial optimizer...")
                self._initialize_cache()
            # –ï—Å–ª–∏ –∫—ç—à —É–∂–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω –±–µ–∑ spatial optimizer, –ø–µ—Ä–µ—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –µ–≥–æ
            elif self.cache_manager is not None and self.cache_manager.is_precomputed:
                logger.info("–ö—ç—à —É–∂–µ —Å–æ–∑–¥–∞–Ω, –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏...")
                # –¢–æ–ª—å–∫–æ –ø–µ—Ä–µ—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –µ—Å–ª–∏ –∫—ç—à –±—ã–ª —Å–æ–∑–¥–∞–Ω –±–µ–∑ spatial optimizer
                if hasattr(self, '_cache_created_without_spatial_optimizer'):
                    logger.info("–ü–µ—Ä–µ—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∫—ç—à–∞ —Å –Ω–æ–≤—ã–º spatial optimizer...")
                    self.cache_adapter.sync_cache_with_optimizer()
        else:
            logger.warning("Cache adapter –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, spatial optimizer –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

    def _initialize_cache(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è pre-computed –∫—ç—à–∞"""
        try:
            if self.cache_manager is not None:
                logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è connection cache...")
                
                # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫—ç—à —Å –¥–∏—Å–∫–∞
                if self.cache_manager._load_cache_from_disk():
                    self.cache_manager.is_precomputed = True
                    logger.info("‚úÖ –ö—ç—à —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω —Å –¥–∏—Å–∫–∞")
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –∫—ç—à–∞
                    stats = self.cache_manager.get_cache_stats()
                    if stats["status"] == "active":
                        logger.info(
                            f"‚úÖ Cache –≥–æ—Ç–æ–≤: {stats['cached_cells']} –∫–ª–µ—Ç–æ–∫, {stats['total_connections']} —Å–≤—è–∑–µ–π, {stats['cache_size_mb']:.1f}MB"
                        )
                    return
                
                # –ï—Å–ª–∏ –∫—ç—à –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ –¥–∏—Å–∫–µ, –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ spatial optimizer
                if (self.cache_adapter is not None and 
                    self.cache_adapter.spatial_optimizer is not None):
                    logger.info("–ö—ç—à –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ –¥–∏—Å–∫–µ. –ò—Å–ø–æ–ª—å–∑—É–µ–º spatial optimizer –¥–ª—è –ø—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∫—ç—à–∞")
                    new_cache = self.cache_adapter.precompute_with_spatial_optimizer()
                    self.cache_manager.cache = new_cache
                    self.cache_manager.is_precomputed = True
                    self.cache_manager._save_cache_to_disk()
                else:
                    # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é –ª–æ–≥–∏–∫—É
                    logger.error("‚ùå Spatial optimizer –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞.")
                    raise RuntimeError("Spatial optimizer –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã")

                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞
                stats = self.cache_manager.get_cache_stats()
                if stats["status"] == "active":
                    logger.info(
                        f"‚úÖ Cache –≥–æ—Ç–æ–≤: {stats['cached_cells']} –∫–ª–µ—Ç–æ–∫, {stats['total_connections']} —Å–≤—è–∑–µ–π, {stats['cache_size_mb']:.1f}MB"
                    )
                else:
                    logger.error("‚ùå Cache –ø—É—Å—Ç –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏!")
                    raise RuntimeError("–ö—ç—à –ø—É—Å—Ç –ø–æ—Å–ª–µ –ø—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–∏—è - —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫—ç—à–∞: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–∞–ª—å—à–µ –≤–º–µ—Å—Ç–æ fallback

    def classify_connections_batch(
        self,
        cell_indices: torch.Tensor,
        neighbor_indices: torch.Tensor,
        states: torch.Tensor,
    ) -> Dict[str, torch.Tensor]:
        """
        Batch –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–≤—è–∑–µ–π —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π —á–µ—Ä–µ–∑ –∫—ç—à

        Args:
            cell_indices: [batch] - –∏–Ω–¥–µ–∫—Å—ã –∫–ª–µ—Ç–æ–∫
            neighbor_indices: [batch, max_neighbors] - –∏–Ω–¥–µ–∫—Å—ã —Å–æ—Å–µ–¥–µ–π
            states: [total_cells, state_size] - —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤—Å–µ—Ö –∫–ª–µ—Ç–æ–∫

        Returns:
            Dict —Å –º–∞—Å–∫–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ —Å–≤—è–∑–µ–π
        """
        if self.enable_performance_monitoring:
            self.performance_stats["total_classifications"] += 1

        # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à
        if self.cache_manager is not None:
            try:
                if self.enable_performance_monitoring:
                    import time

                    start_time = time.time()

                result = self.cache_manager.get_batch_cached_connections(
                    cell_indices=cell_indices,
                    neighbor_indices=neighbor_indices,
                    states=states,
                    functional_similarity_threshold=self.functional_similarity_threshold,
                )

                if self.enable_performance_monitoring:
                    cache_time = time.time() - start_time
                    self.performance_stats["cache_hits"] += 1
                    self.performance_stats["total_cache_time"] += cache_time

                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É speedup
                    self.performance_stats["avg_cache_speedup"] = (
                        self.performance_stats["avg_cache_speedup"] * 0.9
                        + cache_time * 0.1
                    )

                    if self.enable_detailed_stats:
                        logger.debug(
                            f"‚úÖ Cache hit: {cache_time:.4f}s –¥–ª—è batch_size={cell_indices.shape[0]}"
                        )
                return result

            except Exception as e:
                if self.enable_detailed_stats:
                    logger.warning(f"Cache miss, fallback: {e}")
                if self.enable_performance_monitoring:
                    self.performance_stats["cache_misses"] += 1

        # Fallback –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–µ
        if self.enable_performance_monitoring:
            import time

            start_time = time.time()

        result = self._classify_connections_batch_original(
            cell_indices, neighbor_indices, states
        )

        if self.enable_performance_monitoring:
            fallback_time = time.time() - start_time
            self.performance_stats["total_fallback_time"] += fallback_time

        return result

    def _classify_connections_batch_original(
        self,
        cell_indices: torch.Tensor,
        neighbor_indices: torch.Tensor,
        states: torch.Tensor,
    ) -> Dict[str, torch.Tensor]:
        """
        –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è batch –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (fallback —Ä–µ–∂–∏–º)
        """
        try:
            logger.debug(
                f"üîç classify_connections_batch_original: –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ - cell_indices.shape={cell_indices.shape}, neighbor_indices.shape={neighbor_indices.shape}, states.shape={states.shape}"
            )

            batch_size, max_neighbors = neighbor_indices.shape
            device = cell_indices.device

            # –°–æ–∑–¥–∞–µ–º –≤–∞–ª–∏–¥–Ω—É—é –º–∞—Å–∫—É (–∏—Å–∫–ª—é—á–∞–µ–º -1 padding)
            valid_mask = neighbor_indices >= 0

        except Exception as e:
            import traceback

            logger.error(
                f"‚ùå –û–®–ò–ë–ö–ê –≤ classify_connections_batch_original (–Ω–∞—á–∞–ª–æ): {e}"
            )
            logger.error(f"üìç Traceback:\n{traceback.format_exc()}")
            raise

        if valid_mask.sum().item() == 0:
            return self._empty_classification_result(batch_size, max_neighbors, device)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ –ø–∞—Ä—ã
        valid_cells = cell_indices.unsqueeze(1).expand(-1, max_neighbors)[valid_mask]
        valid_neighbors = neighbor_indices[valid_mask]

        # 1. –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        euclidean_distances = self.distance_calculator.euclidean_distance_batch(
            valid_cells, valid_neighbors
        )

        # 2. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é
        local_mask_flat = euclidean_distances <= self.local_distance_threshold
        distant_mask_flat = euclidean_distances >= self.distant_distance_threshold
        # –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–≤—è–∑–∏: –º–µ–∂–¥—É local –∏ functional_distance_threshold
        functional_candidate_mask = (
            euclidean_distances > self.local_distance_threshold
        ) * (euclidean_distances <= self.functional_distance_threshold)
        # –°—Ä–µ–¥–Ω–∏–µ —Å–≤—è–∑–∏: –º–µ–∂–¥—É functional_distance –∏ distant_threshold (–±—É–¥—É—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –Ω–∞ similarity)
        middle_mask = (euclidean_distances > self.functional_distance_threshold) * (
            euclidean_distances < self.distant_distance_threshold
        )

        # 3. –£—Ç–æ—á–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π
        # –ü—Ä—è–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ (–±–ª–∏–∑–∫–∏–µ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é)
        functional_mask_flat = functional_candidate_mask.clone()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ —Å–≤—è–∑–∏ –Ω–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –±–ª–∏–∑–æ—Å—Ç—å
        if middle_mask.sum().item() > 0:
            middle_cells = valid_cells[middle_mask]
            middle_neighbors = valid_neighbors[middle_mask]

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤ –ø–µ—Ä–µ–¥ –¥–æ—Å—Ç—É–ø–æ–º –∫ states
            max_index = states.shape[0] - 1
            valid_middle_cells = middle_cells <= max_index
            valid_middle_neighbors = middle_neighbors <= max_index

            if not (valid_middle_cells.all() and valid_middle_neighbors.all()):
                logger.warning(
                    f"‚ö†Ô∏è –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã: cells max={middle_cells.max().item()}, neighbors max={middle_neighbors.max().item()}, states size={states.shape[0]}"
                )
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
                valid_pairs = valid_middle_cells & valid_middle_neighbors
                if valid_pairs.sum().item() == 0:
                    logger.warning("‚ö†Ô∏è –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–∞—Ä –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏")
                else:
                    middle_cells = middle_cells[valid_pairs]
                    middle_neighbors = middle_neighbors[valid_pairs]
                    cell_states = states[middle_cells]
                    neighbor_states = states[middle_neighbors]

                    similarities = self.similarity_analyzer(
                        cell_states, neighbor_states
                    )
                    high_similarity = (
                        similarities > self.functional_similarity_threshold
                    )

                    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ —Å–≤—è–∑–∏ —Å –≤—ã—Å–æ–∫–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç—å—é –∫ functional
                    middle_indices = torch.where(middle_mask)[0]
                    valid_middle_indices = middle_indices[valid_pairs]
                    functional_additions = valid_middle_indices[high_similarity]
                    functional_mask_flat[functional_additions] = True
            else:
                cell_states = states[middle_cells]
                neighbor_states = states[middle_neighbors]

                similarities = self.similarity_analyzer(cell_states, neighbor_states)
                high_similarity = similarities > self.functional_similarity_threshold

                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ —Å–≤—è–∑–∏ —Å –≤—ã—Å–æ–∫–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç—å—é –∫ functional
                middle_indices = torch.where(middle_mask)[0]
                functional_additions = middle_indices[high_similarity]
                functional_mask_flat[functional_additions] = True

        # 4. –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–æ—Ä–º—É –º–∞—Å–æ–∫
        local_mask = torch.zeros(
            batch_size, max_neighbors, dtype=torch.bool, device=device
        )
        functional_mask = torch.zeros(
            batch_size, max_neighbors, dtype=torch.bool, device=device
        )
        distant_mask = torch.zeros(
            batch_size, max_neighbors, dtype=torch.bool, device=device
        )

        local_mask[valid_mask] = local_mask_flat
        functional_mask[valid_mask] = functional_mask_flat
        distant_mask[valid_mask] = distant_mask_flat

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._update_stats_batch(local_mask, functional_mask, distant_mask)

        return self._create_batch_classification_result(
            batch_size,
            max_neighbors,
            valid_mask,
            local_mask,
            functional_mask,
            distant_mask,
            device,
        )

    def classify_connections(
        self,
        cell_idx: int,
        neighbor_indices: List[int],
        cell_state: torch.Tensor,
        neighbor_states: torch.Tensor,
    ) -> Dict[ConnectionCategory, List[ConnectionInfo]]:
        """–ï–¥–∏–Ω–∏—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–≤—è–∑–µ–π —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Å—Ç—ã–µ neighbor_indices
        if torch.is_tensor(neighbor_indices):
            if neighbor_indices.numel() == 0:
                return {cat: [] for cat in ConnectionCategory}
        else:
            if not neighbor_indices:
                return {cat: [] for cat in ConnectionCategory}

        # –¢–†–ï–ë–£–ï–ú –∫—ç—à - –Ω–∏–∫–∞–∫–∏—Ö fallback'–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ CLAUDE.md
        logger.debug(f"üîç classify_connections –¥–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx}: cache_manager={self.cache_manager is not None}")
        logger.debug(f"üîç neighbor_indices type={type(neighbor_indices)}, len={len(neighbor_indices) if hasattr(neighbor_indices, '__len__') else 'N/A'}")
        logger.debug(f"üîç neighbor_states.shape={neighbor_states.shape}")
        
        if self.cache_manager is None:
            raise RuntimeError(
                f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: cache_manager –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –¥–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx}. "
                f"–°–æ–≥–ª–∞—Å–Ω–æ CLAUDE.md fallback'–∏ –∑–∞–ø—Ä–µ—â–µ–Ω—ã - –∏—Å–ø—Ä–∞–≤—å—Ç–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –∫—ç—à–∞."
            )
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¢–û–õ–¨–ö–û –∫—ç—à
        logger.debug(f"üîç Attempting cache lookup for cell {cell_idx}")
        try:
            # –°–æ–∑–¥–∞–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–∞–º—è—Ç–∏
            cell_state_normalized = (
                cell_state.unsqueeze(0) if cell_state.dim() == 1 else cell_state
            )
            neighbor_states_normalized = (
                neighbor_states
                if neighbor_states.dim() == 2
                else neighbor_states.unsqueeze(0)
            )

            # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –º–∞—Å—Å–∏–≤ —Å–æ—Å—Ç–æ—è–Ω–∏–π: [cell_state, neighbor_states]
            all_states = torch.cat(
                [cell_state_normalized, neighbor_states_normalized], dim=0
            )

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –≤ –ª–æ–∫–∞–ª—å–Ω—ã–µ
            # all_states[0] = cell_state, all_states[1:] = neighbor_states
            neighbor_indices_list = (
                neighbor_indices
                if isinstance(neighbor_indices, list)
                else neighbor_indices.tolist()
            )
            
            # –°–æ–∑–¥–∞–µ–º mapping: global_neighbor_idx -> local_idx (1-based, —Ç.–∫. 0 = cell)
            global_to_local = {global_idx: local_idx + 1 
                             for local_idx, global_idx in enumerate(neighbor_indices_list)}
            
            # –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –∫—ç—à–∞ (–Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å 1, —Ç.–∫. 0 = cell_state)
            local_neighbor_indices = list(range(1, len(neighbor_indices_list) + 1))

            result = self.cache_manager.get_cached_connections(
                cell_idx=cell_idx,
                neighbor_indices=local_neighbor_indices,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
                states=all_states,
                functional_similarity_threshold=self.functional_similarity_threshold,
            )

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –æ–±—Ä–∞—Ç–Ω–æ –≤ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ
            # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞—Ç–Ω—ã–π mapping: local_idx -> global_idx
            local_to_global = {local_idx + 1: global_idx 
                             for local_idx, global_idx in enumerate(neighbor_indices_list)}
            local_to_global[0] = cell_idx  # –ö–ª–µ—Ç–∫–∞ —Å–∞–º–∞ —Å —Å–æ–±–æ–π
            
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å—ã –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
            corrected_result = {}
            for category, connections in result.items():
                corrected_connections = []
                for conn in connections:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º target_idx –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –≤ –≥–ª–æ–±–∞–ª—å–Ω—ã–π
                    if hasattr(conn, 'target_idx') and conn.target_idx in local_to_global:
                        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π ConnectionInfo —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º target_idx
                        corrected_conn = ConnectionInfo(
                            source_idx=conn.source_idx,
                            target_idx=local_to_global[conn.target_idx],  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å
                            euclidean_distance=conn.euclidean_distance,
                            manhattan_distance=conn.manhattan_distance,
                            category=conn.category,
                            strength=conn.strength,
                            functional_similarity=getattr(conn, 'functional_similarity', None)
                        )
                        corrected_connections.append(corrected_conn)
                    else:
                        corrected_connections.append(conn)  # –û—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                corrected_result[category] = corrected_connections

            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–∏ cache hit
            self._update_stats_from_result(corrected_result)

            self.performance_stats["cache_hits"] += 1
            logger.debug(f"‚úÖ Cache hit –¥–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx}")
            logger.debug(
                f"üìä Cache result: LOCAL={len(corrected_result.get(ConnectionCategory.LOCAL, []))}, FUNCTIONAL={len(corrected_result.get(ConnectionCategory.FUNCTIONAL, []))}, DISTANT={len(corrected_result.get(ConnectionCategory.DISTANT, []))}"
            )
            return corrected_result

        except Exception as e:
            # –°–æ–≥–ª–∞—Å–Ω–æ CLAUDE.md - –Ω–∏–∫–∞–∫–∏—Ö fallback'–æ–≤, —Å—Ä–∞–∑—É –ø–æ–¥–Ω–∏–º–∞–µ–º –æ—à–∏–±–∫—É
            raise RuntimeError(
                f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ö—ç—à failed –¥–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx}: {e}. "
                f"–°–æ–≥–ª–∞—Å–Ω–æ CLAUDE.md fallback'–∏ –∑–∞–ø—Ä–µ—â–µ–Ω—ã - –∏—Å–ø—Ä–∞–≤—å—Ç–µ –ø—Ä–æ–±–ª–µ–º—É —Å –∫—ç—à–µ–º."
            ) from e

    def _classify_connections_original(
        self,
        cell_idx: int,
        neighbor_indices: List[int],
        cell_state: torch.Tensor,
        neighbor_states: torch.Tensor,
    ) -> Dict[ConnectionCategory, List[ConnectionInfo]]:
        """–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –µ–¥–∏–Ω–∏—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (fallback)"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ batch —Ñ–æ—Ä–º–∞—Ç
        cell_tensor = torch.tensor([cell_idx], device=cell_state.device)
        if torch.is_tensor(neighbor_indices):
            neighbor_tensor = neighbor_indices.unsqueeze(0)  # [1, num_neighbors]
        else:
            neighbor_tensor = torch.tensor([neighbor_indices], device=cell_state.device)

        # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏–π
        try:
            logger.debug(
                f"üîç concat debug: cell_state.shape={cell_state.shape}, neighbor_states.shape={neighbor_states.shape}"
            )

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏
            if cell_state.dim() == 0:
                raise ValueError(
                    f"cell_state –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–∫–∞–ª—è—Ä–æ–º, –ø–æ–ª—É—á–µ–Ω–æ: {cell_state.shape}"
                )
            elif cell_state.dim() == 1:
                cell_state_normalized = cell_state.unsqueeze(0)
            elif cell_state.dim() == 2 and cell_state.shape[0] == 1:
                cell_state_normalized = cell_state
            else:
                raise ValueError(
                    f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å cell_state: {cell_state.shape}, –æ–∂–∏–¥–∞–ª–æ—Å—å [state_size] –∏–ª–∏ [1, state_size]"
                )

            # neighbor_states –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å [num_neighbors, state_size]
            if neighbor_states.dim() == 1:
                # [state_size] -> [1, state_size] (—Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å–æ—Å–µ–¥)
                neighbor_states_normalized = neighbor_states.unsqueeze(0)
            elif neighbor_states.dim() == 2:
                # [num_neighbors, state_size] - —É–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                neighbor_states_normalized = neighbor_states
            else:
                raise ValueError(
                    f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å neighbor_states: {neighbor_states.shape}, –æ–∂–∏–¥–∞–ª–æ—Å—å [state_size] –∏–ª–∏ [num_neighbors, state_size]"
                )

            # –ö–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ–º states: [1, state_size] + [num_neighbors, state_size] = [1+num_neighbors, state_size]
            all_states = torch.cat(
                [cell_state_normalized, neighbor_states_normalized], dim=0
            )
            logger.debug(f"üîç all_states.shape –ø–æ—Å–ª–µ concat: {all_states.shape}")

        except Exception as e:
            logger.error(f"‚ùå concat error: {e}")
            logger.error(
                f"üîç cell_state.shape={cell_state.shape}, neighbor_states.shape={neighbor_states.shape}"
            )
            logger.error(
                f"üîç cell_state_normalized.shape={locals().get('cell_state_normalized', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')}"
            )
            logger.error(
                f"üîç neighbor_states_normalized.shape={locals().get('neighbor_states_normalized', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')}"
            )
            raise

        # –í—ã–∑—ã–≤–∞–µ–º batch –≤–µ—Ä—Å–∏—é
        batch_result = self._classify_connections_batch_original(
            cell_tensor, neighbor_tensor, all_states
        )

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞—Ç–Ω–æ
        result = {cat: [] for cat in ConnectionCategory}

        for i, neighbor_idx in enumerate(neighbor_indices):
            if batch_result["local_mask"][0, i].item():
                category = ConnectionCategory.LOCAL
            elif batch_result["functional_mask"][0, i].item():
                category = ConnectionCategory.FUNCTIONAL
            elif batch_result["distant_mask"][0, i].item():
                category = ConnectionCategory.DISTANT
            else:
                continue  # –ò—Å–∫–ª—é—á–µ–Ω–Ω—ã–π —Å–æ—Å–µ–¥

            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
            euclidean_dist = self.distance_calculator.euclidean_distance(
                cell_idx, neighbor_idx
            )
            manhattan_dist = self.distance_calculator.manhattan_distance(
                cell_idx, neighbor_idx
            )

            connection_info = ConnectionInfo(
                source_idx=cell_idx,
                target_idx=neighbor_idx,
                euclidean_distance=euclidean_dist,
                manhattan_distance=manhattan_dist,
                category=category,
            )

            result[category].append(connection_info)

        return result

    def _empty_classification_result(
        self, batch_size: int, max_neighbors: int, device: torch.device
    ) -> Dict[str, torch.Tensor]:
        """–ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        return {
            "local_mask": torch.zeros(
                batch_size, max_neighbors, dtype=torch.bool, device=device
            ),
            "functional_mask": torch.zeros(
                batch_size, max_neighbors, dtype=torch.bool, device=device
            ),
            "distant_mask": torch.zeros(
                batch_size, max_neighbors, dtype=torch.bool, device=device
            ),
            "valid_mask": torch.zeros(
                batch_size, max_neighbors, dtype=torch.bool, device=device
            ),
        }

    def _create_batch_classification_result(
        self,
        batch_size: int,
        max_neighbors: int,
        valid_mask: torch.Tensor,
        local_mask: torch.Tensor,
        functional_mask: torch.Tensor,
        distant_mask: torch.Tensor,
        device: torch.device,
    ) -> Dict[str, torch.Tensor]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ batch –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        return {
            "local_mask": local_mask,
            "functional_mask": functional_mask,
            "distant_mask": distant_mask,
            "valid_mask": valid_mask,
        }

    def _update_stats_batch(
        self,
        local_mask: torch.Tensor,
        functional_mask: torch.Tensor,
        distant_mask: torch.Tensor,
    ):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        self.usage_stats["local_count"] += local_mask.sum().item()
        self.usage_stats["functional_count"] += functional_mask.sum().item()
        self.usage_stats["distant_count"] += distant_mask.sum().item()
        self.usage_stats["total_classifications"] += 1

    def get_classification_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤–∫–ª—é—á–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫—ç—à–∞"""
        total = max(
            1,
            self.usage_stats["local_count"]
            + self.usage_stats["functional_count"]
            + self.usage_stats["distant_count"],
        )

        stats = {
            "local_ratio": self.usage_stats["local_count"] / total,
            "functional_ratio": self.usage_stats["functional_count"] / total,
            "distant_ratio": self.usage_stats["distant_count"] / total,
            "total_connections": total,
            "total_classifications": self.usage_stats["total_classifications"],
            "thresholds": {
                "local_distance": self.local_distance_threshold,
                "functional_distance": self.functional_distance_threshold,
                "distant_distance": self.distant_distance_threshold,
                "functional_similarity": self.functional_similarity_threshold,
            },
        }

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫—ç—à–∞ (–µ—Å–ª–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤–∫–ª—é—á–µ–Ω)
        if self.cache_manager is not None:
            cache_stats = self.cache_manager.get_cache_stats()

            stats["cache_performance"] = {
                "cache_enabled": True,
                "performance_monitoring": self.enable_performance_monitoring,
                "detailed_stats": self.enable_detailed_stats,
                "cache_size_mb": cache_stats.get("cache_size_mb", 0),
                "cached_cells": cache_stats.get("cached_cells", 0),
            }

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤–∫–ª—é—á–µ–Ω
            if self.enable_performance_monitoring and self.performance_stats:
                total_requests = self.performance_stats.get(
                    "cache_hits", 0
                ) + self.performance_stats.get("cache_misses", 0)
                hit_rate = self.performance_stats.get("cache_hits", 0) / max(
                    1, total_requests
                )

                stats["cache_performance"].update(
                    {
                        "cache_hit_rate": hit_rate,
                        "cache_hits": self.performance_stats.get("cache_hits", 0),
                        "cache_misses": self.performance_stats.get("cache_misses", 0),
                        "avg_cache_time": self.performance_stats.get(
                            "avg_cache_speedup", 0.0
                        ),
                        "total_cache_time": self.performance_stats.get(
                            "total_cache_time", 0.0
                        ),
                        "total_fallback_time": self.performance_stats.get(
                            "total_fallback_time", 0.0
                        ),
                        "total_classifications": self.performance_stats.get(
                            "total_classifications", 0
                        ),
                    }
                )

                # –í—ã—á–∏—Å–ª—è–µ–º speedup –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
                if (
                    self.performance_stats.get("total_fallback_time", 0) > 0
                    and self.performance_stats.get("total_cache_time", 0) > 0
                ):
                    avg_fallback_time = self.performance_stats[
                        "total_fallback_time"
                    ] / max(1, self.performance_stats.get("cache_misses", 1))
                    avg_cache_time = self.performance_stats["total_cache_time"] / max(
                        1, self.performance_stats.get("cache_hits", 1)
                    )
                    speedup = avg_fallback_time / max(0.001, avg_cache_time)
                    stats["cache_performance"]["speedup_ratio"] = speedup

        else:
            stats["cache_performance"] = {
                "cache_enabled": False,
                "fallback_mode": True,
                "performance_monitoring": self.enable_performance_monitoring,
                "detailed_stats": self.enable_detailed_stats,
                "cache_size_mb": 0,
                "cached_cells": 0,
                "cache_hit_rate": 0.0,
                "cache_hits": 0,
                "cache_misses": 0,
                "avg_cache_time": 0.0,
                "total_cache_time": 0.0,
                "total_fallback_time": 0.0,
                "total_classifications": 0,
                "speedup_ratio": 1.0,
            }

        return stats

    def reset_stats(self):
        """–°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        self.usage_stats = {
            "local_count": 0,
            "functional_count": 0,
            "distant_count": 0,
            "total_classifications": 0,
        }

        if self.enable_performance_monitoring:
            self.performance_stats = {
                "cache_hits": 0,
                "cache_misses": 0,
                "total_classifications": 0,
                "avg_cache_speedup": 0.0,
                "total_fallback_time": 0.0,
                "total_cache_time": 0.0,
            }
        else:
            self.performance_stats = {}

    def rebuild_cache(self, force: bool = True):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∞ –∫—ç—à–∞"""
        if self.cache_manager is not None:
            logger.info("üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∞ –∫—ç—à–∞...")
            self.cache_manager.clear_cache()
            self.cache_manager.precompute_all_connections(force_rebuild=force)
            logger.info("‚úÖ –ö—ç—à –ø–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω")
        else:
            logger.warning("Cache manager –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")

    def get_cache_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞"""
        if self.cache_manager is not None:
            return self.cache_manager.get_cache_stats()
        else:
            return {"status": "disabled"}

    def _update_stats_from_result(
        self, result: Dict[ConnectionCategory, List[ConnectionInfo]]
    ):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        local_count = len(result.get(ConnectionCategory.LOCAL, []))
        functional_count = len(result.get(ConnectionCategory.FUNCTIONAL, []))
        distant_count = len(result.get(ConnectionCategory.DISTANT, []))

        self.usage_stats["local_count"] += local_count
        self.usage_stats["functional_count"] += functional_count
        self.usage_stats["distant_count"] += distant_count
        self.usage_stats["total_classifications"] += 1

        logger.debug(
            f"üìä Stats updated: LOCAL+{local_count}, FUNCTIONAL+{functional_count}, DISTANT+{distant_count}"
        )
