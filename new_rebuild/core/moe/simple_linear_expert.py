#!/usr/bin/env python3
"""
Optimized Simple Linear Expert - Ð´Ð»Ñ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÑÐ²ÑÐ·ÐµÐ¹ (10%)
=========================================================

ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð»Ð¸Ð½ÐµÐ¹Ð½Ñ‹Ð¹ ÑÐºÑÐ¿ÐµÑ€Ñ‚ Ñ Ñ„Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¹ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¾Ð¹.
ÐÐ½Ð°Ð»Ð¾Ð³Ð¸Ñ: Ñ€ÐµÑ„Ð»ÐµÐºÑÑ‹ Ð² Ð½ÐµÑ€Ð²Ð½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ðµ - Ð±Ñ‹ÑÑ‚Ñ€Ð°Ñ Ñ€ÐµÐ°ÐºÑ†Ð¸Ñ Ð±ÐµÐ· ÑÐ»Ð¾Ð¶Ð½Ñ‹Ñ… Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ð¹.

ÐÐ Ð¥Ð˜Ð¢Ð•ÐšÐ¢Ð£Ð Ð:
- Ð¤Ð˜ÐšÐ¡Ð˜Ð ÐžÐ’ÐÐÐÐÐ¯ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ð½ÐµÐ·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ Ð¾Ñ‚ max_neighbors
- Attention-based Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° ÑÐ¾ÑÐµÐ´ÐµÐ¹
- Ð”Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð²ÐµÑÐ° Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ñ€ÑƒÑŽÑ‚ÑÑ Ðº Ð»ÑŽÐ±Ð¾Ð¼Ñƒ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ñƒ ÑÐ¾ÑÐµÐ´ÐµÐ¹
- Ð’ÑÐµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð½Ð°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÑŽÑ‚ÑÑ Ñ‡ÐµÑ€ÐµÐ· Ñ†ÐµÐ½Ñ‚Ñ€Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ„Ð¸Ð³

ÐŸÐ Ð˜ÐÐ¦Ð˜ÐŸÐ«:
1. Ð¤Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²
2. ÐÐ´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ðº Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¼Ñƒ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ñƒ ÑÐ¾ÑÐµÐ´ÐµÐ¹
3. Ð‘Ð¸Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¿Ñ€Ð°Ð²Ð´Ð¾Ð¿Ð¾Ð´Ð¾Ð±Ð½Ð¾ÑÑ‚ÑŒ (Ñ€ÐµÑ„Ð»ÐµÐºÑÑ‹)
4. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ñ‡ÐµÑ€ÐµÐ· Ñ†ÐµÐ½Ñ‚Ñ€Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ„Ð¸Ð³
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, Dict, Any

from ...config import get_project_config
from ...utils.logging import get_logger, log_cell_init, log_cell_forward

logger = get_logger(__name__)


class OptimizedSimpleLinearExpert(nn.Module):
    """
    ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ ÑÐºÑÐ¿ÐµÑ€Ñ‚ Ñ Ñ„Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸ Ð´Ð»Ñ local connections (10%)

    Ð¤Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ð½ÐµÐ·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ Ð¾Ñ‚ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° ÑÐ¾ÑÐµÐ´ÐµÐ¹.
    ÐÐ´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° ÑÐ¾ÑÐµÐ´ÐµÐ¹.
    """

    def __init__(self, state_size: int):
        super().__init__()

        config = get_project_config()
        local_config = config.expert.local

        self.state_size = state_size
        self.target_params = local_config.params  # Ð˜Ð· ÐºÐ¾Ð½Ñ„Ð¸Ð³Ð°

        # === Ð¤Ð˜ÐšÐ¡Ð˜Ð ÐžÐ’ÐÐÐÐÐ¯ ÐÐ Ð¥Ð˜Ð¢Ð•ÐšÐ¢Ð£Ð Ð ===

        # 1. Neighbor aggregator - Ñ„Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€Ñ‹ Ð¸Ð· ÐºÐ¾Ð½Ñ„Ð¸Ð³Ð°
        self.neighbor_aggregator = nn.Sequential(
            nn.Linear(
                state_size, local_config.neighbor_agg_hidden1, bias=True
            ),  # state_size * hidden1 + hidden1
            nn.GELU(),
            nn.Linear(
                local_config.neighbor_agg_hidden1,
                local_config.neighbor_agg_hidden2,
                bias=True,
            ),  # hidden1 * hidden2 + hidden2
        )

        # 2. State processor - ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€ÑƒÐµÑ‚ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ + Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸ÑŽ
        processor_input_size = state_size + local_config.neighbor_agg_hidden2
        self.state_processor = nn.Sequential(
            nn.Linear(
                processor_input_size, local_config.processor_hidden, bias=True
            ),  # (state_size + hidden2) * processor_hidden + processor_hidden
            nn.GELU(),
            nn.Linear(
                local_config.processor_hidden, state_size, bias=True
            ),  # processor_hidden * state_size + state_size
        )

        # 3. Residual connection parameters Ð¸Ð· ÐºÐ¾Ð½Ñ„Ð¸Ð³Ð°
        self.alpha = nn.Parameter(torch.tensor(local_config.alpha))  # 1 Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€
        self.beta = nn.Parameter(torch.tensor(local_config.beta))  # 1 Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€

        # 4. ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸
        self.normalization = nn.LayerNorm(state_size, bias=True)

        # 5. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð´Ð»Ñ adaptive Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ð¸
        self.max_neighbors_buffer = local_config.max_neighbors_buffer
        self.use_attention = local_config.use_attention

        # ÐŸÐ¾Ð´ÑÑ‡ÐµÑ‚ Ð¸ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²
        total_params = sum(p.numel() for p in self.parameters())

        log_cell_init(
            cell_type="OptimizedSimpleLinearExpert",
            total_params=total_params,
            target_params=self.target_params,
            state_size=state_size,
            config=local_config,
        )

        logger.info(
            f"OptimizedSimpleLinearExpert: {total_params} Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² "
            f"(Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð°: {local_config.neighbor_agg_hidden1}->{local_config.neighbor_agg_hidden2} | "
            f"{processor_input_size}->{local_config.processor_hidden}->{state_size})"
        )

    def forward(
        self, current_state: torch.Tensor, neighbor_states: torch.Tensor, **kwargs
    ) -> torch.Tensor:
        """
        Ð‘Ñ‹ÑÑ‚Ñ€Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÑÐ¾ÑÐµÐ´ÐµÐ¹ Ñ Ñ„Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¹ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¾Ð¹

        Args:
            current_state: [batch, state_size] - Ñ‚ÐµÐºÑƒÑ‰ÐµÐµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ
            neighbor_states: [batch, num_neighbors, state_size] - ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ ÑÐ¾ÑÐµÐ´ÐµÐ¹

        Returns:
            new_state: [batch, state_size] - Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ð¾Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ
        """
        batch_size, num_neighbors, _ = neighbor_states.shape

        if num_neighbors == 0:
            # ÐÐµÑ‚ ÑÐ¾ÑÐµÐ´ÐµÐ¹ - Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ
            return self.normalization(current_state)

        # 1. ÐÐ´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ñ ÑÐ¾ÑÐµÐ´ÐµÐ¹
        logger.debug(f"ðŸ” use_attention={self.use_attention}, num_neighbors={num_neighbors}")
        if self.use_attention and num_neighbors > 1:
            # Attention-based Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ñ (Ð½ÐµÐ·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ Ð¾Ñ‚ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° ÑÐ¾ÑÐµÐ´ÐµÐ¹)
            # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚Ð¸ current_state
            if current_state.dim() == 3:
                current_flat = current_state.squeeze(1)  # [1, 1, 32] -> [1, 32]
            else:
                current_flat = current_state  # [1, 32]
            
            logger.debug(f"ðŸ” attention: current_flat.shape={current_flat.shape}, neighbor_states.shape={neighbor_states.shape}")
            current_expanded = current_flat.expand(neighbor_states.shape[0], -1)  # [num_neighbors, state_size]
            logger.debug(f"ðŸ” attention: current_expanded.shape={current_expanded.shape}")
            
            attention_weights = F.softmax(
                torch.sum(neighbor_states * current_expanded, dim=-1), dim=0
            )  # [num_neighbors]
            logger.debug(f"ðŸ” attention: attention_weights.shape={attention_weights.shape}")
            
            aggregated_neighbors = torch.sum(
                neighbor_states * attention_weights.unsqueeze(-1), dim=0, keepdim=True
            )  # [1, state_size]
            logger.debug(f"ðŸ” attention: Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ aggregated_neighbors.shape={aggregated_neighbors.shape}")
        else:
            # ÐŸÑ€Ð¾ÑÑ‚Ð¾Ðµ ÑƒÑÑ€ÐµÐ´Ð½ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÑÐ¾ÑÐµÐ´Ð° Ð¸Ð»Ð¸ fallback
            aggregated_neighbors = torch.mean(neighbor_states, dim=0, keepdim=True)

        # 2. ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð°Ð³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… ÑÐ¾ÑÐµÐ´ÐµÐ¹ Ñ‡ÐµÑ€ÐµÐ· Ñ„Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½ÑƒÑŽ ÑÐµÑ‚ÑŒ
        logger.debug(f"ðŸ” aggregated_neighbors.shape={aggregated_neighbors.shape}")
        neighbor_features = self.neighbor_aggregator(aggregated_neighbors)
        logger.debug(f"ðŸ” neighbor_features Ð¿Ð¾ÑÐ»Ðµ aggregator.shape={neighbor_features.shape}")

        # 3. ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ñ‚ÐµÐºÑƒÑ‰ÐµÐµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ð¼Ð¸ ÑÐ¾ÑÐµÐ´ÑÐ¼Ð¸
        # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚Ð¸ Ð´Ð»Ñ ÐºÐ¾Ð½ÐºÐ°Ñ‚ÐµÐ½Ð°Ñ†Ð¸Ð¸
        if current_state.dim() == 3:
            current_for_concat = current_state.squeeze(1)  # [1, 1, 32] -> [1, 32]
        else:
            current_for_concat = current_state  # [1, 32]
            
        # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð»Ð¸ÑˆÐ½Ð¸Ðµ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ñ Ð¸Ð· neighbor_features Ð±Ð¾Ð»ÐµÐµ Ð°Ð³Ñ€ÐµÑÑÐ¸Ð²Ð½Ð¾
        neighbor_for_concat = neighbor_features
        while neighbor_for_concat.dim() > 2:
            # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° 1 Ð¸ ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ ÐµÐ³Ð¾
            dims_to_squeeze = [i for i in range(neighbor_for_concat.dim()) if neighbor_for_concat.shape[i] == 1]
            if dims_to_squeeze:
                neighbor_for_concat = neighbor_for_concat.squeeze(dims_to_squeeze[0])
            else:
                # Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° 1, Ð¿Ñ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼
                neighbor_for_concat = neighbor_for_concat.view(neighbor_for_concat.shape[0], -1)
                break
            
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð¾Ñ‚Ð»Ð°Ð´ÐºÐ¸
        logger.debug(f"ðŸ” Ð Ð°Ð·Ð¼ÐµÑ€Ñ‹ Ð¿ÐµÑ€ÐµÐ´ ÐºÐ¾Ð½ÐºÐ°Ñ‚ÐµÐ½Ð°Ñ†Ð¸ÐµÐ¹: current_for_concat={current_for_concat.shape}, neighbor_for_concat={neighbor_for_concat.shape}")
            
        combined_input = torch.cat([current_for_concat, neighbor_for_concat], dim=-1)

        # 4. ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ‡ÐµÑ€ÐµÐ· Ñ„Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½ÑƒÑŽ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ
        processed = self.state_processor(combined_input)

        # 5. ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸
        processed = self.normalization(processed)

        # 6. Residual connection Ñ learnable ÐºÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚Ð°Ð¼Ð¸
        new_state = self.alpha * current_state + self.beta * processed

        return new_state

    def get_parameter_info(self) -> Dict[str, Any]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ñ… ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð°"""
        param_breakdown = {
            "neighbor_aggregator": sum(
                p.numel() for p in self.neighbor_aggregator.parameters()
            ),
            "state_processor": sum(
                p.numel() for p in self.state_processor.parameters()
            ),
            "alpha": self.alpha.numel(),
            "beta": self.beta.numel(),
            "normalization": sum(p.numel() for p in self.normalization.parameters()),
        }

        total = sum(param_breakdown.values())

        return {
            "total_params": total,
            "target_params": self.target_params,
            "breakdown": param_breakdown,
            "efficiency": (
                f"{total/self.target_params:.1%}" if self.target_params > 0 else "N/A"
            ),
            "architecture": "fixed",
            "adaptive_neighbors": True,
            "use_attention": self.use_attention,
        }


# Backward compatibility alias
SimpleLinearExpert = OptimizedSimpleLinearExpert
