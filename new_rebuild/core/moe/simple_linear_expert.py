#!/usr/bin/env python3
"""
Optimized Simple Linear Expert - –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π (10%)
=========================================================

–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ª–∏–Ω–µ–π–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π.
–ê–Ω–∞–ª–æ–≥–∏—è: —Ä–µ—Ñ–ª–µ–∫—Å—ã –≤ –Ω–µ—Ä–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ - –±—ã—Å—Ç—Ä–∞—è —Ä–µ–∞–∫—Ü–∏—è –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.

–ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
- –§–ò–ö–°–ò–†–û–í–ê–ù–ù–ê–Ø –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç max_neighbors
- Attention-based –∞–≥—Ä–µ–≥–∞—Ü–∏—è –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ—Å–µ–¥–µ–π
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –≤–µ—Å–∞ –∞–¥–∞–ø—Ç–∏—Ä—É—é—Ç—Å—è –∫ –ª—é–±–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–æ—Å–µ–¥–µ–π
- –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥

–ü–†–ò–ù–¶–ò–ü–´:
1. –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
2. –ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å –∫ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–æ—Å–µ–¥–µ–π
3. –ë–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–æ—Å—Ç—å (—Ä–µ—Ñ–ª–µ–∫—Å—ã)
4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —á–µ—Ä–µ–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, Dict, Any

from ...config import get_project_config
from ...utils.logging import get_logger, log_cell_init, log_cell_forward

logger = get_logger(__name__)


class OptimizedSimpleLinearExpert(nn.Module):
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è local connections (10%)

    –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ—Å–µ–¥–µ–π.
    –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ—Å–µ–¥–µ–π.
    """

    def __init__(self, state_size: int):
        super().__init__()

        config = get_project_config()
        local_config = config.expert.local

        self.state_size = state_size
        self.target_params = local_config.params  # –ò–∑ –∫–æ–Ω—Ñ–∏–≥–∞

        # === –§–ò–ö–°–ò–†–û–í–ê–ù–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê ===

        # 1. Neighbor aggregator - —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        self.neighbor_aggregator = nn.Sequential(
            nn.Linear(
                state_size, local_config.neighbor_agg_hidden1, bias=True
            ),  # state_size * hidden1 + hidden1
            nn.GELU(),
            nn.Linear(
                local_config.neighbor_agg_hidden1,
                local_config.neighbor_agg_hidden2,
                bias=True,
            ),  # hidden1 * hidden2 + hidden2
        )

        # 2. State processor - –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ + –∞–≥—Ä–µ–≥–∞—Ü–∏—é
        processor_input_size = state_size + local_config.neighbor_agg_hidden2
        self.state_processor = nn.Sequential(
            nn.Linear(
                processor_input_size, local_config.processor_hidden, bias=True
            ),  # (state_size + hidden2) * processor_hidden + processor_hidden
            nn.GELU(),
            nn.Linear(
                local_config.processor_hidden, state_size, bias=True
            ),  # processor_hidden * state_size + state_size
        )

        # 3. Residual connection parameters –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        self.alpha = nn.Parameter(torch.tensor(local_config.alpha))  # 1 –ø–∞—Ä–∞–º–µ—Ç—Ä
        self.beta = nn.Parameter(torch.tensor(local_config.beta))  # 1 –ø–∞—Ä–∞–º–µ—Ç—Ä

        # 4. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        self.normalization = nn.LayerNorm(state_size, bias=True)

        # 5. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è adaptive –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        self.max_neighbors_buffer = local_config.max_neighbors_buffer
        self.use_attention = local_config.use_attention

        # –ü–æ–¥—Å—á–µ—Ç –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        total_params = sum(p.numel() for p in self.parameters())

        log_cell_init(
            cell_type="OptimizedSimpleLinearExpert",
            total_params=total_params,
            target_params=self.target_params,
            state_size=state_size,
            config=local_config,
        )

        logger.info(
            f"OptimizedSimpleLinearExpert: {total_params} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ "
            f"(–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {local_config.neighbor_agg_hidden1}->{local_config.neighbor_agg_hidden2} | "
            f"{processor_input_size}->{local_config.processor_hidden}->{state_size})"
        )

    def forward(
        self, current_state: torch.Tensor, neighbor_states: torch.Tensor, **kwargs
    ) -> torch.Tensor:
        """
        –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π

        Args:
            current_state: [batch, state_size] - —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            neighbor_states: [batch, num_neighbors, state_size] - —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ—Å–µ–¥–µ–π

        Returns:
            new_state: [batch, state_size] - –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        """
        batch_size, num_neighbors, _ = neighbor_states.shape

        if num_neighbors == 0:
            # –ù–µ—Ç —Å–æ—Å–µ–¥–µ–π - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            return self.normalization(current_state)

        # 1. –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Å–æ—Å–µ–¥–µ–π
        logger.debug(f"üîç use_attention={self.use_attention}, num_neighbors={num_neighbors}")
        if self.use_attention and num_neighbors > 1:
            # Attention-based –∞–≥—Ä–µ–≥–∞—Ü–∏—è (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ—Å–µ–¥–µ–π)
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ current_state
            if current_state.dim() == 3:
                current_flat = current_state.squeeze(1)  # [1, 1, 32] -> [1, 32]
            else:
                current_flat = current_state  # [1, 32]
            
            logger.debug(f"üîç attention: current_flat.shape={current_flat.shape}, neighbor_states.shape={neighbor_states.shape}")
            current_expanded = current_flat.expand(neighbor_states.shape[0], -1)  # [num_neighbors, state_size]
            logger.debug(f"üîç attention: current_expanded.shape={current_expanded.shape}")
            
            attention_weights = F.softmax(
                torch.sum(neighbor_states * current_expanded, dim=-1), dim=0
            )  # [num_neighbors]
            logger.debug(f"üîç attention: attention_weights.shape={attention_weights.shape}")
            
            aggregated_neighbors = torch.sum(
                neighbor_states * attention_weights.unsqueeze(-1), dim=0, keepdim=True
            )  # [1, state_size]
            logger.debug(f"üîç attention: —Ä–µ–∑—É–ª—å—Ç–∞—Ç aggregated_neighbors.shape={aggregated_neighbors.shape}")
        else:
            # –ü—Ä–æ—Å—Ç–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–æ—Å–µ–¥–∞ –∏–ª–∏ fallback
            aggregated_neighbors = torch.mean(neighbor_states, dim=0, keepdim=True)

        # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π —á–µ—Ä–µ–∑ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å–µ—Ç—å
        logger.debug(f"üîç aggregated_neighbors.shape={aggregated_neighbors.shape}")
        neighbor_features = self.neighbor_aggregator(aggregated_neighbors)
        logger.debug(f"üîç neighbor_features –ø–æ—Å–ª–µ aggregator.shape={neighbor_features.shape}")

        # 3. –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ —Å–æ—Å–µ–¥—è–º–∏
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏
        if current_state.dim() == 3:
            current_for_concat = current_state.squeeze(1)  # [1, 1, 32] -> [1, 32]
        else:
            current_for_concat = current_state  # [1, 32]
            
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏–∑ neighbor_features –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ
        neighbor_for_concat = neighbor_features
        while neighbor_for_concat.dim() > 2:
            # –ù–∞—Ö–æ–¥–∏–º –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ 1 –∏ —É–±–∏—Ä–∞–µ–º –µ–≥–æ
            dims_to_squeeze = [i for i in range(neighbor_for_concat.dim()) if neighbor_for_concat.shape[i] == 1]
            if dims_to_squeeze:
                neighbor_for_concat = neighbor_for_concat.squeeze(dims_to_squeeze[0])
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç –∏–∑–º–µ—Ä–µ–Ω–∏–π —Ä–∞–∑–º–µ—Ä–∞ 1, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º
                neighbor_for_concat = neighbor_for_concat.view(neighbor_for_concat.shape[0], -1)
                break
            
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        logger.debug(f"üîç –†–∞–∑–º–µ—Ä—ã –ø–µ—Ä–µ–¥ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–µ–π: current_for_concat={current_for_concat.shape}, neighbor_for_concat={neighbor_for_concat.shape}")
            
        combined_input = torch.cat([current_for_concat, neighbor_for_concat], dim=-1)

        # 4. –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
        processed = self.state_processor(combined_input)

        # 5. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        processed = self.normalization(processed)

        # 6. Residual connection —Å learnable –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏
        new_state = self.alpha * current_state + self.beta * processed

        return new_state

    def get_parameter_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö —ç–∫—Å–ø–µ—Ä—Ç–∞"""
        param_breakdown = {
            "neighbor_aggregator": sum(
                p.numel() for p in self.neighbor_aggregator.parameters()
            ),
            "state_processor": sum(
                p.numel() for p in self.state_processor.parameters()
            ),
            "alpha": self.alpha.numel(),
            "beta": self.beta.numel(),
            "normalization": sum(p.numel() for p in self.normalization.parameters()),
        }

        total = sum(param_breakdown.values())

        return {
            "total_params": total,
            "target_params": self.target_params,
            "breakdown": param_breakdown,
            "efficiency": (
                f"{total/self.target_params:.1%}" if self.target_params > 0 else "N/A"
            ),
            "architecture": "fixed",
            "adaptive_neighbors": True,
            "use_attention": self.use_attention,
        }


# Backward compatibility alias
SimpleLinearExpert = OptimizedSimpleLinearExpert
