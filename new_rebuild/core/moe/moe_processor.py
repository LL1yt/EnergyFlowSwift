#!/usr/bin/env python3
"""
MoE Processor - ÑƒÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ñ‹Ð¹ Mixture of Experts Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€
=====================================================

ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ MoE Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‰Ð¸Ð¹ Ð¼Ð¾Ð´ÑƒÐ»ÑŒÐ½ÑƒÑŽ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ
Ð´Ð»Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÑÐ²ÑÐ·ÐµÐ¹ Ð² 3D Ð½ÐµÐ¹Ñ€Ð¾Ð½Ð½Ð¾Ð¹ Ñ€ÐµÑˆÐµÑ‚ÐºÐµ.
"""

import torch
import torch.nn as nn
from typing import Dict, List, Optional, Any, Tuple
from torch.utils.checkpoint import checkpoint

from .gating_network import GatingNetwork
from .connection_classifier import UnifiedConnectionClassifier
from .connection_types import ConnectionCategory
from .simple_linear_expert import SimpleLinearExpert
from .hybrid_gnn_cnf_expert import HybridGNN_CNF_Expert
from ..cnf.gpu_enhanced_cnf import GPUEnhancedCNF, ConnectionType
from ...config import get_project_config
from ...utils.logging import get_logger, log_cell_forward
from ...utils.device_manager import get_device_manager
from ..lattice.position import Position3D
from ..lattice.spatial_optimization.memory_manager import get_memory_pool_manager

logger = get_logger(__name__)


class MoEConnectionProcessor(nn.Module):
    """
    Ð£Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ñ‹Ð¹ Mixture of Experts Connection Processor Ð´Ð»Ñ 3D Ñ€ÐµÑˆÐµÑ‚ÐºÐ¸ 27Ã—27Ã—27

    Ð­ÐšÐ¡ÐŸÐ•Ð Ð¢Ð«:
    - local_expert: SimpleLinear (2059 params) - 10% ÑÐ²ÑÐ·ÐµÐ¹
    - functional_expert: HybridGNN_CNF (5500-12233 params) - 55% ÑÐ²ÑÐ·ÐµÐ¹
    - distant_expert: LightweightCNF (1500-4000 params) - 35% ÑÐ²ÑÐ·ÐµÐ¹

    Ð£ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð•:
    - gating_network: (808 params) - Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð¾Ðµ Ð²Ð·Ð²ÐµÑˆÐ¸Ð²Ð°Ð½Ð¸Ðµ
    - connection_classifier: ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ ÑÐ²ÑÐ·ÐµÐ¹ Ð¿Ð¾ Ñ‚Ð¸Ð¿Ð°Ð¼
    """

    def __init__(
        self,
        state_size: Optional[int] = None,
        lattice_dimensions: Optional[Tuple[int, int, int]] = None,
        neighbor_count: Optional[int] = None,
        enable_cnf: Optional[bool] = None,
        config: Optional[Any] = None,
        **kwargs,
    ):
        super().__init__()

        if config is None:
            config = get_project_config()

        # === DEVICE MANAGEMENT ===
        self.device_manager = config.device_manager
        self.device = self.device_manager.get_device()
        self.memory_pool_manager = get_memory_pool_manager()

        # === Ð¦Ð•ÐÐ¢Ð ÐÐ›Ð˜Ð—ÐžÐ’ÐÐÐÐÐ¯ ÐšÐžÐÐ¤Ð˜Ð“Ð£Ð ÐÐ¦Ð˜Ð¯ ===
        # Ð¡Ñ‚Ñ€Ð¾Ð³Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° state_size
        if state_size is None:
            if not hasattr(config.model, 'state_size') or config.model.state_size is None:
                raise RuntimeError(
                    "âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ config.model.state_size. "
                    "ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð² project_config.py"
                )
            self.state_size = config.model.state_size
        else:
            self.state_size = state_size

        # Ð¡Ñ‚Ñ€Ð¾Ð³Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° lattice_dimensions
        if lattice_dimensions is None:
            if not hasattr(config.lattice, 'dimensions') or config.lattice.dimensions is None:
                raise RuntimeError(
                    "âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ config.lattice.dimensions. "
                    "ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð² project_config.py"
                )
            self.lattice_dimensions = config.lattice.dimensions
        else:
            self.lattice_dimensions = lattice_dimensions

        self.adaptive_radius = config.calculate_adaptive_radius()
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ max_neighbors Ð¸Ð· NeighborSettings
        if not hasattr(config, "neighbors") or not hasattr(config.neighbors, 'max_neighbors'):
            raise RuntimeError(
                "âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ config.neighbors.max_neighbors. "
                "ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð² project_config.py"
            )
        self.max_neighbors = config.neighbors.max_neighbors
        
        # neighbor_count Ð¸Ð· ModelSettings Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ
        if hasattr(config.model, 'neighbor_count'):
            self.dynamic_neighbors = (config.model.neighbor_count == -1)
        else:
            self.dynamic_neighbors = True
            
        logger.debug(f"[MoEConnectionProcessor] max_neighbors={self.max_neighbors}, dynamic_neighbors={self.dynamic_neighbors}")

        # Ð¡Ñ‚Ñ€Ð¾Ð³Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° enable_cnf
        if enable_cnf is not None:
            self.enable_cnf = enable_cnf
        else:
            if not hasattr(config.cnf, 'enabled'):
                raise RuntimeError(
                    "âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ config.cnf.enabled. "
                    "ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð² project_config.py"
                )
            self.enable_cnf = config.cnf.enabled

        # ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ ÑÐ²ÑÐ·ÐµÐ¹: 10%/55%/35%
        # Ð¡Ð¢Ð ÐžÐ“ÐÐ¯ ÐŸÐ ÐžÐ’Ð•Ð ÐšÐ - Ð‘Ð•Ð— FALLBACK
        if not hasattr(config, "neighbors") or config.neighbors is None:
            raise RuntimeError(
                "âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ config.neighbors. "
                "ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð² project_config.py. "
                "ÐÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ neighbors Ñ Ð¿Ð¾Ð»ÑÐ¼Ð¸ local_tier, functional_tier, distant_tier"
            )
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ð¾Ð»Ñ neighbors
        required_neighbor_fields = ['local_tier', 'functional_tier', 'distant_tier']
        for field in required_neighbor_fields:
            if not hasattr(config.neighbors, field) or getattr(config.neighbors, field) is None:
                raise RuntimeError(
                    f"âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¿Ð¾Ð»Ðµ config.neighbors.{field}. "
                    f"ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ neighbors Ð² project_config.py"
                )
        
        self.connection_ratios = {
            "local": config.neighbors.local_tier,
            "functional": config.neighbors.functional_tier,
            "distant": config.neighbors.distant_tier,
        }

        # === ÐšÐ›ÐÐ¡Ð¡Ð˜Ð¤Ð˜ÐšÐÐ¢ÐžÐ  Ð¡Ð’Ð¯Ð—Ð•Ð™ Ð¡ ÐšÐ­Ð¨Ð˜Ð ÐžÐ’ÐÐÐ˜Ð•Ðœ ===
        self.connection_classifier = UnifiedConnectionClassifier(
            lattice_dimensions=self.lattice_dimensions,
            enable_cache=True,  # Ð’ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ ÐºÑÑˆ Ð´Ð»Ñ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸
        )
        
        # Spatial optimizer Ð±ÑƒÐ´ÐµÑ‚ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½ Ð¿Ð¾Ð·Ð¶Ðµ Ñ‡ÐµÑ€ÐµÐ· setter
        # self.spatial_optimizer = None

        # === Ð­ÐšÐ¡ÐŸÐ•Ð Ð¢Ð« ===
        self.local_expert = SimpleLinearExpert(state_size=self.state_size)

        # Ð¡Ð¢Ð ÐžÐ“ÐÐ¯ ÐŸÐ ÐžÐ’Ð•Ð ÐšÐ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð¾Ð² - Ð‘Ð•Ð— FALLBACK
        if not hasattr(config, "expert") or config.expert is None:
            raise RuntimeError(
                "âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ config.expert. "
                "ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð¾Ð² Ð² project_config.py"
            )
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° functional expert
        if not hasattr(config.expert, "functional") or config.expert.functional is None:
            raise RuntimeError(
                "âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ config.expert.functional. "
                "ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ functional expert Ð² ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸"
            )
        
        if not hasattr(config.expert.functional, "params") or config.expert.functional.params is None:
            raise RuntimeError(
                "âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ config.expert.functional.params. "
                "Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð´Ð»Ñ functional expert"
            )
        
        functional_params = config.expert.functional.params
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° distant expert
        if not hasattr(config.expert, "distant") or config.expert.distant is None:
            raise RuntimeError(
                "âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ config.expert.distant. "
                "ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ distant expert Ð² ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸"
            )
        
        if not hasattr(config.expert.distant, "params") or config.expert.distant.params is None:
            raise RuntimeError(
                "âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ config.expert.distant.params. "
                "Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð´Ð»Ñ distant expert"
            )
        
        distant_params = config.expert.distant.params

        # Ð”Ð»Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÐ¾ÑÐµÐ´ÐµÐ¹
        self.functional_expert = HybridGNN_CNF_Expert(
            state_size=self.state_size,
            neighbor_count=-1 if self.dynamic_neighbors else self.max_neighbors,  # -1 Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ
            target_params=functional_params,
            cnf_params=distant_params,
        )
        logger.info(f"[MoEConnectionProcessor] Functional expert ÑÐ¾Ð·Ð´Ð°Ð½ Ñ neighbor_count={-1 if self.dynamic_neighbors else self.max_neighbors}")

        # 3. Distant Expert - Ð´Ð¾Ð»Ð³Ð¾ÑÑ€Ð¾Ñ‡Ð½Ð°Ñ Ð¿Ð°Ð¼ÑÑ‚ÑŒ (LightweightCNF)
        # Ð¡Ð¢Ð ÐžÐ“ÐÐ¯ ÐŸÐ ÐžÐ’Ð•Ð ÐšÐ - Ð‘Ð•Ð— FALLBACK Ð´Ð»Ñ CNF
        if not self.enable_cnf:
            raise RuntimeError(
                "âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: CNF Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½ (config.cnf.enabled=False), "
                "Ð½Ð¾ MoE Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ CNF Ð´Ð»Ñ distant_expert. "
                "Ð’ÐºÐ»ÑŽÑ‡Ð¸Ñ‚Ðµ CNF Ð² ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸: config.cnf.enabled = True"
            )
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ CNF
        cnf_required_fields = ['integration_steps', 'batch_processing_mode', 'max_batch_size', 'adaptive_method']
        for field in cnf_required_fields:
            if not hasattr(config.cnf, field) or getattr(config.cnf, field) is None:
                raise RuntimeError(
                    f"âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ config.cnf.{field}. "
                    f"ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ CNF Ð² project_config.py"
                )
        
        self.distant_expert = GPUEnhancedCNF(
            state_size=self.state_size,
            connection_type=ConnectionType.DISTANT,
            integration_steps=config.cnf.integration_steps,
            batch_processing_mode=config.cnf.batch_processing_mode,
            max_batch_size=config.cnf.max_batch_size,
            adaptive_method=config.cnf.adaptive_method,
        )

        # === GATING NETWORK ===
        self.gating_network = GatingNetwork(state_size=self.state_size, num_experts=3)

        # === Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ ===
        self.reset_stats()

        # ÐŸÐ¾Ð´ÑÑ‡ÐµÑ‚ Ð¾Ð±Ñ‰Ð¸Ñ… Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²
        total_params = sum(p.numel() for p in self.parameters())
        logger.info(f"MoEConnectionProcessor: {total_params} Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð²ÑÐµÐ³Ð¾")

        # ÐŸÐµÑ€ÐµÐ½Ð¾Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ðµ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾
        self.device_manager.transfer_module(self)
        logger.info(f"MoEConnectionProcessor Ð¿ÐµÑ€ÐµÐ½ÐµÑÐµÐ½ Ð½Ð° ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾: {self.device}")
        
    def forward(
        self,
        current_state: torch.Tensor,
        neighbor_states: torch.Tensor,  # DEPRECATED - Ð±ÑƒÐ´ÐµÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾ Ð¸Ð· ÐºÑÑˆÐ°
        cell_idx: int,
        neighbor_indices: List[int],  # DEPRECATED - Ð±ÑƒÐ´ÐµÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾ Ð¸Ð· ÐºÑÑˆÐ°
        external_input: Optional[torch.Tensor] = None,
        spatial_optimizer=None,  # DEPRECATED - Ð±Ð¾Ð»ÑŒÑˆÐµ Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ
        **kwargs,
    ) -> Dict[str, Any]:
        # DEBUG: Only log for extreme debug mode
        if logger.isEnabledFor(11):  # DEBUG_VERBOSE only
            logger.debug_verbose(f"ðŸ” MoE FORWARD called for cell {cell_idx}")
        """
        ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ forward pass Ñ ÑƒÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ð¾Ð¹ Ð»Ð¾Ð³Ð¸ÐºÐ¾Ð¹ (ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—Ð˜Ð ÐžÐ’ÐÐÐÐÐ¯ Ð’Ð•Ð Ð¡Ð˜Ð¯)

        Args:
            current_state: [state_size] - Ñ‚ÐµÐºÑƒÑ‰ÐµÐµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ ÐºÐ»ÐµÑ‚ÐºÐ¸
            neighbor_states: DEPRECATED - Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ÑÑ Ð¸Ð· ÐºÑÑˆÐ°
            cell_idx: Ð¸Ð½Ð´ÐµÐºÑ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ ÐºÐ»ÐµÑ‚ÐºÐ¸
            neighbor_indices: DEPRECATED - Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ÑÑ Ð¸Ð· ÐºÑÑˆÐ°
            external_input: Ð²Ð½ÐµÑˆÐ½Ð¸Ð¹ Ð²Ñ…Ð¾Ð´ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
            spatial_optimizer: DEPRECATED - Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ
            **kwargs: Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ full_lattice_states

        Returns:
            Dict Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
        """
        # === ÐÐžÐ’ÐÐ¯ ÐÐ Ð¥Ð˜Ð¢Ð•ÐšÐ¢Ð£Ð Ð: Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐºÑÑˆ ===
        if "full_lattice_states" not in kwargs:
            raise RuntimeError(
                f"âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: Ð”Ð»Ñ ÐºÐ»ÐµÑ‚ÐºÐ¸ {cell_idx} Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ full_lattice_states. "
                f"Ð­Ñ‚Ð¾Ñ‚ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÐµÐ½ Ð´Ð»Ñ Ð½Ð¾Ð²Ð¾Ð¹ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹."
            )
            
        full_states = kwargs["full_lattice_states"]
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÐ¾ÑÐµÐ´ÐµÐ¹ Ð˜ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸ÑŽ Ð¾Ð´Ð½Ð¸Ð¼ Ð²Ñ‹Ð·Ð¾Ð²Ð¾Ð¼ Ð¸Ð· ÐºÑÑˆÐ°
        neighbors_data = self.connection_classifier.get_cached_neighbors_and_classification(
            cell_idx=cell_idx,
            states=full_states
        )
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ñƒ Ð½Ð°Ñ ÐµÑÑ‚ÑŒ Ñ…Ð¾Ñ‚Ñ Ð±Ñ‹ Ð¾Ð´Ð¸Ð½ ÑÐ¾ÑÐµÐ´
        total_neighbors = (
            len(neighbors_data["local"]["indices"]) + 
            len(neighbors_data["functional"]["indices"]) + 
            len(neighbors_data["distant"]["indices"])
        )
        
        if total_neighbors == 0:
            logger.error(f"âŒ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐžÐ¨Ð˜Ð‘ÐšÐ: ÐšÐ»ÐµÑ‚ÐºÐ° {cell_idx} Ð½Ðµ Ð¸Ð¼ÐµÐµÑ‚ ÑÐ¾ÑÐµÐ´ÐµÐ¹ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸!")
            logger.error(f"   Ð­Ñ‚Ð¾ Ð½ÐµÐ²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ Ð² 3D Ñ€ÐµÑˆÐµÑ‚ÐºÐµ - Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ñ€Ð°Ð´Ð¸ÑƒÑ Ð¿Ð¾Ð¸ÑÐºÐ°!")
            raise RuntimeError(
                f"ÐšÐ»ÐµÑ‚ÐºÐ° {cell_idx} Ð¸Ð·Ð¾Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° (0 ÑÐ¾ÑÐµÐ´ÐµÐ¹). "
                f"ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ñ€Ð°Ð´Ð¸ÑƒÑÐ°."
            )

        batch_size = 1
        device = current_state.device

        # Ð£Ð±ÐµÐ¶Ð´Ð°ÐµÐ¼ÑÑ Ñ‡Ñ‚Ð¾ Ð²ÑÐµ tensor'Ñ‹ Ð½Ð° Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ð¼ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ðµ
        current_state = self.device_manager.ensure_device(current_state)
        if external_input is not None:
            external_input = self.device_manager.ensure_device(external_input)
        
        # Cache-based classification results (no logging for performance)

        # === 2. ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ ÐšÐÐ–Ð”Ð«Ðœ Ð­ÐšÐ¡ÐŸÐ•Ð Ð¢ÐžÐœ (ÐÐžÐ’ÐÐ¯ ÐÐ Ð¥Ð˜Ð¢Ð•ÐšÐ¢Ð£Ð Ð) ===
        expert_outputs = []
        tensors_to_return = []

        # Local Expert
        local_data = neighbors_data["local"]
        if local_data["indices"]:
            local_neighbor_states = local_data["states"]

            def local_expert_wrapper(current, neighbors):
                res = self.local_expert(current, neighbors)
                if isinstance(res, dict):
                    return res.get("output", res.get("new_state", current))
                return res

            local_output = checkpoint(
                local_expert_wrapper,
                current_state,
                local_neighbor_states,
                use_reentrant=False,
            )
            logger.debug_forward(
                f"[{cell_idx}] Local expert output shape: {local_output.shape}"
            )

        else:
            local_output = self.memory_pool_manager.get_tensor(
                (1, self.state_size), dtype=current_state.dtype
            )
            tensors_to_return.append(local_output)
        expert_outputs.append(local_output.squeeze(0))

        # Functional Expert
        functional_data = neighbors_data["functional"]
        if functional_data["indices"]:
            functional_neighbor_states = functional_data["states"]

            def functional_expert_wrapper(current, neighbors):
                res = self.functional_expert(current, neighbors)
                if isinstance(res, dict):
                    return res.get("output", res.get("new_state", current))
                return res

            functional_output = checkpoint(
                functional_expert_wrapper,
                current_state,
                functional_neighbor_states,
                use_reentrant=False,
            )
            # Functional expert output processed
        else:
            functional_output = self.memory_pool_manager.get_tensor(
                (1, self.state_size), dtype=current_state.dtype
            )
            tensors_to_return.append(functional_output)
        expert_outputs.append(functional_output.squeeze(0))

        # Distant Expert (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ CNF Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½)
        distant_data = neighbors_data["distant"]
        if self.enable_cnf and distant_data["indices"]:
            distant_neighbor_states = distant_data["states"]

            def distant_expert_wrapper(current, neighbors):
                res = self.distant_expert(current, neighbors)
                if isinstance(res, dict):
                    return res.get("output", res.get("new_state", current))
                return res

            distant_output = checkpoint(
                distant_expert_wrapper,
                current_state,
                distant_neighbor_states,
                use_reentrant=False,
            )
            # Distant expert output processed
        else:
            distant_output = self.memory_pool_manager.get_tensor(
                (1, self.state_size), dtype=current_state.dtype
            )
            tensors_to_return.append(distant_output)
        expert_outputs.append(distant_output.squeeze(0))

        # === 3. ÐšÐžÐœÐ‘Ð˜ÐÐ˜Ð ÐžÐ’ÐÐÐ˜Ð• Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢ÐžÐ’ ===
        try:
            # ÐŸÑ€ÐµÐ´Ð¾Ñ‚Ð²Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ñ Ð¿ÑƒÑÑ‚Ñ‹Ð¼Ð¸ expert_outputs
            if not expert_outputs:
                logger.warning(
                    f"âš ï¸ ÐÐµÑ‚ Ð²Ñ‹Ñ…Ð¾Ð´Ð¾Ð² ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð¾Ð² Ð´Ð»Ñ ÐºÐ»ÐµÑ‚ÐºÐ¸ {cell_idx}, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐº GatingNetwork."
                )
                final_state = current_state
                expert_weights = torch.zeros(
                    1, 3, device=device
                )  # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð½ÑƒÐ»ÐµÐ²Ñ‹Ðµ Ð²ÐµÑÐ°
            else:
                # --- Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð•: ÐÐ³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ñ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ð¹ ÑÐ¾ÑÐµÐ´ÐµÐ¹ ---
                # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ ÑÐ¾ÑÐµÐ´ÐµÐ¹ Ð¸Ð· Ð²ÑÐµÑ… ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¹
                all_neighbor_states = []
                for category in ["local", "functional", "distant"]:
                    if neighbors_data[category]["states"].numel() > 0:
                        all_neighbor_states.append(neighbors_data[category]["states"])
                
                if all_neighbor_states:
                    # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ð²ÑÐµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ ÑÐ¾ÑÐµÐ´ÐµÐ¹
                    combined_neighbor_states = torch.cat(all_neighbor_states, dim=0)
                    neighbor_activity = torch.mean(combined_neighbor_states, dim=0, keepdim=True)
                else:
                    # Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ ÑÐ¾ÑÐµÐ´ÐµÐ¹, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð½ÑƒÐ»ÐµÐ²Ð¾Ð¹ Ð²ÐµÐºÑ‚Ð¾Ñ€
                    neighbor_activity = torch.zeros(
                        1, self.state_size, device=device, dtype=current_state.dtype
                    )
                # neighbor_activity computed

                # Ð’Ñ‹Ð·Ð¾Ð² GatingNetwork Ñ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¼Ð¸ Ð¿Ð¾ Ñ„Ð¾Ñ€Ð¼Ðµ Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ð°Ð¼Ð¸
                logger.debug_forward(f"[{cell_idx}] Ð’Ñ‹Ð·Ð¾Ð² GatingNetwork...")
                combined_output, expert_weights = self.gating_network(
                    current_state=current_state,  # [1, state_size]
                    neighbor_activity=neighbor_activity,  # [1, state_size]
                    expert_outputs=expert_outputs,
                )
                logger.debug_forward(
                    f"[{cell_idx}] GatingNetwork Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½. combined_output: {combined_output.shape}, expert_weights: {expert_weights.shape}"
                )

                # Residual connection
                final_state = current_state + combined_output.squeeze(0)

        except Exception as e:
            logger.error(
                f"âŒ MoE processor CRITICAL error on cell {cell_idx}: {e}",
                exc_info=True,
            )
            # Ð’ ÑÐ»ÑƒÑ‡Ð°Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¿Ñ€ÐµÑ€Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ
            final_state = current_state
            expert_weights = torch.zeros(1, 3, device=device)

        # ÐžÑÐ²Ð¾Ð±Ð¾Ð¶Ð´Ð°ÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ñ‹
        for t in tensors_to_return:
            self.memory_pool_manager.return_tensor(t)

        # === 4. ÐžÐ‘ÐÐžÐ’Ð›Ð•ÐÐ˜Ð• Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ˜ ===
        # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ neighbors_data Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ classifications Ð´Ð»Ñ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚Ð¸
        classifications = {
            ConnectionCategory.LOCAL: [{"target_idx": idx} for idx in neighbors_data["local"]["indices"]],
            ConnectionCategory.FUNCTIONAL: [{"target_idx": idx} for idx in neighbors_data["functional"]["indices"]],
            ConnectionCategory.DISTANT: [{"target_idx": idx} for idx in neighbors_data["distant"]["indices"]]
        }
        self._update_stats(classifications, expert_weights)

        log_cell_forward(
            "MoEConnectionProcessor",
            input_shapes={
                "current_state": current_state.shape,
                "total_neighbors": total_neighbors,
            },
            output_shape=final_state.shape,
        )

        # ÐžÑ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ expert_weights
        logger.debug_training(
            f"[{cell_idx}] Expert weights: {expert_weights.squeeze().tolist()}"
        )

        return {
            "new_state": final_state,
            "expert_weights": expert_weights,
            "classifications": classifications,
        }

    def _empty_forward_result(self, current_state: torch.Tensor) -> Dict[str, Any]:
        """Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð´Ð»Ñ ÑÐ»ÑƒÑ‡Ð°Ñ Ð±ÐµÐ· ÑÐ¾ÑÐµÐ´ÐµÐ¹"""
        return {
            "new_state": current_state,
            "expert_weights": torch.tensor(
                [1.0, 0.0, 0.0], device=current_state.device
            ),
            "classifications": {cat: [] for cat in ConnectionCategory},
            "expert_outputs": [
                current_state,
                torch.zeros_like(current_state),
                torch.zeros_like(current_state),
            ],
            "neighbor_count": 0,
        }

    def _update_stats(self, classifications: Dict, expert_weights: torch.Tensor):
        """ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ"""
        local_count = len(classifications[ConnectionCategory.LOCAL])
        functional_count = len(classifications[ConnectionCategory.FUNCTIONAL])
        distant_count = len(classifications[ConnectionCategory.DISTANT])

        self.usage_stats["local_connections"] += local_count
        self.usage_stats["functional_connections"] += functional_count
        self.usage_stats["distant_connections"] += distant_count
        self.usage_stats["total_forward_calls"] += 1

        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð²ÐµÑÐ¾Ð² ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð¾Ð²
        weights = expert_weights.detach()
        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚Ð¸ weights - Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ [3] Ð¸Ð»Ð¸ [1, 3]
        if weights.dim() == 2:
            weights = weights.squeeze(0)  # [1, 3] -> [3]

        # Statistics collection disabled for performance in production
        # Debug mode check removed - stats always disabled for performance

    def get_usage_stats(self) -> Dict[str, Any]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ"""
        total_connections = max(
            1,
            self.usage_stats["local_connections"]
            + self.usage_stats["functional_connections"]
            + self.usage_stats["distant_connections"],
        )
        total_calls = max(1, self.usage_stats["total_forward_calls"])

        return {
            "connection_distribution": {
                "local_ratio": self.usage_stats["local_connections"]
                / total_connections,
                "functional_ratio": self.usage_stats["functional_connections"]
                / total_connections,
                "distant_ratio": self.usage_stats["distant_connections"]
                / total_connections,
            },
            "expert_usage": {
                "local_avg_weight": self.usage_stats["expert_weights"]["local"]
                / total_calls,
                "functional_avg_weight": self.usage_stats["expert_weights"][
                    "functional"
                ]
                / total_calls,
                "distant_avg_weight": self.usage_stats["expert_weights"]["distant"]
                / total_calls,
            },
            "total_forward_calls": total_calls,
            "total_connections": total_connections,
        }

    def reset_stats(self):
        """Ð¡Ð±Ñ€Ð¾Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸"""
        self.usage_stats = {
            "local_connections": 0,
            "functional_connections": 0,
            "distant_connections": 0,
            "total_forward_calls": 0,
            "expert_weights": {"local": 0.0, "functional": 0.0, "distant": 0.0},
        }

    def get_parameter_breakdown(self) -> Dict[str, Any]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð±Ð¸Ð²ÐºÑƒ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð¿Ð¾ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð°Ð¼"""
        return {
            "local_expert": sum(p.numel() for p in self.local_expert.parameters()),
            "functional_expert": sum(
                p.numel() for p in self.functional_expert.parameters()
            ),
            "distant_expert": sum(p.numel() for p in self.distant_expert.parameters()),
            "gating_network": sum(p.numel() for p in self.gating_network.parameters()),
            "connection_classifier": sum(
                p.numel() for p in self.connection_classifier.parameters()
            ),
            "total": sum(p.numel() for p in self.parameters()),
        }

    def forward_embeddings(self, embeddings: torch.Tensor) -> torch.Tensor:
        """
        Ð£Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ñ‹Ð¹ forward Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÑÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³Ð¾Ð² Ð±ÐµÐ· Ñ€ÐµÑˆÐµÑ‚ÐºÐ¸

        Args:
            embeddings: [batch_size, embedding_dim] - Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ ÑÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³Ð¸

        Returns:
            processed_embeddings: [batch_size, embedding_dim] - Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³Ð¸
        """
        batch_size, embedding_dim = embeddings.shape
        device = embeddings.device

        # Ð”Ð»Ñ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ñ‚Ñ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ functional expert
        # ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¼Ð¾Ð¶ÐµÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸ÑÐ¼Ð¸
        processed_batch = []

        for i in range(batch_size):
            current_embedding = embeddings[i : i + 1]  # [1, embedding_dim]

            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ "ÑÐ¾ÑÐµÐ´ÐµÐ¹" Ð¸Ð· Ð´Ñ€ÑƒÐ³Ð¸Ñ… ÑÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³Ð¾Ð² Ð² batch'Ðµ
            neighbor_indices = [j for j in range(batch_size) if j != i]
            if len(neighbor_indices) > 0:
                neighbor_embeddings = embeddings[
                    neighbor_indices
                ]  # [batch_size-1, embedding_dim]
            else:
                neighbor_embeddings = torch.zeros(0, embedding_dim, device=device)

            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ functional expert Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
            if neighbor_embeddings.shape[0] > 0:
                try:
                    result = self.functional_expert(
                        current_state=current_embedding,
                        neighbor_states=neighbor_embeddings,
                        external_input=None,
                    )
                    if isinstance(result, dict):
                        processed_embedding = result.get("new_state", current_embedding)
                    else:
                        processed_embedding = result
                except Exception as e:
                    logger.warning(f"Functional expert failed for embedding {i}: {e}")
                    processed_embedding = current_embedding
            else:
                processed_embedding = current_embedding

            processed_batch.append(processed_embedding)

        return torch.cat(processed_batch, dim=0)
