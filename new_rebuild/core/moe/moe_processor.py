#!/usr/bin/env python3
"""
MoE Processor - —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π Mixture of Experts –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
=====================================================

–û—Å–Ω–æ–≤–Ω–æ–π MoE –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –º–æ–¥—É–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
–¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–≤—è–∑–µ–π –≤ 3D –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Ä–µ—à–µ—Ç–∫–µ.
"""

import torch
import torch.nn as nn
from typing import Dict, List, Optional, Any, Tuple
from torch.utils.checkpoint import checkpoint

from .gating_network import GatingNetwork
from .connection_classifier import UnifiedConnectionClassifier
from .connection_types import ConnectionCategory
from .simple_linear_expert import SimpleLinearExpert
from .hybrid_gnn_cnf_expert import HybridGNN_CNF_Expert
from ..cnf.gpu_enhanced_cnf import GPUEnhancedCNF, ConnectionType
from ...config import get_project_config
from ...utils.logging import get_logger, log_cell_forward
from ...utils.device_manager import get_device_manager
from ..lattice.position import Position3D
from ..lattice.spatial_optimization.memory_manager import get_memory_pool_manager

logger = get_logger(__name__)


class MoEConnectionProcessor(nn.Module):
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π Mixture of Experts Connection Processor –¥–ª—è 3D —Ä–µ—à–µ—Ç–∫–∏ 27√ó27√ó27

    –≠–ö–°–ü–ï–†–¢–´:
    - local_expert: SimpleLinear (2059 params) - 10% —Å–≤—è–∑–µ–π
    - functional_expert: HybridGNN_CNF (5500-12233 params) - 55% —Å–≤—è–∑–µ–π
    - distant_expert: LightweightCNF (1500-4000 params) - 35% —Å–≤—è–∑–µ–π

    –£–ü–†–ê–í–õ–ï–ù–ò–ï:
    - gating_network: (808 params) - –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ
    - connection_classifier: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–≤—è–∑–µ–π –ø–æ —Ç–∏–ø–∞–º
    """

    def __init__(
        self,
        state_size: Optional[int] = None,
        lattice_dimensions: Optional[Tuple[int, int, int]] = None,
        neighbor_count: Optional[int] = None,
        enable_cnf: Optional[bool] = None,
        **kwargs,
    ):
        super().__init__()

        config = get_project_config()

        # === DEVICE MANAGEMENT ===
        self.device_manager = config.get_device_manager()
        self.device = self.device_manager.get_device()
        self.memory_pool_manager = get_memory_pool_manager()

        # === –¶–ï–ù–¢–†–ê–õ–ò–ó–û–í–ê–ù–ù–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===
        self.state_size = state_size or config.gnn.state_size
        self.lattice_dimensions = lattice_dimensions or config.lattice.dimensions
        self.adaptive_radius = config.calculate_adaptive_radius()
        self.max_neighbors = config.max_neighbors
        self.enable_cnf = enable_cnf if enable_cnf is not None else config.cnf.enabled

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–≤—è–∑–µ–π: 10%/55%/35%
        self.connection_ratios = {
            "local": config.neighbors.local_tier,
            "functional": config.neighbors.functional_tier,
            "distant": config.neighbors.distant_tier,
        }

        # === –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† –°–í–Ø–ó–ï–ô ===
        self.connection_classifier = UnifiedConnectionClassifier(
            lattice_dimensions=self.lattice_dimensions
        )

        # === –≠–ö–°–ü–ï–†–¢–´ ===
        self.local_expert = SimpleLinearExpert(state_size=self.state_size)

        self.functional_expert = HybridGNN_CNF_Expert(
            state_size=self.state_size,
            neighbor_count=self.max_neighbors,
            target_params=config.expert.functional.params,
            cnf_params=config.expert.distant.params,
        )

        # 3. Distant Expert - –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è –ø–∞–º—è—Ç—å (LightweightCNF)
        if self.enable_cnf:
            self.distant_expert = GPUEnhancedCNF(
                state_size=self.state_size,
                connection_type=ConnectionType.DISTANT,
                integration_steps=config.cnf.integration_steps,
                batch_processing_mode=config.cnf.batch_processing_mode,
                max_batch_size=config.cnf.max_batch_size,
                adaptive_method=config.cnf.adaptive_method,
            )
        else:
            # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É linear –µ—Å–ª–∏ CNF –æ—Ç–∫–ª—é—á–µ–Ω
            self.distant_expert = SimpleLinearExpert(state_size=self.state_size)

        # === GATING NETWORK ===
        self.gating_network = GatingNetwork(state_size=self.state_size, num_experts=3)

        # === –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===
        self.reset_stats()

        # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        total_params = sum(p.numel() for p in self.parameters())
        logger.info(f"MoEConnectionProcessor: {total_params} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤—Å–µ–≥–æ")

        # –ü–µ—Ä–µ–Ω–æ—Å –º–æ–¥–µ–ª–∏ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        self.device_manager.transfer_module(self)
        logger.info(f"MoEConnectionProcessor –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")

    def forward(
        self,
        current_state: torch.Tensor,
        neighbor_states: torch.Tensor,
        cell_idx: int,
        neighbor_indices: List[int],
        external_input: Optional[torch.Tensor] = None,
        spatial_optimizer=None,
        **kwargs,
    ) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π forward pass —Å —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π

        Args:
            current_state: [state_size] - —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–ª–µ—Ç–∫–∏
            neighbor_states: [num_neighbors, state_size] - —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ—Å–µ–¥–µ–π
            cell_idx: –∏–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–π –∫–ª–µ—Ç–∫–∏
            neighbor_indices: –∏–Ω–¥–µ–∫—Å—ã —Å–æ—Å–µ–¥–Ω–∏—Ö –∫–ª–µ—Ç–æ–∫
            external_input: –≤–Ω–µ—à–Ω–∏–π –≤—Ö–æ–¥ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            spatial_optimizer: –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π spatial optimizer –¥–ª—è adaptive radius –ø–æ–∏—Å–∫–∞

        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        # === –û–°–ù–û–í–ù–û–ô –ú–ï–¢–û–î: Adaptive Radius Neighbor Search ===
        if spatial_optimizer is not None and hasattr(
            spatial_optimizer, "find_neighbors_by_radius_safe"
        ):
            # –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ–º spatial optimizer –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å–æ—Å–µ–¥–µ–π
            adaptive_neighbors = spatial_optimizer.find_neighbors_by_radius_safe(
                cell_idx
            )

            if adaptive_neighbors and "full_lattice_states" in kwargs:
                # –ü–æ–ª—É—á–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ—Å–µ–¥–µ–π –∏–∑ –ø–æ–ª–Ω–æ–π —Ä–µ—à–µ—Ç–∫–∏
                full_states = kwargs["full_lattice_states"]

                # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø –∏–Ω–¥–µ–∫—Å–æ–≤ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
                max_idx = full_states.shape[0] - 1
                valid_neighbors = [
                    idx for idx in adaptive_neighbors if 0 <= idx <= max_idx
                ]

                if len(valid_neighbors) != len(adaptive_neighbors):
                    logger.warning(
                        f"‚ö†Ô∏è –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(adaptive_neighbors) - len(valid_neighbors)} –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx}"
                    )

                if valid_neighbors:
                    neighbor_indices = valid_neighbors
                    neighbor_states = full_states[neighbor_indices]

                    logger.debug(
                        f"üîç –û–°–ù–û–í–ù–û–ô –†–ï–ñ–ò–ú: spatial_optimizer –¥–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx}: –Ω–∞–π–¥–µ–Ω–æ {len(neighbor_indices)} –≤–∞–ª–∏–¥–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π"
                    )
                else:
                    neighbor_indices = []
                    neighbor_states = torch.empty(
                        0, full_states.shape[1], device=full_states.device
                    )
            else:
                logger.warning(
                    f"‚ö†Ô∏è spatial_optimizer –ø–µ—Ä–µ–¥–∞–Ω, –Ω–æ full_lattice_states –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç - fallback –∫ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–º —Å–æ—Å–µ–¥—è–º"
                )
        else:
            # Fallback —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ spatial_optimizer –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω
            if len(neighbor_indices) > 0:
                logger.debug(
                    f"üîÑ FALLBACK –†–ï–ñ–ò–ú: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ —Å–æ—Å–µ–¥–∏ –¥–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx}: {len(neighbor_indices)} —Å–æ—Å–µ–¥–µ–π"
                )
                # –í fallback —Ä–µ–∂–∏–º–µ –Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å neighbor_states –∏–∑ full_lattice_states –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
                if "full_lattice_states" in kwargs:
                    full_states = kwargs["full_lattice_states"]
                    neighbor_states = full_states[neighbor_indices]
                    logger.debug(f"üîç FALLBACK: –∏–∑–≤–ª–µ—á–µ–Ω–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ—Å–µ–¥–µ–π –∏–∑ full_lattice_states, shape={neighbor_states.shape}")
                else:
                    # –ï—Å–ª–∏ full_lattice_states –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
                    state_size = current_state.shape[-1]
                    neighbor_states = torch.zeros(len(neighbor_indices), state_size, device=current_state.device)
                    logger.warning(f"‚ö†Ô∏è FALLBACK: full_lattice_states –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω—É–ª–µ–≤—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è {len(neighbor_indices)} —Å–æ—Å–µ–¥–µ–π")
            else:
                logger.warning(
                    f"‚ö†Ô∏è –ù–∏ spatial_optimizer, –Ω–∏ neighbor_indices –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã –¥–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx}"
                )
                neighbor_states = torch.empty(0, current_state.shape[-1], device=current_state.device)

        if len(neighbor_indices) == 0:
            return self._empty_forward_result(current_state)

        batch_size = 1
        device = current_state.device

        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –≤—Å–µ tensor'—ã –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
        current_state = self.device_manager.ensure_device(current_state)
        neighbor_states = self.device_manager.ensure_device(neighbor_states)
        if external_input is not None:
            external_input = self.device_manager.ensure_device(external_input)

        # === 1. –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –°–í–Ø–ó–ï–ô ===
        logger.debug(f"[{cell_idx}] –®–∞–≥ 1: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–≤—è–∑–µ–π...")
        classifications = self.connection_classifier.classify_connections(
            cell_idx=cell_idx,
            neighbor_indices=neighbor_indices,
            cell_state=current_state,
            neighbor_states=neighbor_states,
        )
        logger.debug(f"[{cell_idx}] –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

        # === 2. –û–ë–†–ê–ë–û–¢–ö–ê –ö–ê–ñ–î–´–ú –≠–ö–°–ü–ï–†–¢–û–ú ===
        logger.debug(f"[{cell_idx}] –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞–º–∏...")
        expert_outputs = []
        tensors_to_return = []

        # Local Expert
        local_neighbors = [
            conn.target_idx for conn in classifications[ConnectionCategory.LOCAL]
        ]
        logger.debug(f"[{cell_idx}] Local expert, {len(local_neighbors)} —Å–æ—Å–µ–¥–µ–π.")
        if local_neighbors:
            # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è –º–µ—Å—Ç–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π
            local_mask = torch.isin(neighbor_indices, torch.tensor(local_neighbors, device=neighbor_indices.device))
            # Flatten –º–∞—Å–∫—É –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            local_mask_flat = local_mask.flatten()
            local_neighbor_states = neighbor_states[local_mask_flat]
            logger.debug(
                f"[{cell_idx}] Local neighbor states shape: {local_neighbor_states.shape}"
            )

            def local_expert_wrapper(current, neighbors):
                res = self.local_expert(current, neighbors)
                if isinstance(res, dict):
                    return res.get("output", res.get("new_state", current))
                return res

            local_output = checkpoint(
                local_expert_wrapper,
                current_state,
                local_neighbor_states,
                use_reentrant=False,
            )
            logger.debug(
                f"[{cell_idx}] Local expert output shape: {local_output.shape}"
            )

        else:
            local_output = self.memory_pool_manager.get_tensor(
                (1, self.state_size), dtype=current_state.dtype
            )
            tensors_to_return.append(local_output)
        expert_outputs.append(local_output.squeeze(0))

        # Functional Expert
        functional_neighbors = [
            conn.target_idx for conn in classifications[ConnectionCategory.FUNCTIONAL]
        ]
        logger.debug(
            f"[{cell_idx}] Functional expert, {len(functional_neighbors)} —Å–æ—Å–µ–¥–µ–π."
        )
        if functional_neighbors:
            # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π
            functional_mask = torch.isin(neighbor_indices, torch.tensor(functional_neighbors, device=neighbor_indices.device))
            # Flatten –º–∞—Å–∫—É –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            functional_mask_flat = functional_mask.flatten()
            functional_neighbor_states = neighbor_states[functional_mask_flat]
            logger.debug(
                f"[{cell_idx}] Functional neighbor states shape: {functional_neighbor_states.shape}"
            )

            def functional_expert_wrapper(current, neighbors):
                res = self.functional_expert(current, neighbors)
                if isinstance(res, dict):
                    return res.get("output", res.get("new_state", current))
                return res

            functional_output = checkpoint(
                functional_expert_wrapper,
                current_state,
                functional_neighbor_states,
                use_reentrant=False,
            )
            logger.debug(
                f"[{cell_idx}] Functional expert output shape: {functional_output.shape}"
            )
        else:
            functional_output = self.memory_pool_manager.get_tensor(
                (1, self.state_size), dtype=current_state.dtype
            )
            tensors_to_return.append(functional_output)
        expert_outputs.append(functional_output.squeeze(0))

        # Distant Expert (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ CNF –≤–∫–ª—é—á–µ–Ω)
        distant_neighbors = [
            conn.target_idx for conn in classifications[ConnectionCategory.DISTANT]
        ]
        logger.debug(f"[{cell_idx}] Distant expert, {len(distant_neighbors)} —Å–æ—Å–µ–¥–µ–π.")
        if self.enable_cnf and distant_neighbors:
            # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è –¥–∞–ª—å–Ω–∏—Ö —Å–æ—Å–µ–¥–µ–π
            distant_mask = torch.isin(neighbor_indices, torch.tensor(distant_neighbors, device=neighbor_indices.device))
            # Flatten –º–∞—Å–∫—É –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            distant_mask_flat = distant_mask.flatten()
            distant_neighbor_states = neighbor_states[distant_mask_flat]
            logger.debug(
                f"[{cell_idx}] Distant neighbor states shape: {distant_neighbor_states.shape}"
            )

            def distant_expert_wrapper(current, neighbors):
                res = self.distant_expert(current, neighbors)
                if isinstance(res, dict):
                    return res.get("output", res.get("new_state", current))
                return res

            distant_output = checkpoint(
                distant_expert_wrapper,
                current_state,
                distant_neighbor_states,
                use_reentrant=False,
            )
            logger.debug(
                f"[{cell_idx}] Distant expert output shape: {distant_output.shape}"
            )
        else:
            distant_output = self.memory_pool_manager.get_tensor(
                (1, self.state_size), dtype=current_state.dtype
            )
            tensors_to_return.append(distant_output)
        expert_outputs.append(distant_output.squeeze(0))

        # === 3. –ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
        logger.debug(
            f"[{cell_idx}] –®–∞–≥ 3: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. expert_outputs: {[t.shape for t in expert_outputs]}"
        )
        try:
            # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ expert_outputs
            if not expert_outputs:
                logger.warning(
                    f"‚ö†Ô∏è –ù–µ—Ç –≤—ã—Ö–æ–¥–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx}, –ø—Ä–æ–ø—É—Å–∫ GatingNetwork."
                )
                final_state = current_state
                expert_weights = torch.zeros(
                    1, 3, device=device
                )  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤—ã–µ –≤–µ—Å–∞
            else:
                # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏–π —Å–æ—Å–µ–¥–µ–π ---
                # –£—Å—Ä–µ–¥–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤—Å–µ—Ö —Å–æ—Å–µ–¥–µ–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –µ–¥–∏–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                logger.debug(
                    f"[{cell_idx}] –ê–≥—Ä–µ–≥–∞—Ü–∏—è neighbor_states... Shape: {neighbor_states.shape}"
                )
                if neighbor_states.numel() > 0:
                    neighbor_activity = torch.mean(neighbor_states, dim=0, keepdim=True)
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ—Å–µ–¥–µ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä
                    neighbor_activity = torch.zeros(
                        1, self.state_size, device=device, dtype=current_state.dtype
                    )
                logger.debug(
                    f"[{cell_idx}] neighbor_activity shape: {neighbor_activity.shape}"
                )

                # –í—ã–∑–æ–≤ GatingNetwork —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –ø–æ —Ñ–æ—Ä–º–µ —Ç–µ–Ω–∑–æ—Ä–∞–º–∏
                logger.debug(f"[{cell_idx}] –í—ã–∑–æ–≤ GatingNetwork...")
                combined_output, expert_weights = self.gating_network(
                    current_state=current_state,  # [1, state_size]
                    neighbor_activity=neighbor_activity,  # [1, state_size]
                    expert_outputs=expert_outputs,
                )
                logger.debug(
                    f"[{cell_idx}] GatingNetwork –∑–∞–≤–µ—Ä—à–µ–Ω. combined_output: {combined_output.shape}, expert_weights: {expert_weights.shape}"
                )

                # Residual connection
                final_state = current_state + combined_output.squeeze(0)

        except Exception as e:
            logger.error(
                f"‚ùå MoE processor CRITICAL error on cell {cell_idx}: {e}",
                exc_info=True,
            )
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å
            final_state = current_state
            expert_weights = torch.zeros(1, 3, device=device)

        # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ–Ω–∑–æ—Ä—ã
        for t in tensors_to_return:
            self.memory_pool_manager.release_tensor(t)

        # === 4. –û–ë–ù–û–í–õ–ï–ù–ò–ï –°–¢–ê–¢–ò–°–¢–ò–ö–ò ===
        self._update_stats(classifications, expert_weights)

        log_cell_forward(
            "MoEConnectionProcessor",
            input_shapes={
                "current_state": current_state.shape,
                "neighbor_states": neighbor_states.shape,
            },
            output_shape=final_state.shape,
        )
        
        # –û—Ç–¥–µ–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ expert_weights
        logger.debug(f"[{cell_idx}] Expert weights: {expert_weights.squeeze().tolist()}")

        return {
            "new_state": final_state,
            "expert_weights": expert_weights,
            "classifications": classifications,
        }

    def _empty_forward_result(self, current_state: torch.Tensor) -> Dict[str, Any]:
        """–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —Å–ª—É—á–∞—è –±–µ–∑ —Å–æ—Å–µ–¥–µ–π"""
        return {
            "new_state": current_state,
            "expert_weights": torch.tensor(
                [1.0, 0.0, 0.0], device=current_state.device
            ),
            "classifications": {cat: [] for cat in ConnectionCategory},
            "expert_outputs": [
                current_state,
                torch.zeros_like(current_state),
                torch.zeros_like(current_state),
            ],
            "neighbor_count": 0,
        }

    def _update_stats(self, classifications: Dict, expert_weights: torch.Tensor):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        local_count = len(classifications[ConnectionCategory.LOCAL])
        functional_count = len(classifications[ConnectionCategory.FUNCTIONAL])
        distant_count = len(classifications[ConnectionCategory.DISTANT])

        self.usage_stats["local_connections"] += local_count
        self.usage_stats["functional_connections"] += functional_count
        self.usage_stats["distant_connections"] += distant_count
        self.usage_stats["total_forward_calls"] += 1

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Å–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        weights = expert_weights.detach()
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ weights - –º–æ–∂–µ—Ç –±—ã—Ç—å [3] –∏–ª–∏ [1, 3]
        if weights.dim() == 2:
            weights = weights.squeeze(0)  # [1, 3] -> [3]
        
        self.usage_stats["expert_weights"]["local"] += weights[0].item()
        self.usage_stats["expert_weights"]["functional"] += weights[1].item()
        self.usage_stats["expert_weights"]["distant"] += weights[2].item()

    def get_usage_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        total_connections = max(
            1,
            self.usage_stats["local_connections"]
            + self.usage_stats["functional_connections"]
            + self.usage_stats["distant_connections"],
        )
        total_calls = max(1, self.usage_stats["total_forward_calls"])

        return {
            "connection_distribution": {
                "local_ratio": self.usage_stats["local_connections"]
                / total_connections,
                "functional_ratio": self.usage_stats["functional_connections"]
                / total_connections,
                "distant_ratio": self.usage_stats["distant_connections"]
                / total_connections,
            },
            "expert_usage": {
                "local_avg_weight": self.usage_stats["expert_weights"]["local"]
                / total_calls,
                "functional_avg_weight": self.usage_stats["expert_weights"][
                    "functional"
                ]
                / total_calls,
                "distant_avg_weight": self.usage_stats["expert_weights"]["distant"]
                / total_calls,
            },
            "total_forward_calls": total_calls,
            "total_connections": total_connections,
        }

    def reset_stats(self):
        """–°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        self.usage_stats = {
            "local_connections": 0,
            "functional_connections": 0,
            "distant_connections": 0,
            "total_forward_calls": 0,
            "expert_weights": {"local": 0.0, "functional": 0.0, "distant": 0.0},
        }

    def get_parameter_breakdown(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–±–∏–≤–∫—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º"""
        return {
            "local_expert": sum(p.numel() for p in self.local_expert.parameters()),
            "functional_expert": sum(
                p.numel() for p in self.functional_expert.parameters()
            ),
            "distant_expert": sum(p.numel() for p in self.distant_expert.parameters()),
            "gating_network": sum(p.numel() for p in self.gating_network.parameters()),
            "connection_classifier": sum(
                p.numel() for p in self.connection_classifier.parameters()
            ),
            "total": sum(p.numel() for p in self.parameters()),
        }
