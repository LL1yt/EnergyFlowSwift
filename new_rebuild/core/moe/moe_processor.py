#!/usr/bin/env python3
"""
MoE Processor - —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π Mixture of Experts –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
=====================================================

–û—Å–Ω–æ–≤–Ω–æ–π MoE –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –º–æ–¥—É–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
–¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–≤—è–∑–µ–π –≤ 3D –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Ä–µ—à–µ—Ç–∫–µ.
"""

import torch
import torch.nn as nn
from typing import Dict, List, Optional, Any, Tuple
from torch.utils.checkpoint import checkpoint

from .gating_network import GatingNetwork
from .connection_classifier import UnifiedConnectionClassifier
from .connection_types import ConnectionCategory
from .simple_linear_expert import SimpleLinearExpert
from .hybrid_gnn_cnf_expert import HybridGNN_CNF_Expert
from ..cnf.gpu_enhanced_cnf import GPUEnhancedCNF, ConnectionType
from ...config import get_project_config
from ...utils.logging import get_logger, log_cell_forward
from ...utils.device_manager import get_device_manager
from ..lattice.position import Position3D
from ..lattice.spatial_optimization.memory_manager import get_memory_pool_manager

logger = get_logger(__name__)


class MoEConnectionProcessor(nn.Module):
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π Mixture of Experts Connection Processor –¥–ª—è 3D —Ä–µ—à–µ—Ç–∫–∏ 27√ó27√ó27

    –≠–ö–°–ü–ï–†–¢–´:
    - local_expert: SimpleLinear (2059 params) - 10% —Å–≤—è–∑–µ–π
    - functional_expert: HybridGNN_CNF (5500-12233 params) - 55% —Å–≤—è–∑–µ–π
    - distant_expert: LightweightCNF (1500-4000 params) - 35% —Å–≤—è–∑–µ–π

    –£–ü–†–ê–í–õ–ï–ù–ò–ï:
    - gating_network: (808 params) - –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ
    - connection_classifier: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–≤—è–∑–µ–π –ø–æ —Ç–∏–ø–∞–º
    """

    def __init__(
        self,
        state_size: Optional[int] = None,
        lattice_dimensions: Optional[Tuple[int, int, int]] = None,
        neighbor_count: Optional[int] = None,
        enable_cnf: Optional[bool] = None,
        config: Optional[Any] = None,
        **kwargs,
    ):
        super().__init__()

        if config is None:
            config = get_project_config()

        # === DEVICE MANAGEMENT ===
        self.device_manager = config.device_manager
        self.device = self.device_manager.get_device()
        self.memory_pool_manager = get_memory_pool_manager()

        # === –¶–ï–ù–¢–†–ê–õ–ò–ó–û–í–ê–ù–ù–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===
        # –°—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ state_size
        if state_size is None:
            if not hasattr(config.model, 'state_size') or config.model.state_size is None:
                raise RuntimeError(
                    "‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä config.model.state_size. "
                    "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ project_config.py"
                )
            self.state_size = config.model.state_size
        else:
            self.state_size = state_size

        # –°—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ lattice_dimensions
        if lattice_dimensions is None:
            if not hasattr(config.lattice, 'dimensions') or config.lattice.dimensions is None:
                raise RuntimeError(
                    "‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä config.lattice.dimensions. "
                    "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ project_config.py"
                )
            self.lattice_dimensions = config.lattice.dimensions
        else:
            self.lattice_dimensions = lattice_dimensions

        self.adaptive_radius = config.calculate_adaptive_radius()
        
        # –ü–æ–ª—É—á–∞–µ–º max_neighbors –∏–∑ NeighborSettings
        if not hasattr(config, "neighbors") or not hasattr(config.neighbors, 'max_neighbors'):
            raise RuntimeError(
                "‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä config.neighbors.max_neighbors. "
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ project_config.py"
            )
        self.max_neighbors = config.neighbors.max_neighbors
        
        # neighbor_count –∏–∑ ModelSettings –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        if hasattr(config.model, 'neighbor_count'):
            self.dynamic_neighbors = (config.model.neighbor_count == -1)
        else:
            self.dynamic_neighbors = True
            
        logger.debug(f"[MoEConnectionProcessor] max_neighbors={self.max_neighbors}, dynamic_neighbors={self.dynamic_neighbors}")

        # –°—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ enable_cnf
        if enable_cnf is not None:
            self.enable_cnf = enable_cnf
        else:
            if not hasattr(config.cnf, 'enabled'):
                raise RuntimeError(
                    "‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä config.cnf.enabled. "
                    "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ project_config.py"
                )
            self.enable_cnf = config.cnf.enabled

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–≤—è–∑–µ–π: 10%/55%/35%
        # –°–¢–†–û–ì–ê–Ø –ü–†–û–í–ï–†–ö–ê - –ë–ï–ó FALLBACK
        if not hasattr(config, "neighbors") or config.neighbors is None:
            raise RuntimeError(
                "‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è config.neighbors. "
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ project_config.py. "
                "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å neighbors —Å –ø–æ–ª—è–º–∏ local_tier, functional_tier, distant_tier"
            )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è neighbors
        required_neighbor_fields = ['local_tier', 'functional_tier', 'distant_tier']
        for field in required_neighbor_fields:
            if not hasattr(config.neighbors, field) or getattr(config.neighbors, field) is None:
                raise RuntimeError(
                    f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ config.neighbors.{field}. "
                    f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é neighbors –≤ project_config.py"
                )
        
        self.connection_ratios = {
            "local": config.neighbors.local_tier,
            "functional": config.neighbors.functional_tier,
            "distant": config.neighbors.distant_tier,
        }

        # === –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† –°–í–Ø–ó–ï–ô –° –ö–≠–®–ò–†–û–í–ê–ù–ò–ï–ú ===
        self.connection_classifier = UnifiedConnectionClassifier(
            lattice_dimensions=self.lattice_dimensions,
            enable_cache=True,  # –í–∫–ª—é—á–∞–µ–º –∫—ç—à –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        )
        
        # Spatial optimizer –±—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–∑–∂–µ —á–µ—Ä–µ–∑ setter
        # self.spatial_optimizer = None

        # === –≠–ö–°–ü–ï–†–¢–´ ===
        self.local_expert = SimpleLinearExpert(state_size=self.state_size)

        # –°–¢–†–û–ì–ê–Ø –ü–†–û–í–ï–†–ö–ê –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ - –ë–ï–ó FALLBACK
        if not hasattr(config, "expert") or config.expert is None:
            raise RuntimeError(
                "‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è config.expert. "
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ project_config.py"
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ functional expert
        if not hasattr(config.expert, "functional") or config.expert.functional is None:
            raise RuntimeError(
                "‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç config.expert.functional. "
                "–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã functional expert –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"
            )
        
        if not hasattr(config.expert.functional, "params") or config.expert.functional.params is None:
            raise RuntimeError(
                "‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç config.expert.functional.params. "
                "–£–∫–∞–∂–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è functional expert"
            )
        
        functional_params = config.expert.functional.params
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ distant expert
        if not hasattr(config.expert, "distant") or config.expert.distant is None:
            raise RuntimeError(
                "‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç config.expert.distant. "
                "–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã distant expert –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"
            )
        
        if not hasattr(config.expert.distant, "params") or config.expert.distant.params is None:
            raise RuntimeError(
                "‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç config.expert.distant.params. "
                "–£–∫–∞–∂–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è distant expert"
            )
        
        distant_params = config.expert.distant.params

        # –î–ª—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ—Å–µ–¥–µ–π
        self.functional_expert = HybridGNN_CNF_Expert(
            state_size=self.state_size,
            neighbor_count=-1 if self.dynamic_neighbors else self.max_neighbors,  # -1 –æ–∑–Ω–∞—á–∞–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            target_params=functional_params,
            cnf_params=distant_params,
        )
        logger.info(f"[MoEConnectionProcessor] Functional expert —Å–æ–∑–¥–∞–Ω —Å neighbor_count={-1 if self.dynamic_neighbors else self.max_neighbors}")

        # 3. Distant Expert - –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è –ø–∞–º—è—Ç—å (LightweightCNF)
        # –°–¢–†–û–ì–ê–Ø –ü–†–û–í–ï–†–ö–ê - –ë–ï–ó FALLBACK –¥–ª—è CNF
        if not self.enable_cnf:
            raise RuntimeError(
                "‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: CNF –æ—Ç–∫–ª—é—á–µ–Ω (config.cnf.enabled=False), "
                "–Ω–æ MoE –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–µ–±—É–µ—Ç CNF –¥–ª—è distant_expert. "
                "–í–∫–ª—é—á–∏—Ç–µ CNF –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: config.cnf.enabled = True"
            )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã CNF
        cnf_required_fields = ['integration_steps', 'batch_processing_mode', 'max_batch_size', 'adaptive_method']
        for field in cnf_required_fields:
            if not hasattr(config.cnf, field) or getattr(config.cnf, field) is None:
                raise RuntimeError(
                    f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä config.cnf.{field}. "
                    f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é CNF –≤ project_config.py"
                )
        
        self.distant_expert = GPUEnhancedCNF(
            state_size=self.state_size,
            connection_type=ConnectionType.DISTANT,
            integration_steps=config.cnf.integration_steps,
            batch_processing_mode=config.cnf.batch_processing_mode,
            max_batch_size=config.cnf.max_batch_size,
            adaptive_method=config.cnf.adaptive_method,
        )

        # === GATING NETWORK ===
        self.gating_network = GatingNetwork(state_size=self.state_size, num_experts=3)

        # === –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===
        self.reset_stats()

        # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        total_params = sum(p.numel() for p in self.parameters())
        logger.info(f"MoEConnectionProcessor: {total_params} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤—Å–µ–≥–æ")

        # –ü–µ—Ä–µ–Ω–æ—Å –º–æ–¥–µ–ª–∏ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        self.device_manager.transfer_module(self)
        logger.info(f"MoEConnectionProcessor –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        
    def forward(
        self,
        current_state: torch.Tensor,
        neighbor_states: torch.Tensor,  # DEPRECATED - –±—É–¥–µ—Ç –ø–æ–ª—É—á–µ–Ω–æ –∏–∑ –∫—ç—à–∞
        cell_idx: int,
        neighbor_indices: List[int],  # DEPRECATED - –±—É–¥–µ—Ç –ø–æ–ª—É—á–µ–Ω–æ –∏–∑ –∫—ç—à–∞
        external_input: Optional[torch.Tensor] = None,
        spatial_optimizer=None,  # DEPRECATED - –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
        **kwargs,
    ) -> Dict[str, Any]:
        # DEBUG: Only log for extreme debug mode
        if logger.isEnabledFor(11):  # DEBUG_VERBOSE only
            logger.debug_verbose(f"üîç MoE FORWARD called for cell {cell_idx}")
        """
        –û—Å–Ω–æ–≤–Ω–æ–π forward pass —Å —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π (–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)

        Args:
            current_state: [state_size] - —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–ª–µ—Ç–∫–∏
            neighbor_states: DEPRECATED - –ø–æ–ª—É—á–∞–µ—Ç—Å—è –∏–∑ –∫—ç—à–∞
            cell_idx: –∏–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–π –∫–ª–µ—Ç–∫–∏
            neighbor_indices: DEPRECATED - –ø–æ–ª—É—á–∞–µ—Ç—Å—è –∏–∑ –∫—ç—à–∞
            external_input: –≤–Ω–µ—à–Ω–∏–π –≤—Ö–æ–¥ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            spatial_optimizer: DEPRECATED - –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
            **kwargs: –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å full_lattice_states

        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        # === –ù–û–í–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∫—ç—à ===
        if "full_lattice_states" not in kwargs:
            raise RuntimeError(
                f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –î–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç full_lattice_states. "
                f"–≠—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã."
            )
            
        full_states = kwargs["full_lattice_states"]
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ—Å–µ–¥–µ–π –ò –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –æ–¥–Ω–∏–º –≤—ã–∑–æ–≤–æ–º –∏–∑ –∫—ç—à–∞
        neighbors_data = self.connection_classifier.get_cached_neighbors_and_classification(
            cell_idx=cell_idx,
            states=full_states
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Å–æ—Å–µ–¥
        total_neighbors = (
            len(neighbors_data["local"]["indices"]) + 
            len(neighbors_data["functional"]["indices"]) + 
            len(neighbors_data["distant"]["indices"])
        )
        
        if total_neighbors == 0:
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ö–ª–µ—Ç–∫–∞ {cell_idx} –Ω–µ –∏–º–µ–µ—Ç —Å–æ—Å–µ–¥–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")
            logger.error(f"   –≠—Ç–æ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤ 3D —Ä–µ—à–µ—Ç–∫–µ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–¥–∏—É—Å –ø–æ–∏—Å–∫–∞!")
            raise RuntimeError(
                f"–ö–ª–µ—Ç–∫–∞ {cell_idx} –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–∞ (0 —Å–æ—Å–µ–¥–µ–π). "
                f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–¥–∏—É—Å–∞."
            )

        batch_size = 1
        device = current_state.device

        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –≤—Å–µ tensor'—ã –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
        current_state = self.device_manager.ensure_device(current_state)
        if external_input is not None:
            external_input = self.device_manager.ensure_device(external_input)
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å current_state –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ
        if current_state.dim() == 1:
            # –ï—Å–ª–∏ –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π [state_size], –¥–æ–±–∞–≤–ª—è–µ–º batch dimension
            current_state = current_state.unsqueeze(0)  # [1, state_size]
        elif current_state.dim() == 3:
            # –ï—Å–ª–∏ —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã–π [batch, 1, state_size], —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ
            current_state = current_state.squeeze(1)  # [batch, state_size]
            if current_state.shape[0] > 1:
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é –∫–ª–µ—Ç–∫—É –∏–∑ –±–∞—Ç—á–∞
                current_state = current_state[0:1]  # [1, state_size]
        
        # Cache-based classification results (no logging for performance)

        # === 2. –û–ë–†–ê–ë–û–¢–ö–ê –ö–ê–ñ–î–´–ú –≠–ö–°–ü–ï–†–¢–û–ú (–ü–ê–†–ê–õ–õ–ï–õ–¨–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê) ===
        expert_outputs = []
        tensors_to_return = []

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        local_data = neighbors_data["local"]
        functional_data = neighbors_data["functional"]
        distant_data = neighbors_data["distant"]

        # –î–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö —Ä–µ—à–µ—Ç–æ–∫ (‚â§32) –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        if self.device_manager.is_cuda() and max(current_state.shape) <= 1024:  # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è GPU
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º CUDA streams
            with torch.cuda.device(self.device_manager.device):
                # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ stream'—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
                local_stream = torch.cuda.Stream()
                functional_stream = torch.cuda.Stream()
                distant_stream = torch.cuda.Stream() if self.enable_cnf else None

                # Async –æ–±—Ä–∞–±–æ—Ç–∫–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
                with torch.cuda.stream(local_stream):
                    if local_data["indices"]:
                        local_neighbor_states = local_data["states"]
                        # –î–æ–±–∞–≤–ª—è–µ–º batch dimension –∫ neighbor_states –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                        if local_neighbor_states.dim() == 2:
                            local_neighbor_states = local_neighbor_states.unsqueeze(0)  # [1, num_neighbors, state_size]
                        def local_expert_wrapper(current, neighbors):
                            res = self.local_expert(current, neighbors)
                            if isinstance(res, dict):
                                return res.get("output", res.get("new_state", current))
                            return res
                        local_output = checkpoint(
                            local_expert_wrapper,
                            current_state,
                            local_neighbor_states,
                            use_reentrant=False,
                        )
                    else:
                        local_output = self.memory_pool_manager.get_tensor(
                            (1, self.state_size), dtype=current_state.dtype
                        )
                        tensors_to_return.append(local_output)

                with torch.cuda.stream(functional_stream):
                    if functional_data["indices"]:
                        functional_neighbor_states = functional_data["states"]
                        # –î–æ–±–∞–≤–ª—è–µ–º batch dimension –∫ neighbor_states –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                        if functional_neighbor_states.dim() == 2:
                            functional_neighbor_states = functional_neighbor_states.unsqueeze(0)  # [1, num_neighbors, state_size]
                        def functional_expert_wrapper(current, neighbors):
                            res = self.functional_expert(current, neighbors)
                            if isinstance(res, dict):
                                return res.get("output", res.get("new_state", current))
                            return res
                        # –û—Ç–∫–ª—é—á–∞–µ–º checkpoint –¥–ª—è functional expert –∏–∑-–∑–∞ in-place operations
                        # functional_output = checkpoint(
                        #     functional_expert_wrapper,
                        #     current_state,
                        #     functional_neighbor_states,
                        #     use_reentrant=False,
                        # )
                        functional_output = functional_expert_wrapper(
                            current_state,
                            functional_neighbor_states
                        )
                    else:
                        functional_output = self.memory_pool_manager.get_tensor(
                            (1, self.state_size), dtype=current_state.dtype
                        )
                        tensors_to_return.append(functional_output)

                if self.enable_cnf and distant_stream:
                    with torch.cuda.stream(distant_stream):
                        if distant_data["indices"]:
                            distant_neighbor_states = distant_data["states"]
                            # –î–æ–±–∞–≤–ª—è–µ–º batch dimension –∫ neighbor_states –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                            if distant_neighbor_states.dim() == 2:
                                distant_neighbor_states = distant_neighbor_states.unsqueeze(0)  # [1, num_neighbors, state_size]
                            def distant_expert_wrapper(current, neighbors):
                                res = self.distant_expert(current, neighbors)
                                if isinstance(res, dict):
                                    return res.get("output", res.get("new_state", current))
                                return res
                            distant_output = checkpoint(
                                distant_expert_wrapper,
                                current_state,
                                distant_neighbor_states,
                                use_reentrant=False,
                            )
                        else:
                            distant_output = self.memory_pool_manager.get_tensor(
                                (1, self.state_size), dtype=current_state.dtype
                            )
                            tensors_to_return.append(distant_output)

                # –£–±–∏—Ä–∞–µ–º –±–ª–æ–∫–∏—Ä—É—é—â–∏–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ - PyTorch –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç stream'–∞–º–∏
                # local_stream.synchronize()      # –û—Ç–∫–ª—é—á–µ–Ω–æ –¥–ª—è GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                # functional_stream.synchronize() # –û—Ç–∫–ª—é—á–µ–Ω–æ –¥–ª—è GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                # if distant_stream:
                #     distant_stream.synchronize() # –û—Ç–∫–ª—é—á–µ–Ω–æ –¥–ª—è GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

        else:
            # Fallback –∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ä–µ—à–µ—Ç–æ–∫
            # Local Expert
            if local_data["indices"]:
                local_neighbor_states = local_data["states"]
                # –î–æ–±–∞–≤–ª—è–µ–º batch dimension –∫ neighbor_states –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if local_neighbor_states.dim() == 2:
                    local_neighbor_states = local_neighbor_states.unsqueeze(0)  # [1, num_neighbors, state_size]
                def local_expert_wrapper(current, neighbors):
                    res = self.local_expert(current, neighbors)
                    if isinstance(res, dict):
                        return res.get("output", res.get("new_state", current))
                    return res
                local_output = checkpoint(
                    local_expert_wrapper,
                    current_state,
                    local_neighbor_states,
                    use_reentrant=False,
                )
            else:
                local_output = self.memory_pool_manager.get_tensor(
                    (1, self.state_size), dtype=current_state.dtype
                )
                tensors_to_return.append(local_output)

            # Functional Expert
            if functional_data["indices"]:
                functional_neighbor_states = functional_data["states"]
                # –î–æ–±–∞–≤–ª—è–µ–º batch dimension –∫ neighbor_states –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if functional_neighbor_states.dim() == 2:
                    functional_neighbor_states = functional_neighbor_states.unsqueeze(0)  # [1, num_neighbors, state_size]
                def functional_expert_wrapper(current, neighbors):
                    res = self.functional_expert(current, neighbors)
                    if isinstance(res, dict):
                        return res.get("output", res.get("new_state", current))
                    return res
                # –û—Ç–∫–ª—é—á–∞–µ–º checkpoint –¥–ª—è functional expert –∏–∑-–∑–∞ in-place operations
                # functional_output = checkpoint(
                #     functional_expert_wrapper,
                #     current_state,
                #     functional_neighbor_states,
                #     use_reentrant=False,
                # )
                functional_output = functional_expert_wrapper(
                    current_state,
                    functional_neighbor_states
                )
            else:
                functional_output = self.memory_pool_manager.get_tensor(
                    (1, self.state_size), dtype=current_state.dtype
                )
                tensors_to_return.append(functional_output)

            # Distant Expert (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ CNF –≤–∫–ª—é—á–µ–Ω)
            if self.enable_cnf and distant_data["indices"]:
                distant_neighbor_states = distant_data["states"]
                # –î–æ–±–∞–≤–ª—è–µ–º batch dimension –∫ neighbor_states –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if distant_neighbor_states.dim() == 2:
                    distant_neighbor_states = distant_neighbor_states.unsqueeze(0)  # [1, num_neighbors, state_size]
                def distant_expert_wrapper(current, neighbors):
                    res = self.distant_expert(current, neighbors)
                    if isinstance(res, dict):
                        return res.get("output", res.get("new_state", current))
                    return res
                distant_output = checkpoint(
                    distant_expert_wrapper,
                    current_state,
                    distant_neighbor_states,
                    use_reentrant=False,
                )
            else:
                distant_output = self.memory_pool_manager.get_tensor(
                    (1, self.state_size), dtype=current_state.dtype
                )
                tensors_to_return.append(distant_output)

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ expert_outputs
        expert_outputs.append(local_output.squeeze(0))
        expert_outputs.append(functional_output.squeeze(0))
        if self.enable_cnf:
            expert_outputs.append(distant_output.squeeze(0))

        # === 3. –ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
        try:
            # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ expert_outputs
            if not expert_outputs:
                logger.warning(
                    f"‚ö†Ô∏è –ù–µ—Ç –≤—ã—Ö–æ–¥–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx}, –ø—Ä–æ–ø—É—Å–∫ GatingNetwork."
                )
                final_state = current_state
                expert_weights = torch.zeros(
                    1, 3, device=device
                )  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤—ã–µ –≤–µ—Å–∞
            else:
                # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏–π —Å–æ—Å–µ–¥–µ–π ---
                # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ—Å–µ–¥–µ–π –∏–∑ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
                all_neighbor_states = []
                for category in ["local", "functional", "distant"]:
                    if neighbors_data[category]["states"].numel() > 0:
                        all_neighbor_states.append(neighbors_data[category]["states"])
                
                if all_neighbor_states:
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ—Å–µ–¥–µ–π
                    combined_neighbor_states = torch.cat(all_neighbor_states, dim=0)
                    neighbor_activity = torch.mean(combined_neighbor_states, dim=0, keepdim=True)
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ—Å–µ–¥–µ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä
                    neighbor_activity = torch.zeros(
                        1, self.state_size, device=device, dtype=current_state.dtype
                    )
                # neighbor_activity computed

                # –í—ã–∑–æ–≤ GatingNetwork —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –ø–æ —Ñ–æ—Ä–º–µ —Ç–µ–Ω–∑–æ—Ä–∞–º–∏
                logger.debug_forward(f"[{cell_idx}] –í—ã–∑–æ–≤ GatingNetwork...")
                combined_output, expert_weights = self.gating_network(
                    current_state=current_state,  # [1, state_size]
                    neighbor_activity=neighbor_activity,  # [1, state_size]
                    expert_outputs=expert_outputs,
                )
                logger.debug_forward(
                    f"[{cell_idx}] GatingNetwork –∑–∞–≤–µ—Ä—à–µ–Ω. combined_output: {combined_output.shape}, expert_weights: {expert_weights.shape}"
                )

                # Residual connection
                final_state = current_state + combined_output.squeeze(0)

        except Exception as e:
            logger.error(
                f"‚ùå MoE processor CRITICAL error on cell {cell_idx}: {e}",
                exc_info=True,
            )
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å
            final_state = current_state
            expert_weights = torch.zeros(1, 3, device=device)

        # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ–Ω–∑–æ—Ä—ã
        for t in tensors_to_return:
            self.memory_pool_manager.return_tensor(t)

        # === 4. –û–ë–ù–û–í–õ–ï–ù–ò–ï –°–¢–ê–¢–ò–°–¢–ò–ö–ò ===
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º neighbors_data –≤ —Ñ–æ—Ä–º–∞—Ç classifications –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        classifications = {
            ConnectionCategory.LOCAL: [{"target_idx": idx} for idx in neighbors_data["local"]["indices"]],
            ConnectionCategory.FUNCTIONAL: [{"target_idx": idx} for idx in neighbors_data["functional"]["indices"]],
            ConnectionCategory.DISTANT: [{"target_idx": idx} for idx in neighbors_data["distant"]["indices"]]
        }
        self._update_stats(classifications, expert_weights)

        log_cell_forward(
            "MoEConnectionProcessor",
            input_shapes={
                "current_state": current_state.shape,
                "total_neighbors": total_neighbors,
            },
            output_shape=final_state.shape,
        )

        # –û—Ç–¥–µ–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ expert_weights
        logger.debug_training(
            f"[{cell_idx}] Expert weights: {expert_weights.squeeze().tolist()}"
        )

        return {
            "new_state": final_state,
            "expert_weights": expert_weights,
            "classifications": classifications,
        }

    def _empty_forward_result(self, current_state: torch.Tensor) -> Dict[str, Any]:
        """–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —Å–ª—É—á–∞—è –±–µ–∑ —Å–æ—Å–µ–¥–µ–π"""
        return {
            "new_state": current_state,
            "expert_weights": torch.tensor(
                [1.0, 0.0, 0.0], device=current_state.device
            ),
            "classifications": {cat: [] for cat in ConnectionCategory},
            "expert_outputs": [
                current_state,
                torch.zeros_like(current_state),
                torch.zeros_like(current_state),
            ],
            "neighbor_count": 0,
        }

    def _update_stats(self, classifications: Dict, expert_weights: torch.Tensor):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        local_count = len(classifications[ConnectionCategory.LOCAL])
        functional_count = len(classifications[ConnectionCategory.FUNCTIONAL])
        distant_count = len(classifications[ConnectionCategory.DISTANT])

        self.usage_stats["local_connections"] += local_count
        self.usage_stats["functional_connections"] += functional_count
        self.usage_stats["distant_connections"] += distant_count
        self.usage_stats["total_forward_calls"] += 1

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Å–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        weights = expert_weights.detach()
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ weights - –º–æ–∂–µ—Ç –±—ã—Ç—å [3] –∏–ª–∏ [1, 3]
        if weights.dim() == 2:
            weights = weights.squeeze(0)  # [1, 3] -> [3]

        # Statistics collection disabled for performance in production
        # Debug mode check removed - stats always disabled for performance

    def get_usage_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        total_connections = max(
            1,
            self.usage_stats["local_connections"]
            + self.usage_stats["functional_connections"]
            + self.usage_stats["distant_connections"],
        )
        total_calls = max(1, self.usage_stats["total_forward_calls"])

        return {
            "connection_distribution": {
                "local_ratio": self.usage_stats["local_connections"]
                / total_connections,
                "functional_ratio": self.usage_stats["functional_connections"]
                / total_connections,
                "distant_ratio": self.usage_stats["distant_connections"]
                / total_connections,
            },
            "expert_usage": {
                "local_avg_weight": self.usage_stats["expert_weights"]["local"]
                / total_calls,
                "functional_avg_weight": self.usage_stats["expert_weights"][
                    "functional"
                ]
                / total_calls,
                "distant_avg_weight": self.usage_stats["expert_weights"]["distant"]
                / total_calls,
            },
            "total_forward_calls": total_calls,
            "total_connections": total_connections,
        }

    def reset_stats(self):
        """–°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        self.usage_stats = {
            "local_connections": 0,
            "functional_connections": 0,
            "distant_connections": 0,
            "total_forward_calls": 0,
            "expert_weights": {"local": 0.0, "functional": 0.0, "distant": 0.0},
        }

    def get_parameter_breakdown(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–±–∏–≤–∫—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º"""
        return {
            "local_expert": sum(p.numel() for p in self.local_expert.parameters()),
            "functional_expert": sum(
                p.numel() for p in self.functional_expert.parameters()
            ),
            "distant_expert": sum(p.numel() for p in self.distant_expert.parameters()),
            "gating_network": sum(p.numel() for p in self.gating_network.parameters()),
            "connection_classifier": sum(
                p.numel() for p in self.connection_classifier.parameters()
            ),
            "total": sum(p.numel() for p in self.parameters()),
        }

    def forward_embeddings(self, embeddings: torch.Tensor) -> torch.Tensor:
        """
        –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π forward –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –±–µ–∑ —Ä–µ—à–µ—Ç–∫–∏

        Args:
            embeddings: [batch_size, embedding_dim] - –≤—Ö–æ–¥–Ω—ã–µ —ç–º–±–µ–¥–∏–Ω–≥–∏

        Returns:
            processed_embeddings: [batch_size, embedding_dim] - –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —ç–º–±–µ–¥–∏–Ω–≥–∏
        """
        batch_size, embedding_dim = embeddings.shape
        device = embeddings.device

        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ functional expert
        # –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–º–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º–∏
        processed_batch = []

        for i in range(batch_size):
            current_embedding = embeddings[i : i + 1]  # [1, embedding_dim]

            # –°–æ–∑–¥–∞–µ–º "—Å–æ—Å–µ–¥–µ–π" –∏–∑ –¥—Ä—É–≥–∏—Ö —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –≤ batch'–µ
            neighbor_indices = [j for j in range(batch_size) if j != i]
            if len(neighbor_indices) > 0:
                neighbor_embeddings = embeddings[
                    neighbor_indices
                ]  # [batch_size-1, embedding_dim]
            else:
                neighbor_embeddings = torch.zeros(0, embedding_dim, device=device)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º functional expert –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            if neighbor_embeddings.shape[0] > 0:
                try:
                    result = self.functional_expert(
                        current_state=current_embedding,
                        neighbor_states=neighbor_embeddings,
                        external_input=None,
                    )
                    if isinstance(result, dict):
                        processed_embedding = result.get("new_state", current_embedding)
                    else:
                        processed_embedding = result
                except Exception as e:
                    logger.warning(f"Functional expert failed for embedding {i}: {e}")
                    processed_embedding = current_embedding
            else:
                processed_embedding = current_embedding

            processed_batch.append(processed_embedding)

        return torch.cat(processed_batch, dim=0)
