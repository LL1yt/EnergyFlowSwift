#!/usr/bin/env python3
"""
Unified Dataset Loader –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è 3D Cellular Neural Network
======================================================================

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:
- dialogue datasets (cache/dialogue_dataset/)
- prepared embeddings (data/embeddings/)
- cache embeddings (cache/llm_*.pt)

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ new_rebuild.config
"""

import torch
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Union
import random
from dataclasses import dataclass
import gc

from ....config import SimpleProjectConfig
from ....utils.logging import get_logger
from ....utils.device_manager import get_device_manager

logger = get_logger(__name__)


class GPUMemoryEstimator:
    """–û—Ü–µ–Ω–∫–∞ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ GPU –ø–∞–º—è—Ç—å—é –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–æ–≤"""
    
    def __init__(self):
        self.device_manager = get_device_manager()
        self.embedding_size_mb = 768 * 4 / (1024**2)  # float32, 768 dim
    
    def estimate_dataset_memory_mb(self, num_samples: int) -> float:
        """–û—Ü–µ–Ω–∫–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ MB"""
        return num_samples * self.embedding_size_mb
    
    def get_safe_sample_limit(self, reserve_for_training_gb: float = 20.0) -> Optional[int]:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ª–∏–º–∏—Ç —Å—ç–º–ø–ª–æ–≤, –æ—Å—Ç–∞–≤–ª—è—è –ø–∞–º—è—Ç—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            reserve_for_training_gb: –°–∫–æ–ª—å–∫–æ GB –æ—Å—Ç–∞–≤–∏—Ç—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        """
        if not self.device_manager.is_cuda():
            return None  # CPU —Ä–µ–∂–∏–º - –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
            
        total_memory_gb = self.device_manager.get_available_memory_gb()
        available_for_dataset_gb = total_memory_gb - reserve_for_training_gb
        
        if available_for_dataset_gb <= 0:
            logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ GPU –ø–∞–º—è—Ç–∏ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞. Total: {total_memory_gb:.1f}GB, Reserved: {reserve_for_training_gb}GB")
            return 100  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π fallback
            
        available_for_dataset_mb = available_for_dataset_gb * 1024
        safe_samples = int(available_for_dataset_mb / self.embedding_size_mb * 0.8)  # 80% –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        
        logger.info(f"üßÆ GPU Memory Planning:")
        logger.info(f"  Total GPU: {total_memory_gb:.1f}GB")
        logger.info(f"  Reserved for training: {reserve_for_training_gb}GB")
        logger.info(f"  Available for dataset: {available_for_dataset_gb:.1f}GB")
        logger.info(f"  Safe sample limit: {safe_samples:,}")
        
        return safe_samples


@dataclass 
class DatasetStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    total_samples: int
    embedding_dim: int
    source_distribution: Dict[str, int]
    type_distribution: Dict[str, int]


class UnifiedEmbeddingDataset(Dataset):
    """
    Unified Dataset –¥–ª—è –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    """
    
    def __init__(self, config: SimpleProjectConfig, max_total_samples: Optional[int] = None):
        self.config = config
        self.device_manager = get_device_manager()
        self.memory_estimator = GPUMemoryEstimator()
        
        # –£–º–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
        self.max_total_samples = self._plan_memory_usage(max_total_samples)
        
        self.embeddings: List[torch.Tensor] = []
        self.metadata: List[Dict] = []
        self.use_gpu_acceleration = self.device_manager.is_cuda()
        
        logger.info("üîÑ Initializing GPU-accelerated UnifiedEmbeddingDataset...")
        logger.info(f"üöÄ GPU acceleration: {'‚úÖ Enabled' if self.use_gpu_acceleration else '‚ùå Disabled'}")
        if self.max_total_samples is not None:
            logger.info(f"üìä Smart memory limit: {self.max_total_samples:,} samples")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        self._load_all_sources()
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—â–∏–π –ª–∏–º–∏—Ç –µ—Å–ª–∏ –∑–∞–¥–∞–Ω
        self._apply_total_limit()
        
        # GPU-—É—Å–∫–æ—Ä–µ–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è
        if self.use_gpu_acceleration:
            self._gpu_filter_and_validate()
        else:
            self._filter_and_validate()
        
        logger.info(f"‚úÖ Dataset ready: {len(self.embeddings)} samples")
        self._log_memory_usage()
    
    def _plan_memory_usage(self, requested_limit: Optional[int]) -> Optional[int]:
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ —Å —É—á–µ—Ç–æ–º –æ–±—É—á–µ–Ω–∏—è"""
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑–µ—Ä–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        training_reserve_gb = getattr(self.config.training_embedding, 'gpu_memory_reserve_gb', 20.0)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ª–∏–º–∏—Ç –∏—Å—Ö–æ–¥—è –∏–∑ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏
        safe_limit = self.memory_estimator.get_safe_sample_limit(training_reserve_gb)
        
        if requested_limit is None:
            return safe_limit  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ª–∏–º–∏—Ç
        
        if safe_limit is None:
            return requested_limit  # CPU —Ä–µ–∂–∏–º - –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
            
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º—É–º –∏–∑ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–≥–æ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ
        final_limit = min(requested_limit, safe_limit)
        
        if final_limit < requested_limit:
            logger.warning(f"‚ö†Ô∏è Requested {requested_limit:,} samples, but GPU memory allows only {final_limit:,}")
            
        return final_limit
    
    def _log_memory_usage(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        if self.use_gpu_acceleration:
            stats = self.device_manager.get_memory_stats()
            estimated_mb = self.memory_estimator.estimate_dataset_memory_mb(len(self.embeddings))
            
            logger.info(f"üìä GPU Memory Usage:")
            logger.info(f"  Dataset estimated: {estimated_mb:.1f}MB")
            logger.info(f"  GPU allocated: {stats.get('allocated_mb', 0):.1f}MB")
            logger.info(f"  GPU available: {self.device_manager.get_available_memory_gb():.1f}GB")
    
    def _load_all_sources(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        
        # –í—Å–µ–≥–¥–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        self._load_dialogue_cache()
        self._load_prepared_embeddings()
        self._load_cache_embeddings()
    
    def _apply_total_limit(self):
        """–ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—â–∏–π –ª–∏–º–∏—Ç –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—ç–º–ø–ª–æ–≤"""
        if self.max_total_samples is None:
            return
            
        current_total = len(self.embeddings)
        logger.info(f"üìä Before limit: {current_total} samples")
        
        if current_total > self.max_total_samples:
            # –°–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –≤—ã–±–∏—Ä–∞–µ–º —Å—ç–º–ø–ª—ã, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
            indices = list(range(current_total))
            random.shuffle(indices)
            selected_indices = indices[:self.max_total_samples]
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—ã–±–æ—Ä
            self.embeddings = [self.embeddings[i] for i in selected_indices]
            self.metadata = [self.metadata[i] for i in selected_indices]
            
            logger.info(f"üìä Applied total limit: {len(self.embeddings)} samples (reduced from {current_total})")
    
    def _load_dialogue_cache(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º dialogue datasets –∏–∑ cache/dialogue_dataset/"""
        cache_dir = Path("cache/dialogue_dataset")
        files = list(cache_dir.glob("*.pt"))
        
        logger.info(f"üìÇ Loading dialogue cache: {len(files)} files")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        map_location = 'cuda' if self.use_gpu_acceleration else 'cpu'
        
        loaded_count = 0
        for file in files:
            try:
                data = torch.load(file, map_location=map_location)
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑ –∞–Ω–∞–ª–∏–∑–∞: questions [4, 768], answers [4, 768]
                embeddings = []
                
                if 'questions' in data and isinstance(data['questions'], torch.Tensor):
                    questions = data['questions']
                    if questions.dim() == 2:  # [batch, 768]
                        embeddings.extend([questions[i] for i in range(questions.size(0))])
                
                if 'answers' in data and isinstance(data['answers'], torch.Tensor):
                    answers = data['answers'] 
                    if answers.dim() == 2:  # [batch, 768]
                        embeddings.extend([answers[i] for i in range(answers.size(0))])
                
                for emb in embeddings:
                    if self._is_valid_embedding(emb):
                        self.embeddings.append(emb)
                        self.metadata.append({
                            "source": "dialogue_cache",
                            "file": file.name,
                            "type": "dialogue"
                        })
                        loaded_count += 1
                            
            except Exception as e:
                logger.warning(f"Failed to load dialogue file {file}: {e}")
                
        logger.info(f"‚úÖ Loaded {loaded_count} embeddings from dialogue cache")
    
    def _load_prepared_embeddings(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º prepared embeddings –∏–∑ data/embeddings/"""
        embeddings_dir = Path("data/embeddings")
        files = list(embeddings_dir.glob("*.pt"))
        
        logger.info(f"üìÇ Loading prepared embeddings: {len(files)} files")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        map_location = 'cuda' if self.use_gpu_acceleration else 'cpu'
        
        loaded_count = 0
        for file in files:
            try:
                data = torch.load(file, map_location=map_location)
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑ –∞–Ω–∞–ª–∏–∑–∞: question_embeddings, answer_embeddings
                embeddings = []
                
                if isinstance(data, dict):
                    for key in ['question_embeddings', 'answer_embeddings']:
                        if key in data:
                            emb_data = data[key]
                            if isinstance(emb_data, torch.Tensor) and emb_data.dim() == 2:
                                # [num_samples, 768] -> list of [768] tensors
                                embeddings.extend([emb_data[i] for i in range(emb_data.size(0))])
                
                elif isinstance(data, torch.Tensor):
                    if data.dim() == 2:  # [batch, dim]
                        embeddings.extend([data[i] for i in range(data.size(0))])
                    elif data.dim() == 1:  # [dim]
                        embeddings.append(data)
                
                for emb in embeddings:
                    if self._is_valid_embedding(emb):
                        self.embeddings.append(emb)
                        self.metadata.append({
                            "source": "prepared_embeddings",
                            "file": file.name,
                            "type": "prepared"
                        })
                        loaded_count += 1
                    
            except Exception as e:
                logger.warning(f"Failed to load prepared embedding {file}: {e}")
                
        logger.info(f"‚úÖ Loaded {loaded_count} embeddings from prepared files")
    
    def _load_cache_embeddings(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º cache —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ cache/llm_*.pt"""
        cache_files = list(Path("cache").glob("llm_*.pt"))
        
        logger.info(f"üìÇ Loading cache embeddings: {len(cache_files)} files")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        map_location = 'cuda' if self.use_gpu_acceleration else 'cpu'
        
        loaded_count = 0
        for file in cache_files:
            try:
                data = torch.load(file, map_location=map_location)
                
                # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞: [94, 4096] torch.float16
                if isinstance(data, torch.Tensor):
                    # –≠—Ç–∏ —Ñ–∞–π–ª—ã –∏–º–µ—é—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å 4096, –Ω–∞–º –Ω—É–∂–Ω–∞ 768
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Ö –ø–æ–∫–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–µ–∫—Ü–∏—é
                    if data.shape[-1] != self.config.embedding.input_dim:
                        logger.debug(f"Skipping {file.name}: wrong dimension {data.shape[-1]} != {self.config.embedding.input_dim}")
                        continue
                    
                    if data.dim() == 2:  # [batch, dim]
                        for i in range(min(data.size(0), 100)):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                            emb = data[i].float()  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ float16
                            if self._is_valid_embedding(emb):
                                self.embeddings.append(emb)
                                self.metadata.append({
                                    "source": "cache_embeddings",
                                    "file": file.name,
                                    "type": "cache"
                                })
                                loaded_count += 1
                    elif data.dim() == 1:  # [dim]
                        emb = data.float()
                        if self._is_valid_embedding(emb):
                            self.embeddings.append(emb)
                            self.metadata.append({
                                "source": "cache_embeddings",
                                "file": file.name,
                                "type": "cache"
                            })
                            loaded_count += 1
                    
            except Exception as e:
                logger.warning(f"Failed to load cache embedding {file}: {e}")
                
        logger.info(f"‚úÖ Loaded {loaded_count} embeddings from cache files")
    
    def _is_valid_embedding(self, emb: torch.Tensor) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–Ω—Ñ–∏–≥"""
        if not isinstance(emb, torch.Tensor):
            return False
            
        if emb.dim() != 1:
            return False
            
        if emb.size(0) != self.config.embedding.input_dim:
            return False
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ—Ä–º—É (–±–∞–∑–æ–≤—ã–µ –ø—Ä–µ–¥–µ–ª—ã)
        norm = torch.norm(emb).item()
        if norm < 0.1 or norm > 100.0:
            return False
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN/Inf
        if torch.isnan(emb).any() or torch.isinf(emb).any():
            return False
            
        return True
    
    def _filter_and_validate(self):
        """–§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("üîç Filtering and validating dataset...")
        
        # Shuffle
        combined = list(zip(self.embeddings, self.metadata))
        random.shuffle(combined)
        self.embeddings, self.metadata = zip(*combined)
        self.embeddings = list(self.embeddings)
        self.metadata = list(self.metadata)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ç–∏–ø
        self.embeddings = [emb.float() for emb in self.embeddings]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        source_stats = {}
        for meta in self.metadata:
            source = meta['source']
            source_stats[source] = source_stats.get(source, 0) + 1
            
        logger.info("üìä Dataset statistics:")
        for source, count in source_stats.items():
            logger.info(f"  {source}: {count} samples")
    
    def _gpu_filter_and_validate(self):
        """GPU-—É—Å–∫–æ—Ä–µ–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("üöÄ GPU-accelerated filtering and validation...")
        
        if not self.embeddings:
            return
            
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ batch tensor –¥–ª—è GPU –æ–±—Ä–∞–±–æ—Ç–∫–∏
        try:
            # –°–æ–∑–¥–∞–µ–º –±–∞—Ç—á —Ç–µ–Ω–∑–æ—Ä –Ω–∞ GPU
            embeddings_batch = torch.stack([emb.float() for emb in self.embeddings])
            
            # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ GPU
            valid_mask = self._gpu_validate_batch(embeddings_batch)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å–∫—É
            valid_embeddings_batch = embeddings_batch[valid_mask]
            valid_metadata = [meta for i, meta in enumerate(self.metadata) if valid_mask[i]]
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å–ø–∏—Å–æ–∫
            self.embeddings = [valid_embeddings_batch[i] for i in range(valid_embeddings_batch.size(0))]
            self.metadata = valid_metadata
            
            # Shuffle –Ω–∞ GPU
            if len(self.embeddings) > 0:
                indices = torch.randperm(len(self.embeddings), device=embeddings_batch.device)
                self.embeddings = [self.embeddings[i] for i in indices.cpu()]
                self.metadata = [self.metadata[i] for i in indices.cpu()]
            
            logger.info(f"‚úÖ GPU validation completed: {len(self.embeddings)} valid samples")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è GPU validation failed, falling back to CPU: {e}")
            self._filter_and_validate()
            return
            
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        source_stats = {}
        for meta in self.metadata:
            source = meta['source']
            source_stats[source] = source_stats.get(source, 0) + 1
            
        logger.info("üìä GPU Dataset statistics:")
        for source, count in source_stats.items():
            logger.info(f"  {source}: {count} samples")
            
        # –û—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏
        if 'embeddings_batch' in locals():
            del embeddings_batch
        if 'valid_embeddings_batch' in locals():
            del valid_embeddings_batch
        gc.collect()
        torch.cuda.empty_cache()
    
    def _gpu_validate_batch(self, embeddings_batch: torch.Tensor) -> torch.Tensor:
        """
        –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –±–∞—Ç—á–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –Ω–∞ GPU
        
        Args:
            embeddings_batch: [N, 768] tensor on GPU
            
        Returns:
            valid_mask: [N] boolean tensor
        """
        N = embeddings_batch.size(0)
        device = embeddings_batch.device
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (–≤—Å–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å 768)
        dim_valid = embeddings_batch.size(1) == self.config.embedding.input_dim
        
        # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ—Ä–º
        norms = torch.norm(embeddings_batch, dim=1)  # [N]
        norm_valid = (norms > 0.1) & (norms < 100.0)  # [N]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN/Inf
        nan_valid = ~torch.isnan(embeddings_batch).any(dim=1)  # [N]
        inf_valid = ~torch.isinf(embeddings_batch).any(dim=1)  # [N]
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –≤—Å–µ —É—Å–ª–æ–≤–∏—è
        valid_mask = norm_valid & nan_valid & inf_valid
        
        # –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è, –æ—Ç–∫–ª–æ–Ω—è–µ–º –≤—Å–µ
        if not dim_valid:
            valid_mask = torch.zeros(N, dtype=torch.bool, device=device)
            
        logger.info(f"üîç GPU validation: {valid_mask.sum().item()}/{N} samples passed")
        
        return valid_mask
    
    def __len__(self) -> int:
        return len(self.embeddings)
    
    def __getitem__(self, idx: int) -> Dict[str, Union[torch.Tensor, Dict]]:
        return {
            'embedding': self.embeddings[idx],
            'metadata': self.metadata[idx]
        }
    
    def get_stats(self) -> DatasetStats:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É"""
        source_stats = {}
        type_stats = {}
        
        for meta in self.metadata:
            source = meta['source']
            type_name = meta.get('type', 'unknown')
            
            source_stats[source] = source_stats.get(source, 0) + 1
            type_stats[type_name] = type_stats.get(type_name, 0) + 1
        
        return DatasetStats(
            total_samples=len(self.embeddings),
            embedding_dim=self.config.embedding.input_dim,
            source_distribution=source_stats,
            type_distribution=type_stats
        )


def create_training_dataloader(
    config: SimpleProjectConfig,
    max_total_samples: Optional[int] = None,
    shuffle: bool = True,
    num_workers: int = 0
) -> Tuple[DataLoader, DatasetStats]:
    """
    –°–æ–∑–¥–∞–µ—Ç DataLoader –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É—è —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    
    Args:
        config: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
        max_total_samples: –û–±—â–∏–π –ª–∏–º–∏—Ç –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—ç–º–ø–ª–æ–≤ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç config)
        shuffle: –ü–µ—Ä–µ–º–µ—à–∏–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
        num_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        
    Returns:
        Tuple[DataLoader, DatasetStats]: DataLoader –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
    """
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–π –ª–∏–º–∏—Ç –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, –µ—Å–ª–∏ –æ–Ω –∑–∞–¥–∞–Ω
    if config.training_embedding.max_total_samples is not None:
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: max_total_samples –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        effective_max_samples = config.training_embedding.max_total_samples
        logger.info(f"üìä Using max_total_samples from config: {effective_max_samples}")
    else:
        # Fallback –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä —Ñ—É–Ω–∫—Ü–∏–∏
        effective_max_samples = max_total_samples
        if effective_max_samples is not None:
            logger.info(f"üìä Using max_total_samples parameter: {effective_max_samples}")
        else:
            logger.info("üìä No sample limit - using full dataset")
    
    dataset = UnifiedEmbeddingDataset(config, effective_max_samples)
    stats = dataset.get_stats()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º batch_size –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    batch_size = config.training_embedding.embedding_batch_size
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è RTX 5090
    device_manager = get_device_manager()
    is_cuda = device_manager.is_cuda()
    
    # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è RTX 5090
    optimal_num_workers = 8 if is_cuda else num_workers  # 4*2 GPU cores
    prefetch_factor = 4 if is_cuda else 2
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=optimal_num_workers,
        pin_memory=is_cuda,
        drop_last=True,  # –î–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–æ–≤ –±–∞—Ç—á–µ–π
        persistent_workers=True if optimal_num_workers > 0 else False,  # PyTorch 2.x –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        prefetch_factor=prefetch_factor if optimal_num_workers > 0 else None
    )
    
    logger.info(f"üöÄ Optimized DataLoader for RTX 5090:")
    logger.info(f"  Samples: {len(dataset):,}")
    logger.info(f"  Batch size: {batch_size}")
    logger.info(f"  Workers: {optimal_num_workers}")
    logger.info(f"  Pin memory: {is_cuda}")
    logger.info(f"  Persistent workers: {optimal_num_workers > 0}")
    logger.info(f"  Prefetch factor: {prefetch_factor}")
    
    logger.info(f"üöÄ DataLoader created: {len(dataset)} samples, batch_size={batch_size}")
    
    return dataloader, stats


def main():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º unified dataset loader"""
    from ....utils.logging import get_logger
    logger = get_logger(__name__)
    logger.info("üß™ TESTING UNIFIED DATASET LOADER")
    logger.info("=" * 50)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    from ....config import SimpleProjectConfig
    config = SimpleProjectConfig()
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞
    max_samples = 50
    
    # –°–æ–∑–¥–∞–µ–º DataLoader
    dataloader, stats = create_training_dataloader(
        config=config,
        max_total_samples=max_samples,
        shuffle=True
    )
    
    logger.info(f"\nüìä DATASET STATISTICS:")
    logger.info(f"Total samples: {stats.total_samples}")
    logger.info(f"Embedding dim: {stats.embedding_dim}")
    logger.info(f"Source distribution: {stats.source_distribution}")
    logger.info(f"Type distribution: {stats.type_distribution}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –±–∞—Ç—á–µ–π
    logger.info(f"\nüîÑ TESTING BATCH LOADING:")
    for i, batch in enumerate(dataloader):
        embeddings = batch['embedding']  # [batch_size, embedding_dim]
        metadata = batch['metadata']  # List of dicts
        
        logger.info(f"Batch {i+1}:")
        logger.info(f"  Embeddings shape: {embeddings.shape}")
        logger.info(f"  Embeddings dtype: {embeddings.dtype}")
        logger.info(f"  Metadata samples: {len(metadata)}")
        
        if i >= 2:  # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3 –±–∞—Ç—á–∞
            break
    
    logger.info(f"\n‚úÖ Unified Dataset Loader test completed!")
    logger.info(f"üìà Ready for real training with {stats.total_samples} samples")


if __name__ == "__main__":
    main()