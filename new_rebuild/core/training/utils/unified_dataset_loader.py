#!/usr/bin/env python3
"""
Unified Dataset Loader –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è 3D Cellular Neural Network
======================================================================

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:
- dialogue datasets (cache/dialogue_dataset/)
- prepared embeddings (data/embeddings/)
- cache embeddings (cache/llm_*.pt)

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ new_rebuild.config
"""

import torch
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Union
import random
from dataclasses import dataclass

from ....config import SimpleProjectConfig
from ....utils.logging import get_logger

logger = get_logger(__name__)


@dataclass 
class DatasetStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    total_samples: int
    embedding_dim: int
    source_distribution: Dict[str, int]
    type_distribution: Dict[str, int]


class UnifiedEmbeddingDataset(Dataset):
    """
    Unified Dataset –¥–ª—è –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    """
    
    def __init__(self, config: SimpleProjectConfig, max_samples_per_source: Optional[int] = None):
        self.config = config
        self.max_samples_per_source = max_samples_per_source
        self.embeddings: List[torch.Tensor] = []
        self.metadata: List[Dict] = []
        
        logger.info("üîÑ Initializing UnifiedEmbeddingDataset with central config...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        self._load_all_sources()
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º
        self._filter_and_validate()
        
        logger.info(f"‚úÖ Dataset ready: {len(self.embeddings)} samples")
    
    def _load_all_sources(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        
        # –í—Å–µ–≥–¥–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        self._load_dialogue_cache()
        self._load_prepared_embeddings()
        self._load_cache_embeddings()
    
    def _load_dialogue_cache(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º dialogue datasets –∏–∑ cache/dialogue_dataset/"""
        cache_dir = Path("cache/dialogue_dataset")
        files = list(cache_dir.glob("*.pt"))
        
        logger.info(f"üìÇ Loading dialogue cache: {len(files)} files")
        
        loaded_count = 0
        for file in files:
            try:
                data = torch.load(file, map_location='cpu')
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑ –∞–Ω–∞–ª–∏–∑–∞: questions [4, 768], answers [4, 768]
                embeddings = []
                
                if 'questions' in data and isinstance(data['questions'], torch.Tensor):
                    questions = data['questions']
                    if questions.dim() == 2:  # [batch, 768]
                        embeddings.extend([questions[i] for i in range(questions.size(0))])
                
                if 'answers' in data and isinstance(data['answers'], torch.Tensor):
                    answers = data['answers'] 
                    if answers.dim() == 2:  # [batch, 768]
                        embeddings.extend([answers[i] for i in range(answers.size(0))])
                
                for emb in embeddings:
                    if self._is_valid_embedding(emb):
                        self.embeddings.append(emb)
                        self.metadata.append({
                            "source": "dialogue_cache",
                            "file": file.name,
                            "type": "dialogue"
                        })
                        loaded_count += 1
                        
                        if (self.max_samples_per_source and 
                            loaded_count >= self.max_samples_per_source):
                            break
                            
            except Exception as e:
                logger.warning(f"Failed to load dialogue file {file}: {e}")
                
        logger.info(f"‚úÖ Loaded {loaded_count} embeddings from dialogue cache")
    
    def _load_prepared_embeddings(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º prepared embeddings –∏–∑ data/embeddings/"""
        embeddings_dir = Path("data/embeddings")
        files = list(embeddings_dir.glob("*.pt"))
        
        logger.info(f"üìÇ Loading prepared embeddings: {len(files)} files")
        
        loaded_count = 0
        for file in files:
            try:
                data = torch.load(file, map_location='cpu')
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑ –∞–Ω–∞–ª–∏–∑–∞: question_embeddings, answer_embeddings
                embeddings = []
                
                if isinstance(data, dict):
                    for key in ['question_embeddings', 'answer_embeddings']:
                        if key in data:
                            emb_data = data[key]
                            if isinstance(emb_data, torch.Tensor) and emb_data.dim() == 2:
                                # [num_samples, 768] -> list of [768] tensors
                                embeddings.extend([emb_data[i] for i in range(emb_data.size(0))])
                
                elif isinstance(data, torch.Tensor):
                    if data.dim() == 2:  # [batch, dim]
                        embeddings.extend([data[i] for i in range(data.size(0))])
                    elif data.dim() == 1:  # [dim]
                        embeddings.append(data)
                
                for emb in embeddings:
                    if self._is_valid_embedding(emb):
                        self.embeddings.append(emb)
                        self.metadata.append({
                            "source": "prepared_embeddings",
                            "file": file.name,
                            "type": "prepared"
                        })
                        loaded_count += 1
                
                if (self.max_samples_per_source and 
                    loaded_count >= self.max_samples_per_source):
                    break
                    
            except Exception as e:
                logger.warning(f"Failed to load prepared embedding {file}: {e}")
                
        logger.info(f"‚úÖ Loaded {loaded_count} embeddings from prepared files")
    
    def _load_cache_embeddings(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º cache —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ cache/llm_*.pt"""
        cache_files = list(Path("cache").glob("llm_*.pt"))
        
        logger.info(f"üìÇ Loading cache embeddings: {len(cache_files)} files")
        
        loaded_count = 0
        for file in cache_files:
            try:
                data = torch.load(file, map_location='cpu')
                
                # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞: [94, 4096] torch.float16
                if isinstance(data, torch.Tensor):
                    # –≠—Ç–∏ —Ñ–∞–π–ª—ã –∏–º–µ—é—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å 4096, –Ω–∞–º –Ω—É–∂–Ω–∞ 768
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Ö –ø–æ–∫–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–µ–∫—Ü–∏—é
                    if data.shape[-1] != self.config.embedding.input_dim:
                        logger.debug(f"Skipping {file.name}: wrong dimension {data.shape[-1]} != {self.config.embedding.input_dim}")
                        continue
                    
                    if data.dim() == 2:  # [batch, dim]
                        for i in range(min(data.size(0), 100)):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                            emb = data[i].float()  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ float16
                            if self._is_valid_embedding(emb):
                                self.embeddings.append(emb)
                                self.metadata.append({
                                    "source": "cache_embeddings",
                                    "file": file.name,
                                    "type": "cache"
                                })
                                loaded_count += 1
                    elif data.dim() == 1:  # [dim]
                        emb = data.float()
                        if self._is_valid_embedding(emb):
                            self.embeddings.append(emb)
                            self.metadata.append({
                                "source": "cache_embeddings",
                                "file": file.name,
                                "type": "cache"
                            })
                            loaded_count += 1
                
                if (self.max_samples_per_source and 
                    loaded_count >= self.max_samples_per_source):
                    break
                    
            except Exception as e:
                logger.warning(f"Failed to load cache embedding {file}: {e}")
                
        logger.info(f"‚úÖ Loaded {loaded_count} embeddings from cache files")
    
    def _is_valid_embedding(self, emb: torch.Tensor) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–Ω—Ñ–∏–≥"""
        if not isinstance(emb, torch.Tensor):
            return False
            
        if emb.dim() != 1:
            return False
            
        if emb.size(0) != self.config.embedding.input_dim:
            return False
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ—Ä–º—É (–±–∞–∑–æ–≤—ã–µ –ø—Ä–µ–¥–µ–ª—ã)
        norm = torch.norm(emb).item()
        if norm < 0.1 or norm > 100.0:
            return False
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN/Inf
        if torch.isnan(emb).any() or torch.isinf(emb).any():
            return False
            
        return True
    
    def _filter_and_validate(self):
        """–§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("üîç Filtering and validating dataset...")
        
        # Shuffle
        combined = list(zip(self.embeddings, self.metadata))
        random.shuffle(combined)
        self.embeddings, self.metadata = zip(*combined)
        self.embeddings = list(self.embeddings)
        self.metadata = list(self.metadata)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ç–∏–ø
        self.embeddings = [emb.float() for emb in self.embeddings]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        source_stats = {}
        for meta in self.metadata:
            source = meta['source']
            source_stats[source] = source_stats.get(source, 0) + 1
            
        logger.info("üìä Dataset statistics:")
        for source, count in source_stats.items():
            logger.info(f"  {source}: {count} samples")
    
    def __len__(self) -> int:
        return len(self.embeddings)
    
    def __getitem__(self, idx: int) -> Dict[str, Union[torch.Tensor, Dict]]:
        return {
            'embedding': self.embeddings[idx],
            'metadata': self.metadata[idx]
        }
    
    def get_stats(self) -> DatasetStats:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É"""
        source_stats = {}
        type_stats = {}
        
        for meta in self.metadata:
            source = meta['source']
            type_name = meta.get('type', 'unknown')
            
            source_stats[source] = source_stats.get(source, 0) + 1
            type_stats[type_name] = type_stats.get(type_name, 0) + 1
        
        return DatasetStats(
            total_samples=len(self.embeddings),
            embedding_dim=self.config.embedding.input_dim,
            source_distribution=source_stats,
            type_distribution=type_stats
        )


def create_training_dataloader(
    config: SimpleProjectConfig,
    max_samples_per_source: Optional[int] = None,
    shuffle: bool = True,
    num_workers: int = 0
) -> Tuple[DataLoader, DatasetStats]:
    """
    –°–æ–∑–¥–∞–µ—Ç DataLoader –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É—è —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    
    Args:
        config: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
        max_samples_per_source: –ú–∞–∫—Å–∏–º—É–º –æ–±—Ä–∞–∑—Ü–æ–≤ —Å –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–¥–ª—è —Ç–µ—Å—Ç–æ–≤)
        shuffle: –ü–µ—Ä–µ–º–µ—à–∏–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
        num_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        
    Returns:
        Tuple[DataLoader, DatasetStats]: DataLoader –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
    """
    
    dataset = UnifiedEmbeddingDataset(config, max_samples_per_source)
    stats = dataset.get_stats()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º batch_size –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    batch_size = config.training_embedding.embedding_batch_size
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available(),
        drop_last=True  # –î–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–æ–≤ –±–∞—Ç—á–µ–π
    )
    
    logger.info(f"üöÄ DataLoader created: {len(dataset)} samples, batch_size={batch_size}")
    
    return dataloader, stats


def main():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º unified dataset loader"""
    print("üß™ TESTING UNIFIED DATASET LOADER")
    print("=" * 50)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    from ....config import SimpleProjectConfig
    config = SimpleProjectConfig()
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞
    max_samples = 50
    
    # –°–æ–∑–¥–∞–µ–º DataLoader
    dataloader, stats = create_training_dataloader(
        config=config,
        max_samples_per_source=max_samples,
        shuffle=True
    )
    
    print(f"\nüìä DATASET STATISTICS:")
    print(f"Total samples: {stats.total_samples}")
    print(f"Embedding dim: {stats.embedding_dim}")
    print(f"Source distribution: {stats.source_distribution}")
    print(f"Type distribution: {stats.type_distribution}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –±–∞—Ç—á–µ–π
    print(f"\nüîÑ TESTING BATCH LOADING:")
    for i, batch in enumerate(dataloader):
        embeddings = batch['embedding']  # [batch_size, embedding_dim]
        metadata = batch['metadata']  # List of dicts
        
        print(f"Batch {i+1}:")
        print(f"  Embeddings shape: {embeddings.shape}")
        print(f"  Embeddings dtype: {embeddings.dtype}")
        print(f"  Metadata samples: {len(metadata)}")
        
        if i >= 2:  # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3 –±–∞—Ç—á–∞
            break
    
    print(f"\n‚úÖ Unified Dataset Loader test completed!")
    print(f"üìà Ready for real training with {stats.total_samples} samples")


if __name__ == "__main__":
    main()