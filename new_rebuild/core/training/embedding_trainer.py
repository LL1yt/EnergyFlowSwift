#!/usr/bin/env python3
"""
–ë–∞–∑–æ–≤—ã–π —Ç—Ä–µ–Ω–µ—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è 3D –∫—É–±–∞ –Ω–∞ —ç–º–±–µ–¥–∏–Ω–≥–∞—Ö
===================================================

–ì–ª–∞–≤–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è training —Ñ–∞–∑—ã, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π:
1. EmbeddingTransformer - –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ DistilBERT
2. MoE Connection Processor - –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∫–ª–µ—Ç–∫–∞–º–∏
3. TextDecoder - –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ç–µ–∫—Å—Ç
4. Loss —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
Text ‚Üí DistilBERT ‚Üí EmbeddingTransformer ‚Üí MoE Cube ‚Üí EmbeddingTransformer ‚Üí TextDecoder ‚Üí Text

–ü—Ä–∏–Ω—Ü–∏–ø—ã:
- –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ SimpleProjectConfig
- GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è RTX 5090
- –ú–æ–¥—É–ª—å–Ω–æ—Å—Ç—å –∏ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
- –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import time
from torch.utils.data import DataLoader

from ...utils.logging import get_logger
from ...config.simple_config import SimpleProjectConfig

from ..common.interfaces import (
    EmbeddingProcessor,
    CubeInterface,
    TrainingInterface,
    create_embedding_processor,
)
from ..common.embedding_transformer import EmbeddingTransformer
from ..inference.text_decoder import SimpleTextDecoder, JointTextDecoder
from ..moe import create_moe_connection_processor
from ..lattice.lattice import Lattice3D
from .embedding_lattice_mapper import (
    create_embedding_lattice_mapper, 
    create_lattice_embedding_extractor,
    EmbeddingLatticeSettings
)

logger = get_logger(__name__)


class EmbeddingTrainer(TrainingInterface):
    """
    –û—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–µ–Ω–µ—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è 3D –∫—É–±–∞ –Ω–∞ —ç–º–±–µ–¥–∏–Ω–≥–∞—Ö

    –†–µ–∞–ª–∏–∑—É–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª: —ç–º–±–µ–¥–∏–Ω–≥–∏ ‚Üí –∫—É–± ‚Üí —ç–º–±–µ–¥–∏–Ω–≥–∏ ‚Üí —Ç–µ–∫—Å—Ç
    —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–ª–∏—á–Ω—ã—Ö loss —Ñ—É–Ω–∫—Ü–∏–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏.
    """

    def __init__(self, config: SimpleProjectConfig):
        self.config = config
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏—Ö get_project_config()
        from ...config import set_project_config
        set_project_config(config)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º device_manager –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –≤–º–µ—Å—Ç–æ —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ
        self.device_manager = config.device_manager
        self.device = self.device_manager.device

        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è EmbeddingTrainer –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {self.device}")

        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        self._init_components()

        # –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
        self.training_history = {
            "losses": [],
            "reconstruction_losses": [],
            "similarity_losses": [],
            "diversity_losses": [],
            "emergence_losses": [],
            "val_scores": [],
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.performance_stats = {
            "forward_times": [],
            "backward_times": [],
            "total_times": [],
        }

        logger.info("EmbeddingTrainer —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def _init_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""

        # 1. Embedding Transformer (Teacher ‚Üî Cube)
        self.embedding_transformer = EmbeddingTransformer(self.config).to(self.device)
        logger.info(
            f"EmbeddingTransformer: {self.embedding_transformer.get_parameter_count()} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
        )

        # 2. Lattice Integration Components
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–º–µ—Ä—ã –∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        lattice_dims = self.config.lattice.dimensions
        
        # –ú–∞–ø–ø–µ—Ä —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –≤ —Ä–µ—à–µ—Ç–∫—É
        self.lattice_mapper = create_embedding_lattice_mapper(self.config).to(self.device)
        
        # 3D —Ä–µ—à–µ—Ç–∫–∞ —Å MoE –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π (Lattice3D —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç get_project_config())
        self.lattice = Lattice3D().to(self.device)
        
        # –≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –∏–∑ —Ä–µ—à–µ—Ç–∫–∏
        self.lattice_extractor = create_lattice_embedding_extractor(self.config).to(self.device)
        
        logger.info(f"Lattice3D —Å–æ–∑–¥–∞–Ω–∞: {lattice_dims}, total_cells={np.prod(lattice_dims)}")

        # 3. Text Decoder (Cube ‚Üí Text)
        if self.config.training_embedding.test_mode:
            self.text_decoder = SimpleTextDecoder(self.config).to(self.device)
        else:
            # Joint training –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
            self.text_decoder = JointTextDecoder(self.config).to(self.device)

        logger.info(f"Text Decoder: {type(self.text_decoder).__name__}")

        # 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∏–Ω–∞–º–∏–∫–∏ —Ä–µ—à–µ—Ç–∫–∏
        self.lattice_settings = EmbeddingLatticeSettings()
        
        # 5. –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –¥–ª—è –≤—Å–µ—Ö trainable –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        trainable_params = list(self.embedding_transformer.parameters())
        trainable_params.extend(list(self.lattice_mapper.parameters()))
        trainable_params.extend(list(self.lattice.parameters()))
        trainable_params.extend(list(self.lattice_extractor.parameters()))
        
        if hasattr(self.text_decoder, "parameters"):
            trainable_params.extend(list(self.text_decoder.parameters()))

        self.optimizer = optim.AdamW(
            trainable_params, lr=1e-4, weight_decay=1e-5  # Conservative learning rate
        )
        
        total_params = sum(p.numel() for p in trainable_params)
        logger.info(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")


        # 6. Scheduler –¥–ª—è learning rate
        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer, T_0=10, T_mult=2
        )

    def train_epoch(
        self, dataloader: DataLoader, optimizer=None, **kwargs
    ) -> Dict[str, float]:
        """–û–±—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏"""
        if optimizer is None:
            optimizer = self.optimizer

        self.embedding_transformer.train()
        self.lattice_mapper.train()
        self.lattice.train()
        self.lattice_extractor.train()
        if hasattr(self.text_decoder, "train"):
            self.text_decoder.train()

        epoch_losses = {
            "total": 0.0,
            "reconstruction": 0.0,
            "similarity": 0.0,
            "diversity": 0.0,
            "emergence": 0.0,
            "lattice": 0.0,
            "spatial": 0.0,
            "count": 0,
        }

        epoch_start_time = time.time()

        for batch_idx, batch in enumerate(dataloader):
            batch_start_time = time.time()

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞—Ç—á–∞
            if isinstance(batch, dict):
                # Handle both 'embedding' (from dataloader) and 'embeddings' (legacy)
                key = "embedding" if "embedding" in batch else "embeddings"
                input_embeddings = batch[key].to(self.device)
                target_embeddings = batch.get("target_embeddings", input_embeddings).to(
                    self.device
                )
                texts = batch.get("texts", None)
            elif isinstance(batch, (list, tuple)):
                input_embeddings = batch[0].to(self.device)
                target_embeddings = (
                    batch[1].to(self.device) if len(batch) > 1 else input_embeddings
                )
                texts = batch[2] if len(batch) > 2 else None
            else:
                input_embeddings = batch.to(self.device)
                target_embeddings = input_embeddings
                texts = None

            # Forward pass
            forward_start = time.time()
            losses = self._forward_pass(input_embeddings, target_embeddings, texts)
            forward_time = time.time() - forward_start

            # Backward pass
            backward_start = time.time()
            total_loss = losses["total"]

            optimizer.zero_grad()
            total_loss.backward()

            # Gradient clipping –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            torch.nn.utils.clip_grad_norm_(
                [p for p in self.embedding_transformer.parameters()]
                + [p for p in self.lattice_mapper.parameters()]
                + [p for p in self.lattice.parameters()]
                + [p for p in self.lattice_extractor.parameters()],
                max_norm=1.0,
            )

            optimizer.step()
            backward_time = time.time() - backward_start

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            for key in epoch_losses:
                if key != "count":
                    epoch_losses[key] += losses.get(key, 0.0)
            epoch_losses["count"] += 1

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            batch_time = time.time() - batch_start_time
            self.performance_stats["forward_times"].append(forward_time)
            self.performance_stats["backward_times"].append(backward_time)
            self.performance_stats["total_times"].append(batch_time)

            if batch_idx % 10 == 0:
                logger.debug_training(
                    f"Batch {batch_idx}: loss={total_loss.item():.4f}, "
                    f"forward={forward_time:.3f}s, backward={backward_time:.3f}s"
                )

        # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ loss'–æ–≤
        for key in epoch_losses:
            if key != "count" and epoch_losses["count"] > 0:
                epoch_losses[key] /= epoch_losses["count"]

        epoch_time = time.time() - epoch_start_time
        logger.info(
            f"–≠–ø–æ—Ö–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: total_loss={epoch_losses['total']:.4f}, "
            f"–≤—Ä–µ–º—è={epoch_time:.2f}s, –±–∞—Ç—á–µ–π={epoch_losses['count']}"
        )

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ learning rate
        self.scheduler.step()

        return epoch_losses

    def _forward_pass(
        self,
        input_embeddings: torch.Tensor,
        target_embeddings: torch.Tensor,
        texts: Optional[List[str]] = None,
    ) -> Dict[str, torch.Tensor]:
        """
        –ü–æ–ª–Ω—ã–π forward pass —á–µ—Ä–µ–∑ –≤—Å—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É

        –ü–æ—Ç–æ–∫: Teacher Embeddings ‚Üí Surface ‚Üí 3D Lattice ‚Üí Emergent Dynamics ‚Üí Surface ‚Üí Teacher Embeddings
        """

        # 1. Teacher ‚Üí Cube Surface (768D ‚Üí 8√ó8 –¥–ª—è 8√ó8√ó8 –∫—É–±–∞)
        surface_embeddings = self.embedding_transformer.transform_to_cube(input_embeddings)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º 3D surface –≤ –ø–ª–æ—Å–∫–∏–π –≤–µ–∫—Ç–æ—Ä –¥–ª—è lattice_mapper
        batch_size = surface_embeddings.shape[0]
        surface_embeddings_flat = surface_embeddings.view(batch_size, -1)  # [batch, 64]

        # 2. Surface ‚Üí 3D Lattice initialization
        lattice_states = self.lattice_mapper(surface_embeddings_flat)
        
        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è loss'–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
        initial_states = lattice_states.clone()

        # 4. Emergent dynamics (–Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ —á–µ—Ä–µ–∑ MoE)
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤ —Ä–µ—à–µ—Ç–∫—É
        logger.debug_training(f"üîß Setting lattice states: {lattice_states.shape}")
        logger.debug_training(f"üîß Lattice config dimensions: {self.config.lattice.dimensions}")
        logger.debug_training(f"üîß Expected cells: {self.config.lattice.total_cells}")
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: Lattice –æ–∂–∏–¥–∞–µ—Ç [total_cells, state_size], —É–±–∏—Ä–∞–µ–º batch dimension
        # –î–ª—è batch_size=1 –ø—Ä–æ—Å—Ç–æ –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç
        if lattice_states.shape[0] == 1:
            self.lattice.states = lattice_states[0]  # [total_cells, state_size]
        else:
            # –î–ª—è batch_size > 1 –Ω—É–∂–Ω–∞ –¥—Ä—É–≥–∞—è –ª–æ–≥–∏–∫–∞
            raise NotImplementedError("Batch processing not yet supported in lattice")
        
        for step in range(self.lattice_settings.lattice_steps):
            # –í—ã–ø–æ–ª–Ω—è–µ–º —à–∞–≥ —Ä–µ—à–µ—Ç–∫–∏ (–æ–±–Ω–æ–≤–ª—è–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è)
            self.lattice.forward()  # Updates internal states
            
            # –ü–æ–ª—É—á–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –¥–æ–±–∞–≤–ª—è–µ–º batch dimension –æ–±—Ä–∞—Ç–Ω–æ
            current_lattice_states = self.lattice.states.unsqueeze(0)  # [1, total_cells, state_size]
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            if step > 0 and self._check_convergence(current_lattice_states, initial_states):
                logger.debug_training(f"–°—Ö–æ–¥–∏–º–æ—Å—Ç—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –Ω–∞ —à–∞–≥–µ {step}")
                break

        # 5. 3D Lattice ‚Üí Surface extraction
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å batch dimension
        final_lattice_states = self.lattice.states.unsqueeze(0)  # [1, total_cells, state_size]
        final_surface = self.lattice_extractor(final_lattice_states)  # [batch, 64]
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø–ª–æ—Å–∫–∏–π –≤–µ–∫—Ç–æ—Ä –æ–±—Ä–∞—Ç–Ω–æ –≤ 2D surface –¥–ª—è transformer
        # –î–ª—è –∫—É–±–∞ 8√ó8√ó8, –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä 8√ó8 = 64
        surface_size_1d = final_surface.shape[1]  # 64
        surface_size_2d = int(surface_size_1d ** 0.5)  # 8
        final_surface_2d = final_surface.view(batch_size, surface_size_2d, surface_size_2d)  # [batch, 8, 8]

        # 6. Surface ‚Üí Teacher embeddings (8√ó8 ‚Üí 768D –æ–±—Ä–∞—Ç–Ω–æ)
        output_embeddings = self.embedding_transformer.transform_from_cube(final_surface_2d)

        # 7. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ loss'–æ–≤ (–≤–∫–ª—é—á–∞—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—É—é —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å)
        losses = self._compute_losses(
            input_embeddings, output_embeddings, target_embeddings, texts,
            initial_states, final_lattice_states
        )

        return losses
    
    def _check_convergence(self, current_states: torch.Tensor, 
                          initial_states: torch.Tensor) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–∏–Ω–∞–º–∏–∫–∏ —Ä–µ—à–µ—Ç–∫–∏"""
        diff = torch.norm(current_states - initial_states, dim=-1).mean()
        return diff < self.lattice_settings.convergence_threshold

    def _compute_losses(
        self,
        input_embeddings: torch.Tensor,
        output_embeddings: torch.Tensor,
        target_embeddings: torch.Tensor,
        texts: Optional[List[str]] = None,
        initial_lattice_states: Optional[torch.Tensor] = None,
        final_lattice_states: Optional[torch.Tensor] = None,
    ) -> Dict[str, torch.Tensor]:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ loss —Ñ—É–Ω–∫—Ü–∏–∏"""

        losses = {}

        # 1. Reconstruction Loss (MSE –º–µ–∂–¥—É –≤—ã—Ö–æ–¥–æ–º –∏ —Ü–µ–ª–µ–≤—ã–º–∏ —ç–º–±–µ–¥–∏–Ω–≥–∞–º–∏)
        reconstruction_loss = nn.functional.mse_loss(
            output_embeddings, target_embeddings
        )
        losses["reconstruction"] = (
            reconstruction_loss
            * self.config.training_embedding.reconstruction_weight
        )

        # 2. Similarity Loss (cosine similarity preservation)
        input_sim = torch.cosine_similarity(
            input_embeddings.unsqueeze(1), input_embeddings.unsqueeze(0), dim=2
        )
        output_sim = torch.cosine_similarity(
            output_embeddings.unsqueeze(1), output_embeddings.unsqueeze(0), dim=2
        )
        similarity_loss = nn.functional.mse_loss(output_sim, input_sim)
        losses["similarity"] = (
            similarity_loss * self.config.training_embedding.similarity_weight
        )

        # 3. Diversity Loss (–ø–æ–æ—â—Ä–µ–Ω–∏–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –≤—ã—Ö–æ–¥–æ–≤)
        # –î–ª—è batch_size=1 diversity loss –Ω–µ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª–∞
        if output_embeddings.shape[0] > 1:
            output_mean = output_embeddings.mean(dim=0)
            diversity_loss = -torch.var(output_embeddings, dim=0).mean()
        else:
            diversity_loss = torch.tensor(0.0, device=output_embeddings.device)
        losses["diversity"] = (
            diversity_loss * self.config.training_embedding.diversity_weight
        )

        # 4. Emergence Loss (–ø–æ–æ—â—Ä–µ–Ω–∏–µ —ç–º–µ—Ä–¥–∂–µ–Ω—Ç–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è)
        # –ò–∑–º–µ—Ä—è–µ–º, –Ω–∞—Å–∫–æ–ª—å–∫–æ –≤—ã—Ö–æ–¥ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ö–æ–¥–∞
        identity_loss = nn.functional.mse_loss(output_embeddings, input_embeddings)
        emergence_loss = -torch.log(
            identity_loss + 1e-8
        )  # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø–æ–æ—â—Ä–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–∏–π
        losses["emergence"] = (
            emergence_loss * self.config.training_embedding.emergence_weight
        )

        # 5. Lattice Dynamics Loss (–µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ä–µ—à–µ—Ç–∫–∏)
        if initial_lattice_states is not None and final_lattice_states is not None:
            # –ü–æ–æ—â—Ä—è–µ–º –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Ä–µ—à–µ—Ç–∫–µ
            lattice_change = torch.norm(final_lattice_states - initial_lattice_states, dim=-1)
            lattice_loss = lattice_change.mean()  # –ù–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            losses["lattice"] = lattice_loss * self.lattice_settings.lattice_loss_weight
            
            # –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
            spatial_loss = self._compute_spatial_consistency_loss(final_lattice_states)
            losses["spatial"] = spatial_loss * self.lattice_settings.spatial_consistency_weight

        # 6. –û–±—â–∏–π loss
        losses["total"] = sum(losses.values())

        return losses
    
    def _compute_spatial_consistency_loss(self, lattice_states: torch.Tensor) -> torch.Tensor:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ loss'–∞ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
        
        –ü–æ–æ—â—Ä—è–µ—Ç —Å—Ö–æ–∂–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —É —Å–æ—Å–µ–¥–Ω–∏—Ö –∫–ª–µ—Ç–æ–∫.
        """
        batch_size, total_cells, state_size = lattice_states.shape
        
        # –ü—Ä–æ—Å—Ç–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è: —Å–æ—Å–µ–¥–Ω–∏–µ –∫–ª–µ—Ç–∫–∏ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –ø–æ—Ö–æ–∂–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        # –î–ª—è –∫—É–±–∞ 8√ó8√ó8 –±–µ—Ä–µ–º –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π –ø–æ –∏–Ω–¥–µ–∫—Å–∞–º
        consistency_loss = 0.0
        num_comparisons = 0
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—É—é –∫–ª–µ—Ç–∫—É —Å –µ–µ –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Å–æ—Å–µ–¥—è–º–∏
        lattice_dim = round(total_cells ** (1/3))  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –∫—É–±–∏—á–µ—Å–∫—É—é —Ä–µ—à–µ—Ç–∫—É
        
        for i in range(min(100, total_cells)):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            for j in range(i+1, min(i+27, total_cells)):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å–µ–¥–µ–π
                diff = torch.norm(lattice_states[:, i] - lattice_states[:, j], dim=-1)
                consistency_loss += diff.mean()
                num_comparisons += 1
        
        if num_comparisons > 0:
            consistency_loss /= num_comparisons
            
        return consistency_loss

    def validate_epoch(self, dataloader: DataLoader, **kwargs) -> Dict[str, float]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏"""
        self.embedding_transformer.eval()
        self.lattice_mapper.eval()
        self.lattice.eval()
        self.lattice_extractor.eval()
        if hasattr(self.text_decoder, "eval"):
            self.text_decoder.eval()

        val_losses = {
            "total": 0.0,
            "reconstruction": 0.0,
            "similarity": 0.0,
            "diversity": 0.0,
            "emergence": 0.0,
            "lattice": 0.0,
            "spatial": 0.0,
            "count": 0,
        }

        with torch.no_grad():
            for batch in dataloader:
                # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ train_epoch, –Ω–æ –±–µ–∑ backward pass
                if isinstance(batch, dict):
                    # Handle both 'embedding' (from dataloader) and 'embeddings' (legacy)
                    key = "embedding" if "embedding" in batch else "embeddings"
                    input_embeddings = batch[key].to(self.device)
                    target_embeddings = batch.get(
                        "target_embeddings", input_embeddings
                    ).to(self.device)
                    texts = batch.get("texts", None)
                elif isinstance(batch, (list, tuple)):
                    input_embeddings = batch[0].to(self.device)
                    target_embeddings = (
                        batch[1].to(self.device) if len(batch) > 1 else input_embeddings
                    )
                    texts = batch[2] if len(batch) > 2 else None
                else:
                    input_embeddings = batch.to(self.device)
                    target_embeddings = input_embeddings
                    texts = None

                losses = self._forward_pass(input_embeddings, target_embeddings, texts)

                for key in val_losses:
                    if key != "count":
                        val_losses[key] += losses.get(key, torch.tensor(0.0)).item()
                val_losses["count"] += 1

        # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
        for key in val_losses:
            if key != "count" and val_losses["count"] > 0:
                val_losses[key] /= val_losses["count"]

        logger.info(f"–í–∞–ª–∏–¥–∞—Ü–∏—è: total_loss={val_losses['total']:.4f}")

        return val_losses

    def save_checkpoint(self, path: str, **metadata):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ checkpoint'–∞"""
        checkpoint_path = Path(path)
        checkpoint_path.parent.mkdir(parents=True, exist_ok=True)

        checkpoint = {
            "embedding_transformer": self.embedding_transformer.state_dict(),
            "lattice": self.lattice.state_dict(),
            "lattice_mapper": self.lattice_mapper.state_dict(),
            "lattice_extractor": self.lattice_extractor.state_dict(),
            "optimizer": self.optimizer.state_dict(),
            "scheduler": self.scheduler.state_dict(),
            "training_history": self.training_history,
            "performance_stats": self.performance_stats,
            "config": self.config,
            **metadata,
        }

        if hasattr(self.text_decoder, "state_dict"):
            checkpoint["text_decoder"] = self.text_decoder.state_dict()

        torch.save(checkpoint, checkpoint_path)
        logger.info(f"Checkpoint —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {checkpoint_path}")

    def load_checkpoint(self, path: str) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ checkpoint'–∞"""
        checkpoint_path = Path(path)
        if not checkpoint_path.exists():
            raise FileNotFoundError(f"Checkpoint –Ω–µ –Ω–∞–π–¥–µ–Ω: {checkpoint_path}")

        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)

        self.embedding_transformer.load_state_dict(checkpoint["embedding_transformer"])
        self.lattice.load_state_dict(checkpoint["lattice"])
        self.lattice_mapper.load_state_dict(checkpoint["lattice_mapper"])
        self.lattice_extractor.load_state_dict(checkpoint["lattice_extractor"])
        self.optimizer.load_state_dict(checkpoint["optimizer"])
        self.scheduler.load_state_dict(checkpoint["scheduler"])

        if "text_decoder" in checkpoint and hasattr(
            self.text_decoder, "load_state_dict"
        ):
            self.text_decoder.load_state_dict(checkpoint["text_decoder"])

        self.training_history = checkpoint.get(
            "training_history", self.training_history
        )
        self.performance_stats = checkpoint.get(
            "performance_stats", self.performance_stats
        )

        logger.info(f"Checkpoint –∑–∞–≥—Ä—É–∂–µ–Ω: {checkpoint_path}")

        return checkpoint

    def get_training_summary(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –ø–æ –æ–±—É—á–µ–Ω–∏—é"""
        return {
            "device": str(self.device),
            "total_parameters": sum(p.numel() for p in self.embedding_transformer.parameters())
            + sum(p.numel() for p in self.lattice_mapper.parameters())
            + sum(p.numel() for p in self.lattice.parameters())
            + sum(p.numel() for p in self.lattice_extractor.parameters()),
            "training_history": self.training_history,
            "performance_stats": {
                "avg_forward_time": sum(self.performance_stats["forward_times"])
                / max(len(self.performance_stats["forward_times"]), 1),
                "avg_backward_time": sum(self.performance_stats["backward_times"])
                / max(len(self.performance_stats["backward_times"]), 1),
                "avg_total_time": sum(self.performance_stats["total_times"])
                / max(len(self.performance_stats["total_times"]), 1),
            },
        }


# === –§–ê–ë–†–ò–ß–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ===


def create_embedding_trainer(config: SimpleProjectConfig) -> EmbeddingTrainer:
    """–§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞"""
    return EmbeddingTrainer(config)
