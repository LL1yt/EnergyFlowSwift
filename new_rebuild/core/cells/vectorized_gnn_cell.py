#!/usr/bin/env python3
"""
Vectorized GNN Cell - –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
========================================================

–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è GNN Cell —Å batch processing –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
–ò—Å–∫–ª—é—á–∞–µ—Ç –≤—Å–µ —Ü–∏–∫–ª—ã –∏ sequential –æ–ø–µ—Ä–∞—Ü–∏–∏.

–ö–õ–Æ–ß–ï–í–´–ï –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:
1. ‚úÖ Vectorized Message Passing - –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
2. ‚úÖ Batched Attention - attention –¥–ª—è –≤—Å–µ—Ö –∫–ª–µ—Ç–æ–∫ —Å—Ä–∞–∑—É
3. ‚úÖ GPU Memory Optimization - –º–∏–Ω–∏–º—É–º –∞–ª–ª–æ–∫–∞—Ü–∏–π
4. ‚úÖ Tensor Reuse - –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±—É—Ñ–µ—Ä–æ–≤
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, Dict, Any, Tuple

from .base_cell import BaseCell
from ...config import get_project_config
from ...utils.logging import get_logger
from ...utils.device_manager import get_device_manager

logger = get_logger(__name__)


class VectorizedMessageNetwork(nn.Module):
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Å–µ—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–π

    –°–æ–∑–¥–∞–µ—Ç –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ä–∞–∑—É –≤ –æ–¥–Ω–æ–π batch –æ–ø–µ—Ä–∞—Ü–∏–∏
    """

    def __init__(self, state_size: int, message_dim: int, hidden_dim: int):
        super().__init__()

        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è —Å–µ—Ç—å –¥–ª—è batch –æ–±—Ä–∞–±–æ—Ç–∫–∏
        combined_size = state_size * 2  # sender + receiver

        self.message_creator = nn.Sequential(
            nn.Linear(combined_size, hidden_dim, bias=True),
            nn.GELU(),
            nn.Linear(hidden_dim, message_dim, bias=True),
        )

    def forward(
        self, neighbor_states: torch.Tensor, own_states: torch.Tensor
    ) -> torch.Tensor:
        """
        –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

        Args:
            neighbor_states: [batch, num_neighbors, state_size] - —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ—Å–µ–¥–µ–π
            own_states: [batch, state_size] - —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è

        Returns:
            messages: [batch, num_neighbors, message_dim] - –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        """
        batch_size, num_neighbors, state_size = neighbor_states.shape

        # –†–∞—Å—à–∏—Ä—è–µ–º own_states –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ—Å–µ–¥–∞: [batch, num_neighbors, state_size]
        own_expanded = own_states.unsqueeze(1).expand(-1, num_neighbors, -1)

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø–∞—Ä—ã (neighbor, own) –≤ –æ–¥–∏–Ω —Ç–µ–Ω–∑–æ—Ä
        # [batch, num_neighbors, state_size * 2]
        combined = torch.cat([neighbor_states, own_expanded], dim=-1)

        # Reshape –¥–ª—è batch –æ–±—Ä–∞–±–æ—Ç–∫–∏: [batch * num_neighbors, combined_size]
        combined_flat = combined.view(-1, combined.shape[-1])

        # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        messages_flat = self.message_creator(combined_flat)

        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–æ—Ä–º—É: [batch, num_neighbors, message_dim]
        messages = messages_flat.view(batch_size, num_neighbors, -1)

        return messages


class VectorizedAttentionAggregator(nn.Module):
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è attention –∞–≥—Ä–µ–≥–∞—Ü–∏—è

    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç attention –¥–ª—è –≤—Å–µ–≥–æ batch —Å—Ä–∞–∑—É
    """

    def __init__(self, message_dim: int, state_size: int):
        super().__init__()

        self.attention_network = nn.Sequential(
            nn.Linear(message_dim + state_size, message_dim, bias=True),
            nn.Tanh(),
            nn.Linear(message_dim, 1, bias=True),
        )

    def forward(
        self, messages: torch.Tensor, receiver_states: torch.Tensor
    ) -> torch.Tensor:
        """
        –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è attention –∞–≥—Ä–µ–≥–∞—Ü–∏—è

        Args:
            messages: [batch, num_neighbors, message_dim] - –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            receiver_states: [batch, state_size] - —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π

        Returns:
            aggregated: [batch, message_dim] - –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        """
        batch_size, num_neighbors, message_dim = messages.shape

        # –†–∞—Å—à–∏—Ä—è–µ–º receiver_states: [batch, num_neighbors, state_size]
        receiver_expanded = receiver_states.unsqueeze(1).expand(-1, num_neighbors, -1)

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–ª—è attention: [batch, num_neighbors, message_dim + state_size]
        attention_input = torch.cat([messages, receiver_expanded], dim=-1)

        # Reshape –¥–ª—è batch –æ–±—Ä–∞–±–æ—Ç–∫–∏: [batch * num_neighbors, input_size]
        attention_input_flat = attention_input.view(-1, attention_input.shape[-1])

        # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ attention scores
        attention_logits_flat = self.attention_network(attention_input_flat)

        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–æ—Ä–º—É: [batch, num_neighbors, 1]
        attention_logits = attention_logits_flat.view(batch_size, num_neighbors, 1)

        # Softmax –ø–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —Å–æ—Å–µ–¥–µ–π
        attention_weights = F.softmax(attention_logits, dim=1)

        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è: [batch, message_dim]
        aggregated = torch.sum(messages * attention_weights, dim=1)

        return aggregated


class VectorizedStateUpdater(nn.Module):
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π

    GRU-style gates –¥–ª—è –≤—Å–µ–≥–æ batch —Å—Ä–∞–∑—É
    """

    def __init__(self, state_size: int, message_dim: int, external_input_size: int):
        super().__init__()

        input_size = message_dim + external_input_size

        # –í—Å–µ gates –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ
        self.update_gate = nn.Linear(state_size + input_size, state_size, bias=True)
        self.reset_gate = nn.Linear(state_size + input_size, state_size, bias=True)
        self.candidate_network = nn.Linear(
            state_size + input_size, state_size, bias=True
        )

    def forward(
        self,
        current_states: torch.Tensor,
        aggregated_messages: torch.Tensor,
        external_inputs: torch.Tensor,
    ) -> torch.Tensor:
        """
        –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π

        Args:
            current_states: [batch, state_size] - —Ç–µ–∫—É—â–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
            aggregated_messages: [batch, message_dim] - –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            external_inputs: [batch, external_input_size] - –≤–Ω–µ—à–Ω–∏–µ –≤—Ö–æ–¥—ã

        Returns:
            new_states: [batch, state_size] - –Ω–æ–≤—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        """
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –≤—Ö–æ–¥—ã: [batch, message_dim + external_input_size]
        combined_input = torch.cat([aggregated_messages, external_inputs], dim=-1)

        # –ü–æ–ª–Ω—ã–π –≤—Ö–æ–¥ –¥–ª—è gates: [batch, state_size + input_size]
        full_input = torch.cat([current_states, combined_input], dim=-1)

        # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤—Å–µ—Ö gates
        update = torch.sigmoid(self.update_gate(full_input))
        reset = torch.sigmoid(self.reset_gate(full_input))

        # Candidate state —Å reset gate
        reset_state = reset * current_states
        candidate_input = torch.cat([reset_state, combined_input], dim=-1)
        candidate = torch.tanh(self.candidate_network(candidate_input))

        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è (–≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ)
        new_states = (1 - update) * current_states + update * candidate

        return new_states


class VectorizedGNNCell(BaseCell):
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è GNN Cell

    –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
    1. VectorizedMessageNetwork: –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    2. VectorizedAttentionAggregator: batch attention
    3. VectorizedStateUpdater: batch state update

    –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:
    - –ù–µ—Ç —Ü–∏–∫–ª–æ–≤ –∏–ª–∏ sequential –æ–ø–µ—Ä–∞—Ü–∏–π
    - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
    - –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
    """

    def __init__(
        self,
        state_size: Optional[int] = None,
        neighbor_count: Optional[int] = None,
        message_dim: Optional[int] = None,
        hidden_dim: Optional[int] = None,
        external_input_size: Optional[int] = None,
        activation: Optional[str] = None,
        target_params: Optional[int] = None,
        use_attention: Optional[bool] = None,
        **kwargs,
    ):
        super().__init__()

        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config = get_project_config()

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å fallback –Ω–∞ –∫–æ–Ω—Ñ–∏–≥
        self.state_size = state_size or config.model.state_size
        self.neighbor_count = neighbor_count or config.model.neighbor_count
        self.message_dim = message_dim or config.model.message_dim
        self.hidden_dim = hidden_dim or config.model.hidden_dim
        self.external_input_size = (
            external_input_size or config.model.external_input_size
        )
        self.activation = activation or config.model.activation
        self.target_params = target_params or config.model.target_params
        self.use_attention = use_attention or config.model.use_attention

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.message_network = VectorizedMessageNetwork(
            state_size=self.state_size,
            message_dim=self.message_dim,
            hidden_dim=self.hidden_dim,
        )

        if self.use_attention:
            self.aggregator = VectorizedAttentionAggregator(
                message_dim=self.message_dim,
                state_size=self.state_size,
            )
        else:
            self.aggregator = None

        self.state_updater = VectorizedStateUpdater(
            state_size=self.state_size,
            message_dim=self.message_dim,
            external_input_size=self.external_input_size,
        )

        # –ü–µ—Ä–µ–Ω–æ—Å –≤—Å–µ—Ö –º–æ–¥—É–ª–µ–π –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        device_manager = get_device_manager()
        self.to(device_manager.get_device())

        if config.logging.debug_mode:
            self._log_parameter_count()

    def _log_parameter_count(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        total_params = sum(p.numel() for p in self.parameters())

        logger.info(f"üöÄ VectorizedGNNCell initialized:")
        logger.info(
            f"   Total params: {total_params:,} (target: {self.target_params:,})"
        )
        logger.info(f"   State size: {self.state_size}")
        logger.info(f"   Message dim: {self.message_dim}")
        logger.info(f"   Neighbor count: {self.neighbor_count}")
        logger.info(f"   Use attention: {self.use_attention}")

    def forward(
        self,
        neighbor_states: torch.Tensor,
        own_state: torch.Tensor,
        external_input: Optional[torch.Tensor] = None,
        connection_weights: Optional[torch.Tensor] = None,
        **kwargs,
    ) -> torch.Tensor:
        """
        –ü–æ–ª–Ω–æ—Å—Ç—å—é –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π forward pass

        Args:
            neighbor_states: [batch, neighbor_count, state_size] - —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ—Å–µ–¥–µ–π
            own_state: [batch, state_size] - —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
            external_input: [batch, external_input_size] - –≤–Ω–µ—à–Ω–∏–π –≤—Ö–æ–¥
            connection_weights: [batch, neighbor_count] - STDP –≤–µ—Å–∞

        Returns:
            new_states: [batch, state_size] - –Ω–æ–≤—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        """
        batch_size = own_state.shape[0]
        device = next(self.parameters()).device

        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –≤—Å–µ —Ç–µ–Ω–∑–æ—Ä—ã –Ω–∞ –æ–¥–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
        neighbor_states = neighbor_states.to(device)
        own_state = own_state.to(device)

        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
        if neighbor_states.dim() == 2:
            neighbor_states = neighbor_states.unsqueeze(0)

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ external_input
        if external_input is None:
            external_input = torch.zeros(
                batch_size, self.external_input_size, device=device
            )
        else:
            external_input = external_input.to(device)
            if external_input.shape[-1] != self.external_input_size:
                if external_input.shape[-1] < self.external_input_size:
                    padding = torch.zeros(
                        batch_size,
                        self.external_input_size - external_input.shape[-1],
                        device=device,
                    )
                    external_input = torch.cat([external_input, padding], dim=-1)
                else:
                    external_input = external_input[:, : self.external_input_size]

        # === –í–ï–ö–¢–û–†–ò–ó–û–í–ê–ù–ù–´–ô MESSAGE PASSING ===

        # 1. –°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å—Ä–∞–∑—É (–±–µ–∑ —Ü–∏–∫–ª–æ–≤!)
        messages = self.message_network(neighbor_states, own_state)

        # 2. –ú–æ–¥—É–ª—è—Ü–∏—è —á–µ—Ä–µ–∑ STDP –≤–µ—Å–∞ (–≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ)
        if connection_weights is not None:
            connection_weights = connection_weights.to(device)
            # [batch, neighbor_count] ‚Üí [batch, neighbor_count, 1]
            stdp_weights = connection_weights.unsqueeze(-1)
            messages = messages * stdp_weights

        # 3. –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π (–≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ)
        if self.use_attention:
            aggregated_message = self.aggregator(messages, own_state)
        else:
            # –ü—Ä–æ—Å—Ç–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Å—Ä–µ–¥–Ω–µ–µ (–≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ)
            aggregated_message = torch.mean(messages, dim=1)

        # 4. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è (–≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ)
        new_states = self.state_updater(own_state, aggregated_message, external_input)

        return new_states

    def forward_batch(
        self,
        batch_neighbor_states: torch.Tensor,
        batch_own_states: torch.Tensor,
        batch_external_input: Optional[torch.Tensor] = None,
        batch_connection_weights: Optional[torch.Tensor] = None,
        **kwargs,
    ) -> torch.Tensor:
        """
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π batch forward –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ä–µ—à–µ—Ç–æ–∫

        Args:
            batch_neighbor_states: [batch, neighbor_count, state_size]
            batch_own_states: [batch, state_size]
            batch_external_input: [batch, external_input_size]
            batch_connection_weights: [batch, neighbor_count]

        Returns:
            batch_new_states: [batch, state_size]
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π forward - –æ–Ω —É–∂–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω
        return self.forward(
            neighbor_states=batch_neighbor_states,
            own_state=batch_own_states,
            external_input=batch_external_input,
            connection_weights=batch_connection_weights,
            **kwargs,
        )

    def get_performance_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏"""
        total_params = sum(p.numel() for p in self.parameters())

        return {
            "architecture": "vectorized_gnn",
            "total_params": total_params,
            "optimization": "full_vectorization",
            "sequential_operations": 0,  # –ù–ï–¢ —Ü–∏–∫–ª–æ–≤!
            "batch_optimized": True,
            "gpu_optimized": True,
        }
