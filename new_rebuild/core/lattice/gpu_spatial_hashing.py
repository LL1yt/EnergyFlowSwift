#!/usr/bin/env python3
"""
GPU-Accelerated Spatial Hashing –¥–ª—è 3D –†–µ—à–µ—Ç–∫–∏
==============================================

–í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è spatial hashing —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPU.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç PyTorch tensor –æ–ø–µ—Ä–∞—Ü–∏–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ CUDA kernels –¥–ª—è
–±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å–æ—Å–µ–¥–µ–π –≤ —Ç—Ä–µ—Ö–º–µ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ.

–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- GPU-accelerated –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å PyTorch
- Batch processing –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
- Memory-efficient —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
- Adaptive chunking –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏

–ê–≤—Ç–æ—Ä: 3D Cellular Neural Network Project
–í–µ—Ä—Å–∏—è: 2.0.0 (2024-12-27)
"""

import torch
import numpy as np
from typing import Tuple, List, Dict, Optional, Set, Any
from dataclasses import dataclass
import math

try:
    from ...config import get_project_config
    from ...utils.device_manager import get_device_manager
    from ...utils.logging import get_logger
except ImportError:
    # Fallback –¥–ª—è –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
    import sys
    import os

    sys.path.append(os.path.join(os.path.dirname(__file__), "..", "..", ".."))
    from config import get_project_config
    from utils.device_manager import get_device_manager
    from utils.logging import get_logger

logger = get_logger(__name__)

Coordinates3D = Tuple[int, int, int]


@dataclass
class GPUSpatialHashingStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ GPU spatial hashing"""

    total_queries: int = 0
    avg_query_time_ms: float = 0.0
    memory_usage_mb: float = 0.0
    cache_hit_rate: float = 0.0
    batch_processing_efficiency: float = 0.0


class GPUMortonEncoder:
    """
    GPU-accelerated –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ –∫—Ä–∏–≤–æ–π –ú–æ—Ä—Ç–æ–Ω–∞ –¥–ª—è 3D-–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ PyTorch –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ
    –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è/–¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö batch'–µ–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    """

    def __init__(self, dimensions: Coordinates3D):
        self.device_manager = get_device_manager()
        self.device = self.device_manager.get_device()

        self.max_dim = max(dimensions)
        self.bits = self.max_dim.bit_length()

        # –ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ –º–∞—Å–∫–∏ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        self._prepare_bit_masks()

        logger.debug(
            f"üî¢ GPUMortonEncoder –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è {dimensions}, {self.bits} –±–∏—Ç"
        )

    def _prepare_bit_masks(self):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –±–∏—Ç–æ–≤—ã–µ –º–∞—Å–∫–∏ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π"""
        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫–∏ –¥–ª—è –∏–Ω—Ç–µ—Ä–ª–∏–≤–∏–Ω–≥–∞ –±–∏—Ç–æ–≤
        bit_positions = torch.arange(self.bits, device=self.device)

        # –ú–∞—Å–∫–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –±–∏—Ç–æ–≤
        self.bit_masks = 2**bit_positions

        # –ü–æ–∑–∏—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –±–∏—Ç–æ–≤ –≤ Morton –∫–æ–¥–µ
        self.x_positions = 3 * bit_positions + 2
        self.y_positions = 3 * bit_positions + 1
        self.z_positions = 3 * bit_positions

    def encode_batch(self, coords_batch: torch.Tensor) -> torch.Tensor:
        """
        –ö–æ–¥–∏—Ä—É–µ—Ç batch –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –≤ Morton –∫–æ–¥—ã

        Args:
            coords_batch: tensor —Ñ–æ—Ä–º—ã (N, 3) —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏

        Returns:
            tensor —Ñ–æ—Ä–º—ã (N,) —Å Morton –∫–æ–¥–∞–º–∏
        """
        coords_batch = self.device_manager.ensure_device(coords_batch)
        batch_size = coords_batch.shape[0]

        x, y, z = coords_batch[:, 0], coords_batch[:, 1], coords_batch[:, 2]

        # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∏—Ç–æ–≤
        x_bits = (x.unsqueeze(1) & self.bit_masks.unsqueeze(0)) != 0
        y_bits = (y.unsqueeze(1) & self.bit_masks.unsqueeze(0)) != 0
        z_bits = (z.unsqueeze(1) & self.bit_masks.unsqueeze(0)) != 0

        # –ò–Ω—Ç–µ—Ä–ª–∏–≤–∏–Ω–≥ –±–∏—Ç–æ–≤
        morton_codes = torch.zeros(batch_size, device=self.device, dtype=torch.long)

        morton_codes += (x_bits * (2 ** self.x_positions.unsqueeze(0))).sum(dim=1)
        morton_codes += (y_bits * (2 ** self.y_positions.unsqueeze(0))).sum(dim=1)
        morton_codes += (z_bits * (2 ** self.z_positions.unsqueeze(0))).sum(dim=1)

        return morton_codes

    def decode_batch(self, morton_codes: torch.Tensor) -> torch.Tensor:
        """
        –î–µ–∫–æ–¥–∏—Ä—É–µ—Ç batch Morton –∫–æ–¥–æ–≤ –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã

        Args:
            morton_codes: tensor —Ñ–æ—Ä–º—ã (N,) —Å Morton –∫–æ–¥–∞–º–∏

        Returns:
            tensor —Ñ–æ—Ä–º—ã (N, 3) —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
        """
        morton_codes = self.device_manager.ensure_device(morton_codes)
        batch_size = morton_codes.shape[0]

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∏—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        x_bits = (morton_codes.unsqueeze(1) >> self.x_positions.unsqueeze(0)) & 1
        y_bits = (morton_codes.unsqueeze(1) >> self.y_positions.unsqueeze(0)) & 1
        z_bits = (morton_codes.unsqueeze(1) >> self.z_positions.unsqueeze(0)) & 1

        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
        x = (x_bits * self.bit_masks.unsqueeze(0)).sum(dim=1)
        y = (y_bits * self.bit_masks.unsqueeze(0)).sum(dim=1)
        z = (z_bits * self.bit_masks.unsqueeze(0)).sum(dim=1)

        return torch.stack([x, y, z], dim=1)


class GPUSpatialHashGrid:
    """
    GPU-accelerated –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Ö—ç—à-—Ä–µ—à–µ—Ç–∫–∞

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç PyTorch –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –ø–æ–∏—Å–∫–∞ —Å–æ—Å–µ–¥–µ–π.
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è batch processing –∏ –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ memory transfers.
    """

    def __init__(self, dimensions: Coordinates3D, cell_size: int = 4):
        self.device_manager = get_device_manager()
        self.device = self.device_manager.get_device()

        self.dimensions = dimensions
        self.cell_size = cell_size

        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ö—ç—à-—Ä–µ—à–µ—Ç–∫–∏
        self.grid_dims = tuple((d + cell_size - 1) // cell_size for d in dimensions)

        # GPU —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        self._initialize_gpu_structures()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = GPUSpatialHashingStats()

        logger.info(
            f"üèéÔ∏è GPUSpatialHashGrid –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {dimensions} ‚Üí {self.grid_dims} "
            f"(cell_size={cell_size}) –Ω–∞ {self.device}"
        )

    def _initialize_gpu_structures(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç GPU —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö"""
        max_cells_estimate = np.prod(self.dimensions)

        # –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –Ω–∞ GPU
        self.cell_coordinates = torch.empty(
            (0, 3), device=self.device, dtype=torch.long
        )
        self.cell_indices = torch.empty(0, device=self.device, dtype=torch.long)
        self.grid_hash_table = {}  # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU dict, –ø–æ–∑–∂–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º

        # –ö—ç—à –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        self.query_cache = {}
        self.cache_max_size = 10000

    def insert_batch(self, coordinates: torch.Tensor, indices: torch.Tensor):
        """
        –í—Å—Ç–∞–≤–ª—è–µ—Ç batch –∫–ª–µ—Ç–æ–∫ –≤ —Ä–µ—à–µ—Ç–∫—É

        Args:
            coordinates: tensor —Ñ–æ—Ä–º—ã (N, 3) —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
            indices: tensor —Ñ–æ—Ä–º—ã (N,) —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ –∫–ª–µ—Ç–æ–∫
        """
        coordinates = self.device_manager.ensure_device(coordinates)
        indices = self.device_manager.ensure_device(indices)

        # –í—ã—á–∏—Å–ª—è–µ–º grid –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –≤—Å–µ–≥–æ batch'–∞
        grid_coords = coordinates // self.cell_size

        # –í—ã—á–∏—Å–ª—è–µ–º —Ö—ç—à–∏ –¥–ª—è grid —è—á–µ–µ–∫
        grid_hashes = self._compute_grid_hashes_batch(grid_coords)

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ö—ç—à–∞–º
        unique_hashes, inverse_indices = torch.unique(grid_hashes, return_inverse=True)

        for i, hash_val in enumerate(unique_hashes):
            mask = inverse_indices == i
            cell_indices_for_hash = indices[mask]

            hash_key = hash_val.item()
            if hash_key not in self.grid_hash_table:
                self.grid_hash_table[hash_key] = []

            self.grid_hash_table[hash_key].extend(cell_indices_for_hash.cpu().tolist())

        # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–∞–≤–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        self.cell_coordinates = torch.cat([self.cell_coordinates, coordinates], dim=0)
        self.cell_indices = torch.cat([self.cell_indices, indices], dim=0)

    def _compute_grid_hashes_batch(self, grid_coords: torch.Tensor) -> torch.Tensor:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ö—ç—à–∏ –¥–ª—è batch grid –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç"""
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω–æ–º—É —Ç–∏–ø—É –¥–ª—è –±–∏—Ç–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        grid_coords = grid_coords.long()
        x, y, z = grid_coords[:, 0], grid_coords[:, 1], grid_coords[:, 2]

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é —Ö—ç—à-—Ñ—É–Ω–∫—Ü–∏—é
        prime1, prime2, prime3 = 73856093, 19349663, 83492791
        hashes = (x * prime1) ^ (y * prime2) ^ (z * prime3)

        return hashes

    def query_radius_batch(
        self, query_points: torch.Tensor, radius: float
    ) -> List[torch.Tensor]:
        """
        –ü–æ–∏—Å–∫ —Å–æ—Å–µ–¥–µ–π –≤ —Ä–∞–¥–∏—É—Å–µ –¥–ª—è batch —Ç–æ—á–µ–∫

        Args:
            query_points: tensor —Ñ–æ—Ä–º—ã (N, 3) —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –∑–∞–ø—Ä–æ—Å–∞
            radius: —Ä–∞–¥–∏—É—Å –ø–æ–∏—Å–∫–∞

        Returns:
            –°–ø–∏—Å–æ–∫ tensor'–æ–≤ —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏
        """
        query_points = self.device_manager.ensure_device(query_points)
        batch_size = query_points.shape[0]

        start_time = (
            torch.cuda.Event(enable_timing=True) if self.device.type == "cuda" else None
        )
        end_time = (
            torch.cuda.Event(enable_timing=True) if self.device.type == "cuda" else None
        )

        if start_time:
            start_time.record()

        results = []

        for i, point in enumerate(query_points):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            cache_key = (tuple(point.cpu().tolist()), radius)
            if cache_key in self.query_cache:
                results.append(self.query_cache[cache_key])
                continue

            # –í—ã—á–∏—Å–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω grid —è—á–µ–µ–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞
            min_grid = ((point - radius) // self.cell_size).long()
            max_grid = ((point + radius) // self.cell_size).long()

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –≥—Ä–∞–Ω–∏—Ü–∞–º–∏ —Ä–µ—à–µ—Ç–∫–∏
            grid_dims_tensor = torch.tensor(
                self.grid_dims, device=self.device, dtype=torch.long
            )
            max_bounds = grid_dims_tensor - 1
            zero_tensor = torch.zeros_like(max_bounds)
            min_grid = torch.clamp(min_grid, min=zero_tensor, max=max_bounds)
            max_grid = torch.clamp(max_grid, min=zero_tensor, max=max_bounds)

            # –°–æ–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ –≤—Å–µ—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —è—á–µ–µ–∫
            candidates = set()

            for gx in range(min_grid[0].item(), max_grid[0].item() + 1):
                for gy in range(min_grid[1].item(), max_grid[1].item() + 1):
                    for gz in range(min_grid[2].item(), max_grid[2].item() + 1):
                        grid_coord = torch.tensor([gx, gy, gz], device=self.device)
                        hash_val = self._compute_grid_hashes_batch(
                            grid_coord.unsqueeze(0)
                        )[0].item()

                        if hash_val in self.grid_hash_table:
                            candidates.update(self.grid_hash_table[hash_val])

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ tensor
            if candidates:
                neighbor_indices = torch.tensor(
                    list(candidates), device=self.device, dtype=torch.long
                )
            else:
                neighbor_indices = torch.empty(0, device=self.device, dtype=torch.long)

            results.append(neighbor_indices)

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫—ç—à
            if len(self.query_cache) < self.cache_max_size:
                self.query_cache[cache_key] = neighbor_indices

        if end_time:
            end_time.record()
            torch.cuda.synchronize()
            query_time_ms = start_time.elapsed_time(end_time)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.stats.total_queries += batch_size
            old_avg = self.stats.avg_query_time_ms
            self.stats.avg_query_time_ms = (
                old_avg * (self.stats.total_queries - batch_size) + query_time_ms
            ) / self.stats.total_queries

        return results

    def optimize_memory(self):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏"""
        # –û—á–∏—â–∞–µ–º –∫—ç—à –µ—Å–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π
        if len(self.query_cache) > self.cache_max_size * 0.8:
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ 50% —Å–∞–º—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∑–∞–ø–∏—Å–µ–π
            self.query_cache.clear()
            logger.debug("üßπ Query cache –æ—á–∏—â–µ–Ω –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏")

        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏
        self.device_manager.cleanup()

    def get_memory_usage(self) -> Dict[str, float]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        coords_mb = self.cell_coordinates.numel() * 4 / (1024**2)  # int32
        indices_mb = self.cell_indices.numel() * 4 / (1024**2)  # int32

        return {
            "coordinates_mb": coords_mb,
            "indices_mb": indices_mb,
            "cache_entries": len(self.query_cache),
            "grid_buckets": len(self.grid_hash_table),
            "total_gpu_mb": coords_mb + indices_mb,
        }

    def get_stats(self) -> GPUSpatialHashingStats:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        memory_stats = self.get_memory_usage()
        self.stats.memory_usage_mb = memory_stats["total_gpu_mb"]
        self.stats.cache_hit_rate = len(self.query_cache) / max(
            1, self.stats.total_queries
        )

        return self.stats


class AdaptiveGPUSpatialHash:
    """
    Adaptive GPU Spatial Hash —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä —è—á–µ–µ–∫ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
    –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
    """

    def __init__(self, dimensions: Coordinates3D, target_memory_mb: float = 1024.0):
        self.device_manager = get_device_manager()
        self.device = self.device_manager.get_device()
        self.dimensions = dimensions
        self.target_memory_mb = target_memory_mb

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —è—á–µ–µ–∫
        self.optimal_cell_size = self._calculate_optimal_cell_size()

        # –°–æ–∑–¥–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é hash grid
        self.hash_grid = GPUSpatialHashGrid(dimensions, self.optimal_cell_size)

        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.adaptation_frequency = 1000  # –ü–µ—Ä–µ–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–∞–∂–¥—ã–µ N –∑–∞–ø—Ä–æ—Å–æ–≤
        self.query_count = 0

        logger.info(
            f"üéØ AdaptiveGPUSpatialHash —Å–æ–∑–¥–∞–Ω: cell_size={self.optimal_cell_size}, "
            f"target_memory={target_memory_mb}MB"
        )

    def _calculate_optimal_cell_size(self) -> int:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —è—á–µ–µ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏"""
        total_cells = np.prod(self.dimensions)

        # –û—Ü–µ–Ω–∫–∞ –ø–∞–º—è—Ç–∏ –Ω–∞ –∫–ª–µ—Ç–∫—É (–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã + –∏–Ω–¥–µ–∫—Å + –Ω–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã)
        memory_per_cell_bytes = 3 * 4 + 4 + 8  # 24 –±–∞–π—Ç–∞ –Ω–∞ –∫–ª–µ—Ç–∫—É

        # –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —è—á–µ–µ–∫ –≤ hash grid
        target_hash_cells = min(
            total_cells // 8,  # –ù–µ –±–æ–ª—å—à–µ 1/8 –æ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
            int(self.target_memory_mb * 1024**2 / memory_per_cell_bytes),
        )

        # –†–∞—Å—á–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —è—á–µ–µ–∫
        if target_hash_cells <= 0:
            return max(self.dimensions) // 4  # Fallback

        # –ö—É–±–∏—á–µ—Å–∫–∏–π –∫–æ—Ä–µ–Ω—å –¥–ª—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        optimal_cell_size = max(1, int((total_cells / target_hash_cells) ** (1 / 3)))

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏
        max_cell_size = max(self.dimensions) // 2
        optimal_cell_size = min(optimal_cell_size, max_cell_size)

        return max(2, optimal_cell_size)  # –ú–∏–Ω–∏–º—É–º 2 –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏

    def insert_batch(self, coordinates: torch.Tensor, indices: torch.Tensor):
        """–í—Å—Ç–∞–≤–∫–∞ batch —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π"""
        self.hash_grid.insert_batch(coordinates, indices)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
        if self.query_count % self.adaptation_frequency == 0:
            self._adapt_parameters()

    def query_radius_batch(
        self, query_points: torch.Tensor, radius: float
    ) -> List[torch.Tensor]:
        """–ü–æ–∏—Å–∫ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
        self.query_count += query_points.shape[0]

        results = self.hash_grid.query_radius_batch(query_points, radius)

        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
        if self.query_count % (self.adaptation_frequency // 2) == 0:
            self.hash_grid.optimize_memory()

        return results

    def _adapt_parameters(self):
        """–ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        stats = self.hash_grid.get_stats()
        memory_usage = self.hash_grid.get_memory_usage()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–∞–º—è—Ç–∏
        if memory_usage["total_gpu_mb"] > self.target_memory_mb * 1.2:
            logger.warning(
                f"‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ target memory: {memory_usage['total_gpu_mb']:.1f}MB > "
                f"{self.target_memory_mb * 1.2:.1f}MB"
            )

            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —è—á–µ–µ–∫ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
            new_cell_size = min(self.optimal_cell_size * 2, max(self.dimensions) // 2)
            if new_cell_size != self.optimal_cell_size:
                self._rebuild_with_new_cell_size(new_cell_size)

        elif memory_usage["total_gpu_mb"] < self.target_memory_mb * 0.5:
            # –ú–æ–∂–µ–º —É–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä —è—á–µ–µ–∫ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            new_cell_size = max(self.optimal_cell_size // 2, 2)
            if new_cell_size != self.optimal_cell_size:
                self._rebuild_with_new_cell_size(new_cell_size)

        logger.debug(
            f"üìä Adaptive stats: queries={stats.total_queries}, "
            f"avg_time={stats.avg_query_time_ms:.2f}ms, "
            f"memory={memory_usage['total_gpu_mb']:.1f}MB"
        )

    def _rebuild_with_new_cell_size(self, new_cell_size: int):
        """–ü–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç hash grid —Å –Ω–æ–≤—ã–º —Ä–∞–∑–º–µ—Ä–æ–º —è—á–µ–µ–∫"""
        logger.info(
            f"üîÑ Rebuilding hash grid: {self.optimal_cell_size} ‚Üí {new_cell_size}"
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        old_coordinates = self.hash_grid.cell_coordinates
        old_indices = self.hash_grid.cell_indices

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        self.optimal_cell_size = new_cell_size
        self.hash_grid = GPUSpatialHashGrid(self.dimensions, new_cell_size)

        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –¥–∞–Ω–Ω—ã–µ
        if len(old_coordinates) > 0:
            self.hash_grid.insert_batch(old_coordinates, old_indices)

    def get_comprehensive_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        hash_stats = self.hash_grid.get_stats()
        memory_stats = self.hash_grid.get_memory_usage()
        device_stats = self.device_manager.get_memory_stats()

        return {
            "hash_grid": {
                "cell_size": self.optimal_cell_size,
                "queries": hash_stats.total_queries,
                "avg_query_time_ms": hash_stats.avg_query_time_ms,
                "cache_hit_rate": hash_stats.cache_hit_rate,
            },
            "memory": memory_stats,
            "device": device_stats,
            "adaptations": {
                "adaptation_frequency": self.adaptation_frequency,
                "query_count": self.query_count,
                "target_memory_mb": self.target_memory_mb,
                "adaptations_performed": max(
                    0, self.query_count // self.adaptation_frequency
                ),
            },
        }
