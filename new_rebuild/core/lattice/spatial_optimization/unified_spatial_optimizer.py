#!/usr/bin/env python3
"""
Unified Spatial Optimizer - –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
==============================================================================

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å SpatialOptimizer –∏ MoESpatialOptimizer –≤ –µ–¥–∏–Ω—É—é
–≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—É—é —Å–∏—Å—Ç–µ–º—É —Å –ø–æ–ª–Ω–æ–π GPU –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π.

–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- –ï–¥–∏–Ω—ã–π API –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- –ü–æ–ª–Ω–∞—è GPU-acceleration —Å fallback –Ω–∞ CPU
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è MoE –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- GPUMortonEncoder –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ spatial indexing
- Adaptive chunking –∏ memory management
- Real-time performance monitoring

–ê–≤—Ç–æ—Ä: 3D Cellular Neural Network Project
–í–µ—Ä—Å–∏—è: 3.0.0 (2024-12-27)
"""

import torch
import torch.nn as nn
from typing import Dict, List, Optional, Any, Tuple, Union, Set, Callable
import time
import numpy as np
from abc import ABC, abstractmethod
from dataclasses import dataclass
from enum import Enum

try:
    from ....config.project_config import get_project_config, ChunkInfo
    from ....utils.logging import get_logger
    from ....utils.device_manager import get_device_manager
    from ..position import Position3D
    from .hierarchical_index import HierarchicalSpatialIndex
    from ..spatial_hashing import SpatialHashGrid
    from .gpu_spatial_processor import GPUSpatialProcessor, SpatialQueryResult
    from .adaptive_chunker import AdaptiveGPUChunker
    from ..gpu_spatial_hashing import AdaptiveGPUSpatialHash, GPUMortonEncoder
except ImportError:
    # Fallback –¥–ª—è –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
    import sys
    import os
    sys.path.append(os.path.join(os.path.dirname(__file__), "..", "..", "..", ".."))
    from config.project_config import get_project_config, ChunkInfo
    from utils.logging import get_logger
    from utils.device_manager import get_device_manager
    from core.lattice.position import Position3D

logger = get_logger(__name__)

Coordinates3D = Tuple[int, int, int]


class OptimizationMode(Enum):
    """–†–µ–∂–∏–º—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    AUTO = "auto"  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä
    CPU_ONLY = "cpu_only"  # –¢–æ–ª—å–∫–æ CPU
    GPU_ONLY = "gpu_only"  # –¢–æ–ª—å–∫–æ GPU
    HYBRID = "hybrid"  # –ì–∏–±—Ä–∏–¥–Ω—ã–π —Ä–µ–∂–∏–º


class ConnectionType(Enum):
    """–¢–∏–ø—ã —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –¥–ª—è MoE –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""
    LOCAL = "local"
    FUNCTIONAL = "functional"
    DISTANT = "distant"


@dataclass
class OptimizationConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è UnifiedSpatialOptimizer"""
    mode: OptimizationMode = OptimizationMode.AUTO
    enable_moe: bool = True
    enable_morton_encoding: bool = True
    enable_adaptive_chunking: bool = True
    max_memory_gb: float = 8.0
    target_performance_ms: float = 10.0
    fallback_enabled: bool = True


@dataclass
class SpatialOptimizationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    new_states: torch.Tensor
    processing_time_ms: float
    memory_usage_mb: float
    neighbors_found: int
    gpu_utilization: float
    mode_used: OptimizationMode
    cache_hit_rate: float = 0.0
    chunks_processed: int = 0


class BaseSpatialProcessor(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤—Å–µ—Ö spatial processors"""
    
    @abstractmethod
    def find_neighbors(
        self, 
        coords: Union[Coordinates3D, torch.Tensor], 
        radius: float
    ) -> List[int]:
        """–ù–∞–π—Ç–∏ —Å–æ—Å–µ–¥–µ–π –≤ —Ä–∞–¥–∏—É—Å–µ"""
        pass
    
    @abstractmethod
    def process_lattice(
        self, 
        states: torch.Tensor, 
        processor_fn: Callable
    ) -> torch.Tensor:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ä–µ—à–µ—Ç–∫—É"""
        pass
    
    @abstractmethod
    def get_performance_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        pass


class CPUFallbackProcessor(BaseSpatialProcessor):
    """CPU fallback processor –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    
    def __init__(self, dimensions: Coordinates3D, config: dict):
        self.dimensions = dimensions
        self.config = config
        self.pos_helper = Position3D(dimensions)
        
        # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        self.spatial_index = HierarchicalSpatialIndex(dimensions, config)
        max_dim = max(dimensions)
        cell_size = max(1, max_dim // 32)
        self.spatial_grid = SpatialHashGrid(dimensions, cell_size)
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å—ã
        total_cells = dimensions[0] * dimensions[1] * dimensions[2]
        coords_list = []
        indices_list = []
        
        for idx in range(total_cells):
            coords = self.pos_helper.to_3d_coordinates(idx)
            coords_list.append(coords)
            indices_list.append(idx)
            self.spatial_grid.insert(coords, idx)
        
        self.spatial_index.insert_batch(coords_list, indices_list)
        self.stats = {"total_queries": 0, "total_time_ms": 0.0}
    
    def find_neighbors(self, coords: Union[Coordinates3D, torch.Tensor], radius: float) -> List[int]:
        """CPU —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Å–æ—Å–µ–¥–µ–π"""
        if isinstance(coords, torch.Tensor):
            coords = tuple(coords.cpu().numpy().astype(int))
        
        start_time = time.time()
        neighbors = list(self.spatial_grid.query_radius(coords, radius))
        
        # –£–±–∏—Ä–∞–µ–º —Å–∞–º—É —Ç–æ—á–∫—É
        center_idx = self.pos_helper.to_linear_index(coords)
        if center_idx in neighbors:
            neighbors.remove(center_idx)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        query_time = (time.time() - start_time) * 1000
        self.stats["total_queries"] += 1
        self.stats["total_time_ms"] += query_time
        
        return neighbors
    
    def process_lattice(self, states: torch.Tensor, processor_fn: Callable) -> torch.Tensor:
        """CPU –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ—à–µ—Ç–∫–∏"""
        num_cells = states.shape[0]
        output_states = states.clone()
        
        for cell_idx in range(num_cells):
            coords = self.pos_helper.to_3d_coordinates(cell_idx)
            neighbors = self.find_neighbors(coords, self.config.get("max_search_radius", 10.0))
            
            if neighbors:
                new_state = processor_fn(
                    states[cell_idx], states[neighbors], cell_idx, neighbors
                )
                output_states[cell_idx] = new_state
        
        return output_states
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ CPU processor"""
        avg_time = (self.stats["total_time_ms"] / max(1, self.stats["total_queries"]))
        return {
            "mode": "cpu_fallback",
            "total_queries": self.stats["total_queries"],
            "avg_query_time_ms": avg_time,
            "memory_usage_mb": 0.0,  # CPU –Ω–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º
        }


class GPUSpatialProcessorWrapper(BaseSpatialProcessor):
    """Wrapper –¥–ª—è GPU Spatial Processor"""
    
    def __init__(self, dimensions: Coordinates3D, config: dict):
        self.dimensions = dimensions
        self.config = config
        self.device_manager = get_device_manager()
        self.device = self.device_manager.get_device()
        
        # –°–æ–∑–¥–∞–µ–º GPU –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.gpu_processor = GPUSpatialProcessor(dimensions, config)
        self.pos_helper = Position3D(dimensions)
        
        # GPU-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.morton_encoder = GPUMortonEncoder(dimensions)
        self.adaptive_hash = AdaptiveGPUSpatialHash(
            dimensions, 
            config.get("memory_pool_size_gb", 8.0) * 1024 * 0.6
        )
        
        logger.info(f"üöÄ GPU Spatial Processor –≥–æ—Ç–æ–≤ –Ω–∞ {self.device}")
    
    def find_neighbors(self, coords: Union[Coordinates3D, torch.Tensor], radius: float) -> List[int]:
        """GPU-accelerated –ø–æ–∏—Å–∫ —Å–æ—Å–µ–¥–µ–π"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ tensor
        if isinstance(coords, (tuple, list)):
            coords_tensor = torch.tensor(
                [list(coords)], dtype=torch.float32, device=self.device
            )
        else:
            coords_tensor = self.device_manager.ensure_device(coords)
            if coords_tensor.dim() == 1:
                coords_tensor = coords_tensor.unsqueeze(0)
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ GPU processor
            result = self.gpu_processor.query_neighbors_sync(
                coords_tensor, radius, timeout=10.0
            )
            
            if result and result.neighbor_lists:
                neighbors = result.neighbor_lists[0].cpu().tolist()
                return neighbors
            else:
                return []
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è GPU –ø–æ–∏—Å–∫ –Ω–µ —É–¥–∞–ª—Å—è: {e}, fallback –Ω–∞ adaptive hash")
            
            # Fallback –Ω–∞ adaptive hash
            try:
                neighbor_lists = self.adaptive_hash.query_radius_batch(coords_tensor, radius)
                if neighbor_lists:
                    return neighbor_lists[0].cpu().tolist()
                return []
            except Exception as e2:
                logger.error(f"‚ùå Adaptive hash —Ç–æ–∂–µ –Ω–µ —É–¥–∞–ª—Å—è: {e2}")
                return []
    
    def process_lattice(self, states: torch.Tensor, processor_fn: Callable) -> torch.Tensor:
        """GPU –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ—à–µ—Ç–∫–∏ —Å chunking"""
        states = self.device_manager.ensure_device(states)
        num_cells = states.shape[0]
        output_states = states.clone()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º adaptive chunker –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ä–µ—à–µ—Ç–æ–∫
        project_config = get_project_config()
        max_batch_size = getattr(project_config, "max_test_batches", 3) * 1000
        
        if num_cells > max_batch_size:
            # Chunked processing
            for batch_start in range(0, num_cells, max_batch_size):
                batch_end = min(batch_start + max_batch_size, num_cells)
                batch_indices = list(range(batch_start, batch_end))
                
                batch_output = self._process_batch_gpu(
                    states, batch_indices, processor_fn
                )
                output_states[batch_start:batch_end] = batch_output
        else:
            # Single batch processing
            batch_indices = list(range(num_cells))
            output_states = self._process_batch_gpu(states, batch_indices, processor_fn)
        
        return output_states
    
    def _process_batch_gpu(
        self, 
        states: torch.Tensor, 
        batch_indices: List[int], 
        processor_fn: Callable
    ) -> torch.Tensor:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ batch –Ω–∞ GPU"""
        batch_size = len(batch_indices)
        output_batch = torch.zeros_like(states[batch_indices])
        
        for i, cell_idx in enumerate(batch_indices):
            coords = self.pos_helper.to_3d_coordinates(cell_idx)
            neighbors = self.find_neighbors(coords, self.config.get("max_search_radius", 10.0))
            
            if neighbors:
                neighbor_states = states[neighbors]
                new_state = processor_fn(
                    states[cell_idx].unsqueeze(0), 
                    neighbor_states, 
                    cell_idx, 
                    neighbors
                )
                output_batch[i] = new_state.squeeze(0)
            else:
                output_batch[i] = states[cell_idx]
        
        return output_batch
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ GPU processor"""
        gpu_stats = self.gpu_processor.get_performance_stats()
        device_stats = self.device_manager.get_memory_stats()
        
        return {
            "mode": "gpu_accelerated",
            "gpu_processor": gpu_stats,
            "device": device_stats,
            "morton_encoder": {
                "enabled": True,
                "dimensions": self.dimensions,
                "device": str(self.device)
            }
        }


class UnifiedSpatialOptimizer:
    """
    –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å SpatialOptimizer –∏ MoESpatialOptimizer
    —Å –ø–æ–ª–Ω–æ–π GPU –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –≤—ã–±–æ—Ä–æ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.
    """
    
    def __init__(
        self, 
        dimensions: Coordinates3D, 
        config: Optional[OptimizationConfig] = None,
        moe_processor: Optional[nn.Module] = None
    ):
        self.dimensions = dimensions
        self.config = config or OptimizationConfig()
        self.moe_processor = moe_processor
        
        # Device management
        self.device_manager = get_device_manager()
        self.device = self.device_manager.get_device()
        
        # –í—ã–±–∏—Ä–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
        self.active_mode = self._determine_optimal_mode()
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã
        self._initialize_processors()
        
        # MoE —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        if self.config.enable_moe and moe_processor:
            self._setup_moe_integration()
        
        # Performance monitoring
        self.performance_history = []
        self.adaptive_threshold_ms = self.config.target_performance_ms
        
        logger.info(f"üîß UnifiedSpatialOptimizer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω:")
        logger.info(f"   üìä –†–∞–∑–º–µ—Ä—ã: {dimensions}")
        logger.info(f"   üéØ –†–µ–∂–∏–º: {self.active_mode.value}")
        logger.info(f"   ü§ñ MoE: {'–≤–∫–ª—é—á–µ–Ω' if self.config.enable_moe else '–≤—ã–∫–ª—é—á–µ–Ω'}")
        logger.info(f"   üöÄ GPU: {self.device}")
    
    def _determine_optimal_mode(self) -> OptimizationMode:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã"""
        if self.config.mode != OptimizationMode.AUTO:
            return self.config.mode
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Å–ª–æ–≤–∏–π
        total_cells = np.prod(self.dimensions)
        available_memory_gb = self.device_manager.get_available_memory_gb()
        
        if not self.device_manager.is_cuda():
            logger.info("üñ•Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU —Ä–µ–∂–∏–º")
            return OptimizationMode.CPU_ONLY
        
        if total_cells > 1000000 and available_memory_gb < 4.0:
            logger.info("‚öñÔ∏è –ë–æ–ª—å—à–∞—è —Ä–µ—à–µ—Ç–∫–∞ + –º–∞–ª–æ –ø–∞–º—è—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π —Ä–µ–∂–∏–º")
            return OptimizationMode.HYBRID
        
        if available_memory_gb >= 4.0:
            logger.info("üöÄ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ GPU –ø–∞–º—è—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º GPU —Ä–µ–∂–∏–º")
            return OptimizationMode.GPU_ONLY
        
        return OptimizationMode.HYBRID
    
    def _initialize_processors(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞"""
        project_config = get_project_config()
        base_config = project_config.get_spatial_optim_config()
        
        # –í—Å–µ–≥–¥–∞ —Å–æ–∑–¥–∞–µ–º CPU fallback
        self.cpu_processor = CPUFallbackProcessor(self.dimensions, base_config)
        
        # GPU processor –µ—Å–ª–∏ –Ω—É–∂–µ–Ω
        if self.active_mode in [OptimizationMode.GPU_ONLY, OptimizationMode.HYBRID]:
            try:
                self.gpu_processor = GPUSpatialProcessorWrapper(self.dimensions, base_config)
                self.has_gpu = True
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å GPU processor: {e}")
                self.has_gpu = False
                if self.active_mode == OptimizationMode.GPU_ONLY:
                    logger.info("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ CPU —Ä–µ–∂–∏–º")
                    self.active_mode = OptimizationMode.CPU_ONLY
        else:
            self.has_gpu = False
    
    def _setup_moe_integration(self):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å MoE –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π"""
        project_config = get_project_config()
        
        self.connection_distributions = {
            ConnectionType.LOCAL: project_config.local_connections_ratio,
            ConnectionType.FUNCTIONAL: project_config.functional_connections_ratio,
            ConnectionType.DISTANT: project_config.distant_connections_ratio,
        }
        
        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º MoE processor –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        if hasattr(self.moe_processor, "to"):
            self.moe_processor.to(self.device)
        
        logger.info(f"ü§ñ MoE –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞: {self.connection_distributions}")
    
    def find_neighbors_optimized(
        self, 
        coords: Union[Coordinates3D, torch.Tensor], 
        radius: float
    ) -> List[int]:
        """
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å–æ—Å–µ–¥–µ–π —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º –∞–ª–≥–æ—Ä–∏—Ç–º–∞
        
        Args:
            coords: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–æ—á–∫–∏ –ø–æ–∏—Å–∫–∞
            radius: –†–∞–¥–∏—É—Å –ø–æ–∏—Å–∫–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π
        """
        start_time = time.time()
        
        try:
            # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–≥–æ —Ä–µ–∂–∏–º–∞
            if self.active_mode == OptimizationMode.CPU_ONLY or not self.has_gpu:
                neighbors = self.cpu_processor.find_neighbors(coords, radius)
                mode_used = OptimizationMode.CPU_ONLY
            
            elif self.active_mode == OptimizationMode.GPU_ONLY:
                neighbors = self.gpu_processor.find_neighbors(coords, radius)
                mode_used = OptimizationMode.GPU_ONLY
            
            else:  # HYBRID mode
                # –ü—Ä–æ–±—É–µ–º GPU, fallback –Ω–∞ CPU –ø—Ä–∏ –æ—à–∏–±–∫–µ
                try:
                    neighbors = self.gpu_processor.find_neighbors(coords, radius)
                    mode_used = OptimizationMode.GPU_ONLY
                except Exception as e:
                    logger.debug(f"GPU fallback: {e}")
                    neighbors = self.cpu_processor.find_neighbors(coords, radius)
                    mode_used = OptimizationMode.CPU_ONLY
            
            query_time_ms = (time.time() - start_time) * 1000
            
            # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–µ–∂–∏–º–∞
            self._record_performance(query_time_ms, mode_used, len(neighbors))
            
            return neighbors
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ find_neighbors_optimized: {e}")
            # –§–∏–Ω–∞–ª—å–Ω—ã–π fallback
            return self.cpu_processor.find_neighbors(coords, radius)
    
    def optimize_lattice_forward(
        self,
        states: torch.Tensor,
        processor_fn: Optional[Callable] = None
    ) -> SpatialOptimizationResult:
        """
        –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–µ—à–µ—Ç–∫–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π MoE
        
        Args:
            states: –°–æ—Å—Ç–æ—è–Ω–∏—è –∫–ª–µ—Ç–æ–∫ [num_cells, state_size]
            processor_fn: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å –ø–æ–ª–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        start_time = time.time()
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ states –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
        if self.active_mode in [OptimizationMode.GPU_ONLY, OptimizationMode.HYBRID] and self.has_gpu:
            states = self.device_manager.ensure_device(states)
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        if processor_fn is None:
            if self.config.enable_moe and self.moe_processor:
                processor_fn = self._create_moe_processor_fn()
            else:
                processor_fn = self._create_default_processor_fn()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
        try:
            if self.active_mode == OptimizationMode.CPU_ONLY or not self.has_gpu:
                new_states = self.cpu_processor.process_lattice(states, processor_fn)
                mode_used = OptimizationMode.CPU_ONLY
                
            elif self.active_mode == OptimizationMode.GPU_ONLY:
                new_states = self.gpu_processor.process_lattice(states, processor_fn)
                mode_used = OptimizationMode.GPU_ONLY
                
            else:  # HYBRID
                try:
                    new_states = self.gpu_processor.process_lattice(states, processor_fn)
                    mode_used = OptimizationMode.GPU_ONLY
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è GPU processing failed, fallback: {e}")
                    new_states = self.cpu_processor.process_lattice(states, processor_fn)
                    mode_used = OptimizationMode.CPU_ONLY
        
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            new_states = states.clone()  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π fallback
            mode_used = OptimizationMode.CPU_ONLY
        
        processing_time_ms = (time.time() - start_time) * 1000
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        result = self._create_optimization_result(
            new_states, processing_time_ms, mode_used, states.shape[0]
        )
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        self._record_performance(processing_time_ms, mode_used, states.shape[0])
        
        return result
    
    def _create_moe_processor_fn(self) -> Callable:
        """–°–æ–∑–¥–∞–µ—Ç processor function –¥–ª—è MoE –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""
        def moe_processor(current_state, neighbor_states, cell_idx, neighbor_indices):
            try:
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥—ã –¥–ª—è MoE
                if current_state.dim() == 1:
                    current_state = current_state.unsqueeze(0)
                
                if len(neighbor_indices) == 0:
                    empty_neighbors = torch.empty(1, 0, current_state.shape[-1], device=current_state.device)
                else:
                    if neighbor_states.dim() == 1:
                        neighbor_states = neighbor_states.unsqueeze(0).unsqueeze(0)
                    elif neighbor_states.dim() == 2:
                        neighbor_states = neighbor_states.unsqueeze(0)
                    empty_neighbors = neighbor_states
                
                # –í—ã–∑—ã–≤–∞–µ–º MoE processor
                result = self.moe_processor(
                    current_state=current_state,
                    neighbor_states=empty_neighbors,
                    cell_idx=cell_idx,
                    neighbor_indices=neighbor_indices,
                    spatial_optimizer=self
                )
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                if isinstance(result, dict) and "new_state" in result:
                    return result["new_state"].squeeze(0)
                elif isinstance(result, torch.Tensor):
                    return result.squeeze(0)
                else:
                    return current_state.squeeze(0)
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è MoE processor error: {e}")
                return current_state.squeeze(0) if current_state.dim() > 1 else current_state
        
        return moe_processor
    
    def _create_default_processor_fn(self) -> Callable:
        """–°–æ–∑–¥–∞–µ—Ç –±–∞–∑–æ–≤—É—é processor function"""
        def default_processor(current_state, neighbor_states, cell_idx, neighbor_indices):
            if len(neighbor_indices) == 0:
                return current_state
            
            # –ü—Ä–æ—Å—Ç–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ —Å —Ç–µ–∫—É—â–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º
            if neighbor_states.dim() == 1:
                neighbor_states = neighbor_states.unsqueeze(0) 
            
            mean_neighbor = neighbor_states.mean(dim=0)
            
            # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ: 70% —Ç–µ–∫—É—â–µ–µ, 30% —Å–æ—Å–µ–¥–∏
            new_state = 0.7 * current_state + 0.3 * mean_neighbor
            
            return new_state
            
        return default_processor
    
    def _create_optimization_result(
        self, 
        new_states: torch.Tensor, 
        processing_time_ms: float, 
        mode_used: OptimizationMode,
        num_cells: int
    ) -> SpatialOptimizationResult:
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        
        # Memory usage
        memory_usage_mb = 0.0
        if mode_used == OptimizationMode.GPU_ONLY and self.has_gpu:
            device_stats = self.device_manager.get_memory_stats()
            memory_usage_mb = device_stats.get("allocated_mb", 0.0)
        
        # GPU utilization
        gpu_utilization = 1.0 if mode_used == OptimizationMode.GPU_ONLY else 0.0
        
        # Cache hit rate (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
        cache_hit_rate = 0.0
        if self.has_gpu and hasattr(self, 'gpu_processor'):
            gpu_stats = self.gpu_processor.get_performance_stats()
            cache_hit_rate = gpu_stats.get("gpu_processor", {}).get("processor", {}).get("cache_hit_rate", 0.0)
        
        return SpatialOptimizationResult(
            new_states=new_states,
            processing_time_ms=processing_time_ms,
            memory_usage_mb=memory_usage_mb,
            neighbors_found=num_cells * 20,  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            gpu_utilization=gpu_utilization,
            mode_used=mode_used,
            cache_hit_rate=cache_hit_rate,
            chunks_processed=max(1, num_cells // 1000)
        )
    
    def _record_performance(
        self, 
        time_ms: float, 
        mode: OptimizationMode, 
        data_size: int
    ):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        self.performance_history.append({
            "time_ms": time_ms,
            "mode": mode,
            "data_size": data_size,
            "timestamp": time.time()
        })
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–∞–ø–∏—Å–µ–π
        if len(self.performance_history) > 100:
            self.performance_history = self.performance_history[-100:]
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ –≤ HYBRID mode
        if (self.config.mode == OptimizationMode.AUTO and 
            self.active_mode == OptimizationMode.HYBRID):
            self._adaptive_mode_optimization()
    
    def _adaptive_mode_optimization(self):
        """–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã"""
        if len(self.performance_history) < 10:
            return
        
        recent_history = self.performance_history[-10:]
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å GPU vs CPU
        gpu_times = [h["time_ms"] for h in recent_history if h["mode"] == OptimizationMode.GPU_ONLY]
        cpu_times = [h["time_ms"] for h in recent_history if h["mode"] == OptimizationMode.CPU_ONLY]
        
        if len(gpu_times) >= 3 and len(cpu_times) >= 3:
            avg_gpu = np.mean(gpu_times)
            avg_cpu = np.mean(cpu_times)
            
            # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º
            if avg_gpu < avg_cpu * 0.8:  # GPU –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–µ–µ
                if self.active_mode != OptimizationMode.GPU_ONLY:
                    logger.info("üöÄ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ GPU_ONLY —Ä–µ–∂–∏–º (–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å)")
                    self.active_mode = OptimizationMode.GPU_ONLY
            elif avg_cpu < avg_gpu * 0.8:  # CPU –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–µ–µ
                if self.active_mode != OptimizationMode.CPU_ONLY:
                    logger.info("üñ•Ô∏è –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ CPU_ONLY —Ä–µ–∂–∏–º (–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å)")
                    self.active_mode = OptimizationMode.CPU_ONLY
    
    def get_comprehensive_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏—Å—Ç–µ–º—ã"""
        stats = {
            "unified_optimizer": {
                "dimensions": self.dimensions,
                "active_mode": self.active_mode.value,
                "moe_enabled": self.config.enable_moe,
                "morton_enabled": self.config.enable_morton_encoding,
                "performance_history_length": len(self.performance_history)
            }
        }
        
        # CPU stats
        stats["cpu_processor"] = self.cpu_processor.get_performance_stats()
        
        # GPU stats –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        if self.has_gpu:
            stats["gpu_processor"] = self.gpu_processor.get_performance_stats()
            stats["device"] = self.device_manager.get_memory_stats()
        
        # Performance analysis
        if self.performance_history:
            recent = self.performance_history[-20:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 20 –æ–ø–µ—Ä–∞—Ü–∏–π
            stats["performance_analysis"] = {
                "avg_time_ms": np.mean([h["time_ms"] for h in recent]),
                "mode_distribution": {
                    mode.value: len([h for h in recent if h["mode"] == mode]) 
                    for mode in OptimizationMode
                },
                "target_performance_ms": self.adaptive_threshold_ms
            }
        
        return stats
    
    def optimize_performance(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        logger.info("üîß –ó–∞–ø—É—Å–∫ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ UnifiedSpatialOptimizer")
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º GPU –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        if self.has_gpu:
            self.gpu_processor.gpu_processor.optimize_performance()
        
        # –û—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.performance_history = self.performance_history[-20:]  # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20
        
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        self.device_manager.cleanup()
        
        logger.info("‚úÖ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    
    def cleanup(self):
        """–û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã UnifiedSpatialOptimizer")
        
        if self.has_gpu:
            self.gpu_processor.gpu_processor.shutdown()
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
        self.device_manager.cleanup()
        
        logger.info("‚úÖ UnifiedSpatialOptimizer –∑–∞–≤–µ—Ä—à–µ–Ω")


# === FACTORY FUNCTIONS ===

def create_unified_spatial_optimizer(
    dimensions: Coordinates3D,
    config: Optional[OptimizationConfig] = None,
    moe_processor: Optional[nn.Module] = None
) -> UnifiedSpatialOptimizer:
    """
    –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
    
    Args:
        dimensions: –†–∞–∑–º–µ—Ä—ã —Ä–µ—à–µ—Ç–∫–∏
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        moe_processor: MoE processor –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
        
    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π UnifiedSpatialOptimizer
    """
    if config is None:
        config = OptimizationConfig()
    
    logger.info(f"üè≠ –°–æ–∑–¥–∞–Ω–∏–µ UnifiedSpatialOptimizer –¥–ª—è {dimensions}")
    
    return UnifiedSpatialOptimizer(
        dimensions=dimensions,
        config=config,
        moe_processor=moe_processor
    )


def estimate_unified_memory_requirements(
    dimensions: Coordinates3D,
    config: Optional[OptimizationConfig] = None
) -> Dict[str, float]:
    """
    –û—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ –ø–∞–º—è—Ç–∏ –¥–ª—è —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
    
    Args:
        dimensions: –†–∞–∑–º–µ—Ä—ã —Ä–µ—à–µ—Ç–∫–∏
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –ø–∞–º—è—Ç–∏ –≤ GB
    """
    if config is None:
        config = OptimizationConfig()
    
    total_cells = np.prod(dimensions)
    
    # –ë–∞–∑–æ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
    cell_states_gb = total_cells * 32 * 4 / (1024**3)  # float32 —Å–æ—Å—Ç–æ—è–Ω–∏—è
    
    # CPU –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–≤—Å–µ–≥–¥–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç)
    cpu_requirements = {
        "cpu_spatial_index_gb": total_cells * 16 / (1024**3),
        "cpu_neighbor_cache_gb": total_cells * 26 * 4 / (1024**3)
    }
    
    # GPU –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã)
    gpu_requirements = {}
    if config.mode in [OptimizationMode.AUTO, OptimizationMode.GPU_ONLY, OptimizationMode.HYBRID]:
        gpu_requirements = {
            "gpu_spatial_hash_gb": total_cells * 8 / (1024**3),
            "gpu_morton_encoder_gb": total_cells * 4 / (1024**3),
            "gpu_chunker_gb": config.max_memory_gb * 0.1,
            "gpu_tensor_overhead_gb": cell_states_gb * 0.3
        }
    
    # MoE –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã)
    moe_requirements = {}
    if config.enable_moe:
        moe_requirements = {
            "moe_expert_states_gb": total_cells * 32 * 4 * 3 / (1024**3),  # 3 —ç–∫—Å–ø–µ—Ä—Ç–∞
            "moe_connection_classification_gb": total_cells * 26 * 4 / (1024**3)
        }
    
    # –û–±—â–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
    base_memory = cell_states_gb
    cpu_memory = sum(cpu_requirements.values())
    gpu_memory = sum(gpu_requirements.values())
    moe_memory = sum(moe_requirements.values())
    
    total_memory_gb = base_memory + cpu_memory + gpu_memory + moe_memory
    
    result = {
        "cell_states_gb": base_memory,
        **cpu_requirements,
        **gpu_requirements,
        **moe_requirements,
        "total_memory_gb": total_memory_gb,
        "recommended_gpu_memory_gb": total_memory_gb * 1.4,  # 40% –∑–∞–ø–∞—Å
        "recommended_system_memory_gb": cpu_memory * 1.5,   # CPU fallback
    }
    
    return result