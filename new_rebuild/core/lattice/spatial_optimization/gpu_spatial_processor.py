#!/usr/bin/env python3
"""
GPU Spatial Processor - –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
==========================================================================

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç GPU-accelerated spatial hashing –∏ adaptive chunking –≤ –µ–¥–∏–Ω—É—é
–≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
–≤ –±–æ–ª—å—à–∏—Ö 3D —Ä–µ—à–µ—Ç–∫–∞—Ö.

–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- Unified API –¥–ª—è spatial hashing –∏ chunking
- Automatic memory management –∏ optimization
- Real-time performance monitoring
- Intelligent prefetching –∏ caching
- Seamless GPU/CPU fallback

–ê–≤—Ç–æ—Ä: 3D Cellular Neural Network Project
–í–µ—Ä—Å–∏—è: 2.0.0 (2024-12-27)
"""

import torch
import numpy as np
from typing import List, Dict, Tuple, Optional, Set, Union, Any, Callable
from dataclasses import dataclass
import time
import threading
from concurrent.futures import Future, as_completed
import asyncio


try:
    # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –º–æ–¥—É–ª—è
    from ....config import get_project_config
    from ....utils.logging import get_logger
    from ....utils.device_manager import get_device_manager
    from ..position import Position3D
    from ..gpu_spatial_hashing import (
        AdaptiveGPUSpatialHash,
        GPUSpatialHashGrid,
        GPUSpatialHashingStats,
        GPUMortonEncoder,
    )
    from .adaptive_chunker import AdaptiveGPUChunker, ChunkProcessingTask, AdaptiveChunkInfo

except ImportError:
    # –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∏–ª–∏ –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
    import sys
    import os

    sys.path.append(os.path.join(os.path.dirname(__file__), "..", "..", "..", ".."))
    from config import get_project_config
    from utils.logging import get_logger
    from utils.device_manager import get_device_manager
    from core.lattice.position import Position3D
    from core.lattice.gpu_spatial_hashing import (
        AdaptiveGPUSpatialHash,
        GPUSpatialHashGrid,
        GPUSpatialHashingStats,
        GPUMortonEncoder,
    )
    from core.lattice.spatial_optimization.adaptive_chunker import AdaptiveGPUChunker, ChunkProcessingTask, AdaptiveChunkInfo
    from new_rebuild.core.lattice.spatial_optimization.adaptive_chunker import (
        AdaptiveGPUChunker,
        ChunkProcessingTask,
    )

logger = get_logger(__name__)

Coordinates3D = Tuple[int, int, int]


@dataclass
class SpatialQuery:
    """–ó–∞–ø—Ä–æ—Å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""

    query_id: str
    coordinates: torch.Tensor  # (N, 3) tensor —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
    radius: float
    chunk_ids: Optional[Set[int]] = None
    priority: int = 0
    callback: Optional[callable] = None


@dataclass
class SpatialQueryResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""

    query_id: str
    neighbor_lists: List[torch.Tensor]  # –°–ø–∏—Å–æ–∫ neighbors –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏
    processing_time_ms: float
    memory_usage_mb: float
    cache_hit_rate: float
    chunks_accessed: Set[int]


class GPUSpatialProcessor:
    """
    –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π GPU Spatial Processor

    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç spatial hashing –∏ adaptive chunking –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π
    –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –±–æ–ª—å—à–∏—Ö 3D —Ä–µ—à–µ—Ç–∫–∞—Ö.
    """

    def __init__(self, dimensions: Coordinates3D, config: dict = None):
        self.dimensions = dimensions
        self.config = config or get_project_config().get_spatial_optim_config()

        # Device management
        self.device_manager = get_device_manager()
        self.device = self.device_manager.get_device()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self._initialize_components()

        # Query management
        from queue import Queue

        self.query_queue = Queue()
        self.active_queries: Dict[str, SpatialQuery] = {}
        self.query_results: Dict[str, SpatialQueryResult] = {}

        # Performance monitoring
        self.performance_metrics = {
            "total_queries": 0,
            "avg_query_time_ms": 0.0,
            "memory_efficiency": 0.0,
            "gpu_utilization": 0.0,
            "cache_hit_rate": 0.0,
            "chunk_rebalancing_events": 0,
        }
        
        # –§–ª–∞–≥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ spatial hash (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑)
        self._spatial_hash_initialized = False

        # Background task –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
        self._start_background_processing()

        logger.info(
            f"üöÄ GPUSpatialProcessor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {dimensions} –Ω–∞ {self.device}"
        )

    def _initialize_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: Morton Encoder, Adaptive Hash –∏ Chunker."""
        project_cfg = get_project_config()

        # GPU-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.morton_encoder = GPUMortonEncoder(self.dimensions)
        self.adaptive_hash = AdaptiveGPUSpatialHash(
            self.dimensions,
            project_cfg.spatial.memory_pool_size_gb * 1024 * 0.6,
        )

        # Chunker –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è —Å–æ —Å–≤–æ–µ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
        self.chunker = AdaptiveGPUChunker(self.dimensions)

        if getattr(self.config, "log_memory_usage", False):
            logger.info("–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã GPUSpatialProcessor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.")

        # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π layer –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
        self._setup_integration_layer()

    def _setup_integration_layer(self):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –º–µ–∂–¥—É chunker –∏ spatial hash"""
        # –ú–∞–ø–ø–∏–Ω–≥ chunk'–æ–≤ –∫ spatial hash regions
        self.chunk_to_hash_mapping: Dict[int, Set[int]] = {}
        self.hash_to_chunk_mapping: Dict[int, Set[int]] = {}

        # –ö—ç—à –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –º–µ–∂–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        self.integration_cache = {}
        self.cache_max_size = 5000

        # Thread-safe locks –¥–ª—è concurrent access
        self.mapping_lock = threading.RLock()

    def _start_background_processing(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–æ–≤"""
        self.processing_active = True

        # –ó–∞–ø—É—Å–∫–∞–µ–º async event loop –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        self.processing_thread = threading.Thread(target=self._run_async_processing)
        self.processing_thread.daemon = True
        self.processing_thread.start()

    def _run_async_processing(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç async –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            loop.run_until_complete(self._async_processing_loop())
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ async processing loop: {e}")
        finally:
            loop.close()

    async def _async_processing_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"""
        from queue import Empty

        while self.processing_active:
            try:
                # –ñ–¥–µ–º –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (—Å —Ç–∞–π–º–∞—É—Ç–æ–º)
                try:
                    query = self.query_queue.get(timeout=1.0)
                    await self._process_spatial_query(query)
                except Empty:
                    # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è
                    await self._perform_maintenance_tasks()

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ spatial query: {e}")

    async def _process_spatial_query(self, query: SpatialQuery):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å"""
        start_time = time.time()

        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ chunk'–∏
            affected_chunks = self._identify_affected_chunks(query)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ chunk'–∏ –≤ –ø–∞–º—è—Ç—å
            await self._ensure_chunks_loaded(affected_chunks)

            # –í—ã–ø–æ–ª–Ω—è–µ–º spatial hash –ø–æ–∏—Å–∫
            neighbor_lists = self.adaptive_hash.query_radius_batch(
                query.coordinates, query.radius
            )

            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ chunk boundaries –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
            if query.chunk_ids:
                neighbor_lists = self._filter_by_chunks(neighbor_lists, query.chunk_ids)

            processing_time_ms = (time.time() - start_time) * 1000

            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = SpatialQueryResult(
                query_id=query.query_id,
                neighbor_lists=neighbor_lists,
                processing_time_ms=processing_time_ms,
                memory_usage_mb=self._estimate_query_memory_usage(query),
                cache_hit_rate=self._calculate_cache_hit_rate(query),
                chunks_accessed=affected_chunks,
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ —É–≤–µ–¥–æ–º–ª—è–µ–º callback
            self.query_results[query.query_id] = result

            if query.callback:
                query.callback(result)

            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            self._update_performance_metrics(result)

            logger.debug(
                f"‚úÖ Query {query.query_id} –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {processing_time_ms:.1f}ms, "
                f"chunks: {len(affected_chunks)}"
            )

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ query {query.query_id}: {e}")
        finally:
            # –û—á–∏—â–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            self.active_queries.pop(query.query_id, None)

    def _identify_affected_chunks(self, query: SpatialQuery) -> Set[int]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç chunk'–∏, –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ –∑–∞–ø—Ä–æ—Å–æ–º"""
        affected_chunks = set()

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É –∑–∞–ø—Ä–æ—Å–∞
        for coord_idx in range(query.coordinates.shape[0]):
            coord = tuple(query.coordinates[coord_idx].cpu().numpy().astype(int))

            try:
                # –ù–∞—Ö–æ–¥–∏–º chunk –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                chunk_info = self.chunker.get_chunk_by_coords(coord)
                affected_chunks.add(chunk_info.chunk_id)

                # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ chunk'–∏ –µ—Å–ª–∏ radius –±–æ–ª—å—à–æ–π
                if query.radius > chunk_info.memory_size_mb * 0.1:  # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
                    affected_chunks.update(chunk_info.neighbor_chunks)

            except ValueError:
                logger.warning(f"‚ö†Ô∏è –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ {coord} –≤–Ω–µ boundaries —Ä–µ—à–µ—Ç–∫–∏")

        return affected_chunks

    async def _ensure_chunks_loaded(self, chunk_ids: Set[int]):
        """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö chunk'–æ–≤ –≤ –ø–∞–º—è—Ç—å"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ chunk'–∏ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
        chunks_to_load = []

        for chunk_id in chunk_ids:
            chunk_info = self.chunker.adaptive_chunks[chunk_id]
            if chunk_info.gpu_memory_usage_mb == 0:  # –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω
                chunks_to_load.append(chunk_id)

        if chunks_to_load:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º chunk'–∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
            load_tasks = []
            for chunk_id in chunks_to_load:
                future = self.chunker.process_chunk_async(
                    chunk_id, "load", self._chunk_load_callback
                )
                load_tasks.append(future)

            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏
            if load_tasks:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ awaitable
                await asyncio.get_event_loop().run_in_executor(
                    None, self._wait_for_chunk_loading, load_tasks
                )

    def _wait_for_chunk_loading(self, futures: List[Future]):
        """–ñ–¥–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ chunk'–æ–≤"""
        for future in as_completed(futures):
            try:
                result = future.result(timeout=10.0)  # 10 —Å–µ–∫—É–Ω–¥ —Ç–∞–π–º–∞—É—Ç
                logger.debug(f"‚úÖ Chunk –∑–∞–≥—Ä—É–∂–µ–Ω: {result}")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ chunk: {e}")

    def _chunk_load_callback(self, task: ChunkProcessingTask):
        """Callback –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ chunk'–∞"""
        try:
            chunk_info = self.chunker.adaptive_chunks[task.chunk_id]
        except (IndexError, KeyError):
            logger.error(f"‚ùå Chunk {task.chunk_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return f"Chunk {task.chunk_id} not found"

        # –°–æ–∑–¥–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è spatial hash
        coordinates = []
        indices = []

        for cell_idx in chunk_info.cell_indices:
            coord = self.chunker.pos_helper.to_3d_coordinates(cell_idx)
            coordinates.append(coord)
            indices.append(cell_idx)

        if coordinates:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ tensors
            coords_tensor = torch.tensor(
                coordinates, device=self.device, dtype=torch.float32
            )
            indices_tensor = torch.tensor(indices, device=self.device, dtype=torch.long)

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ spatial hash
            self.adaptive_hash.insert_batch(coords_tensor, indices_tensor)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É chunk'–∞
            chunk_info.gpu_memory_usage_mb = self._estimate_chunk_gpu_memory(chunk_info)
            chunk_info.last_access_time = time.time()

            logger.debug(
                f"üì¶ Chunk {task.chunk_id} –∑–∞–≥—Ä—É–∂–µ–Ω: {len(coordinates)} –∫–ª–µ—Ç–æ–∫"
            )

        return f"Chunk {task.chunk_id} loaded successfully"

    def _filter_by_chunks(
        self, neighbor_lists: List[torch.Tensor], allowed_chunk_ids: Set[int]
    ) -> List[torch.Tensor]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–º chunk'–∞–º"""
        filtered_lists = []

        for neighbors in neighbor_lists:
            if len(neighbors) == 0:
                filtered_lists.append(neighbors)
                continue

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º chunk'–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ neighbor'–∞
            valid_neighbors = []

            for neighbor_idx in neighbors:
                neighbor_coord = self.chunker.pos_helper.to_3d_coordinates(
                    neighbor_idx.item()
                )
                try:
                    neighbor_chunk = self.chunker.get_chunk_by_coords(neighbor_coord)
                    if neighbor_chunk.chunk_id in allowed_chunk_ids:
                        valid_neighbors.append(neighbor_idx)
                except ValueError:
                    pass  # neighbor –≤–Ω–µ boundaries

            if valid_neighbors:
                filtered_neighbors = torch.stack(valid_neighbors)
            else:
                filtered_neighbors = torch.empty(
                    0, device=self.device, dtype=torch.long
                )

            filtered_lists.append(filtered_neighbors)

        return filtered_lists

    def _estimate_query_memory_usage(self, query: SpatialQuery) -> float:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–º"""
        # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
        query_memory = query.coordinates.numel() * 4 / (1024**2)  # float32 –≤ MB

        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ü–µ–Ω–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        avg_neighbors_per_point = 50  # —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞
        result_memory = (
            query.coordinates.shape[0] * avg_neighbors_per_point * 4 / (1024**2)
        )

        return query_memory + result_memory

    def _calculate_cache_hit_rate(self, query: SpatialQuery) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç cache hit rate –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞"""
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ spatial hash
        hash_stats = self.adaptive_hash.get_comprehensive_stats()
        return hash_stats.get("spatial_hash", {}).get("cache_hit_rate", 0.0)

    def _estimate_chunk_gpu_memory(self, chunk_info: AdaptiveChunkInfo) -> float:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç GPU –ø–∞–º—è—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é chunk'–æ–º"""
        num_cells = len(chunk_info.cell_indices)

        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: 3 * 4 bytes per cell
        coordinates_memory = num_cells * 3 * 4

        # –ò–Ω–¥–µ–∫—Å—ã: 4 bytes per cell
        indices_memory = num_cells * 4

        # –ù–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã: –ø—Ä–∏–º–µ—Ä–Ω–æ 20%
        overhead = (coordinates_memory + indices_memory) * 0.2

        total_memory_bytes = coordinates_memory + indices_memory + overhead
        return total_memory_bytes / (1024**2)  # –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ MB

    async def _perform_maintenance_tasks(self):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è"""
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
        self.adaptive_hash.hash_grid.optimize_memory()

        # –ü–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ chunk'–æ–≤
        self.chunker.rebalance_chunks()

        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        self._cleanup_old_query_results()

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self._update_integration_metrics()

    def _cleanup_old_query_results(self):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤"""
        if len(self.query_results) > 1000:  # –º–∞–∫—Å–∏–º—É–º 1000 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 500
            sorted_results = sorted(
                self.query_results.items(), key=lambda x: x[1].processing_time_ms
            )

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for query_id, _ in sorted_results[:-500]:
                del self.query_results[query_id]

    def _update_performance_metrics(self, result: SpatialQueryResult):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        self.performance_metrics["total_queries"] += 1

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        old_avg = self.performance_metrics["avg_query_time_ms"]
        total_queries = self.performance_metrics["total_queries"]

        new_avg = (
            old_avg * (total_queries - 1) + result.processing_time_ms
        ) / total_queries
        self.performance_metrics["avg_query_time_ms"] = new_avg

        # –û–±–Ω–æ–≤–ª—è–µ–º cache hit rate
        self.performance_metrics["cache_hit_rate"] = result.cache_hit_rate

    def _update_integration_metrics(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        chunker_stats = self.chunker.get_comprehensive_stats()
        hash_stats = self.adaptive_hash.get_comprehensive_stats()

        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏
        chunker_efficiency = chunker_stats.get("memory", {}).get(
            "memory_efficiency", 0.0
        )
        hash_memory = hash_stats.get("memory", {}).get("total_gpu_mb", 0.0)
        total_memory = chunker_stats.get("memory", {}).get(
            "total_chunks_memory_mb", 0.0
        )

        if total_memory > 0:
            self.performance_metrics["memory_efficiency"] = (
                chunker_efficiency * 0.7 + (hash_memory / total_memory) * 0.3
            )

        # GPU utilization (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
        device_stats = self.device_manager.get_memory_stats()
        if self.device_manager.is_cuda() and "allocated_mb" in device_stats:
            allocated_mb = device_stats["allocated_mb"]
            reserved_mb = device_stats.get("reserved_mb", allocated_mb)

            if reserved_mb > 0:
                self.performance_metrics["gpu_utilization"] = allocated_mb / reserved_mb

    # === PUBLIC API ===

    def query_neighbors_async(
        self,
        coordinates: Union[torch.Tensor, np.ndarray, List],
        radius: float,
        chunk_ids: Optional[Set[int]] = None,
        priority: int = 0,
        callback: Optional[callable] = None,
    ) -> str:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å–æ—Å–µ–¥–µ–π

        Args:
            coordinates: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ (N, 3)
            radius: –†–∞–¥–∏—É—Å –ø–æ–∏—Å–∫–∞
            chunk_ids: –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –ø–æ–∏—Å–∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ chunk'–∞–º–∏
            priority: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∑–∞–ø—Ä–æ—Å–∞ (0-100)
            callback: Callback —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

        Returns:
            query_id –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ tensor
        if isinstance(coordinates, (np.ndarray, list)):
            coords_tensor = torch.tensor(
                coordinates, device=self.device, dtype=torch.float32
            )
        else:
            coords_tensor = self.device_manager.ensure_device(coordinates)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π query_id
        query_id = f"query_{int(time.time() * 1000000)}_{len(self.active_queries)}"

        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å
        query = SpatialQuery(
            query_id=query_id,
            coordinates=coords_tensor,
            radius=radius,
            chunk_ids=chunk_ids,
            priority=priority,
            callback=callback,
        )

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∏ –æ—á–µ—Ä–µ–¥—å
        self.active_queries[query_id] = query

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ queue (thread-safe)
        self.query_queue.put(query)

        return query_id

    def query_neighbors_sync(
        self,
        coordinates: Union[torch.Tensor, np.ndarray, List],
        radius: float,
        chunk_ids: Optional[Set[int]] = None,
        timeout: float = 30.0,
    ) -> SpatialQueryResult:
        """
        –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å–æ—Å–µ–¥–µ–π

        Args:
            coordinates: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
            radius: –†–∞–¥–∏—É—Å –ø–æ–∏—Å–∫–∞
            chunk_ids: –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –ø–æ–∏—Å–∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ chunk'–∞–º–∏
            timeout: –¢–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞
        """
        result_ready = threading.Event()
        result_container = {}

        def sync_callback(result: SpatialQueryResult):
            result_container["result"] = result
            result_ready.set()

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        query_id = self.query_neighbors_async(
            coordinates,
            radius,
            chunk_ids,
            priority=100,  # –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è sync –∑–∞–ø—Ä–æ—Å–æ–≤
            callback=sync_callback,
        )

        # –ñ–¥–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if result_ready.wait(timeout):
            return result_container["result"]
        else:
            raise TimeoutError(f"Query {query_id} –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –∑–∞ {timeout}s")

    def get_query_result(self, query_id: str) -> Optional[SpatialQueryResult]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ ID"""
        return self.query_results.get(query_id)

    def is_query_complete(self, query_id: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –∑–∞–≤–µ—Ä—à–µ–Ω –ª–∏ –∑–∞–ø—Ä–æ—Å"""
        return query_id in self.query_results

    def get_performance_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—Ç –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        chunker_stats = self.chunker.get_comprehensive_stats()
        hash_stats = self.adaptive_hash.get_comprehensive_stats()
        device_stats = self.device_manager.get_memory_stats()

        return {
            "processor": self.performance_metrics,
            "chunker": chunker_stats,
            "spatial_hash": hash_stats,
            "device": device_stats,
            "integration": {
                "active_queries": len(self.active_queries),
                "cached_results": len(self.query_results),
                "cache_size": len(self.integration_cache),
            },
        }

    def optimize_performance(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        logger.info("üîß –ó–∞–ø—É—â–µ–Ω–∞ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è spatial hash
        self.adaptive_hash.hash_grid.optimize_memory()

        # –ü–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ chunk'–æ–≤
        self.chunker.rebalance_chunks()

        # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–µ–π
        self.integration_cache.clear()
        self._cleanup_old_query_results()

        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏
        self.device_manager.cleanup()

        logger.info("‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    def shutdown(self):
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã processor'–∞"""
        logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã GPUSpatialProcessor")

        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º background processing
        self.processing_active = False

        if hasattr(self, "processing_thread") and self.processing_thread.is_alive():
            self.processing_thread.join(timeout=5.0)

        # –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.chunker.cleanup()

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        self.device_manager.cleanup()

        logger.info("‚úÖ GPUSpatialProcessor –∑–∞–≤–µ—Ä—à–µ–Ω")

    # === PUBLIC API ===
    
    def process_lattice(
        self,
        states: torch.Tensor,
        processor_fn: callable,
        chunker=None
    ) -> torch.Tensor:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ—à–µ—Ç–∫—É —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º spatial optimization
        
        Args:
            states: –°–æ—Å—Ç–æ—è–Ω–∏—è –∫–ª–µ—Ç–æ–∫ —Ä–µ—à–µ—Ç–∫–∏
            processor_fn: –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            chunker: Chunker –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—à –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π chunker –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω –≤–Ω–µ—à–Ω–∏–π
        active_chunker = chunker or self.chunker
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º spatial hash –≤—Å–µ–º–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –∫–ª–µ—Ç–æ–∫
        self._populate_spatial_hash(states)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ chunk'–æ–≤
        schedule = active_chunker.get_adaptive_processing_schedule()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º chunk'–∏ —Å–æ–≥–ª–∞—Å–Ω–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é
        processed_states = states.clone()
        
        # Store updates to apply later (to avoid in-place operations during autograd)
        updates = {}
        
        for batch in schedule:
            batch_futures = []
            
            for chunk_id in batch:
                # –ü–ª–∞–Ω–∏—Ä—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É chunk'–∞
                future = active_chunker.process_chunk_async(
                    chunk_id,
                    "process",
                    callback=lambda cid, chunk_info: self._process_chunk_with_function(
                        chunk_info, processed_states, processor_fn, updates
                    ),
                    all_states=processed_states
                )
                batch_futures.append(future)
            
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö chunk'–æ–≤ –≤ batch'–µ
            for future in batch_futures:
                try:
                    future.result(timeout=30.0)  # 30 —Å–µ–∫—É–Ω–¥ —Ç–∞–π–º–∞—É—Ç
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ chunk'–∞: {e}")
        
        # Apply all updates at once to create new tensor
        if updates:
            if processed_states.dim() == 3:
                new_states = processed_states.clone()
                for indices, chunk_states in updates.items():
                    new_states[:, list(indices), :] = chunk_states
                processed_states = new_states
            else:
                new_states = processed_states.clone()
                for indices, chunk_states in updates.items():
                    new_states[list(indices)] = chunk_states
                processed_states = new_states
        
        return processed_states
    
    def _process_chunk_with_function(
        self,
        chunk_info,
        all_states: torch.Tensor,
        processor_fn: callable,
        updates: dict = None
    ) -> str:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω chunk —Å –∑–∞–¥–∞–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π"""
        try:
            # DEBUG: –õ–æ–≥–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
            logger.debug(f"üîß CHUNK PROCESSING: all_states shape {all_states.shape}")
            logger.debug(f"üîß CHUNK INDICES count: {len(chunk_info.cell_indices)}")
            logger.debug(f"üîß CHUNK INDICES range: {min(chunk_info.cell_indices)} - {max(chunk_info.cell_indices)}")
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –∫–ª–µ—Ç–æ–∫ chunk'–∞
            indices = torch.tensor(
                chunk_info.cell_indices,
                device=self.device,
                dtype=torch.long
            )
            
            # –ò–°–ü–†–ê–í–õ–Ø–ï–ú –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ: all_states –∏–º–µ–µ—Ç shape [batch, cells, features]
            # –ò–Ω–¥–µ–∫—Å—ã chunk_info.cell_indices –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ cells dimension (–≤—Ç–æ—Ä–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏)
            logger.debug(f"üîç INDEXING DEBUG: all_states.shape={all_states.shape}, indices.shape={indices.shape}")
            logger.debug(f"üîç INDICES SAMPLE: {indices[:5].tolist()} ... {indices[-5:].tolist()}")
            
            if all_states.dim() == 3:  # [batch, cells, features]
                batch_size, num_cells, features = all_states.shape
                max_cell_index = num_cells - 1
                
                logger.debug(f"üîç BATCH INDEXING: batch_size={batch_size}, num_cells={num_cells}, max_index={max_cell_index}")
                
                if torch.any(indices > max_cell_index):
                    invalid_indices = indices[indices > max_cell_index]
                    logger.error(f"‚ùå INVALID CELL INDICES: {invalid_indices.tolist()} > {max_cell_index}")
                    logger.error(f"‚ùå All states shape: {all_states.shape}")
                    raise RuntimeError(f"Cell index out of bounds: max valid cell index is {max_cell_index}")
                
                logger.debug(f"üîç BEFORE INDEXING: about to do all_states[:, indices, :]")
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è chunk'–∞: [:, indices, :] - –≤—Å–µ –±–∞—Ç—á–∏, –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–ª–µ—Ç–∫–∏, –≤—Å–µ —Ñ–∏—á–∏
                chunk_states = all_states[:, indices, :]  # [batch, chunk_cells, features]
                logger.debug(f"üîç AFTER INDEXING: chunk_states.shape={chunk_states.shape}")
                
            else:  # Fallback –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
                max_index = all_states.shape[0] - 1
                if torch.any(indices > max_index):
                    invalid_indices = indices[indices > max_index]
                    logger.error(f"‚ùå INVALID INDICES: {invalid_indices.tolist()} > {max_index}")
                    raise RuntimeError(f"Index out of bounds: max valid index is {max_index}")
                
                chunk_states = all_states[indices]
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –∫–ª–µ—Ç–∫—É –≤ chunk'–µ
            # Create list to collect processed states instead of in-place modification
            processed_states_list = []
            
            for i, cell_idx in enumerate(indices):
                if all_states.dim() == 3:  # [batch, cells, features]
                    cell_state = chunk_states[:, i:i+1, :]  # [batch, 1, features] - —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–¥–Ω–æ–π –∫–ª–µ—Ç–∫–∏ –¥–ª—è –≤—Å–µ—Ö –±–∞—Ç—á–µ–π
                else:
                    cell_state = chunk_states[i:i+1]  # Fallback
                
                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–ª–µ—Ç–∫–∏
                cell_coords = self.chunker.pos_helper.to_3d_coordinates(cell_idx.item())
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º spatial hash –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ—Å–µ–¥–µ–π
                try:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ tensor –¥–ª—è spatial hash
                    coords_tensor = torch.tensor(
                        [cell_coords], device=self.device, dtype=torch.float32
                    )
                    
                    # –ò—â–µ–º —Å–æ—Å–µ–¥–µ–π –≤ —Ä–∞–¥–∏—É—Å–µ (–∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–∞–¥–∏—É—Å)
                    config = get_project_config()
                    search_radius = config.calculate_adaptive_radius()
                    
                    neighbor_lists = self.adaptive_hash.query_radius_batch(
                        coords_tensor, search_radius
                    )
                    
                    neighbor_indices = neighbor_lists[0] if neighbor_lists else torch.empty(
                        0, device=self.device, dtype=torch.long
                    )
                    
                except Exception as e:
                    logger.debug(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–æ—Å–µ–¥–µ–π –¥–ª—è –∫–ª–µ—Ç–∫–∏ {cell_idx}: {e}")
                    neighbor_indices = torch.empty(0, device=self.device, dtype=torch.long)
                
                # –°–æ–±–∏—Ä–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ—Å–µ–¥–µ–π
                if len(neighbor_indices) > 0:
                    # Get neighbor states from all_states
                    if all_states.dim() == 3:  # [batch, cells, features]
                        # Extract neighbor states for all batches
                        neighbor_states = all_states[:, neighbor_indices, :]  # [batch, num_neighbors, features]
                        # For now, average across batch dimension for neighbors
                        # This is a simplification - in production you might want batch-aware neighbor processing
                        neighbor_states = neighbor_states.mean(dim=0)  # [num_neighbors, features]
                    else:
                        neighbor_states = all_states[neighbor_indices]  # [num_neighbors, features]
                else:
                    neighbor_states = torch.empty(0, all_states.shape[-1], device=self.device)
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫ –æ–¥–Ω–æ–π –∫–ª–µ—Ç–∫–µ
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º cell_idx –≤ int, —Ç–∞–∫ –∫–∞–∫ MoE processor –æ–∂–∏–¥–∞–µ—Ç int
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º neighbor_indices –≤ —Å–ø–∏—Å–æ–∫ int'–æ–≤
                processed_state = processor_fn(
                    cell_state,
                    neighbor_states,
                    cell_idx.item() if isinstance(cell_idx, torch.Tensor) else cell_idx,
                    neighbor_indices.tolist() if isinstance(neighbor_indices, torch.Tensor) else neighbor_indices
                )
                
                if all_states.dim() == 3:  # [batch, cells, features]
                    processed_states_list.append(processed_state.squeeze(1))  # –£–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∫–ª–µ—Ç–∫–∏
                else:
                    processed_states_list.append(processed_state.squeeze(0))
            
            # Stack all processed states into a single tensor
            if all_states.dim() == 3:
                processed_chunk_states = torch.stack(processed_states_list, dim=1)  # [batch, chunk_cells, features]
            else:
                processed_chunk_states = torch.stack(processed_states_list, dim=0)  # [chunk_cells, features]
            
            # Store updates instead of applying them directly
            if updates is not None:
                # Convert indices to tuple for use as dictionary key
                indices_tuple = tuple(indices.cpu().numpy())
                updates[indices_tuple] = processed_chunk_states
            else:
                # Fallback to direct update if no updates dict provided
                if all_states.dim() == 3:  # [batch, cells, features]
                    all_states[:, indices, :] = processed_chunk_states
                else:
                    all_states[indices] = processed_chunk_states
            
            return f"Chunk {chunk_info.chunk_id} processed successfully"
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ chunk {chunk_info.chunk_id}: {e}")
            return f"Chunk {chunk_info.chunk_id} processing failed: {e}"
    
    def _populate_spatial_hash(self, states: torch.Tensor):
        """–ó–∞–ø–æ–ª–Ω—è–µ—Ç spatial hash –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –≤—Å–µ—Ö –∫–ª–µ—Ç–æ–∫ —Ä–µ—à–µ—Ç–∫–∏"""
        total_cells = states.shape[0]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Å–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏ –∏–Ω–¥–µ–∫—Å—ã
        all_coordinates = []
        all_indices = []
        
        for cell_idx in range(total_cells):
            coords = self.chunker.pos_helper.to_3d_coordinates(cell_idx)
            all_coordinates.append(coords)
            all_indices.append(cell_idx)
        
        if all_coordinates:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ tensors
            coords_tensor = torch.tensor(
                all_coordinates, device=self.device, dtype=torch.float32
            )
            indices_tensor = torch.tensor(
                all_indices, device=self.device, dtype=torch.long
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ spatial hash
            self.adaptive_hash.insert_batch(coords_tensor, indices_tensor)
            
            logger.debug(f"üìç Spatial hash –∑–∞–ø–æ–ª–Ω–µ–Ω: {len(all_coordinates)} –∫–ª–µ—Ç–æ–∫")
    
    def find_neighbors(
        self, coords: Union[Tuple[int, int, int], List[int], torch.Tensor], radius: float
    ) -> List[int]:
        """
        –ü—Ä–æ—Å—Ç–æ–π API –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ—Å–µ–¥–µ–π –≤ —Ä–∞–¥–∏—É—Å–µ
        
        Args:
            coords: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–æ—á–∫–∏ (x, y, z)
            radius: —Ä–∞–¥–∏—É—Å –ø–æ–∏—Å–∫–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤ —Å–æ—Å–µ–¥–Ω–∏—Ö –∫–ª–µ—Ç–æ–∫
        """
        # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        logger.info(f"üîç [GPUSpatialProcessor.find_neighbors] –í—ã–∑–≤–∞–Ω –¥–ª—è coords={coords}, radius={radius}")
        
        # –õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è spatial hash, –µ—Å–ª–∏ –æ–Ω –ø—É—Å—Ç–æ–π
        self._ensure_spatial_hash_initialized()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ —Ç–µ–Ω–∑–æ—Ä
        if isinstance(coords, (tuple, list)):
            coords_tensor = torch.tensor([coords], device=self.device, dtype=torch.float32)
        elif isinstance(coords, torch.Tensor):
            if coords.dim() == 1:
                coords_tensor = coords.unsqueeze(0).to(self.device)
            else:
                coords_tensor = coords.to(self.device)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: {type(coords)}")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π adaptive_hash –¥–ª—è –ø–æ–∏—Å–∫–∞
        neighbor_lists = self.adaptive_hash.query_radius_batch(coords_tensor, radius)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ —Å–ø–∏—Å–æ–∫ Python integers
        if neighbor_lists and len(neighbor_lists) > 0:
            neighbors_tensor = neighbor_lists[0]
            neighbors_list = neighbors_tensor.cpu().tolist()
            
            # –£–±–∏—Ä–∞–µ–º —Å–∞–º—É —Ç–æ—á–∫—É –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–Ω—É–∂–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç—å –∏–Ω–¥–µ–∫—Å —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π —Ç–æ—á–∫–∏)
            if isinstance(coords, (tuple, list)):
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –ª–∏–Ω–µ–π–Ω—ã–π –∏–Ω–¥–µ–∫—Å
                center_x, center_y, center_z = coords
                if hasattr(self.chunker, 'pos_helper'):
                    center_idx = self.chunker.pos_helper.to_linear_index((center_x, center_y, center_z))
                    if center_idx in neighbors_list:
                        neighbors_list.remove(center_idx)
            
            # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            logger.info(f"   [GPUSpatialProcessor.find_neighbors] –ù–∞–π–¥–µ–Ω–æ {len(neighbors_list)} —Å–æ—Å–µ–¥–µ–π")
            if len(neighbors_list) > 10:
                logger.info(f"   –ü–µ—Ä–≤—ã–µ 10 —Å–æ—Å–µ–¥–µ–π: {neighbors_list[:10]}...")
            else:
                logger.info(f"   –í—Å–µ —Å–æ—Å–µ–¥–∏: {neighbors_list}")
            
            return neighbors_list
        else:
            logger.info(f"   [GPUSpatialProcessor.find_neighbors] –°–æ—Å–µ–¥–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
            return []
    
    def _ensure_spatial_hash_initialized(self):
        """
        –õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è spatial hash
        –ó–∞–ø–æ–ª–Ω—è–µ—Ç hash –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –≤—Å–µ—Ö –∫–ª–µ—Ç–æ–∫ —Ä–µ—à–µ—Ç–∫–∏ –µ—Å–ª–∏ –æ–Ω –µ—â–µ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
        """
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º spatial hash —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑
        if not self._spatial_hash_initialized:
            logger.debug("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º spatial hash –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏...")
            
            # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–µ—Ç–æ–∫ –≤ —Ä–µ—à–µ—Ç–∫–µ
            total_cells = self.dimensions[0] * self.dimensions[1] * self.dimensions[2]
            
            # –°–æ–∑–¥–∞–µ–º dummy states –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            dummy_states = torch.zeros(total_cells, 1, device=self.device)
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º spatial hash
            self._populate_spatial_hash(dummy_states)
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ —á—Ç–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞
            self._spatial_hash_initialized = True
            
            logger.info(f"‚úÖ Spatial hash –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è {total_cells} –∫–ª–µ—Ç–æ–∫")
