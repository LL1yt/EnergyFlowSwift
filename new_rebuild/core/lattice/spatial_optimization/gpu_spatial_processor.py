#!/usr/bin/env python3
"""
GPU Spatial Processor - –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
==========================================================================

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç GPU-accelerated spatial hashing –∏ adaptive chunking –≤ –µ–¥–∏–Ω—É—é
–≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
–≤ –±–æ–ª—å—à–∏—Ö 3D —Ä–µ—à–µ—Ç–∫–∞—Ö.

–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- Unified API –¥–ª—è spatial hashing –∏ chunking
- Automatic memory management –∏ optimization
- Real-time performance monitoring
- Intelligent prefetching –∏ caching
- Seamless GPU/CPU fallback

–ê–≤—Ç–æ—Ä: 3D Cellular Neural Network Project
–í–µ—Ä—Å–∏—è: 2.0.0 (2024-12-27)
"""

import torch
import numpy as np
from typing import List, Dict, Tuple, Optional, Set, Union, Any, Callable
from dataclasses import dataclass
import time
import threading
from concurrent.futures import Future, as_completed
import asyncio


try:
    # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –º–æ–¥—É–ª—è
    from ....config.project_config import get_project_config
    from ....utils.logging import get_logger
    from ....utils.device_manager import get_device_manager
    from ..position import Position3D
    from ..gpu_spatial_hashing import (
        AdaptiveGPUSpatialHash,
        GPUSpatialHashGrid,
        GPUSpatialHashingStats,
        GPUMortonEncoder,
    )
    from .adaptive_chunker import AdaptiveGPUChunker, ChunkProcessingTask

except ImportError:
    # –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∏–ª–∏ –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
    import sys
    import os

    sys.path.append(os.path.join(os.path.dirname(__file__), "..", "..", "..", ".."))
    from config.project_config import get_project_config
    from utils.logging import get_logger
    from utils.device_manager import get_device_manager
    from core.lattice.position import Position3D
    from core.lattice.gpu_spatial_hashing import (
        AdaptiveGPUSpatialHash,
        GPUSpatialHashGrid,
        GPUSpatialHashingStats,
        GPUMortonEncoder,
    )
    from new_rebuild.core.lattice.spatial_optimization.adaptive_chunker import (
        AdaptiveGPUChunker,
        ChunkProcessingTask,
    )

logger = get_logger(__name__)

Coordinates3D = Tuple[int, int, int]


@dataclass
class SpatialQuery:
    """–ó–∞–ø—Ä–æ—Å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""

    query_id: str
    coordinates: torch.Tensor  # (N, 3) tensor —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
    radius: float
    chunk_ids: Optional[Set[int]] = None
    priority: int = 0
    callback: Optional[callable] = None


@dataclass
class SpatialQueryResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""

    query_id: str
    neighbor_lists: List[torch.Tensor]  # –°–ø–∏—Å–æ–∫ neighbors –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏
    processing_time_ms: float
    memory_usage_mb: float
    cache_hit_rate: float
    chunks_accessed: Set[int]


class GPUSpatialProcessor:
    """
    –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π GPU Spatial Processor

    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç spatial hashing –∏ adaptive chunking –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π
    –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –±–æ–ª—å—à–∏—Ö 3D —Ä–µ—à–µ—Ç–∫–∞—Ö.
    """

    def __init__(self, dimensions: Coordinates3D, config: dict = None):
        self.dimensions = dimensions
        self.config = config or get_project_config().get_spatial_optim_config()

        # Device management
        self.device_manager = get_device_manager()
        self.device = self.device_manager.get_device()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self._initialize_components()

        # Query management
        from queue import Queue

        self.query_queue = Queue()
        self.active_queries: Dict[str, SpatialQuery] = {}
        self.query_results: Dict[str, SpatialQueryResult] = {}

        # Performance monitoring
        self.performance_metrics = {
            "total_queries": 0,
            "avg_query_time_ms": 0.0,
            "memory_efficiency": 0.0,
            "gpu_utilization": 0.0,
            "cache_hit_rate": 0.0,
            "chunk_rebalancing_events": 0,
        }

        # Background task –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
        self._start_background_processing()

        logger.info(
            f"üöÄ GPUSpatialProcessor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {dimensions} –Ω–∞ {self.device}"
        )

    def _initialize_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: Morton Encoder, Adaptive Hash –∏ Chunker."""
        project_cfg = get_project_config()

        # GPU-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.morton_encoder = GPUMortonEncoder(self.dimensions)
        self.adaptive_hash = AdaptiveGPUSpatialHash(
            self.dimensions,
            project_cfg.spatial.memory_pool_size_gb * 1024 * 0.6,
        )

        # Chunker –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è —Å–æ —Å–≤–æ–µ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
        self.chunker = AdaptiveGPUChunker(self.dimensions)

        if self.config.get("log_memory_usage", False):
            logger.info("–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã GPUSpatialProcessor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.")

        # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π layer –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
        self._setup_integration_layer()

    def _setup_integration_layer(self):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –º–µ–∂–¥—É chunker –∏ spatial hash"""
        # –ú–∞–ø–ø–∏–Ω–≥ chunk'–æ–≤ –∫ spatial hash regions
        self.chunk_to_hash_mapping: Dict[int, Set[int]] = {}
        self.hash_to_chunk_mapping: Dict[int, Set[int]] = {}

        # –ö—ç—à –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –º–µ–∂–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        self.integration_cache = {}
        self.cache_max_size = 5000

        # Thread-safe locks –¥–ª—è concurrent access
        self.mapping_lock = threading.RLock()

    def _start_background_processing(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–æ–≤"""
        self.processing_active = True

        # –ó–∞–ø—É—Å–∫–∞–µ–º async event loop –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        self.processing_thread = threading.Thread(target=self._run_async_processing)
        self.processing_thread.daemon = True
        self.processing_thread.start()

    def _run_async_processing(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç async –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            loop.run_until_complete(self._async_processing_loop())
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ async processing loop: {e}")
        finally:
            loop.close()

    async def _async_processing_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"""
        from queue import Empty

        while self.processing_active:
            try:
                # –ñ–¥–µ–º –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (—Å —Ç–∞–π–º–∞—É—Ç–æ–º)
                try:
                    query = self.query_queue.get(timeout=1.0)
                    await self._process_spatial_query(query)
                except Empty:
                    # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è
                    await self._perform_maintenance_tasks()

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ spatial query: {e}")

    async def _process_spatial_query(self, query: SpatialQuery):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å"""
        start_time = time.time()

        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ chunk'–∏
            affected_chunks = self._identify_affected_chunks(query)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ chunk'–∏ –≤ –ø–∞–º—è—Ç—å
            await self._ensure_chunks_loaded(affected_chunks)

            # –í—ã–ø–æ–ª–Ω—è–µ–º spatial hash –ø–æ–∏—Å–∫
            neighbor_lists = self.spatial_hash.query_radius_batch(
                query.coordinates, query.radius
            )

            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ chunk boundaries –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
            if query.chunk_ids:
                neighbor_lists = self._filter_by_chunks(neighbor_lists, query.chunk_ids)

            processing_time_ms = (time.time() - start_time) * 1000

            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = SpatialQueryResult(
                query_id=query.query_id,
                neighbor_lists=neighbor_lists,
                processing_time_ms=processing_time_ms,
                memory_usage_mb=self._estimate_query_memory_usage(query),
                cache_hit_rate=self._calculate_cache_hit_rate(query),
                chunks_accessed=affected_chunks,
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ —É–≤–µ–¥–æ–º–ª—è–µ–º callback
            self.query_results[query.query_id] = result

            if query.callback:
                query.callback(result)

            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            self._update_performance_metrics(result)

            logger.debug(
                f"‚úÖ Query {query.query_id} –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {processing_time_ms:.1f}ms, "
                f"chunks: {len(affected_chunks)}"
            )

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ query {query.query_id}: {e}")
        finally:
            # –û—á–∏—â–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            self.active_queries.pop(query.query_id, None)

    def _identify_affected_chunks(self, query: SpatialQuery) -> Set[int]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç chunk'–∏, –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ –∑–∞–ø—Ä–æ—Å–æ–º"""
        affected_chunks = set()

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É –∑–∞–ø—Ä–æ—Å–∞
        for coord_idx in range(query.coordinates.shape[0]):
            coord = tuple(query.coordinates[coord_idx].cpu().numpy().astype(int))

            try:
                # –ù–∞—Ö–æ–¥–∏–º chunk –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                chunk_info = self.chunker.get_chunk_by_coords(coord)
                affected_chunks.add(chunk_info.chunk_id)

                # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ chunk'–∏ –µ—Å–ª–∏ radius –±–æ–ª—å—à–æ–π
                if query.radius > chunk_info.memory_size_mb * 0.1:  # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
                    affected_chunks.update(chunk_info.neighbor_chunks)

            except ValueError:
                logger.warning(f"‚ö†Ô∏è –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ {coord} –≤–Ω–µ boundaries —Ä–µ—à–µ—Ç–∫–∏")

        return affected_chunks

    async def _ensure_chunks_loaded(self, chunk_ids: Set[int]):
        """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö chunk'–æ–≤ –≤ –ø–∞–º—è—Ç—å"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ chunk'–∏ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
        chunks_to_load = []

        for chunk_id in chunk_ids:
            chunk_info = self.chunker.adaptive_chunks[chunk_id]
            if chunk_info.gpu_memory_usage_mb == 0:  # –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω
                chunks_to_load.append(chunk_id)

        if chunks_to_load:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º chunk'–∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
            load_tasks = []
            for chunk_id in chunks_to_load:
                future = self.chunker.process_chunk_async(
                    chunk_id, "load", self._chunk_load_callback
                )
                load_tasks.append(future)

            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏
            if load_tasks:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ awaitable
                await asyncio.get_event_loop().run_in_executor(
                    None, self._wait_for_chunk_loading, load_tasks
                )

    def _wait_for_chunk_loading(self, futures: List[Future]):
        """–ñ–¥–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ chunk'–æ–≤"""
        for future in as_completed(futures):
            try:
                result = future.result(timeout=10.0)  # 10 —Å–µ–∫—É–Ω–¥ —Ç–∞–π–º–∞—É—Ç
                logger.debug(f"‚úÖ Chunk –∑–∞–≥—Ä—É–∂–µ–Ω: {result}")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ chunk: {e}")

    def _chunk_load_callback(self, task: ChunkProcessingTask):
        """Callback –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ chunk'–∞"""
        try:
            chunk_info = self.chunker.adaptive_chunks[task.chunk_id]
        except (IndexError, KeyError):
            logger.error(f"‚ùå Chunk {task.chunk_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return f"Chunk {task.chunk_id} not found"

        # –°–æ–∑–¥–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è spatial hash
        coordinates = []
        indices = []

        for cell_idx in chunk_info.cell_indices:
            coord = self.chunker.pos_helper.to_3d_coordinates(cell_idx)
            coordinates.append(coord)
            indices.append(cell_idx)

        if coordinates:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ tensors
            coords_tensor = torch.tensor(
                coordinates, device=self.device, dtype=torch.float32
            )
            indices_tensor = torch.tensor(indices, device=self.device, dtype=torch.long)

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ spatial hash
            self.spatial_hash.insert_batch(coords_tensor, indices_tensor)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É chunk'–∞
            chunk_info.gpu_memory_usage_mb = self._estimate_chunk_gpu_memory(chunk_info)
            chunk_info.last_access_time = time.time()

            logger.debug(
                f"üì¶ Chunk {task.chunk_id} –∑–∞–≥—Ä—É–∂–µ–Ω: {len(coordinates)} –∫–ª–µ—Ç–æ–∫"
            )

        return f"Chunk {task.chunk_id} loaded successfully"

    def _filter_by_chunks(
        self, neighbor_lists: List[torch.Tensor], allowed_chunk_ids: Set[int]
    ) -> List[torch.Tensor]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–º chunk'–∞–º"""
        filtered_lists = []

        for neighbors in neighbor_lists:
            if len(neighbors) == 0:
                filtered_lists.append(neighbors)
                continue

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º chunk'–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ neighbor'–∞
            valid_neighbors = []

            for neighbor_idx in neighbors:
                neighbor_coord = self.chunker.pos_helper.to_3d_coordinates(
                    neighbor_idx.item()
                )
                try:
                    neighbor_chunk = self.chunker.get_chunk_by_coords(neighbor_coord)
                    if neighbor_chunk.chunk_id in allowed_chunk_ids:
                        valid_neighbors.append(neighbor_idx)
                except ValueError:
                    pass  # neighbor –≤–Ω–µ boundaries

            if valid_neighbors:
                filtered_neighbors = torch.stack(valid_neighbors)
            else:
                filtered_neighbors = torch.empty(
                    0, device=self.device, dtype=torch.long
                )

            filtered_lists.append(filtered_neighbors)

        return filtered_lists

    def _estimate_query_memory_usage(self, query: SpatialQuery) -> float:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–º"""
        # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
        query_memory = query.coordinates.numel() * 4 / (1024**2)  # float32 –≤ MB

        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ü–µ–Ω–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        avg_neighbors_per_point = 50  # —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞
        result_memory = (
            query.coordinates.shape[0] * avg_neighbors_per_point * 4 / (1024**2)
        )

        return query_memory + result_memory

    def _calculate_cache_hit_rate(self, query: SpatialQuery) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç cache hit rate –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞"""
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ spatial hash
        hash_stats = self.spatial_hash.get_comprehensive_stats()
        return hash_stats.get("spatial_hash", {}).get("cache_hit_rate", 0.0)

    def _estimate_chunk_gpu_memory(self, chunk_info: AdaptiveChunkInfo) -> float:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç GPU –ø–∞–º—è—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é chunk'–æ–º"""
        num_cells = len(chunk_info.cell_indices)

        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: 3 * 4 bytes per cell
        coordinates_memory = num_cells * 3 * 4

        # –ò–Ω–¥–µ–∫—Å—ã: 4 bytes per cell
        indices_memory = num_cells * 4

        # –ù–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã: –ø—Ä–∏–º–µ—Ä–Ω–æ 20%
        overhead = (coordinates_memory + indices_memory) * 0.2

        total_memory_bytes = coordinates_memory + indices_memory + overhead
        return total_memory_bytes / (1024**2)  # –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ MB

    async def _perform_maintenance_tasks(self):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è"""
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
        self.spatial_hash.hash_grid.optimize_memory()

        # –ü–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ chunk'–æ–≤
        self.chunker.rebalance_chunks()

        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        self._cleanup_old_query_results()

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self._update_integration_metrics()

    def _cleanup_old_query_results(self):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤"""
        if len(self.query_results) > 1000:  # –º–∞–∫—Å–∏–º—É–º 1000 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 500
            sorted_results = sorted(
                self.query_results.items(), key=lambda x: x[1].processing_time_ms
            )

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for query_id, _ in sorted_results[:-500]:
                del self.query_results[query_id]

    def _update_performance_metrics(self, result: SpatialQueryResult):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        self.performance_metrics["total_queries"] += 1

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        old_avg = self.performance_metrics["avg_query_time_ms"]
        total_queries = self.performance_metrics["total_queries"]

        new_avg = (
            old_avg * (total_queries - 1) + result.processing_time_ms
        ) / total_queries
        self.performance_metrics["avg_query_time_ms"] = new_avg

        # –û–±–Ω–æ–≤–ª—è–µ–º cache hit rate
        self.performance_metrics["cache_hit_rate"] = result.cache_hit_rate

    def _update_integration_metrics(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        chunker_stats = self.chunker.get_comprehensive_stats()
        hash_stats = self.spatial_hash.get_comprehensive_stats()

        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏
        chunker_efficiency = chunker_stats.get("memory", {}).get(
            "memory_efficiency", 0.0
        )
        hash_memory = hash_stats.get("memory", {}).get("total_gpu_mb", 0.0)
        total_memory = chunker_stats.get("memory", {}).get(
            "total_chunks_memory_mb", 0.0
        )

        if total_memory > 0:
            self.performance_metrics["memory_efficiency"] = (
                chunker_efficiency * 0.7 + (hash_memory / total_memory) * 0.3
            )

        # GPU utilization (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
        device_stats = self.device_manager.get_memory_stats()
        if self.device_manager.is_cuda() and "allocated_mb" in device_stats:
            allocated_mb = device_stats["allocated_mb"]
            reserved_mb = device_stats.get("reserved_mb", allocated_mb)

            if reserved_mb > 0:
                self.performance_metrics["gpu_utilization"] = allocated_mb / reserved_mb

    # === PUBLIC API ===

    def query_neighbors_async(
        self,
        coordinates: Union[torch.Tensor, np.ndarray, List],
        radius: float,
        chunk_ids: Optional[Set[int]] = None,
        priority: int = 0,
        callback: Optional[callable] = None,
    ) -> str:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å–æ—Å–µ–¥–µ–π

        Args:
            coordinates: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ (N, 3)
            radius: –†–∞–¥–∏—É—Å –ø–æ–∏—Å–∫–∞
            chunk_ids: –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –ø–æ–∏—Å–∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ chunk'–∞–º–∏
            priority: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∑–∞–ø—Ä–æ—Å–∞ (0-100)
            callback: Callback —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

        Returns:
            query_id –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ tensor
        if isinstance(coordinates, (np.ndarray, list)):
            coords_tensor = torch.tensor(
                coordinates, device=self.device, dtype=torch.float32
            )
        else:
            coords_tensor = self.device_manager.ensure_device(coordinates)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π query_id
        query_id = f"query_{int(time.time() * 1000000)}_{len(self.active_queries)}"

        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å
        query = SpatialQuery(
            query_id=query_id,
            coordinates=coords_tensor,
            radius=radius,
            chunk_ids=chunk_ids,
            priority=priority,
            callback=callback,
        )

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∏ –æ—á–µ—Ä–µ–¥—å
        self.active_queries[query_id] = query

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ queue (thread-safe)
        self.query_queue.put(query)

        return query_id

    def query_neighbors_sync(
        self,
        coordinates: Union[torch.Tensor, np.ndarray, List],
        radius: float,
        chunk_ids: Optional[Set[int]] = None,
        timeout: float = 30.0,
    ) -> SpatialQueryResult:
        """
        –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å–æ—Å–µ–¥–µ–π

        Args:
            coordinates: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
            radius: –†–∞–¥–∏—É—Å –ø–æ–∏—Å–∫–∞
            chunk_ids: –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –ø–æ–∏—Å–∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ chunk'–∞–º–∏
            timeout: –¢–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞
        """
        result_ready = threading.Event()
        result_container = {}

        def sync_callback(result: SpatialQueryResult):
            result_container["result"] = result
            result_ready.set()

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        query_id = self.query_neighbors_async(
            coordinates,
            radius,
            chunk_ids,
            priority=100,  # –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è sync –∑–∞–ø—Ä–æ—Å–æ–≤
            callback=sync_callback,
        )

        # –ñ–¥–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if result_ready.wait(timeout):
            return result_container["result"]
        else:
            raise TimeoutError(f"Query {query_id} –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –∑–∞ {timeout}s")

    def get_query_result(self, query_id: str) -> Optional[SpatialQueryResult]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ ID"""
        return self.query_results.get(query_id)

    def is_query_complete(self, query_id: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –∑–∞–≤–µ—Ä—à–µ–Ω –ª–∏ –∑–∞–ø—Ä–æ—Å"""
        return query_id in self.query_results

    def get_performance_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—Ç –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        chunker_stats = self.chunker.get_comprehensive_stats()
        hash_stats = self.spatial_hash.get_comprehensive_stats()
        device_stats = self.device_manager.get_memory_stats()

        return {
            "processor": self.performance_metrics,
            "chunker": chunker_stats,
            "spatial_hash": hash_stats,
            "device": device_stats,
            "integration": {
                "active_queries": len(self.active_queries),
                "cached_results": len(self.query_results),
                "cache_size": len(self.integration_cache),
            },
        }

    def optimize_performance(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        logger.info("üîß –ó–∞–ø—É—â–µ–Ω–∞ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è spatial hash
        self.spatial_hash.hash_grid.optimize_memory()

        # –ü–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ chunk'–æ–≤
        self.chunker.rebalance_chunks()

        # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–µ–π
        self.integration_cache.clear()
        self._cleanup_old_query_results()

        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏
        self.device_manager.cleanup()

        logger.info("‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    def shutdown(self):
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã processor'–∞"""
        logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã GPUSpatialProcessor")

        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º background processing
        self.processing_active = False

        if hasattr(self, "processing_thread") and self.processing_thread.is_alive():
            self.processing_thread.join(timeout=5.0)

        # –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.chunker.cleanup()

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        self.device_manager.cleanup()

        logger.info("‚úÖ GPUSpatialProcessor –∑–∞–≤–µ—Ä—à–µ–Ω")
