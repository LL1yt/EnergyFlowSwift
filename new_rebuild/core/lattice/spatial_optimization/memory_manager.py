#!/usr/bin/env python3
"""
Memory Pool Manager - –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ GPU –ø–∞–º—è—Ç—å—é
========================================================

MemoryPoolManager –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏
—á–µ—Ä–µ–∑ pool allocation –∏ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ tensor'–æ–≤.
"""

import torch
import gc
from typing import Dict, List, Tuple
from ....config import get_project_config
from ....utils.logging import get_logger
from ....utils.device_manager import get_device_manager

logger = get_logger(__name__)


class MemoryPoolManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä memory pool –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è GPU –ø–∞–º—è—Ç—å—é

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç pool allocation –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏
    –∏ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è tensor'–æ–≤.
    """

    def __init__(self, config: dict = None):
        if config is None:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ - –±–µ–∑ fallback!
            project_config = get_project_config()
            if not hasattr(project_config, "spatial") or project_config.spatial is None:
                raise ValueError(
                    "MemoryPoolManager —Ç—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—É—é spatial –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é! "
                    "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ config.spatial –Ω–∞—Å—Ç—Ä–æ–µ–Ω –≤ SimpleProjectConfig."
                )
            
            spatial_cfg = project_config.spatial
            self.config = {
                "garbage_collect_frequency": spatial_cfg.garbage_collect_frequency,
                "memory_pool_size_gb": spatial_cfg.memory_pool_size_gb,
                "chunk_size": spatial_cfg.chunk_size,
                "max_chunks_in_memory": spatial_cfg.max_chunks_in_memory,
                "enable_profiling": spatial_cfg.enable_profiling,
                "log_memory_usage": spatial_cfg.log_memory_usage,
            }
        else:
            self.config = config

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º DeviceManager –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏
        self.device_manager = get_device_manager()
        self.device = self.device_manager.get_device()

        # Memory pools –ø–æ —Ç–∏–ø–∞–º tensor'–æ–≤
        self.tensor_pools: Dict[Tuple[int, ...], List[torch.Tensor]] = {}
        self.allocated_tensors: List[torch.Tensor] = []
        self.allocation_count = 0

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        self.stats = {
            "total_allocations": 0,
            "pool_hits": 0,
            "pool_misses": 0,
            "memory_peak_mb": 0.0,
            "gc_calls": 0,
        }

        logger.info(
            f"üíæ MemoryPoolManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ DeviceManager –¥–ª—è {self.device}"
        )

    def get_tensor(
        self, shape: Tuple[int, ...], dtype: torch.dtype = torch.float32
    ) -> torch.Tensor:
        """
        –ü–æ–ª—É—á–∞–µ—Ç tensor –∏–∑ pool –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π

        Args:
            shape: —Ñ–æ—Ä–º–∞ tensor'–∞
            dtype: —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö

        Returns:
            tensor –≥–æ—Ç–æ–≤—ã–π –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
        """
        self.stats["total_allocations"] += 1

        # –ò—â–µ–º –≤ pool'–µ
        if shape in self.tensor_pools and self.tensor_pools[shape]:
            tensor = self.tensor_pools[shape].pop()
            tensor.zero_()  # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            self.stats["pool_hits"] += 1
            return tensor

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π tensor —á–µ—Ä–µ–∑ DeviceManager –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –≤—ã–¥–µ–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
        tensor = self.device_manager.allocate_tensor(shape, dtype=dtype)
        self.stats["pool_misses"] += 1
        self._track_allocation(tensor)

        return tensor

    def return_tensor(self, tensor: torch.Tensor):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç tensor –≤ pool –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

        Args:
            tensor: tensor –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ pool
        """
        if tensor.device != self.device:
            return  # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º tensor'—ã —Å –¥—Ä—É–≥–∏—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤

        shape = tuple(tensor.shape)

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π pool
        if shape not in self.tensor_pools:
            self.tensor_pools[shape] = []

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä pool'–∞
        max_pool_size = 10  # –ú–∞–∫—Å–∏–º—É–º 10 tensor'–æ–≤ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        if len(self.tensor_pools[shape]) < max_pool_size:
            self.tensor_pools[shape].append(tensor.detach())

    def _track_allocation(self, tensor: torch.Tensor):
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –≤—ã–¥–µ–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏"""
        self.allocated_tensors.append(tensor)
        self.allocation_count += 1

        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ–º garbage collection
        if self.allocation_count % self.config["garbage_collect_frequency"] == 0:
            logger.debug_memory(
                f"   üßπ –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ–º garbage collection allocation_count: {self.allocation_count}"
            )
            self.garbage_collect()

        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∏–∫–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
        if self.device.type == "cuda":
            current_memory_mb = torch.cuda.memory_allocated(self.device) / (1024**2)
            self.stats["memory_peak_mb"] = max(
                self.stats["memory_peak_mb"], current_memory_mb
            )

    def garbage_collect(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ —á–µ—Ä–µ–∑ DeviceManager"""
        # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–∫–∏ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö tensor'–æ–≤
        self.allocated_tensors = [t for t in self.allocated_tensors if t.numel() > 0]

        # –û—á–∏—â–∞–µ–º pools –æ—Ç —Å–ª–∏—à–∫–æ–º —Å—Ç–∞—Ä—ã—Ö tensor'–æ–≤
        for shape, pool in self.tensor_pools.items():
            if len(pool) > 5:  # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ 5 newest tensor'–æ–≤
                pool[:] = pool[-5:]

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º DeviceManager –¥–ª—è —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏ - –æ—Ç–∫–ª—é—á–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π cleanup
        # self.device_manager.cleanup()

        self.stats["gc_calls"] += 1
        logger.info(
            f"   üßπ Memory cleanup —á–µ—Ä–µ–∑ DeviceManager: GC –≤—ã–∑–≤–∞–Ω #{self.stats['gc_calls']}"
        )

    def get_memory_stats(self) -> Dict[str, float]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        stats = self.stats.copy()

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
        if self.device.type == "cuda":
            stats["current_memory_mb"] = torch.cuda.memory_allocated(self.device) / (
                1024**2
            )
            stats["reserved_memory_mb"] = torch.cuda.memory_reserved(self.device) / (
                1024**2
            )
        else:
            stats["current_memory_mb"] = 0.0
            stats["reserved_memory_mb"] = 0.0

        # –í—ã—á–∏—Å–ª—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å pool'–∞
        total_requests = stats["pool_hits"] + stats["pool_misses"]
        if total_requests > 0:
            stats["pool_hit_rate"] = stats["pool_hits"] / total_requests
        else:
            stats["pool_hit_rate"] = 0.0

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ pool'–∞—Ö
        stats["active_pools"] = len(self.tensor_pools)
        stats["pooled_tensors"] = sum(len(pool) for pool in self.tensor_pools.values())

        return stats

    def cleanup(self):
        """–ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ memory manager'–∞"""
        # –û—á–∏—â–∞–µ–º –≤—Å–µ pools
        for pool in self.tensor_pools.values():
            pool.clear()
        self.tensor_pools.clear()

        # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–∫–∏
        self.allocated_tensors.clear()

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        self.garbage_collect()

        logger.info("üßπ MemoryPoolManager –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–µ–Ω")


_memory_pool_manager_instance = None


def get_memory_pool_manager(config: dict = None) -> MemoryPoolManager:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∏–Ω–≥–ª—Ç–æ–Ω-—ç–∫–∑–µ–º–ø–ª—è—Ä MemoryPoolManager.
    """
    global _memory_pool_manager_instance
    if _memory_pool_manager_instance is None:
        _memory_pool_manager_instance = MemoryPoolManager(config)
    return _memory_pool_manager_instance
