#!/usr/bin/env python3
"""
–¢–µ—Å—Ç GPU Spatial Optimization Components
========================================

–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –Ω–æ–≤—ã—Ö GPU-accelerated –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:
- GPU Spatial Hashing
- Adaptive Chunking
- Integrated Spatial Processor

–≠—Ç–æ—Ç —Ç–µ—Å—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã.
"""

import sys
import os
import torch
import numpy as np
import time
import logging
from typing import List, Tuple

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
try:
    from core.lattice.gpu_spatial_hashing import (
        AdaptiveGPUSpatialHash,
        GPUSpatialHashGrid,
        GPUMortonEncoder,
    )
    from core.lattice.spatial_optimization.adaptive_chunker import AdaptiveGPUChunker
    from core.lattice.spatial_optimization.gpu_spatial_processor import (
        GPUSpatialProcessor,
    )

    from config.project_config import get_project_config
    from utils.device_manager import get_device_manager
except ImportError as e:
    print(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –∑–∞–ø—É—Å–∫–∞–µ—Ç–µ —Ç–µ—Å—Ç –∏–∑ –ø–∞–ø–∫–∏ new_rebuild")
    sys.exit(1)


def test_gpu_morton_encoder():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç GPU Morton Encoder"""
    print("\n" + "=" * 60)
    print("üî¢ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU Morton Encoder")
    print("=" * 60)

    dimensions = (32, 32, 32)
    encoder = GPUMortonEncoder(dimensions)

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
    test_coords = torch.tensor(
        [[0, 0, 0], [1, 1, 1], [15, 15, 15], [31, 31, 31]],
        device=encoder.device,
        dtype=torch.long,
    )

    print(f"–¢–µ—Å—Ç–æ–≤—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã:\n{test_coords}")

    # –ö–æ–¥–∏—Ä—É–µ–º
    start_time = time.time()
    morton_codes = encoder.encode_batch(test_coords)
    encode_time = (time.time() - start_time) * 1000

    print(f"Morton –∫–æ–¥—ã: {morton_codes}")
    print(f"–í—Ä–µ–º—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è: {encode_time:.2f}ms")

    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ
    start_time = time.time()
    decoded_coords = encoder.decode_batch(morton_codes)
    decode_time = (time.time() - start_time) * 1000

    print(f"–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã:\n{decoded_coords}")
    print(f"–í—Ä–µ–º—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è: {decode_time:.2f}ms")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å
    matches = torch.allclose(test_coords.float(), decoded_coords.float())
    print(f"‚úÖ –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è/–¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è: {matches}")

    return matches


def test_gpu_spatial_hash():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç GPU Spatial Hash Grid"""
    print("\n" + "=" * 60)
    print("üèéÔ∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU Spatial Hash Grid")
    print("=" * 60)

    dimensions = (64, 64, 64)
    cell_size = 8
    hash_grid = GPUSpatialHashGrid(dimensions, cell_size)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏ –∏–Ω–¥–µ–∫—Å—ã
    num_cells = 10000
    coordinates = torch.randint(
        0, 64, (num_cells, 3), device=hash_grid.device, dtype=torch.long
    )
    indices = torch.arange(num_cells, device=hash_grid.device, dtype=torch.long)

    print(f"–í—Å—Ç–∞–≤–ª—è–µ–º {num_cells} –∫–ª–µ—Ç–æ–∫...")

    # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
    start_time = time.time()
    hash_grid.insert_batch(coordinates, indices)
    insert_time = (time.time() - start_time) * 1000

    print(f"–í—Ä–µ–º—è –≤—Å—Ç–∞–≤–∫–∏: {insert_time:.2f}ms")
    print(f"–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {num_cells / insert_time * 1000:.0f} –∫–ª–µ—Ç–æ–∫/—Å–µ–∫")

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    query_points = torch.randint(
        0, 64, (100, 3), device=hash_grid.device, dtype=torch.float32
    )
    radius = 5.0

    print(f"\n–í—ã–ø–æ–ª–Ω—è–µ–º {len(query_points)} –∑–∞–ø—Ä–æ—Å–æ–≤ —Å —Ä–∞–¥–∏—É—Å–æ–º {radius}...")

    start_time = time.time()
    results = hash_grid.query_radius_batch(query_points, radius)
    query_time = (time.time() - start_time) * 1000

    print(f"–í—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {query_time:.2f}ms")
    print(
        f"–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {len(query_points) / query_time * 1000:.0f} –∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫"
    )

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    neighbor_counts = [len(neighbors) for neighbors in results]
    avg_neighbors = np.mean(neighbor_counts)
    max_neighbors = max(neighbor_counts)

    print(f"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π: {avg_neighbors:.1f}")
    print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π: {max_neighbors}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–º—è—Ç–∏
    memory_stats = hash_grid.get_memory_usage()
    print(f"\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏:")
    print(f"  GPU –ø–∞–º—è—Ç—å: {memory_stats['total_gpu_mb']:.1f}MB")
    print(f"  –ó–∞–ø–∏—Å–∏ –≤ –∫—ç—à–µ: {memory_stats['cache_entries']}")
    print(f"  Hash buckets: {memory_stats['grid_buckets']}")

    return True


def test_adaptive_spatial_hash():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç Adaptive GPU Spatial Hash"""
    print("\n" + "=" * 60)
    print("üéØ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Adaptive GPU Spatial Hash")
    print("=" * 60)

    dimensions = (100, 100, 100)
    target_memory_mb = 512.0  # 512MB —Ü–µ–ª–µ–≤–∞—è –ø–∞–º—è—Ç—å

    adaptive_hash = AdaptiveGPUSpatialHash(dimensions, target_memory_mb)

    print(f"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —è—á–µ–π–∫–∏: {adaptive_hash.optimal_cell_size}")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç—Ç–∞–ø–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
    stages = [1000, 5000, 10000, 20000]

    for stage_idx, num_cells in enumerate(stages):
        print(f"\n--- –≠—Ç–∞–ø {stage_idx + 1}: {num_cells} –∫–ª–µ—Ç–æ–∫ ---")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç–∏)
        center = np.random.randint(20, 80, 3)
        spread = 15

        coordinates = []
        indices = []

        for i in range(num_cells):
            coord = center + np.random.normal(0, spread, 3)
            coord = np.clip(coord, 0, 99).astype(int)
            coordinates.append(coord)
            indices.append(len(coordinates) - 1)

        coords_tensor = torch.tensor(
            coordinates, device=adaptive_hash.device, dtype=torch.float32
        )
        indices_tensor = torch.tensor(
            indices, device=adaptive_hash.device, dtype=torch.long
        )

        # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        start_time = time.time()
        adaptive_hash.insert_batch(coords_tensor, indices_tensor)
        insert_time = (time.time() - start_time) * 1000

        print(f"–í—Ä–µ–º—è –≤—Å—Ç–∞–≤–∫–∏: {insert_time:.2f}ms")

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
        query_points = coords_tensor[:50]  # –ø–µ—Ä–≤—ã–µ 50 —Ç–æ—á–µ–∫ –∫–∞–∫ –∑–∞–ø—Ä–æ—Å—ã
        radius = 10.0

        start_time = time.time()
        results = adaptive_hash.query_radius_batch(query_points, radius)
        query_time = (time.time() - start_time) * 1000

        neighbor_counts = [len(neighbors) for neighbors in results]
        avg_neighbors = np.mean(neighbor_counts) if neighbor_counts else 0

        print(f"–í—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {query_time:.2f}ms")
        print(f"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π: {avg_neighbors:.1f}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = adaptive_hash.get_comprehensive_stats()
        print(f"–ü–∞–º—è—Ç—å: {stats['memory']['total_gpu_mb']:.1f}MB")
        print(f"–ó–∞–ø—Ä–æ—Å—ã: {stats['spatial_hash']['queries']}")
        print(f"Cache hit rate: {stats['spatial_hash']['cache_hit_rate']:.2f}")

    return True


def test_adaptive_chunker():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç Adaptive GPU Chunker"""
    print("\n" + "=" * 60)
    print("üß© –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Adaptive GPU Chunker")
    print("=" * 60)

    dimensions = (80, 80, 80)
    chunker = AdaptiveGPUChunker(dimensions)

    print(f"–°–æ–∑–¥–∞–Ω–æ {len(chunker.adaptive_chunks)} chunk'–æ–≤")

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º chunk'–∏
    chunk_sizes = [len(chunk.cell_indices) for chunk in chunker.adaptive_chunks]
    total_cells = sum(chunk_sizes)
    avg_chunk_size = np.mean(chunk_sizes)

    print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–µ—Ç–æ–∫: {total_cells}")
    print(f"–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä chunk'–∞: {avg_chunk_size:.1f}")

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ chunk'–∞ –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º
    test_coordinates = [(10, 10, 10), (40, 40, 40), (70, 70, 70)]

    print(f"\n–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ chunk'–æ–≤ –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º:")
    for coord in test_coordinates:
        try:
            chunk = chunker.get_chunk_by_coords(coord)
            print(
                f"  {coord} -> Chunk {chunk.chunk_id} "
                f"(–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {chunk.processing_priority}, "
                f"–ø–∞–º—è—Ç—å: {chunk.memory_size_mb:.1f}MB)"
            )
        except ValueError as e:
            print(f"  {coord} -> –û—à–∏–±–∫–∞: {e}")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º adaptive schedule
    print(f"\n–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º adaptive —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ...")
    schedule = chunker.get_adaptive_processing_schedule()

    print(f"–°–æ–∑–¥–∞–Ω–æ {len(schedule)} batch'–µ–π:")
    for i, batch in enumerate(schedule[:5]):  # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
        print(f"  Batch {i+1}: {len(batch)} chunk'–æ–≤")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–º—è—Ç–∏
    memory_stats = chunker.get_memory_stats()
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–º—è—Ç–∏:")
    print(f"  –û–±—â–∞—è –ø–∞–º—è—Ç—å chunk'–æ–≤: {memory_stats['total_chunks_memory_mb']:.1f}MB")
    print(f"  –ê–∫—Ç–∏–≤–Ω–∞—è –ø–∞–º—è—Ç—å: {memory_stats['active_chunks_memory_mb']:.1f}MB")
    print(f"  –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏: {memory_stats['memory_efficiency']:.2f}")

    return True


def test_integrated_spatial_processor():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π GPU Spatial Processor"""
    print("\n" + "=" * 60)
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Integrated GPU Spatial Processor")
    print("=" * 60)

    dimensions = (50, 50, 50)
    processor = GPUSpatialProcessor(dimensions)

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    num_queries = 10
    coordinates = torch.randint(0, 50, (num_queries, 3), dtype=torch.float32)
    radius = 8.0

    print(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫: {num_queries} –∑–∞–ø—Ä–æ—Å–æ–≤ —Å —Ä–∞–¥–∏—É—Å–æ–º {radius}")

    try:
        # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
        start_time = time.time()
        result = processor.query_neighbors_sync(coordinates, radius, timeout=30.0)
        sync_time = (time.time() - start_time) * 1000

        print(f"‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {sync_time:.2f}ms")
        print(f"Query ID: {result.query_id}")
        print(f"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.processing_time_ms:.2f}ms")
        print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {result.memory_usage_mb:.2f}MB")
        print(f"Cache hit rate: {result.cache_hit_rate:.2f}")
        print(f"–ó–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ chunk'–∏: {len(result.chunks_accessed)}")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        neighbor_counts = [len(neighbors) for neighbors in result.neighbor_lists]
        if neighbor_counts:
            print(f"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π: {np.mean(neighbor_counts):.1f}")
            print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π: {max(neighbor_counts)}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
        return False

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
    print(f"\n–¢–µ—Å—Ç–∏—Ä—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫...")

    async_results = []
    query_ids = []

    # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    for i in range(5):
        coords = torch.randint(0, 50, (5, 3), dtype=torch.float32)
        query_id = processor.query_neighbors_async(coords, radius=6.0, priority=i * 10)
        query_ids.append(query_id)
        print(f"  –ó–∞–ø—É—â–µ–Ω –∑–∞–ø—Ä–æ—Å {query_id}")

    # –ñ–¥–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"–û–∂–∏–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")
    start_wait = time.time()
    completed_queries = 0

    while completed_queries < len(query_ids) and (time.time() - start_wait) < 30:
        for query_id in query_ids:
            if processor.is_query_complete(query_id):
                if query_id not in [r.query_id for r in async_results]:
                    result = processor.get_query_result(query_id)
                    async_results.append(result)
                    completed_queries += 1
                    print(
                        f"  ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω {query_id}: {result.processing_time_ms:.1f}ms"
                    )

        time.sleep(0.1)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:")
    perf_stats = processor.get_performance_stats()

    processor_stats = perf_stats["processor"]
    print(f"  –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {processor_stats['total_queries']}")
    print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processor_stats['avg_query_time_ms']:.2f}ms")
    print(f"  –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏: {processor_stats['memory_efficiency']:.2f}")
    print(f"  Cache hit rate: {processor_stats['cache_hit_rate']:.2f}")

    chunker_stats = perf_stats["chunker"]
    print(f"  Chunk'–∏ - –≤—Å–µ–≥–æ: {chunker_stats['chunks']['total_chunks']}")
    print(
        f"  Chunk'–∏ - –≤—ã—Å–æ–∫–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ: {chunker_stats['chunks']['high_pressure_chunks']}"
    )

    # –û—á–∏—Å—Ç–∫–∞
    processor.shutdown()

    return True


def benchmark_performance():
    """–ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
    print("\n" + "=" * 60)
    print("‚ö° –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    print("=" * 60)

    device_manager = get_device_manager()
    device = device_manager.get_device()

    print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

    # –†–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã —Ä–µ—à–µ—Ç–æ–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    test_sizes = [(32, 32, 32), (64, 64, 64), (100, 100, 100)]

    results = []

    for dimensions in test_sizes:
        print(f"\n--- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ {dimensions} ---")

        total_cells = np.prod(dimensions)
        print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–µ—Ç–æ–∫: {total_cells:,}")

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º GPU Spatial Hash
        target_memory = 256.0  # 256MB
        adaptive_hash = AdaptiveGPUSpatialHash(dimensions, target_memory)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        num_test_cells = min(10000, total_cells // 4)
        coordinates = torch.randint(
            0, max(dimensions), (num_test_cells, 3), device=device, dtype=torch.float32
        )
        indices = torch.arange(num_test_cells, device=device, dtype=torch.long)

        # –í—Ä–µ–º—è –≤—Å—Ç–∞–≤–∫–∏
        start_time = time.time()
        adaptive_hash.insert_batch(coordinates, indices)
        insert_time = (time.time() - start_time) * 1000

        # –í—Ä–µ–º—è –ø–æ–∏—Å–∫–∞
        query_points = coordinates[:100]
        radius = max(dimensions) * 0.1

        start_time = time.time()
        query_results = adaptive_hash.query_radius_batch(query_points, radius)
        query_time = (time.time() - start_time) * 1000

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = adaptive_hash.get_comprehensive_stats()
        memory_usage = stats["memory"]["total_gpu_mb"]

        result = {
            "dimensions": dimensions,
            "total_cells": total_cells,
            "test_cells": num_test_cells,
            "insert_time_ms": insert_time,
            "query_time_ms": query_time,
            "memory_usage_mb": memory_usage,
            "insert_rate": num_test_cells / insert_time * 1000,
            "query_rate": len(query_points) / query_time * 1000,
        }

        results.append(result)

        print(
            f"  –í—Å—Ç–∞–≤–∫–∞: {insert_time:.1f}ms ({result['insert_rate']:.0f} –∫–ª–µ—Ç–æ–∫/—Å–µ–∫)"
        )
        print(f"  –ü–æ–∏—Å–∫: {query_time:.1f}ms ({result['query_rate']:.0f} –∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫)")
        print(f"  –ü–∞–º—è—Ç—å: {memory_usage:.1f}MB")

    # –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
    print(f"\nüìä –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:")
    print(f"{'–†–∞–∑–º–µ—Ä':<15} {'–ö–ª–µ—Ç–∫–∏':<10} {'–í—Å—Ç–∞–≤–∫–∞':<12} {'–ü–æ–∏—Å–∫':<12} {'–ü–∞–º—è—Ç—å':<10}")
    print("-" * 70)

    for result in results:
        dim_str = f"{result['dimensions'][0]}¬≥"
        cells_str = f"{result['total_cells']:,}"
        insert_str = f"{result['insert_rate']:.0f}/—Å–µ–∫"
        query_str = f"{result['query_rate']:.0f}/—Å–µ–∫"
        memory_str = f"{result['memory_usage_mb']:.1f}MB"

        print(
            f"{dim_str:<15} {cells_str:<10} {insert_str:<12} {query_str:<12} {memory_str:<10}"
        )

    return results


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU Spatial Optimization Components")
    print("=" * 80)

    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
        device_manager = get_device_manager()
        device_stats = device_manager.get_memory_stats()

        print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device_manager.get_device()}")
        print(f"CUDA –¥–æ—Å—Ç—É–ø–µ–Ω: {device_manager.is_cuda()}")

        if device_manager.is_cuda():
            print(f"GPU –ø–∞–º—è—Ç—å - –≤—ã–¥–µ–ª–µ–Ω–æ: {device_stats.get('allocated_mb', 0):.1f}MB")
            print(
                f"GPU –ø–∞–º—è—Ç—å - –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ: {device_stats.get('reserved_mb', 0):.1f}MB"
            )

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
        test_results = []

        print("\nüîç –ó–∞–ø—É—Å–∫ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤...")

        # –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã
        test_results.append(("Morton Encoder", test_gpu_morton_encoder()))
        test_results.append(("Spatial Hash Grid", test_gpu_spatial_hash()))
        test_results.append(("Adaptive Spatial Hash", test_adaptive_spatial_hash()))
        test_results.append(("Adaptive Chunker", test_adaptive_chunker()))
        test_results.append(("Spatial Processor", test_integrated_spatial_processor()))

        # –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        print("\n‚ö° –ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
        benchmark_results = benchmark_performance()

        # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        print("\n" + "=" * 80)
        print("üìã –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
        print("=" * 80)

        print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤:")
        for test_name, result in test_results:
            status = "‚úÖ –ü–†–û–®–ï–õ" if result else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
            print(f"  {test_name:<25} {status}")

        passed_tests = sum(1 for _, result in test_results if result)
        total_tests = len(test_results)

        print(f"\n–û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {passed_tests}/{total_tests} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ—à–ª–∏")

        if passed_tests == total_tests:
            print("üéâ –í—Å–µ —Ç–µ—Å—Ç—ã —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–π–¥–µ–Ω—ã!")
            print("üöÄ GPU Spatial Optimization –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        else:
            print("‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–≤–∞–ª–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é.")

        return passed_tests == total_tests

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
