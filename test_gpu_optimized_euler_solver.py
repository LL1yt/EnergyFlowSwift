#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU Optimized Euler Solver
=======================================

–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è GPU-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ Euler solver'–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π:
- Vectorized –æ–ø–µ—Ä–∞—Ü–∏–π
- Batch processing
- Adaptive step size –Ω–∞ –æ—Å–Ω–æ–≤–µ Lipschitz –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
- Memory efficiency
- Performance benchmarks

–ê–≤—Ç–æ—Ä: 3D Cellular Neural Network Project
–í–µ—Ä—Å–∏—è: 2.0.0 (2024-12-27)
"""

import torch
import numpy as np
import time
import logging
from typing import List, Dict, Any
import matplotlib.pyplot as plt

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_imports():
    """–¢–µ—Å—Ç 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤"""
    logger.info("üß™ –¢–µ—Å—Ç 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤ GPU Optimized Euler Solver")

    try:
        from new_rebuild.core.cnf.gpu_optimized_euler_solver import (
            GPUOptimizedEulerSolver,
            SolverConfig,
            AdaptiveMethod,
            IntegrationResult,
            create_gpu_optimized_euler_solver,
            batch_euler_solve,
            benchmark_solver_performance,
        )

        logger.info("‚úÖ –í—Å–µ –∏–º–ø–æ—Ä—Ç—ã —É—Å–ø–µ—à–Ω—ã")
        return True
    except ImportError as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        return False


def test_basic_functionality():
    """–¢–µ—Å—Ç 2: –ë–∞–∑–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å"""
    logger.info("üß™ –¢–µ—Å—Ç 2: –ë–∞–∑–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å")

    try:
        from new_rebuild.core.cnf.gpu_optimized_euler_solver import (
            create_gpu_optimized_euler_solver,
            AdaptiveMethod,
        )

        # –°–æ–∑–¥–∞–µ–º solver
        solver = create_gpu_optimized_euler_solver(
            adaptive_method=AdaptiveMethod.LIPSCHITZ_BASED, max_batch_size=100
        )

        logger.info(f"   ‚úÖ Solver —Å–æ–∑–¥–∞–Ω: {type(solver).__name__}")
        logger.info(f"   üéØ Device: {solver.device}")
        logger.info(f"   ‚öôÔ∏è Config: {solver.config.adaptive_method.value}")

        # –ü—Ä–æ—Å—Ç–∞—è —Ç–µ—Å—Ç–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π
        def simple_derivative(t: torch.Tensor, states: torch.Tensor) -> torch.Tensor:
            # dx/dt = -x (—ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π —Ä–∞—Å–ø–∞–¥)
            return -states

        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        batch_size = 5
        state_size = 8
        initial_states = torch.randn(batch_size, state_size)

        logger.info(f"   üìä –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {initial_states.shape}")

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é
        result = solver.batch_integrate(
            simple_derivative, initial_states, integration_time=1.0, num_steps=3
        )

        logger.info(f"   ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
        logger.info(f"     ‚è±Ô∏è –í—Ä–µ–º—è: {result.integration_time_ms:.1f}ms")
        logger.info(f"     üìä –®–∞–≥–∏: {result.steps_taken}")
        logger.info(f"     üéØ –£—Å–ø–µ—Ö: {result.success}")
        logger.info(f"     üíæ –ü–∞–º—è—Ç—å: {result.memory_usage_mb:.1f}MB")
        logger.info(f"     üîß Adjustments: {result.adaptive_adjustments}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        assert result.final_state.shape == initial_states.shape
        assert not torch.isnan(result.final_state).any()
        assert not torch.isinf(result.final_state).any()

        # –î–ª—è —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø–∞–¥–∞ –æ–∂–∏–¥–∞–µ–º —É–º–µ–Ω—å—à–µ–Ω–∏–µ
        initial_norm = torch.norm(initial_states)
        final_norm = torch.norm(result.final_state)
        logger.info(f"     üìâ –ù–æ—Ä–º–∞: {initial_norm:.3f} ‚Üí {final_norm:.3f}")

        solver.cleanup()

        return True

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_adaptive_methods():
    """–¢–µ—Å—Ç 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤"""
    logger.info("üß™ –¢–µ—Å—Ç 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤")

    try:
        from new_rebuild.core.cnf.gpu_optimized_euler_solver import (
            create_gpu_optimized_euler_solver,
            AdaptiveMethod,
        )

        # –ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π
        def complex_derivative(t: torch.Tensor, states: torch.Tensor) -> torch.Tensor:
            # –ù–µ–ª–∏–Ω–µ–π–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å oscillations
            x, y = states[..., 0], states[..., 1]
            dxdt = -0.1 * x + 0.5 * y * torch.sin(
                t.unsqueeze(-1) if t.dim() == 1 else t
            )
            dydt = -0.2 * y - 0.3 * x * torch.cos(
                t.unsqueeze(-1) if t.dim() == 1 else t
            )

            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –∫–∞–∫ damped
            rest = (
                -0.1 * states[..., 2:]
                if states.shape[-1] > 2
                else torch.empty(states.shape[0], 0, device=states.device)
            )

            return torch.cat([dxdt.unsqueeze(-1), dydt.unsqueeze(-1), rest], dim=-1)

        methods_to_test = [
            AdaptiveMethod.LIPSCHITZ_BASED,
            AdaptiveMethod.ACTIVITY_BASED,
        ]

        batch_size = 10
        state_size = 4
        initial_states = torch.randn(batch_size, state_size) * 0.5

        results = {}

        for method in methods_to_test:
            logger.info(f"   üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–µ—Ç–æ–¥: {method.value}")

            solver = create_gpu_optimized_euler_solver(adaptive_method=method)

            result = solver.batch_integrate(
                complex_derivative, initial_states, integration_time=2.0, num_steps=5
            )

            results[method.value] = {
                "integration_time_ms": result.integration_time_ms,
                "adaptive_adjustments": result.adaptive_adjustments,
                "stability_violations": result.stability_violations,
                "success": result.success,
                "final_norm": torch.norm(result.final_state).item(),
            }

            logger.info(f"     ‚è±Ô∏è –í—Ä–µ–º—è: {result.integration_time_ms:.1f}ms")
            logger.info(f"     üîß Adjustments: {result.adaptive_adjustments}")
            logger.info(f"     ‚ö†Ô∏è Violations: {result.stability_violations}")
            logger.info(
                f"     üìä Final norm: {results[method.value]['final_norm']:.3f}"
            )

            solver.cleanup()

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        logger.info("   üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤:")
        for method, result in results.items():
            logger.info(
                f"     {method}: {result['integration_time_ms']:.1f}ms, "
                f"{result['adaptive_adjustments']} adj, "
                f"norm={result['final_norm']:.3f}"
            )

        return True

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ adaptive –º–µ—Ç–æ–¥–æ–≤: {e}")
        return False


def test_batch_processing():
    """–¢–µ—Å—Ç 4: Batch processing –∏ scalability"""
    logger.info("üß™ –¢–µ—Å—Ç 4: Batch processing –∏ scalability")

    try:
        from new_rebuild.core.cnf.gpu_optimized_euler_solver import (
            create_gpu_optimized_euler_solver,
        )

        # –ü—Ä–æ—Å—Ç–∞—è linear dynamics
        def linear_dynamics(t: torch.Tensor, states: torch.Tensor) -> torch.Tensor:
            # –†–∞–∑–Ω—ã–µ rates –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π
            rates = torch.tensor([-0.1, -0.2, -0.3, -0.4], device=states.device)
            rates = rates[: states.shape[-1]]  # –ü–æ–¥–≥–æ–Ω—è–µ–º –ø–æ–¥ —Ä–∞–∑–º–µ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏—è
            return states * rates.unsqueeze(0)

        batch_sizes = [1, 10, 50, 100]
        state_size = 4

        performance_results = {}

        for batch_size in batch_sizes:
            logger.info(f"   üìä Batch size: {batch_size}")

            # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            initial_states = torch.randn(batch_size, state_size) * 0.1

            # –°–æ–∑–¥–∞–µ–º solver
            solver = create_gpu_optimized_euler_solver(
                max_batch_size=max(100, batch_size)
            )

            # –ò–∑–º–µ—Ä—è–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            start_time = time.time()

            result = solver.batch_integrate(
                linear_dynamics, initial_states, integration_time=1.0, num_steps=5
            )

            wall_time = time.time() - start_time

            # –í—ã—á–∏—Å–ª—è–µ–º throughput
            trajectories_per_second = batch_size / wall_time

            performance_results[batch_size] = {
                "wall_time_s": wall_time,
                "integration_time_ms": result.integration_time_ms,
                "memory_usage_mb": result.memory_usage_mb,
                "trajectories_per_second": trajectories_per_second,
                "success": result.success,
            }

            logger.info(f"     ‚è±Ô∏è Wall time: {wall_time:.3f}s")
            logger.info(f"     üöÄ Integration time: {result.integration_time_ms:.1f}ms")
            logger.info(f"     üíæ Memory: {result.memory_usage_mb:.1f}MB")
            logger.info(f"     üìà Throughput: {trajectories_per_second:.1f} traj/s")

            solver.cleanup()

        # –ê–Ω–∞–ª–∏–∑ scalability
        logger.info("   üìà Scalability –∞–Ω–∞–ª–∏–∑:")

        baseline_batch = min(batch_sizes)
        baseline_throughput = performance_results[baseline_batch][
            "trajectories_per_second"
        ]

        for batch_size in batch_sizes:
            if batch_size == baseline_batch:
                continue

            current_throughput = performance_results[batch_size][
                "trajectories_per_second"
            ]
            speedup = current_throughput / baseline_throughput
            efficiency = speedup / (batch_size / baseline_batch)

            logger.info(
                f"     Batch {batch_size}: {speedup:.1f}x speedup, "
                f"{efficiency:.1%} efficiency"
            )

        return performance_results

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ batch processing —Ç–µ—Å—Ç–µ: {e}")
        return {}


def test_adaptive_integration():
    """–¢–µ—Å—Ç 5: Adaptive –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –æ—à–∏–±–∫–∏"""
    logger.info("üß™ –¢–µ—Å—Ç 5: Adaptive –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –æ—à–∏–±–∫–∏")

    try:
        from new_rebuild.core.cnf.gpu_optimized_euler_solver import (
            create_gpu_optimized_euler_solver,
        )

        # Stiff ODE –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è adaptive capabilities
        def stiff_ode(t: torch.Tensor, states: torch.Tensor) -> torch.Tensor:
            # –ñ–µ—Å—Ç–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –±—ã—Å—Ç—Ä—ã–º–∏ –∏ –º–µ–¥–ª–µ–Ω–Ω—ã–º–∏ –º–æ–¥–∞–º–∏
            fast_rate = -100.0
            slow_rate = -1.0

            # –ü–µ—Ä–≤–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π - –±—ã—Å—Ç—Ä—ã–µ –º–æ–¥—ã
            # –í—Ç–æ—Ä–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ - –º–µ–¥–ª–µ–Ω–Ω—ã–µ –º–æ–¥—ã
            state_size = states.shape[-1]
            fast_size = state_size // 2

            fast_dynamics = fast_rate * states[..., :fast_size]
            slow_dynamics = slow_rate * states[..., fast_size:]

            return torch.cat([fast_dynamics, slow_dynamics], dim=-1)

        batch_size = 5
        state_size = 6
        initial_states = torch.randn(batch_size, state_size) * 0.1

        # –°–æ–∑–¥–∞–µ–º solver
        solver = create_gpu_optimized_euler_solver()

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º adaptive –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é
        logger.info("   üîÑ –ó–∞–ø—É—Å–∫ adaptive –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏...")

        result = solver.batch_integrate_adaptive(
            stiff_ode,
            initial_states,
            integration_time=0.1,  # –ö–æ—Ä–æ—Ç–∫–æ–µ –≤—Ä–µ–º—è –¥–ª—è stiff system
            target_error=1e-3,
            max_steps=50,
            return_trajectory=True,
        )

        logger.info(f"   ‚úÖ Adaptive –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
        logger.info(f"     ‚è±Ô∏è –í—Ä–µ–º—è: {result.integration_time_ms:.1f}ms")
        logger.info(f"     üìä –®–∞–≥–∏: {result.steps_taken}")
        logger.info(f"     üîß Adjustments: {result.adaptive_adjustments}")
        logger.info(f"     üéØ –£—Å–ø–µ—Ö: {result.success}")
        logger.info(f"     üìà Error estimates: {len(result.error_estimates)}")

        if result.trajectory is not None:
            logger.info(f"     üìä Trajectory shape: {result.trajectory.shape}")

            # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ - fast –º–æ–¥—ã –¥–æ–ª–∂–Ω—ã –±—ã—Å—Ç—Ä–æ –∑–∞—Ç—É—Ö–∞—Ç—å
            fast_states = result.trajectory[..., : state_size // 2]
            slow_states = result.trajectory[..., state_size // 2 :]

            initial_fast_norm = torch.norm(fast_states[0])
            final_fast_norm = torch.norm(fast_states[-1])
            initial_slow_norm = torch.norm(slow_states[0])
            final_slow_norm = torch.norm(slow_states[-1])

            logger.info(
                f"     ‚ö° Fast modes: {initial_fast_norm:.4f} ‚Üí {final_fast_norm:.4f}"
            )
            logger.info(
                f"     üêå Slow modes: {initial_slow_norm:.4f} ‚Üí {final_slow_norm:.4f}"
            )

            # Fast –º–æ–¥—ã –¥–æ–ª–∂–Ω—ã –∑–∞—Ç—É—Ö–∞—Ç—å –±—ã—Å—Ç—Ä–µ–µ
            fast_decay_ratio = final_fast_norm / (initial_fast_norm + 1e-8)
            slow_decay_ratio = final_slow_norm / (initial_slow_norm + 1e-8)

            logger.info(
                f"     üìâ Decay ratios - Fast: {fast_decay_ratio:.4f}, "
                f"Slow: {slow_decay_ratio:.4f}"
            )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º error estimates
        if result.error_estimates:
            avg_error = np.mean(result.error_estimates)
            max_error = np.max(result.error_estimates)
            logger.info(
                f"     üìä Error estimates - Avg: {avg_error:.2e}, Max: {max_error:.2e}"
            )

        solver.cleanup()

        return True

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ adaptive –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_performance_benchmark():
    """–¢–µ—Å—Ç 6: Performance benchmark"""
    logger.info("üß™ –¢–µ—Å—Ç 6: Performance benchmark")

    try:
        from new_rebuild.core.cnf.gpu_optimized_euler_solver import (
            benchmark_solver_performance,
        )

        # –ó–∞–ø—É—Å–∫–∞–µ–º –±–µ–Ω—á–º–∞—Ä–∫
        logger.info("   üöÄ –ó–∞–ø—É—Å–∫ performance benchmark...")

        results = benchmark_solver_performance(
            state_size=32,
            batch_sizes=[1, 10, 100],  # –£–º–µ–Ω—å—à–µ–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞
            num_steps=3,
            num_trials=3,
        )

        logger.info("   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã benchmark:")

        for batch_key, metrics in results.items():
            batch_size = int(batch_key.split("_")[1])
            logger.info(f"     Batch {batch_size}:")
            logger.info(f"       ‚è±Ô∏è Time: {metrics['avg_integration_time_ms']:.1f}ms")
            logger.info(f"       üíæ Memory: {metrics['avg_memory_usage_mb']:.1f}MB")
            logger.info(
                f"       üöÄ Throughput: {metrics['throughput_trajectories_per_second']:.0f} traj/s"
            )
            logger.info(
                f"       üìä Efficiency: {metrics['memory_efficiency_mb_per_trajectory']:.2f} MB/traj"
            )
            logger.info(f"       ‚úÖ Success: {metrics['success_rate']:.1%}")

        # –ê–Ω–∞–ª–∏–∑ efficiency scaling
        batch_sizes = [int(k.split("_")[1]) for k in results.keys()]
        throughputs = [
            results[f"batch_{bs}"]["throughput_trajectories_per_second"]
            for bs in batch_sizes
        ]

        if len(batch_sizes) > 1:
            logger.info("   üìà Throughput scaling:")
            baseline_throughput = (
                throughputs[0] / batch_sizes[0]
            )  # per-trajectory throughput

            for i, (bs, throughput) in enumerate(zip(batch_sizes, throughputs)):
                per_traj_throughput = throughput / bs
                scaling_efficiency = per_traj_throughput / baseline_throughput
                logger.info(
                    f"     Batch {bs}: {scaling_efficiency:.2f}x efficiency vs single trajectory"
                )

        return results

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ performance benchmark: {e}")
        return {}


def test_memory_efficiency():
    """–¢–µ—Å—Ç 7: Memory efficiency"""
    logger.info("üß™ –¢–µ—Å—Ç 7: Memory efficiency")

    try:
        from new_rebuild.core.cnf.gpu_optimized_euler_solver import (
            create_gpu_optimized_euler_solver,
        )

        def simple_derivative(t: torch.Tensor, states: torch.Tensor) -> torch.Tensor:
            return -0.1 * states

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å –∏ –±–µ–∑ memory efficiency
        batch_size = 50
        state_size = 16
        initial_states = torch.randn(batch_size, state_size)

        configs = [("Memory Efficient", True), ("Standard", False)]

        results = {}

        for config_name, memory_efficient in configs:
            logger.info(f"   üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º {config_name} —Ä–µ–∂–∏–º")

            solver = create_gpu_optimized_euler_solver(
                memory_efficient=memory_efficient
            )

            # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ memory pooling
            integration_results = []

            for i in range(3):
                result = solver.batch_integrate(
                    simple_derivative, initial_states, integration_time=1.0, num_steps=5
                )
                integration_results.append(result)

                logger.info(f"     –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è {i+1}: {result.memory_usage_mb:.1f}MB")

            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É solver'–∞
            stats = solver.get_comprehensive_stats()

            results[config_name] = {
                "avg_memory_per_integration": np.mean(
                    [r.memory_usage_mb for r in integration_results]
                ),
                "memory_pool_size": stats["memory_pool"]["pool_size"],
                "peak_memory_mb": stats["performance"]["gpu_memory_peak_mb"],
            }

            logger.info(
                f"     üìä Memory pool size: {stats['memory_pool']['pool_size']}"
            )
            logger.info(
                f"     üíæ Peak memory: {stats['performance']['gpu_memory_peak_mb']:.1f}MB"
            )

            solver.cleanup()

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        logger.info("   üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ memory efficiency:")
        for config_name, metrics in results.items():
            logger.info(f"     {config_name}:")
            logger.info(
                f"       üìä Avg memory/integration: {metrics['avg_memory_per_integration']:.1f}MB"
            )
            logger.info(f"       üóÉÔ∏è Pool size: {metrics['memory_pool_size']}")
            logger.info(f"       ‚õ∞Ô∏è Peak memory: {metrics['peak_memory_mb']:.1f}MB")

        return results

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ memory efficiency —Ç–µ—Å—Ç–µ: {e}")
        return {}


def run_all_tests():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è GPU Optimized Euler Solver")
    logger.info("=" * 80)

    test_results = {}

    # –¢–µ—Å—Ç 1: –ò–º–ø–æ—Ä—Ç—ã
    test_results["imports"] = test_imports()

    if not test_results["imports"]:
        logger.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –∏–º–ø–æ—Ä—Ç—ã –Ω–µ —É–¥–∞–ª–∏—Å—å")
        return test_results

    # –¢–µ—Å—Ç 2: –ë–∞–∑–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
    test_results["basic_functionality"] = test_basic_functionality()

    # –¢–µ—Å—Ç 3: Adaptive –º–µ—Ç–æ–¥—ã
    test_results["adaptive_methods"] = test_adaptive_methods()

    # –¢–µ—Å—Ç 4: Batch processing
    test_results["batch_processing"] = test_batch_processing()

    # –¢–µ—Å—Ç 5: Adaptive –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
    test_results["adaptive_integration"] = test_adaptive_integration()

    # –¢–µ—Å—Ç 6: Performance benchmark
    test_results["performance_benchmark"] = test_performance_benchmark()

    # –¢–µ—Å—Ç 7: Memory efficiency
    test_results["memory_efficiency"] = test_memory_efficiency()

    # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    logger.info("=" * 80)
    logger.info("üìã –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    logger.info("=" * 80)

    successful_tests = sum(
        1
        for result in test_results.values()
        if isinstance(result, (bool, dict))
        and (result is True or (isinstance(result, dict) and result))
    )

    total_tests = len(test_results)

    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω—ã–µ —Ç–µ—Å—Ç—ã: {successful_tests}/{total_tests}")

    if successful_tests == total_tests:
        logger.info("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        logger.info("üöÄ GPU Optimized Euler Solver –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
        logger.info("‚ö° Vectorized –æ–ø–µ—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç")
        logger.info("üìä Batch processing —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω")
        logger.info("üéØ Lipschitz-based adaptation —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä—É–µ—Ç")
        logger.info("üíæ Memory efficiency –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    else:
        logger.warning(f"‚ö†Ô∏è {total_tests - successful_tests} —Ç–µ—Å—Ç–æ–≤ —Ç—Ä–µ–±—É—é—Ç –≤–Ω–∏–º–∞–Ω–∏—è")
        logger.info("üîß –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤—ã—à–µ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º")

    return test_results


if __name__ == "__main__":
    results = run_all_tests()
