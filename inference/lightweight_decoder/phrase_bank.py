"""
üè¶ PHRASE BANK - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ—Ä–∞–∑–æ–≤–æ–π –±–∞–∑–æ–π –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Ä–µ–∞–ª–∏–∑—É–µ—Ç —Å–∏—Å—Ç–µ–º—É —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –ø–æ–∏—Å–∫–∞ —Ñ—Ä–∞–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞.
–û—Å–Ω–æ–≤–∞ –¥–ª—è PhraseBankDecoder –≤ Phase 2.7.1.

–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
- PhraseBank: –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ñ—Ä–∞–∑–∞–º–∏
- PhraseIndex: –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ similarity
- PhraseLoader: –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
"""

import torch
import numpy as np
import pickle
import logging
from pathlib import Path
from typing import List, Tuple, Dict, Optional, Union
from dataclasses import dataclass
import time

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ FAISS (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)
try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False
    logging.warning("FAISS not available, falling back to linear search")

@dataclass
class PhraseEntry:
    """–ó–∞–ø–∏—Å—å —Ñ—Ä–∞–∑—ã –≤ –±–∞–Ω–∫–µ"""
    text: str                    # –¢–µ–∫—Å—Ç —Ñ—Ä–∞–∑—ã
    embedding: torch.Tensor      # –≠–º–±–µ–¥–∏–Ω–≥ —Ñ—Ä–∞–∑—ã (768D)
    frequency: int = 1           # –ß–∞—Å—Ç–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    category: str = "general"    # –ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ñ—Ä–∞–∑—ã
    length: int = 0              # –î–ª–∏–Ω–∞ –≤ —Å–ª–æ–≤–∞—Ö
    
    def __post_init__(self):
        if self.length == 0:
            self.length = len(self.text.split())

class PhraseIndex:
    """–ò–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Ñ—Ä–∞–∑ –ø–æ similarity"""
    
    def __init__(self, embedding_dim: int = 768, index_type: str = "faiss"):
        self.embedding_dim = embedding_dim
        self.index_type = index_type
        self.index = None
        self.phrases = []  # –°–ø–∏—Å–æ–∫ PhraseEntry
        self.built = False
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞
        if index_type == "faiss" and FAISS_AVAILABLE:
            # FAISS index –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            self.index = faiss.IndexFlatIP(embedding_dim)  # Inner Product –¥–ª—è cosine similarity
            self.use_faiss = True
        else:
            # Fallback –∫ linear search
            self.use_faiss = False
            self.embeddings_matrix = None
            logging.info(f"Using linear search index (FAISS not available or type={index_type})")
    
    def add_phrases(self, phrases: List[PhraseEntry]):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ—Ä–∞–∑ –≤ –∏–Ω–¥–µ–∫—Å"""
        self.phrases.extend(phrases)
        
        if self.use_faiss:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –¥–ª—è FAISS
            embeddings = []
            for phrase in phrases:
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è cosine similarity
                embedding = phrase.embedding.numpy()
                embedding = embedding / np.linalg.norm(embedding)
                embeddings.append(embedding)
            
            embeddings_matrix = np.vstack(embeddings).astype(np.float32)
            self.index.add(embeddings_matrix)
        else:
            # Linear search –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞
            all_embeddings = []
            for phrase in self.phrases:
                embedding = phrase.embedding.numpy()
                embedding = embedding / np.linalg.norm(embedding)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
                all_embeddings.append(embedding)
            
            self.embeddings_matrix = np.vstack(all_embeddings).astype(np.float32)
        
        self.built = True
        logging.info(f"Added {len(phrases)} phrases to index. Total: {len(self.phrases)}")
    
    def search(self, query_embedding: torch.Tensor, k: int = 10) -> List[Tuple[PhraseEntry, float]]:
        """–ü–æ–∏—Å–∫ k –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö —Ñ—Ä–∞–∑"""
        if not self.built:
            raise ValueError("Index not built. Call add_phrases() first.")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è query –¥–ª—è cosine similarity
        query = query_embedding.numpy()
        query = query / np.linalg.norm(query)
        query = query.reshape(1, -1).astype(np.float32)
        
        if self.use_faiss:
            # FAISS –ø–æ–∏—Å–∫
            similarities, indices = self.index.search(query, k)
            
            results = []
            for i, (similarity, idx) in enumerate(zip(similarities[0], indices[0])):
                if idx < len(self.phrases):  # –í–∞–ª–∏–¥–Ω—ã–π –∏–Ω–¥–µ–∫—Å
                    results.append((self.phrases[idx], float(similarity)))
            
            return results
        else:
            # Linear search
            similarities = np.dot(self.embeddings_matrix, query.T).flatten()
            top_indices = np.argsort(similarities)[::-1][:k]
            
            results = []
            for idx in top_indices:
                similarity = similarities[idx]
                results.append((self.phrases[idx], float(similarity)))
            
            return results

class PhraseLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ —Ñ—Ä–∞–∑ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    
    @staticmethod
    def create_sample_phrases(embedding_loader) -> List[PhraseEntry]:
        """–°–æ–∑–¥–∞–Ω–∏–µ sample phrase bank –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        
        # –ë–∞–∑–æ–≤—ã–µ —Ñ—Ä–∞–∑—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        sample_phrases = [
            # –û–±—â–∏–µ —Ñ—Ä–∞–∑—ã
            "Hello, how are you?",
            "Thank you very much.",
            "I don't understand.",
            "Could you please help me?",
            "That's a great idea!",
            
            # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ñ—Ä–∞–∑—ã
            "Machine learning is fascinating.",
            "Neural networks process information.",
            "Artificial intelligence advances rapidly.",
            "Data science requires careful analysis.",
            "Computer vision enables automation.",
            
            # –†–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–µ —Ñ—Ä–∞–∑—ã
            "What's the weather like today?",
            "I'm looking forward to it.",
            "Let me think about that.",
            "This is really interesting.",
            "I completely agree with you.",
            
            # –§—Ä–∞–∑—ã –¥–ª—è –¥–∏–∞–ª–æ–≥–∞
            "Can you explain that further?",
            "I see what you mean.",
            "That makes perfect sense.",
            "I have a question about this.",
            "Thank you for your patience.",
            
            # –ö—Ä–µ–∞—Ç–∏–≤–Ω—ã–µ —Ñ—Ä–∞–∑—ã  
            "The sun shines brightly today.",
            "Music fills the air with joy.",
            "Books open doors to knowledge.",
            "Technology shapes our future.",
            "Learning never truly ends."
        ]
        
        phrase_entries = []
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Ñ—Ä–∞–∑ –±–∞—Ç—á–∞–º–∏ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ —Å—Ä–∞–∑—É —á–µ—Ä–µ–∑ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API
            embeddings = embedding_loader.load_from_llm(
                texts=sample_phrases,
                model_key="distilbert",
                use_cache=True
            )
        except Exception as e:
            logging.error(f"Failed to generate embeddings: {e}")
            return []
        
        # –°–æ–∑–¥–∞–Ω–∏–µ phrase entries
        for i, phrase_text in enumerate(sample_phrases):
            try:
                embedding = embeddings[i]
                
                # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                if "machine learning" in phrase_text.lower() or "neural" in phrase_text.lower():
                    category = "technical"
                elif "hello" in phrase_text.lower() or "thank you" in phrase_text.lower():
                    category = "greeting"
                elif "sun" in phrase_text.lower() or "music" in phrase_text.lower():
                    category = "creative"
                else:
                    category = "general"
                
                phrase_entry = PhraseEntry(
                    text=phrase_text,
                    embedding=embedding,
                    frequency=1,
                    category=category
                )
                phrase_entries.append(phrase_entry)
                
            except Exception as e:
                logging.warning(f"Failed to create embedding for phrase '{phrase_text}': {e}")
                continue
        
        logging.info(f"Created {len(phrase_entries)} sample phrases")
        return phrase_entries
    
    @staticmethod
    def load_from_file(file_path: str) -> List[PhraseEntry]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ—Ä–∞–∑ –∏–∑ —Ñ–∞–π–ª–∞"""
        path = Path(file_path)
        
        if not path.exists():
            raise FileNotFoundError(f"Phrase file not found: {file_path}")
        
        try:
            with open(path, 'rb') as f:
                phrase_data = pickle.load(f)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ PhraseEntry –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if isinstance(phrase_data, list) and len(phrase_data) > 0:
                if isinstance(phrase_data[0], PhraseEntry):
                    return phrase_data
                else:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
                    logging.warning("Converting phrase data format")
                    return []
            
        except Exception as e:
            logging.error(f"Failed to load phrases from {file_path}: {e}")
            return []
    
    @staticmethod
    def save_to_file(phrases: List[PhraseEntry], file_path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ—Ä–∞–∑ –≤ —Ñ–∞–π–ª"""
        path = Path(file_path)
        path.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            with open(path, 'wb') as f:
                pickle.dump(phrases, f)
            
            logging.info(f"Saved {len(phrases)} phrases to {file_path}")
        except Exception as e:
            logging.error(f"Failed to save phrases to {file_path}: {e}")

class PhraseBank:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è phrase bank"""
    
    def __init__(self, 
                 embedding_dim: int = 768,
                 similarity_threshold: float = 0.8,
                 max_phrases: int = 50000,
                 index_type: str = "faiss",
                 cache_size: int = 1000):
        
        self.embedding_dim = embedding_dim
        self.similarity_threshold = similarity_threshold
        self.max_phrases = max_phrases
        self.cache_size = cache_size
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.index = PhraseIndex(embedding_dim, index_type)
        self.cache = {}  # –ü—Ä–æ—Å—Ç–æ–π cache –¥–ª—è —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        self.stats = {
            'total_searches': 0,
            'cache_hits': 0,
            'avg_search_time': 0
        }
        
        logging.info(f"PhraseBank initialized: dim={embedding_dim}, threshold={similarity_threshold}")
    
    def add_phrases(self, phrases: List[PhraseEntry]):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ—Ä–∞–∑ –≤ –±–∞–Ω–∫"""
        if len(self.index.phrases) + len(phrases) > self.max_phrases:
            logging.warning(f"Phrase limit reached ({self.max_phrases}), truncating")
            phrases = phrases[:self.max_phrases - len(self.index.phrases)]
        
        self.index.add_phrases(phrases)
        
        # –û—á–∏—Å—Ç–∫–∞ cache –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏
        self.cache.clear()
    
    def search_phrases(self, 
                      query_embedding: torch.Tensor, 
                      k: int = 10,
                      min_similarity: Optional[float] = None) -> List[Tuple[PhraseEntry, float]]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ñ—Ä–∞–∑"""
        
        start_time = time.time()
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ threshold –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if min_similarity is None:
            min_similarity = self.similarity_threshold
        
        # –ü—Ä–æ—Å—Ç–æ–π cache key (hash –æ—Ç embedding)
        cache_key = hash(query_embedding.numpy().tobytes())
        
        if cache_key in self.cache:
            self.stats['cache_hits'] += 1
            return self.cache[cache_key]
        
        # –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –∏–Ω–¥–µ–∫—Å
        results = self.index.search(query_embedding, k * 2)  # –ë–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ threshold
        filtered_results = [
            (phrase, similarity) for phrase, similarity in results
            if similarity >= min_similarity
        ]
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        filtered_results = filtered_results[:k]
        
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if len(self.cache) < self.cache_size:
            self.cache[cache_key] = filtered_results
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        search_time = time.time() - start_time
        self.stats['total_searches'] += 1
        self.stats['avg_search_time'] = (
            (self.stats['avg_search_time'] * (self.stats['total_searches'] - 1) + search_time) /
            self.stats['total_searches']
        )
        
        return filtered_results
    
    def get_best_phrase(self, query_embedding: torch.Tensor) -> Optional[Tuple[PhraseEntry, float]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π —Ñ—Ä–∞–∑—ã –¥–ª—è query"""
        results = self.search_phrases(query_embedding, k=1)
        
        if results:
            return results[0]
        return None
    
    def get_statistics(self) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        cache_hit_rate = (
            self.stats['cache_hits'] / max(self.stats['total_searches'], 1) * 100
        )
        
        return {
            'total_phrases': len(self.index.phrases),
            'total_searches': self.stats['total_searches'],
            'cache_hit_rate': f"{cache_hit_rate:.1f}%",
            'avg_search_time_ms': f"{self.stats['avg_search_time'] * 1000:.2f}",
            'index_type': self.index.index_type,
            'faiss_available': FAISS_AVAILABLE
        }
    
    def load_sample_bank(self, embedding_loader):
        """–ó–∞–≥—Ä—É–∑–∫–∞ sample phrase bank –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        sample_phrases = PhraseLoader.create_sample_phrases(embedding_loader)
        self.add_phrases(sample_phrases)
        logging.info(f"Loaded sample bank with {len(sample_phrases)} phrases")
    
    def save_bank(self, file_path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ phrase bank"""
        PhraseLoader.save_to_file(self.index.phrases, file_path)
    
    def load_bank(self, file_path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ phrase bank –∏–∑ —Ñ–∞–π–ª–∞"""
        phrases = PhraseLoader.load_from_file(file_path)
        if phrases:
            self.add_phrases(phrases)
            logging.info(f"Loaded {len(phrases)} phrases from {file_path}")
        else:
            logging.warning(f"No phrases loaded from {file_path}")

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –º–æ–¥—É–ª—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__) 