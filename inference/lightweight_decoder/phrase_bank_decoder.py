"""
üî§ PHRASE BANK DECODER - –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ —Ñ—Ä–∞–∑

–†–µ–∞–ª–∏–∑—É–µ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –≤ —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ –Ω–∞–∏–±–æ–ª–µ–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏
–±–ª–∏–∑–∫–∏—Ö —Ñ—Ä–∞–∑ –≤ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–º phrase bank.

Phase 2.7.1 - PhraseBankDecoder Implementation
"""

import torch
import numpy as np
import logging
from typing import List, Optional, Dict, Tuple
from dataclasses import dataclass

from .phrase_bank import PhraseBank, PhraseEntry

@dataclass
class DecodingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    max_candidates: int = 10          # –ú–∞–∫—Å–∏–º—É–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
    similarity_threshold: float = 0.8  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π threshold similarity
    assembly_method: str = "weighted"  # –ú–µ—Ç–æ–¥ —Å–±–æ—Ä–∫–∏: weighted, greedy, beam_search
    coherence_weight: float = 0.3     # –í–µ—Å –∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏
    relevance_weight: float = 0.7     # –í–µ—Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    min_phrase_length: int = 3        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ñ—Ä–∞–∑—ã (—Å–ª–æ–≤–∞)
    max_phrase_length: int = 50       # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ñ—Ä–∞–∑—ã (—Å–ª–æ–≤–∞)

class TextAssembler:
    """–°–±–æ—Ä—â–∏–∫ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑"""
    
    def __init__(self, config: DecodingConfig):
        self.config = config
    
    def assemble_weighted(self, candidates: List[Tuple[PhraseEntry, float]]) -> str:
        """–í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å–±–æ—Ä–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ similarity scores"""
        if not candidates:
            return "No suitable phrases found."
        
        # –ü—Ä–æ—Å—Ç–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: –±–µ—Ä–µ–º –ª—É—á—à—É—é —Ñ—Ä–∞–∑—É
        best_phrase, best_similarity = candidates[0]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        if best_similarity < self.config.similarity_threshold:
            return "Low confidence phrase match."
        
        return best_phrase.text
    
    def assemble_greedy(self, candidates: List[Tuple[PhraseEntry, float]]) -> str:
        """–ñ–∞–¥–Ω–∞—è —Å–±–æ—Ä–∫–∞ - –ø—Ä–æ—Å—Ç–æ –ª—É—á—à–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç"""
        if not candidates:
            return "No phrases available."
        
        best_phrase, _ = candidates[0]
        return best_phrase.text
    
    def assemble_beam_search(self, candidates: List[Tuple[PhraseEntry, float]]) -> str:
        """Beam search —Å–±–æ—Ä–∫–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        if not candidates:
            return "No beam candidates."
        
        # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è - –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –¥–ª—è multi-phrase assembly
        filtered_candidates = [
            (phrase, similarity) for phrase, similarity in candidates
            if self.config.min_phrase_length <= phrase.length <= self.config.max_phrase_length
        ]
        
        if not filtered_candidates:
            # Fallback –∫ –ø–µ—Ä–≤–æ–º—É –∫–∞–Ω–¥–∏–¥–∞—Ç—É
            return candidates[0][0].text
        
        # –í–æ–∑—å–º–µ–º –ª—É—á—à–∏–π –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π
        best_phrase, _ = filtered_candidates[0]
        return best_phrase.text
    
    def assemble(self, candidates: List[Tuple[PhraseEntry, float]]) -> str:
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Å–±–æ—Ä–∫–∏"""
        if self.config.assembly_method == "weighted":
            return self.assemble_weighted(candidates)
        elif self.config.assembly_method == "greedy":
            return self.assemble_greedy(candidates)
        elif self.config.assembly_method == "beam_search":
            return self.assemble_beam_search(candidates)
        else:
            logging.warning(f"Unknown assembly method: {self.config.assembly_method}")
            return self.assemble_greedy(candidates)

class QualityAssessor:
    """–û—Ü–µ–Ω—â–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self, config: DecodingConfig):
        self.config = config
    
    def assess_candidates(self, candidates: List[Tuple[PhraseEntry, float]]) -> Dict:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"""
        if not candidates:
            return {
                'quality_score': 0.0,
                'confidence': 0.0,
                'coherence': 0.0,
                'diversity': 0.0
            }
        
        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        similarities = [similarity for _, similarity in candidates]
        
        quality_score = np.mean(similarities)
        confidence = max(similarities)
        coherence = self._assess_coherence(candidates)
        diversity = self._assess_diversity(candidates)
        
        return {
            'quality_score': float(quality_score),
            'confidence': float(confidence),
            'coherence': float(coherence),
            'diversity': float(diversity)
        }
    
    def _assess_coherence(self, candidates: List[Tuple[PhraseEntry, float]]) -> float:
        """–û—Ü–µ–Ω–∫–∞ –∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"""
        if len(candidates) <= 1:
            return 1.0
        
        # –ü—Ä–æ—Å—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞: —Å—Ö–æ–∂–µ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        categories = [phrase.category for phrase, _ in candidates]
        unique_categories = set(categories)
        
        # –ë–æ–ª—å—à–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π = –≤—ã—à–µ –∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å
        coherence = 1.0 - (len(unique_categories) - 1) / len(candidates)
        return max(0.0, coherence)
    
    def _assess_diversity(self, candidates: List[Tuple[PhraseEntry, float]]) -> float:
        """–û—Ü–µ–Ω–∫–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"""
        if len(candidates) <= 1:
            return 0.0
        
        # –ü—Ä–æ—Å—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞: —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –¥–ª–∏–Ω —Ñ—Ä–∞–∑
        lengths = [phrase.length for phrase, _ in candidates]
        diversity = np.std(lengths) / max(lengths) if max(lengths) > 0 else 0.0
        
        return min(1.0, diversity)

class PhraseBankDecoder:
    """–û—Å–Ω–æ–≤–Ω–æ–π –¥–µ–∫–æ–¥–µ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ phrase bank"""
    
    def __init__(self, 
                 embedding_dim: int = 768,
                 phrase_bank_size: int = 50000,
                 similarity_threshold: float = 0.8,
                 config: Optional[DecodingConfig] = None):
        
        self.embedding_dim = embedding_dim
        self.phrase_bank_size = phrase_bank_size
        self.similarity_threshold = similarity_threshold
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.config = config or DecodingConfig(similarity_threshold=similarity_threshold)
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.phrase_bank = PhraseBank(
            embedding_dim=embedding_dim,
            similarity_threshold=similarity_threshold,
            max_phrases=phrase_bank_size
        )
        
        self.assembler = TextAssembler(self.config)
        self.quality_assessor = QualityAssessor(self.config)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_decodings': 0,
            'successful_decodings': 0,
            'avg_confidence': 0.0,
            'avg_quality': 0.0
        }
        
        self.ready = False
        
        logging.info(f"PhraseBankDecoder initialized: dim={embedding_dim}, threshold={similarity_threshold}")
    
    def load_phrase_bank(self, embedding_loader=None, bank_path: Optional[str] = None):
        """–ó–∞–≥—Ä—É–∑–∫–∞ phrase bank"""
        if bank_path:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ —Ñ–∞–π–ª–∞
            self.phrase_bank.load_bank(bank_path)
        elif embedding_loader:
            # –°–æ–∑–¥–∞–Ω–∏–µ sample bank –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            self.phrase_bank.load_sample_bank(embedding_loader)
        else:
            raise ValueError("Either embedding_loader or bank_path must be provided")
        
        self.ready = True
        logging.info("Phrase bank loaded successfully")
    
    def decode(self, embedding: torch.Tensor) -> str:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        if not self.ready:
            raise ValueError("Phrase bank not loaded. Call load_phrase_bank() first.")
        
        if embedding.dim() != 1 or embedding.size(0) != self.embedding_dim:
            raise ValueError(f"Expected embedding shape ({self.embedding_dim},), got {embedding.shape}")
        
        try:
            # –ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
            candidates = self.phrase_bank.search_phrases(
                embedding, 
                k=self.config.max_candidates,
                min_similarity=self.config.similarity_threshold
            )
            
            # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            quality_metrics = self.quality_assessor.assess_candidates(candidates)
            
            # –°–±–æ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞
            decoded_text = self.assembler.assemble(candidates)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self._update_stats(quality_metrics, len(candidates) > 0)
            
            logging.debug(f"Decoded: {decoded_text} (confidence: {quality_metrics['confidence']:.3f})")
            
            return decoded_text
            
        except Exception as e:
            logging.error(f"Decoding failed: {e}")
            self._update_stats({'quality_score': 0.0, 'confidence': 0.0}, False)
            return "Decoding error occurred."
    
    def decode_with_metrics(self, embedding: torch.Tensor) -> Tuple[str, Dict]:
        """–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
        if not self.ready:
            raise ValueError("Phrase bank not loaded.")
        
        # –ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        candidates = self.phrase_bank.search_phrases(
            embedding, 
            k=self.config.max_candidates,
            min_similarity=self.config.similarity_threshold
        )
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_metrics = self.quality_assessor.assess_candidates(candidates)
        
        # –°–±–æ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞
        decoded_text = self.assembler.assemble(candidates)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        detailed_metrics = {
            **quality_metrics,
            'num_candidates': len(candidates),
            'top_similarity': candidates[0][1] if candidates else 0.0,
            'phrase_categories': [phrase.category for phrase, _ in candidates[:3]],
            'phrase_bank_stats': self.phrase_bank.get_statistics()
        }
        
        self._update_stats(quality_metrics, len(candidates) > 0)
        
        return decoded_text, detailed_metrics
    
    def batch_decode(self, embeddings: torch.Tensor) -> List[str]:
        """Batch –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        if embeddings.dim() != 2 or embeddings.size(1) != self.embedding_dim:
            raise ValueError(f"Expected embeddings shape (N, {self.embedding_dim}), got {embeddings.shape}")
        
        results = []
        for i, embedding in enumerate(embeddings):
            try:
                result = self.decode(embedding)
                results.append(result)
            except Exception as e:
                logging.warning(f"Batch decode failed for item {i}: {e}")
                results.append("Batch decode error.")
        
        return results
    
    def get_statistics(self) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–µ–∫–æ–¥–µ—Ä–∞"""
        success_rate = (
            self.stats['successful_decodings'] / max(self.stats['total_decodings'], 1) * 100
        )
        
        return {
            **self.stats,
            'success_rate': f"{success_rate:.1f}%",
            'phrase_bank_stats': self.phrase_bank.get_statistics(),
            'config': {
                'similarity_threshold': self.config.similarity_threshold,
                'assembly_method': self.config.assembly_method,
                'max_candidates': self.config.max_candidates
            }
        }
    
    def _update_stats(self, quality_metrics: Dict, success: bool):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        self.stats['total_decodings'] += 1
        
        if success:
            self.stats['successful_decodings'] += 1
        
        # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è –º–µ—Ç—Ä–∏–∫
        total = self.stats['total_decodings']
        
        self.stats['avg_confidence'] = (
            (self.stats['avg_confidence'] * (total - 1) + quality_metrics.get('confidence', 0.0)) / total
        )
        
        self.stats['avg_quality'] = (
            (self.stats['avg_quality'] * (total - 1) + quality_metrics.get('quality_score', 0.0)) / total
        )
    
    def set_config(self, **kwargs):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        for key, value in kwargs.items():
            if hasattr(self.config, key):
                setattr(self.config, key, value)
                logging.info(f"Updated config: {key} = {value}")
            else:
                logging.warning(f"Unknown config parameter: {key}")
        
        # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        self.assembler = TextAssembler(self.config)
        self.quality_assessor = QualityAssessor(self.config)

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logger = logging.getLogger(__name__) 