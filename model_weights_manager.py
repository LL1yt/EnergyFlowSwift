#!/usr/bin/env python3
"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏ - –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫–∞/–æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤
"""

import torch
import os
import json
from datetime import datetime
from pathlib import Path
import shutil
import hashlib

class ModelWeightsManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ—Å–∞–º–∏ –º–æ–¥–µ–ª–∏"""
    
    def __init__(self, base_dir="checkpoints"):
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
        self.latest_dir = self.base_dir / "latest"
        self.versioned_dir = self.base_dir / "versioned"
        self.backups_dir = self.base_dir / "backups"
        
        for dir_path in [self.latest_dir, self.versioned_dir, self.backups_dir]:
            dir_path.mkdir(exist_ok=True)
        
        print(f"üìÅ Model Weights Manager initialized: {self.base_dir}")
    
    def save_latest_weights(self, trainer, config, metadata=None):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤–µ—Å–∞ (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ)"""
        
        # –†–µ–∑–µ—Ä–≤–∏—Ä—É–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –≤–µ—Å–∞ –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        latest_path = self.latest_dir / "trainer_latest.pt"
        if latest_path.exists():
            backup_name = f"trainer_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pt"
            shutil.copy2(latest_path, self.backups_dir / backup_name)
            print(f"   üì¶ –ü—Ä–µ–¥—ã–¥—É—â–∏–µ –≤–µ—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ backup: {backup_name}")
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–µ metadata
        full_metadata = {
            'timestamp': datetime.now().isoformat(),
            'model_params': sum(p.numel() for p in trainer.parameters()),
            'trainable_params': sum(p.numel() for p in trainer.parameters() if p.requires_grad),
            'model_size_mb': sum(p.numel() * p.element_size() for p in trainer.parameters()) / (1024**2),
            'config_hash': self._hash_config(config),
            'custom_metadata': metadata or {}
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞
        save_data = {
            'model_state_dict': trainer.state_dict(),
            'config': config,
            'metadata': full_metadata
        }
        
        torch.save(save_data, latest_path)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º readable metadata
        metadata_path = self.latest_dir / "metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(full_metadata, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ –ü–æ—Å–ª–µ–¥–Ω–∏–µ –≤–µ—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {latest_path}")
        print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {full_metadata['trainable_params']:,}")
        print(f"   –†–∞–∑–º–µ—Ä: {full_metadata['model_size_mb']:.1f} MB")
        
        return latest_path
    
    def save_versioned_weights(self, trainer, config, version_name, metadata=None):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ (–¥–ª—è milestone)"""
        
        version_dir = self.versioned_dir / version_name
        version_dir.mkdir(exist_ok=True)
        
        full_metadata = {
            'version': version_name,
            'timestamp': datetime.now().isoformat(),
            'model_params': sum(p.numel() for p in trainer.parameters()),
            'trainable_params': sum(p.numel() for p in trainer.parameters() if p.requires_grad),
            'model_size_mb': sum(p.numel() * p.element_size() for p in trainer.parameters()) / (1024**2),
            'config_hash': self._hash_config(config),
            'custom_metadata': metadata or {}
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞
        weights_path = version_dir / f"trainer_{version_name}.pt"
        save_data = {
            'model_state_dict': trainer.state_dict(),
            'config': config,
            'metadata': full_metadata
        }
        
        torch.save(save_data, weights_path)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º metadata
        metadata_path = version_dir / "metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(full_metadata, f, indent=2, ensure_ascii=False)
        
        print(f"üè∑Ô∏è –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {weights_path}")
        print(f"   –í–µ—Ä—Å–∏—è: {version_name}")
        
        return weights_path
    
    def load_latest_weights(self, trainer):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤–µ—Å–∞"""
        latest_path = self.latest_dir / "trainer_latest.pt"
        
        if not latest_path.exists():
            print(f"‚ö†Ô∏è –ü–æ—Å–ª–µ–¥–Ω–∏–µ –≤–µ—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {latest_path}")
            return None
        
        return self._load_weights(trainer, latest_path)
    
    def load_versioned_weights(self, trainer, version_name):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞"""
        weights_path = self.versioned_dir / version_name / f"trainer_{version_name}.pt"
        
        if not weights_path.exists():
            print(f"‚ö†Ô∏è –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {weights_path}")
            return None
        
        return self._load_weights(trainer, weights_path)
    
    def _load_weights(self, trainer, weights_path):
        """–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤"""
        try:
            checkpoint = torch.load(weights_path, map_location='cpu')
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
            current_state = trainer.state_dict()
            loaded_state = checkpoint['model_state_dict']
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–π
            current_keys = set(current_state.keys())
            loaded_keys = set(loaded_state.keys())
            
            if current_keys != loaded_keys:
                missing = current_keys - loaded_keys
                extra = loaded_keys - current_keys
                
                print(f"‚ö†Ô∏è –ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤–µ—Å–æ–≤:")
                if missing:
                    print(f"   –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–ª—é—á–∏: {missing}")
                if extra:
                    print(f"   –õ–∏—à–Ω–∏–µ –∫–ª—é—á–∏: {extra}")
                
                return None
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
            trainer.load_state_dict(loaded_state)
            
            metadata = checkpoint.get('metadata', {})
            config = checkpoint.get('config', {})
            
            print(f"‚úÖ –í–µ—Å–∞ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {weights_path}")
            print(f"   Timestamp: {metadata.get('timestamp', 'unknown')}")
            print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {metadata.get('trainable_params', 'unknown'):,}")
            
            return {
                'config': config,
                'metadata': metadata,
                'path': weights_path
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤: {e}")
            return None
    
    def list_available_weights(self):
        """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–µ—Å–æ–≤"""
        print(f"\nüìã –î–û–°–¢–£–ü–ù–´–ï –í–ï–°–ê:")
        
        # Latest weights
        latest_path = self.latest_dir / "trainer_latest.pt"
        if latest_path.exists():
            metadata_path = self.latest_dir / "metadata.json"
            if metadata_path.exists():
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                
                print(f"   üîÑ LATEST:")
                print(f"      Path: {latest_path}")
                print(f"      Timestamp: {metadata.get('timestamp', 'unknown')}")
                print(f"      Parameters: {metadata.get('trainable_params', 'unknown'):,}")
                print(f"      Size: {metadata.get('model_size_mb', 'unknown')} MB")
            else:
                print(f"   üîÑ LATEST: {latest_path} (no metadata)")
        else:
            print(f"   üîÑ LATEST: –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # Versioned weights
        print(f"\n   üè∑Ô∏è VERSIONED:")
        version_dirs = [d for d in self.versioned_dir.iterdir() if d.is_dir()]
        
        if version_dirs:
            for version_dir in sorted(version_dirs):
                version_name = version_dir.name
                weights_path = version_dir / f"trainer_{version_name}.pt"
                metadata_path = version_dir / "metadata.json"
                
                if weights_path.exists():
                    if metadata_path.exists():
                        with open(metadata_path, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                        
                        print(f"      {version_name}:")
                        print(f"         Path: {weights_path}")
                        print(f"         Timestamp: {metadata.get('timestamp', 'unknown')}")
                        print(f"         Parameters: {metadata.get('trainable_params', 'unknown'):,}")
                    else:
                        print(f"      {version_name}: {weights_path} (no metadata)")
        else:
            print(f"      –ù–µ—Ç –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤")
        
        # Backups
        print(f"\n   üì¶ BACKUPS:")
        backup_files = list(self.backups_dir.glob("trainer_backup_*.pt"))
        if backup_files:
            for backup_file in sorted(backup_files, reverse=True)[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5
                print(f"      {backup_file.name}")
        else:
            print(f"      –ù–µ—Ç backup —Ñ–∞–π–ª–æ–≤")
    
    def create_training_checkpoint(self, trainer, config, epoch, loss, similarity, metadata=None):
        """–°–æ–∑–¥–∞—Ç—å checkpoint –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è"""
        checkpoint_name = f"epoch_{epoch:03d}_loss_{loss:.4f}_sim_{similarity:.3f}"
        
        training_metadata = {
            'epoch': epoch,
            'loss': loss,
            'similarity': similarity,
            'training_stage': 'in_progress'
        }
        
        if metadata:
            training_metadata.update(metadata)
        
        return self.save_versioned_weights(trainer, config, checkpoint_name, training_metadata)
    
    def create_milestone_checkpoint(self, trainer, config, milestone_name, results, metadata=None):
        """–°–æ–∑–¥–∞—Ç—å checkpoint –¥–ª—è –≤–∞–∂–Ω–æ–≥–æ milestone"""
        milestone_metadata = {
            'milestone': milestone_name,
            'results': results,
            'training_stage': 'milestone'
        }
        
        if metadata:
            milestone_metadata.update(metadata)
        
        return self.save_versioned_weights(trainer, config, f"milestone_{milestone_name}", milestone_metadata)
    
    def _hash_config(self, config):
        """–°–æ–∑–¥–∞—Ç—å hash config –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        config_str = json.dumps(config, sort_keys=True)
        return hashlib.md5(config_str.encode()).hexdigest()[:8]
    
    def cleanup_old_backups(self, keep_last=10):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö backup —Ñ–∞–π–ª–æ–≤"""
        backup_files = list(self.backups_dir.glob("trainer_backup_*.pt"))
        backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        if len(backup_files) > keep_last:
            old_backups = backup_files[keep_last:]
            
            for backup_file in old_backups:
                backup_file.unlink()
                print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π backup: {backup_file.name}")
            
            print(f"üßπ –û—á–∏—â–µ–Ω–æ {len(old_backups)} —Å—Ç–∞—Ä—ã—Ö backup —Ñ–∞–π–ª–æ–≤")

def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º –≤–µ—Å–æ–≤"""
    manager = ModelWeightsManager()
    manager.list_available_weights()
    
    print(f"\nüí° –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:")
    print(f"1. manager.save_latest_weights(trainer, config) - —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–µ –≤–µ—Å–∞")
    print(f"2. manager.load_latest_weights(trainer) - –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤–µ—Å–∞")
    print(f"3. manager.create_training_checkpoint(trainer, config, epoch, loss, sim) - checkpoint")
    print(f"4. manager.list_available_weights() - –ø–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –≤–µ—Å–∞")

if __name__ == "__main__":
    main() 