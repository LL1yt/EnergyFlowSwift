#!/usr/bin/env python3
"""
Test Vectorized Forward Pass - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
==========================================================

–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–∑–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É:
1. Sequential –æ–±—Ä–∞–±–æ—Ç–∫–æ–π (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
2. Vectorized batch processing (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)

–†–µ–∑—É–ª—å—Ç–∞—Ç: –æ–∂–∏–¥–∞–µ–º 3-10x –ø—Ä–∏—Ä–æ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
"""

import torch
import time
import matplotlib.pyplot as plt
from typing import Dict, List, Any

from new_rebuild.config import get_project_config, set_project_config, ProjectConfig
from new_rebuild.core.cells.gnn_cell import GNNCell
from new_rebuild.core.cells.vectorized_gnn_cell import VectorizedGNNCell
from new_rebuild.core.lattice.vectorized_spatial_processor import (
    VectorizedSpatialProcessor,
)


def create_test_data(dimensions=(10, 10, 10), state_size=32, neighbor_count=26):
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–µ–Ω—á–º–∞—Ä–∫–∞"""
    total_cells = dimensions[0] * dimensions[1] * dimensions[2]

    # –°–ª—É—á–∞–π–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∫–ª–µ—Ç–æ–∫
    states = torch.randn(total_cells, state_size)

    # –°–ª—É—á–∞–π–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ—Å–µ–¥–µ–π –¥–ª—è –∫–∞–∂–¥–æ–π –∫–ª–µ—Ç–∫–∏
    neighbor_states = torch.randn(total_cells, neighbor_count, state_size)

    # –°–ª—É—á–∞–π–Ω—ã–µ external inputs
    external_inputs = torch.randn(total_cells, 8)

    return states, neighbor_states, external_inputs


def benchmark_original_approach(
    states: torch.Tensor,
    neighbor_states: torch.Tensor,
    external_inputs: torch.Tensor,
    num_iterations: int = 10,
) -> Dict[str, Any]:
    """–ë–µ–Ω—á–º–∞—Ä–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ —Å —Ü–∏–∫–ª–∞–º–∏"""

    # –°–æ–∑–¥–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é GNN Cell
    original_cell = GNNCell()

    total_cells = states.shape[0]
    processing_times = []

    print(
        f"üîÑ Testing ORIGINAL approach ({total_cells} cells, {num_iterations} iterations)..."
    )

    for iteration in range(num_iterations):
        start_time = time.time()

        # SEQUENTIAL PROCESSING - –∫–ª–µ—Ç–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –ø–æ –æ–¥–Ω–æ–π
        new_states = []
        for i in range(total_cells):
            cell_state = states[i : i + 1]  # [1, state_size]
            cell_neighbors = neighbor_states[
                i : i + 1
            ]  # [1, neighbor_count, state_size]
            cell_external = external_inputs[i : i + 1]  # [1, external_input_size]

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –∫–ª–µ—Ç–∫–∏
            new_state = original_cell(
                neighbor_states=cell_neighbors,
                own_state=cell_state,
                external_input=cell_external,
            )
            new_states.append(new_state)

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        final_states = torch.cat(new_states, dim=0)

        iteration_time = time.time() - start_time
        processing_times.append(iteration_time)

        if iteration % 3 == 0:
            print(f"   Iteration {iteration+1}: {iteration_time:.3f}s")

    avg_time = sum(processing_times) / len(processing_times)
    cells_per_second = total_cells / avg_time

    return {
        "approach": "original_sequential",
        "avg_time": avg_time,
        "cells_per_second": cells_per_second,
        "processing_times": processing_times,
        "total_cells": total_cells,
    }


def benchmark_vectorized_approach(
    states: torch.Tensor,
    neighbor_states: torch.Tensor,
    external_inputs: torch.Tensor,
    num_iterations: int = 10,
) -> Dict[str, Any]:
    """–ë–µ–Ω—á–º–∞—Ä–∫ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞"""

    # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—É—é GNN Cell
    vectorized_cell = VectorizedGNNCell()

    total_cells = states.shape[0]
    processing_times = []

    print(
        f"üöÄ Testing VECTORIZED approach ({total_cells} cells, {num_iterations} iterations)..."
    )

    for iteration in range(num_iterations):
        start_time = time.time()

        # VECTORIZED PROCESSING - –≤—Å–µ –∫–ª–µ—Ç–∫–∏ —Å—Ä–∞–∑—É
        final_states = vectorized_cell.forward_batch(
            batch_neighbor_states=neighbor_states,
            batch_own_states=states,
            batch_external_input=external_inputs,
        )

        iteration_time = time.time() - start_time
        processing_times.append(iteration_time)

        if iteration % 3 == 0:
            print(f"   Iteration {iteration+1}: {iteration_time:.3f}s")

    avg_time = sum(processing_times) / len(processing_times)
    cells_per_second = total_cells / avg_time

    return {
        "approach": "vectorized_batch",
        "avg_time": avg_time,
        "cells_per_second": cells_per_second,
        "processing_times": processing_times,
        "total_cells": total_cells,
    }


def benchmark_spatial_processor(
    dimensions=(10, 10, 10), num_iterations: int = 5
) -> Dict[str, Any]:
    """–ë–µ–Ω—á–º–∞—Ä–∫ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ spatial processor"""

    total_cells = dimensions[0] * dimensions[1] * dimensions[2]
    state_size = 32

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    states = torch.randn(total_cells, state_size)

    # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π spatial processor
    spatial_processor = VectorizedSpatialProcessor(dimensions)
    vectorized_cell = VectorizedGNNCell()

    processing_times = []

    print(
        f"üåê Testing SPATIAL PROCESSOR ({total_cells} cells, {num_iterations} iterations)..."
    )

    def cell_processor_func(
        neighbor_states: torch.Tensor, own_state: torch.Tensor, **kwargs
    ) -> torch.Tensor:
        """Wrapper —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è spatial processor"""
        return vectorized_cell.forward_batch(
            batch_neighbor_states=neighbor_states, batch_own_states=own_state
        )

    for iteration in range(num_iterations):
        start_time = time.time()

        # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ spatial processor
        new_states = spatial_processor.process_lattice_vectorized(
            states, cell_processor_func
        )

        iteration_time = time.time() - start_time
        processing_times.append(iteration_time)

        print(f"   Iteration {iteration+1}: {iteration_time:.3f}s")

    avg_time = sum(processing_times) / len(processing_times)
    cells_per_second = total_cells / avg_time

    return {
        "approach": "vectorized_spatial_processor",
        "avg_time": avg_time,
        "cells_per_second": cells_per_second,
        "processing_times": processing_times,
        "total_cells": total_cells,
    }


def run_comprehensive_benchmark():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""

    print("=" * 70)
    print("üî¨ VECTORIZED FORWARD PASS BENCHMARK")
    print("=" * 70)

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤
    test_configs = [
        {"dimensions": (5, 5, 5), "name": "Small (125 cells)"},
        {"dimensions": (10, 10, 10), "name": "Medium (1,000 cells)"},
        {"dimensions": (15, 15, 15), "name": "Large (3,375 cells)"},
    ]

    results = []

    for config in test_configs:
        dimensions = config["dimensions"]
        name = config["name"]

        print(f"\nüìä {name}")
        print("-" * 40)

        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        states, neighbor_states, external_inputs = create_test_data(
            dimensions=dimensions
        )

        # –ë–µ–Ω—á–º–∞—Ä–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
        original_result = benchmark_original_approach(
            states, neighbor_states, external_inputs, num_iterations=5
        )

        # –ë–µ–Ω—á–º–∞—Ä–∫ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
        vectorized_result = benchmark_vectorized_approach(
            states, neighbor_states, external_inputs, num_iterations=5
        )

        # –ë–µ–Ω—á–º–∞—Ä–∫ spatial processor
        spatial_result = benchmark_spatial_processor(
            dimensions=dimensions, num_iterations=3
        )

        # –í—ã—á–∏—Å–ª—è–µ–º speedup
        speedup_vectorized = original_result["avg_time"] / vectorized_result["avg_time"]
        speedup_spatial = original_result["avg_time"] / spatial_result["avg_time"]

        result = {
            "name": name,
            "dimensions": dimensions,
            "original": original_result,
            "vectorized": vectorized_result,
            "spatial": spatial_result,
            "speedup_vectorized": speedup_vectorized,
            "speedup_spatial": speedup_spatial,
        }
        results.append(result)

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"\nüìà RESULTS for {name}:")
        print(
            f"   Original:    {original_result['avg_time']:.3f}s ({original_result['cells_per_second']:.0f} cells/s)"
        )
        print(
            f"   Vectorized:  {vectorized_result['avg_time']:.3f}s ({vectorized_result['cells_per_second']:.0f} cells/s)"
        )
        print(
            f"   Spatial:     {spatial_result['avg_time']:.3f}s ({spatial_result['cells_per_second']:.0f} cells/s)"
        )
        print(f"   Speedup (Vectorized): {speedup_vectorized:.1f}x")
        print(f"   Speedup (Spatial):    {speedup_spatial:.1f}x")

    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–≤–æ–¥–∫–∞
    print("\n" + "=" * 70)
    print("üìä FINAL SUMMARY")
    print("=" * 70)

    total_speedup_vectorized = sum(r["speedup_vectorized"] for r in results) / len(
        results
    )
    total_speedup_spatial = sum(r["speedup_spatial"] for r in results) / len(results)

    print(f"Average Speedup (Vectorized): {total_speedup_vectorized:.1f}x")
    print(f"Average Speedup (Spatial):    {total_speedup_spatial:.1f}x")

    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    create_performance_plot(results)

    return results


def create_performance_plot(results: List[Dict]):
    """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""

    names = [r["name"] for r in results]
    original_times = [r["original"]["avg_time"] for r in results]
    vectorized_times = [r["vectorized"]["avg_time"] for r in results]
    spatial_times = [r["spatial"]["avg_time"] for r in results]

    x = range(len(names))
    width = 0.25

    plt.figure(figsize=(12, 8))

    plt.bar(
        [i - width for i in x],
        original_times,
        width,
        label="Original (Sequential)",
        alpha=0.8,
        color="red",
    )
    plt.bar(
        x,
        vectorized_times,
        width,
        label="Vectorized GNN Cell",
        alpha=0.8,
        color="green",
    )
    plt.bar(
        [i + width for i in x],
        spatial_times,
        width,
        label="Vectorized Spatial Processor",
        alpha=0.8,
        color="blue",
    )

    plt.xlabel("Test Configuration")
    plt.ylabel("Processing Time (seconds)")
    plt.title("Forward Pass Performance Comparison\n(Lower is Better)")
    plt.xticks(x, names)
    plt.legend()
    plt.grid(True, alpha=0.3)

    # –î–æ–±–∞–≤–ª—è–µ–º speedup –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    for i, result in enumerate(results):
        plt.annotate(
            f'{result["speedup_vectorized"]:.1f}x',
            xy=(i, vectorized_times[i]),
            xytext=(5, 5),
            textcoords="offset points",
            fontsize=9,
            color="green",
        )
        plt.annotate(
            f'{result["speedup_spatial"]:.1f}x',
            xy=(i + width, spatial_times[i]),
            xytext=(5, 5),
            textcoords="offset points",
            fontsize=9,
            color="blue",
        )

    plt.tight_layout()
    plt.savefig("vectorized_forward_pass_benchmark.png", dpi=300, bbox_inches="tight")
    plt.show()

    print(f"üìä Performance plot saved as 'vectorized_forward_pass_benchmark.png'")


if __name__ == "__main__":
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è —Ç–µ—Å—Ç–æ–≤
    test_config = ProjectConfig()
    test_config.device.prefer_cuda = True
    test_config.logging.debug_mode = False  # –û—Ç–∫–ª—é—á–∞–µ–º debug –ª–æ–≥–∏ –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞
    set_project_config(test_config)

    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–µ–Ω—á–º–∞—Ä–∫
    results = run_comprehensive_benchmark()

    print("\nüéâ Benchmark completed!")
    print("Key takeaways:")
    print("1. ‚úÖ Vectorized processing eliminates sequential bottlenecks")
    print("2. ‚úÖ GPU parallelization provides significant speedup")
    print("3. ‚úÖ Batch operations are much more memory efficient")
    print("4. ‚úÖ Scalability improves with larger lattice sizes")
