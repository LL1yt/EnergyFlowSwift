#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ dataset –º–æ–¥—É–ª—è
==========================================

–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
- –°–æ–∑–¥–∞–Ω–∏–µ DatasetManager —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å EnergyTrainer
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from energy_flow.config import create_debug_config, set_energy_config
from energy_flow.dataset import (
    DatasetConfig, 
    DatasetManager,
    create_dataset_config_from_energy,
    create_dataset_manager
)
from energy_flow.dataset.utils import create_dataset_summary_report
from energy_flow.training import EnergyTrainer
from energy_flow.utils.logging import get_logger

logger = get_logger(__name__)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è dataset –º–æ–¥—É–ª—è"""
    print("üöÄ Energy Flow Dataset Module Demo")
    print("=" * 50)
    
    # 1. –°–æ–∑–¥–∞–µ–º —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    print("\n1Ô∏è‚É£ Creating energy configuration...")
    energy_config = create_debug_config()
    set_energy_config(energy_config)
    
    # 2. –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–∞—Ç–∞—Å–µ—Ç–∞ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è)
    print("\n2Ô∏è‚É£ Creating dataset configuration...")
    dataset_config = create_dataset_config_from_energy(
        energy_config,
        dataset_sources=["precomputed", "snli"],  # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        max_samples_per_source=50  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –¥–µ–º–æ
    )
    
    print(f"Dataset config: sources={dataset_config.dataset_sources}, "
          f"batch_size={dataset_config.batch_size}")
    
    # 3. –°–æ–∑–¥–∞–µ–º DatasetManager
    print("\n3Ô∏è‚É£ Creating DatasetManager...")
    dataset_manager = create_dataset_manager(dataset_config, energy_config)
    
    # 4. –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É
    print("\n4Ô∏è‚É£ Running comprehensive validation...")
    validation = dataset_manager.validate_setup()
    
    print(f"Validation results:")
    print(f"  Teacher model: {'‚úÖ' if validation['teacher_model'] else '‚ùå'}")
    print(f"  Providers: {sum(validation['providers'].values())}/{len(validation['providers'])} available")
    print(f"  Dataset prep: {'‚úÖ' if validation['dataset_preparation'] else '‚ùå'}")
    print(f"  Overall: {'üéâ READY' if validation['overall_status'] else '‚ö†Ô∏è ISSUES'}")
    
    if validation['errors']:
        print(f"  Errors: {validation['errors']}")
    
    # 5. –ï—Å–ª–∏ –≤—Å–µ –≥–æ—Ç–æ–≤–æ, —Å–æ–∑–¥–∞–µ–º DataLoader
    if validation['overall_status']:
        print("\n5Ô∏è‚É£ Creating DataLoader...")
        dataloader = dataset_manager.create_dataloader(batch_size=8, shuffle=True)
        
        if dataloader:
            print(f"‚úÖ DataLoader created: {len(dataloader)} batches")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–¥–∏–Ω –±–∞—Ç—á
            print("\n6Ô∏è‚É£ Testing batch loading...")
            for i, batch in enumerate(dataloader):
                print(f"Batch {i+1}:")
                print(f"  Input texts: {len(batch['input_text'])}")
                print(f"  Target texts: {len(batch['target_text'])}")
                print(f"  Input embeddings: {batch['input_embedding'].shape}")
                print(f"  Target embeddings: {batch['target_embedding'].shape}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤
                print(f"  Example input: '{batch['input_text'][0][:50]}...'")
                print(f"  Example target: '{batch['target_text'][0][:50]}...'")
                
                if i >= 2:  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3 –±–∞—Ç—á–∞
                    break
            
            # 7. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å EnergyTrainer (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)
            print("\n7Ô∏è‚É£ Testing EnergyTrainer integration...")
            try:
                trainer = EnergyTrainer(energy_config)
                
                # –ü–æ–ª—É—á–∞–µ–º –æ–¥–∏–Ω –±–∞—Ç—á –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                test_batch = next(iter(dataloader))
                input_texts = test_batch['input_text']
                target_texts = test_batch['target_text']
                input_embeddings = test_batch['input_embedding']
                target_embeddings = test_batch['target_embedding']
                
                print(f"‚úÖ EnergyTrainer initialized successfully")
                print(f"   Ready for training with {len(input_texts)} samples per batch")
                
                # –ú–æ–∂–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                # step_metrics = trainer.train_step(input_texts, target_texts, input_embeddings, target_embeddings)
                # print(f"   Test training step completed: loss={step_metrics.get('total_loss', 'N/A')}")
                
            except Exception as e:
                print(f"‚ùå EnergyTrainer integration failed: {e}")
        
        # 8. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        print("\n8Ô∏è‚É£ Generating summary report...")
        report = create_dataset_summary_report(dataset_manager)
        print(report)
        
    else:
        print("\n‚ùå Setup validation failed - cannot proceed with training")
        print("Please check the errors above and resolve them.")
    
    print("\nüéâ Demo completed!")


def test_teacher_model_only():
    """–¢–µ—Å—Ç —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏-—É—á–∏—Ç–µ–ª—è –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    print("\nüß™ Testing Teacher Model Only")
    print("-" * 30)
    
    # –ü—Ä–æ—Å—Ç–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è teacher model
    from energy_flow.dataset.config import DatasetConfig
    from energy_flow.dataset.providers import create_teacher_model_provider
    
    config = DatasetConfig(
        teacher_model="distilbert-base-uncased",
        use_local_model=True
    )
    
    teacher_provider = create_teacher_model_provider(config)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
    if teacher_provider.is_available():
        print("‚úÖ Teacher model available")
        
        if teacher_provider.ensure_initialized():
            print("‚úÖ Teacher model initialized")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            test_texts = [
                "What is artificial intelligence?",
                "How does machine learning work?",
                "The weather is nice today."
            ]
            
            embeddings = teacher_provider.encode_texts(test_texts)
            print(f"‚úÖ Generated embeddings: {embeddings.shape}")
            print(f"   Embedding norms: {embeddings.norm(dim=1).tolist()}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
            cache_info = teacher_provider.get_cache_info()
            print(f"   Cache info: {cache_info}")
        else:
            print("‚ùå Teacher model initialization failed")
    else:
        print("‚ùå Teacher model not available")
        
        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å
        if teacher_provider.download_model_if_needed():
            print("‚úÖ Model downloaded successfully, try again")
        else:
            print("‚ùå Model download failed")


if __name__ == "__main__":
    try:
        main()
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç teacher model
        test_teacher_model_only()
        
    except KeyboardInterrupt:
        print("\nüõë Demo interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Demo failed with error: {e}")
        import traceback
        traceback.print_exc()