#!/usr/bin/env python3
"""
–¢–ï–°–¢ –î–ò–ù–ê–ú–ò–ß–ï–°–ö–û–ô –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò –≤ —Ä–µ–∂–∏–º–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ (scale=0.01)
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è development —Ä–µ–∂–∏–º–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –æ–±—É—á–µ–Ω–∏—è
"""

import logging
import torch
from pathlib import Path
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
sys.path.append(str(Path(__file__).parent))

from utils.config_manager.dynamic_config import DynamicConfigManager

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def test_development_mode():
    """–¢–µ—Å—Ç development —Ä–µ–∂–∏–º–∞ (scale=0.01)"""
    print("üß™ –¢–ï–°–¢ –†–ê–ó–í–ò–¢–û–ì–û –†–ï–ñ–ò–ú–ê (SCALE=0.01)")
    print("=" * 50)

    try:
        # –°–æ–∑–¥–∞–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä
        config_manager = DynamicConfigManager()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–ø–ø–∞—Ä–∞—Ç—É—Ä—É
        import torch

        gpu_memory_gb = 0
        gpu_name = "CPU"
        if torch.cuda.is_available():
            gpu_props = torch.cuda.get_device_properties(0)
            gpu_memory_gb = gpu_props.total_memory / (1024**3)
            gpu_name = gpu_props.name

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º —á–µ—Ä–µ–∑ generator
        recommended_mode = config_manager.generator.detect_hardware_mode()

        print(f"üìä –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–∞—è –∞–ø–ø–∞—Ä–∞—Ç—É—Ä–∞:")
        print(f"   GPU: {gpu_name}")
        print(f"   VRAM: {gpu_memory_gb:.1f} GB")
        print(f"   –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º: {recommended_mode}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è development —Ä–µ–∂–∏–º–∞
        config = config_manager.create_config_for_mode("development")

        # –ü–æ–ª—É—á–∞–µ–º scale_factor –∏–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –º–µ—Å—Ç–∞
        scale_factor = config.get("_metadata", {}).get("scale_factor") or config.get(
            "lattice", {}
        ).get("scale_factor")

        print(f"\nüìê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø DEVELOPMENT –†–ï–ñ–ò–ú–ê:")
        print(f"   Scale factor: {scale_factor}")
        print(
            f"   Lattice size: {config['lattice']['xs']}√ó{config['lattice']['ys']}√ó{config['lattice']['zs']}"
        )
        print(f"   Total neurons: {config['lattice']['total_neurons']:,}")
        print(f"   Embedding dim: {config['embeddings']['embedding_dim']:,}")
        print(f"   Batch size: {config['training']['batch_size']}")
        print(f"   Learning rate: {config['training']['learning_rate']}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ development —Ä–µ–∂–∏–º (scale=0.01)
        assert scale_factor == 0.01, f"Expected scale=0.01, got {scale_factor}"

        # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–∏–º–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–∞–º—è—Ç–∏
        lattice_size = (
            config["lattice"]["xs"] * config["lattice"]["ys"] * config["lattice"]["zs"]
        )
        embedding_dim = config["embeddings"]["embedding_dim"]
        estimated_memory_gb = (lattice_size * embedding_dim * 4) / (1024**3)  # float32

        print(f"\nüíæ –û–¶–ï–ù–ö–ê –ü–ê–ú–Ø–¢–ò:")
        print(f"   –ü—Ä–∏–º–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ä–µ—à–µ—Ç–∫–∏: {estimated_memory_gb:.2f} GB")
        print(f"   –î–æ—Å—Ç—É–ø–Ω–∞—è VRAM: {gpu_memory_gb:.1f} GB")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞ –∏ –ø–∞–º—è—Ç–∏
        batch_memory = (config["training"]["batch_size"] * embedding_dim * 4) / (
            1024**2
        )  # MB
        print(f"   –ü–∞–º—è—Ç—å –Ω–∞ –±–∞—Ç—á: {batch_memory:.1f} MB")

        print(f"\n‚úÖ –¢–ï–°–¢ –ü–†–û–®–ï–õ –£–°–ü–ï–®–ù–û!")
        print(f"   Development —Ä–µ–∂–∏–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        print(f"   Scale factor: {scale_factor} (–ø—Ä–∞–≤–∏–ª—å–Ω–æ –¥–ª—è development)")
        print(f"   –†–∞–∑–º–µ—Ä—ã –ø–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ precomputed datasets
        try:
            from precomputed_embedding_loader import PrecomputedEmbeddingLoader

            loader = PrecomputedEmbeddingLoader()
            datasets = loader.list_available_datasets()

            if datasets:
                print(f"\nüìÅ –î–û–°–¢–£–ü–ù–´–ï –î–ê–¢–ê–°–ï–¢–´:")
                for i, dataset in enumerate(datasets[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                    print(f"   {i+1}. {dataset['filename']} ({dataset['size']} pairs)")
                print(f"   –í—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤: {len(datasets)}")
            else:
                print(f"\n‚ö†Ô∏è –î–ê–¢–ê–°–ï–¢–´ –ù–ï –ù–ê–ô–î–ï–ù–´!")
                print(f"   –ù—É–∂–Ω–æ —Å–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç—å generate_large_embedding_dataset.py")

        except ImportError as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ PrecomputedEmbeddingLoader: {e}")

        return config

    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê –¢–ï–°–¢–ê: {e}")
        raise


def test_checkpoint_naming():
    """–¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è checkpoint'–æ–≤"""
    print(f"\nüè∑Ô∏è –¢–ï–°–¢ –ò–ú–ï–ù–û–í–ê–ù–ò–Ø CHECKPOINT'–û–í")
    print("=" * 50)

    try:
        from datetime import datetime

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è
        mode = "development"
        scale_factor = 0.01
        dataset_size = 1000
        epochs = 50
        best_similarity = 0.234
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞–∫ –≤ —Å–∏—Å—Ç–µ–º–µ
        result_name = f"dynamic_{mode}_scale{scale_factor}_{dataset_size}pairs_{epochs}epochs_{best_similarity:.3f}sim_{timestamp}"

        print(f"‚úÖ –ü—Ä–∏–º–µ—Ä –Ω–∞–∑–≤–∞–Ω–∏—è checkpoint'–∞:")
        print(f"   {result_name}")
        print(f"   –°–æ–¥–µ—Ä–∂–∏—Ç scale factor: ‚úì")
        print(f"   –°–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ–∂–∏–º: ‚úì")
        print(f"   –°–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: ‚úì")
        print(f"   –°–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö: ‚úì")
        print(f"   –°–æ–¥–µ—Ä–∂–∏—Ç –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: ‚úì")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞ –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è: {e}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∞"""
    print("üß™ –¢–ï–°–¢ –î–ò–ù–ê–ú–ò–ß–ï–°–ö–û–ô –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò –î–õ–Ø DEVELOPMENT –†–ï–ñ–ò–ú–ê")
    print("–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ scale=0.01 –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å precomputed embeddings")
    print()

    try:
        # –¢–µ—Å—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config = test_development_mode()

        # –¢–µ—Å—Ç –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è
        test_checkpoint_naming()

        print(f"\nüéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–®–õ–ò –£–°–ü–ï–®–ù–û!")
        print(f"   Development —Ä–µ–∂–∏–º –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
        print(f"   –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å: python run_dynamic_training.py --mode development")

        return 0

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
