# Embedding Trainer ‚úÖ Stage 2.1 DIALOGUE TRAINING –ó–ê–í–ï–†–®–ï–ù!

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** –ú–æ–¥—É–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è 3D Cubic Core (–ú–æ–¥—É–ª—å 2) –Ω–∞ —ç–º–±–µ–¥–∏–Ω–≥‚Üí—ç–º–±–µ–¥–∏–Ω–≥ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è—Ö

## üéâ Breakthrough Milestone: DIALOGUE TRAINING FUNCTIONAL!

**Stage 2.1 —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω (7 –∏—é–Ω—è 2025)** - –ø–æ–ª–Ω—ã–π dialogue training pipeline —Ä–∞–±–æ—Ç–∞–µ—Ç!
3D Cubic Core –Ω–∞—É—á–∏–ª—Å—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å Q‚ÜíA —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Teacher LLM Knowledge Distillation.

**–ó–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ —ç—Ç–∞–ø—ã:**

- ‚úÖ **Stage 1.1** - CubeTrainer (8/8 —Ç–µ—Å—Ç–æ–≤)
- ‚úÖ **Stage 1.2** - AutoencoderDataset (10/10 —Ç–µ—Å—Ç–æ–≤)
- ‚úÖ **Stage 1.3** - DialogueDataset (ALL —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ) ‚≠ê
- ‚úÖ **Stage 2.1** - Dialogue Training Execution (FUNCTIONAL) ‚≠ê NEW!

## –û–±–∑–æ—Ä

EmbeddingTrainer —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Å–∏—Å—Ç–µ–º—ã - 3D Cubic Core. –ú–æ–¥—É–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ä–µ–∂–∏–º–∞ –æ–±—É—á–µ–Ω–∏—è:

1. **Autoencoder Mode** - –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö —ç–º–±–µ–¥–∏–Ω–≥–æ–≤
2. **Dialogue Mode** - –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –ø–∞—Ä–∞—Ö (–≤–æ–ø—Ä–æ—Å‚Üí–æ—Ç–≤–µ—Ç)

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
–í—Ö–æ–¥–Ω–æ–π —ç–º–±–µ–¥–∏–Ω–≥ ‚Üí EmbeddingReshaper ‚Üí 3D Cubic Core ‚Üí EmbeddingReshaper ‚Üí –í—ã—Ö–æ–¥–Ω–æ–π —ç–º–±–µ–¥–∏–Ω–≥
     (768D)              (8√ó8√ó12)         (–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä)        (8√ó8√ó12)           (768D)
```

## –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

- ‚úÖ **`CubeTrainer`** - –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∫—É–±–∞ (–ó–ê–í–ï–†–®–ï–ù!)
- ‚úÖ **`TrainingConfig`** - —Å–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–ó–ê–í–ï–†–®–ï–ù–ê!)
- ‚úÖ **`EmbeddingMetrics`** - –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–∏—è (–ó–ê–í–ï–†–®–ï–ù–´!)
- ‚úÖ **`AutoencoderDataset`** - –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è autoencoder –∑–∞–¥–∞—á (–ó–ê–í–ï–†–®–ï–ù!)
- ‚úÖ **`DatasetConfig`** - –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è dataset'–æ–≤ (–ó–ê–í–ï–†–®–ï–ù–ê!)
- ‚úÖ **`create_text_dataset`** - —É–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤ (–ì–û–¢–û–í–ê!)
- ‚úÖ **`create_file_dataset`** - —É–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–æ–≤ (–ì–û–¢–û–í–ê!)
- ‚úÖ **`DialogueDataset`** - –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –∑–∞–¥–∞—á (–ó–ê–í–ï–†–®–ï–ù!) ‚≠ê
- ‚úÖ **`create_dialogue_dataset`** - —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è Q&A –¥–∞–Ω–Ω—ã—Ö (–ì–û–¢–û–í–ê!) ‚≠ê
- ‚úÖ **`run_dialogue_training.py`** - –ø–æ–ª–Ω—ã–π dialogue training pipeline (FUNCTIONAL!) ‚≠ê NEW!

## –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. AutoencoderDataset ‚úÖ –ì–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!

```python
from training.embedding_trainer import (
    AutoencoderDataset,
    create_text_dataset,
    create_file_dataset
)

# –°–æ–∑–¥–∞–Ω–∏–µ dataset –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤ ‚≠ê NEW!
texts = [
    "Machine learning is transforming the world",
    "Neural networks can learn complex patterns",
    "Deep learning enables amazing applications"
]

dataset = create_text_dataset(
    texts=texts,
    llm_model="distilbert",  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ 8+ LLM –º–æ–¥–µ–ª–µ–π
    validation_split=0.2,
    use_cache=True,          # Smart caching
    normalize_embeddings=True
)

# –°–æ–∑–¥–∞–Ω–∏–µ DataLoaders –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
train_loader = dataset.get_dataloader(batch_size=32, validation=False)
val_loader = dataset.get_dataloader(batch_size=32, validation=True)

print(f"Dataset –≥–æ—Ç–æ–≤: {dataset}")
print(f"Train batches: {len(train_loader)}")
print(f"Val batches: {len(val_loader)}")

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ autoencoder format
for input_emb, target_emb in train_loader:
    print(f"Batch shapes: {input_emb.shape} -> {target_emb.shape}")
    break  # input_emb == target_emb –¥–ª—è autoencoder —Ä–µ–∂–∏–º–∞
```

### 2. CubeTrainer ‚úÖ –ì–æ—Ç–æ–≤ –∫ –æ–±—É—á–µ–Ω–∏—é!

```python
from training.embedding_trainer import CubeTrainer, TrainingConfig

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
config = TrainingConfig(
    mode="autoencoder",  # autoencoder | dialogue | mixed
    lattice_size=[8, 8, 8],
    learning_rate=0.001,
    epochs=50,
    batch_size=32
)

# –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–Ω–µ—Ä–∞ ‚úÖ –†–ê–ë–û–¢–ê–ï–¢!
trainer = CubeTrainer(config=config)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
trainer.initialize_components()

# –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç—Ä–µ–Ω–µ—Ä–µ
info = trainer.get_info()
print(f"–†–µ–∂–∏–º: {info['mode']}")
print(f"–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≥–æ—Ç–æ–≤—ã: {info['components_initialized']}")

# Forward pass (–≥–æ—Ç–æ–≤ –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏)
# output = trainer.forward(input_embedding)
```

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- –ú–æ–¥—É–ª—å 1 (Teacher LLM Encoder) –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≥–æ—Ç–æ–≤
- –ú–æ–¥—É–ª—å 2 (EmbeddingReshaper + EmbeddingProcessor) –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω
- –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤

## –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ `config/cube_training.yaml`:

```yaml
cube_training:
  mode: "autoencoder" # autoencoder | dialogue
  lattice_size: [8, 8, 8]
  learning_rate: 0.001
  epochs: 50
  batch_size: 32
  convergence_threshold: 0.001
  target_similarity: 0.90
```

## –°–≤—è–∑–∞–Ω–Ω—ã–µ –º–æ–¥—É–ª–∏

- `core/embedding_processor/` - –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
- `data/embedding_loader/` - –∏—Å—Ç–æ—á–Ω–∏–∫ –æ–±—É—á–∞—é—â–∏—Ö —ç–º–±–µ–¥–∏–Ω–≥–æ–≤
- `data/embedding_reshaper/` - –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤
- `evaluation/embedding_metrics/` - –¥–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞

## –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- `plan.md` - –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
- `meta.md` - —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
- `examples.md` - –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
- `diagram.mmd` - –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
