# Embedding Trainer - –ü—Ä–∏–º–µ—Ä—ã –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ‚úÖ Stage 1.1 –ì–û–¢–û–í!

**–¶–µ–ª—å:** –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ, —Ä–∞–±–æ—Ç–∞—é—â–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ –¥–ª—è –º–æ–¥—É–ª—è embedding_trainer  
**–û–±–Ω–æ–≤–ª–µ–Ω–æ:** 6 –∏—é–Ω—è 2025

---

## üöÄ –ë–ê–ó–û–í–´–ï –ü–†–ò–ú–ï–†–´

### ‚úÖ –ü—Ä–∏–º–µ—Ä 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CubeTrainer (–†–ê–ë–û–¢–ê–ï–¢!)

```python
# ‚úÖ –ì–û–¢–û–í–û: CubeTrainer –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–µ–Ω!
from training.embedding_trainer import CubeTrainer, TrainingConfig

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
config = TrainingConfig(
    mode="autoencoder",
    lattice_size=[8, 8, 8],
    learning_rate=0.001,
    epochs=50,
    device="cpu"
)

# –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–Ω–µ—Ä–∞
trainer = CubeTrainer(config=config)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
info = trainer.get_info()
print(f"–†–µ–∂–∏–º: {info['mode']}")
print(f"Lattice size: {info['lattice_size']}")
print(f"Learning rate: {trainer.config.learning_rate}")
print(f"–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≥–æ—Ç–æ–≤—ã: {info['components_initialized']}")
```

**‚úÖ –†–µ–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**

```
–†–µ–∂–∏–º: autoencoder
Lattice size: [8, 8, 8]
Learning rate: 0.001
–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≥–æ—Ç–æ–≤—ã: False
```

### ‚úÖ –ü—Ä–∏–º–µ—Ä 2: –ü–æ–ª–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å CubeTrainer (–†–ê–ë–û–¢–ê–ï–¢!)

```python
# ‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π Stage 1.1
from training.embedding_trainer import CubeTrainer, TrainingConfig, EmbeddingMetrics
import torch

# 1. –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
config_dict = {
    'mode': 'dialogue',
    'lattice_size': [6, 6, 6],
    'learning_rate': 0.002,
    'target_similarity': 0.92
}

trainer = CubeTrainer(config=config_dict)
print(f"‚úÖ –°–æ–∑–¥–∞–Ω –∏–∑ —Å–ª–æ–≤–∞—Ä—è: {trainer.config.mode}")

# 2. –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤
trainer.set_mode("mixed")
print(f"‚úÖ –†–µ–∂–∏–º –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: {trainer.config.mode}")

# 3. –†–∞–±–æ—Ç–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
metrics = EmbeddingMetrics(device="cpu")

# –¢–µ—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–∏–Ω–≥–∏
emb1 = torch.randn(2, 768)
emb2 = torch.randn(2, 768)

batch_metrics = metrics.compute_batch_metrics(emb1, emb2)
print("‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã:")
for metric, value in batch_metrics.items():
    print(f"   {metric}: {value:.4f}")

# 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ forward pass –±–µ–∑ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
try:
    output = trainer.forward(torch.randn(1, 768))
except ValueError as e:
    print(f"‚úÖ –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")

print("üéâ –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç!")
```

**‚úÖ –†–µ–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**

```
‚úÖ –°–æ–∑–¥–∞–Ω –∏–∑ —Å–ª–æ–≤–∞—Ä—è: dialogue
‚úÖ –†–µ–∂–∏–º –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: mixed
‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã:
   cosine_similarity: 0.0234
   mse_loss: 2.0156
   semantic_preservation: 0.0117
‚úÖ –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: Components must be initialized before forward pass
üéâ –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç!
```

### –ü—Ä–∏–º–µ—Ä 3: –°–æ–∑–¥–∞–Ω–∏–µ Autoencoder Dataset (–ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è Stage 1.2)

```python
from training.embedding_trainer import AutoencoderDataset
from data.embedding_loader import EmbeddingLoader

# –ó–∞–≥—Ä—É–∑–∫–∞ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –∏–∑ Teacher LLM
embedding_loader = EmbeddingLoader(model_name="llama3-8b")

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
sample_texts = [
    "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç —Ä–∞–∑–≤–∏–≤–∞–µ—Ç—Å—è –±—ã—Å—Ç—Ä–æ.",
    "–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –æ–±—É—á–∞—é—Ç—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö.",
    "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Ä–µ—à–∞–µ—Ç —Å–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏.",
    "–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ —Å–µ—Ç–∏."
]

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
dataset = AutoencoderDataset(
    texts=sample_texts,
    embedding_loader=embedding_loader,
    cache_embeddings=True
)

print(f"Dataset size: {len(dataset)}")

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞
sample = dataset[0]
print(f"Input shape: {sample['input'].shape}")
print(f"Target shape: {sample['target'].shape}")
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**

```
Dataset size: 4
Input shape: torch.Size([768])
Target shape: torch.Size([768])
```

### –ü—Ä–∏–º–µ—Ä 3: Dialogue Dataset

```python
from training.embedding_trainer import DialogueDataset

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –ø–∞—Ä
dialogue_pairs = [
    {
        "question": "–ß—Ç–æ —Ç–∞–∫–æ–µ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å?",
        "answer": "–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å - —ç—Ç–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å, –≤–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã–º–∏ —Å–µ—Ç—è–º–∏."
    },
    {
        "question": "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º?",
        "answer": "–û–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏."
    }
]

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
dialogue_dataset = DialogueDataset(
    dialogue_pairs=dialogue_pairs,
    embedding_loader=embedding_loader,
    cache_embeddings=True
)

print(f"Dialogue dataset size: {len(dialogue_dataset)}")

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞
sample = dialogue_dataset[0]
print(f"Question embedding: {sample['input'].shape}")
print(f"Answer embedding: {sample['target'].shape}")
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**

```
Dialogue dataset size: 2
Question embedding: torch.Size([768])
Answer embedding: torch.Size([768])
```

---

## üéì –ü–†–ò–ú–ï–†–´ –û–ë–£–ß–ï–ù–ò–Ø

### –ü—Ä–∏–º–µ—Ä 4: –ë–∞–∑–æ–≤–æ–µ Autoencoder –û–±—É—á–µ–Ω–∏–µ

```python
import torch
from torch.utils.data import DataLoader

# –°–æ–∑–¥–∞–Ω–∏–µ DataLoader
dataloader = DataLoader(
    dataset,
    batch_size=2,
    shuffle=True
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç—Ä–µ–Ω–µ—Ä–∞
trainer.setup_training(
    dataloader=dataloader,
    learning_rate=0.001,
    optimizer_type="adam"
)

# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö
print("Starting training...")
for epoch in range(5):
    metrics = trainer.train_epoch()
    print(f"Epoch {epoch+1}: Loss={metrics['loss']:.4f}, "
          f"Similarity={metrics['cosine_similarity']:.4f}")
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**

```
Starting training...
Epoch 1: Loss=0.2456, Similarity=0.8234
Epoch 2: Loss=0.1892, Similarity=0.8567
Epoch 3: Loss=0.1523, Similarity=0.8798
Epoch 4: Loss=0.1289, Similarity=0.8923
Epoch 5: Loss=0.1156, Similarity=0.9012
```

### –ü—Ä–∏–º–µ—Ä 5: Dialogue Training

```python
# –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –≤ dialogue —Ä–µ–∂–∏–º
trainer.set_mode("dialogue")

# –°–æ–∑–¥–∞–Ω–∏–µ DataLoader –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤
dialogue_loader = DataLoader(
    dialogue_dataset,
    batch_size=1,
    shuffle=True
)

# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
print("Starting dialogue training...")
for epoch in range(3):
    trainer.setup_training(dataloader=dialogue_loader)
    metrics = trainer.train_epoch()
    print(f"Dialogue Epoch {epoch+1}: "
          f"Loss={metrics['loss']:.4f}, "
          f"Relevance={metrics['semantic_relevance']:.4f}")
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**

```
Starting dialogue training...
Dialogue Epoch 1: Loss=0.3123, Relevance=0.7845
Dialogue Epoch 2: Loss=0.2567, Relevance=0.8234
Dialogue Epoch 3: Loss=0.2198, Relevance=0.8456
```

---

## üìä –ü–†–ò–ú–ï–†–´ –û–¶–ï–ù–ö–ò –ò –ú–ï–¢–†–ò–ö

### –ü—Ä–∏–º–µ—Ä 6: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ú–µ—Ç—Ä–∏–∫

```python
from training.embedding_trainer import EmbeddingMetrics

# –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –º–µ—Ç—Ä–∏–∫
metrics = EmbeddingMetrics()

# –¢–µ—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–∏–Ω–≥–∏
test_input = torch.randn(4, 768)
test_output = trainer.model.forward(test_input)

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
similarity_score = metrics.cosine_similarity(test_input, test_output)
mse_score = metrics.mse_loss(test_input, test_output)
semantic_preservation = metrics.semantic_preservation(test_input, test_output)

print(f"Cosine Similarity: {similarity_score:.4f}")
print(f"MSE Loss: {mse_score:.4f}")
print(f"Semantic Preservation: {semantic_preservation:.4f}")
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**

```
Cosine Similarity: 0.9012
MSE Loss: 0.0234
Semantic Preservation: 0.8876
```

### –ü—Ä–∏–º–µ—Ä 7: –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –û—Ü–µ–Ω–∫–∞

```python
# –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏
evaluation_results = trainer.evaluate(
    test_dataloader=dataloader,
    metrics=['cosine_similarity', 'mse_loss', 'semantic_preservation']
)

print("=== Evaluation Results ===")
for metric, value in evaluation_results.items():
    print(f"{metric}: {value:.4f}")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
target_similarity = 0.90
if evaluation_results['cosine_similarity'] >= target_similarity:
    print(f"‚úÖ Target similarity achieved: {evaluation_results['cosine_similarity']:.4f}")
else:
    print(f"‚ùå Target similarity not reached: {evaluation_results['cosine_similarity']:.4f}")
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**

```
=== Evaluation Results ===
cosine_similarity: 0.9123
mse_loss: 0.0198
semantic_preservation: 0.8967
‚úÖ Target similarity achieved: 0.9123
```

---

## üíæ –ü–†–ò–ú–ï–†–´ –°–û–•–†–ê–ù–ï–ù–ò–Ø –ò –ó–ê–ì–†–£–ó–ö–ò

### –ü—Ä–∏–º–µ—Ä 8: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Checkpoint

```python
from training.embedding_trainer import CheckpointManager

# –°–æ–∑–¥–∞–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —á–µ–∫–ø–æ–π–Ω—Ç–æ–≤
checkpoint_manager = CheckpointManager(
    checkpoint_dir="checkpoints/embedding_trainer"
)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
checkpoint_data = {
    'model_state': trainer.model.state_dict(),
    'optimizer_state': trainer.optimizer.state_dict(),
    'epoch': 10,
    'metrics': evaluation_results
}

checkpoint_path = checkpoint_manager.save_checkpoint(
    checkpoint_data,
    epoch=10,
    suffix="autoencoder"
)

print(f"Checkpoint saved: {checkpoint_path}")
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**

```
Checkpoint saved: checkpoints/embedding_trainer/epoch_10_autoencoder.pt
```

### –ü—Ä–∏–º–µ—Ä 9: –ó–∞–≥—Ä—É–∑–∫–∞ Checkpoint

```python
# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ checkpoint
loaded_data = checkpoint_manager.load_checkpoint(checkpoint_path)

# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–∏
trainer.model.load_state_dict(loaded_data['model_state'])
trainer.optimizer.load_state_dict(loaded_data['optimizer_state'])

print(f"Model restored from epoch: {loaded_data['epoch']}")
print(f"Restored metrics: {loaded_data['metrics']}")

# –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
trainer.resume_training(start_epoch=loaded_data['epoch'] + 1)
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**

```
Model restored from epoch: 10
Restored metrics: {'cosine_similarity': 0.9123, 'mse_loss': 0.0198}
Training resumed from epoch 11
```

---

## üîß –ü–†–û–î–í–ò–ù–£–¢–´–ï –ü–†–ò–ú–ï–†–´

### –ü—Ä–∏–º–µ—Ä 10: Mixed Mode Training

```python
# –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (autoencoder + dialogue)
trainer.set_mode("mixed")
trainer.configure_mixed_training(
    autoencoder_ratio=0.7,
    dialogue_ratio=0.3,
    alternate_epochs=True
)

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
mixed_config = {
    'autoencoder_data': dataloader,
    'dialogue_data': dialogue_loader,
    'epochs_per_mode': 2
}

# –ó–∞–ø—É—Å–∫ —Å–º–µ—à–∞–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
print("Starting mixed training...")
for cycle in range(3):
    # Autoencoder phase
    trainer.train_mixed_cycle(mixed_config, cycle)
    print(f"Mixed Cycle {cycle+1} completed")
```

### –ü—Ä–∏–º–µ—Ä 11: Custom Loss Function

```python
import torch.nn as nn

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–π loss —Ñ—É–Ω–∫—Ü–∏–∏
class CustomEmbeddingLoss(nn.Module):
    def __init__(self, cosine_weight=0.7, mse_weight=0.3):
        super().__init__()
        self.cosine_weight = cosine_weight
        self.mse_weight = mse_weight
        self.cosine_loss = nn.CosineSimilarity(dim=1)
        self.mse_loss = nn.MSELoss()

    def forward(self, input_emb, target_emb):
        cosine_sim = self.cosine_loss(input_emb, target_emb).mean()
        cosine_loss = 1 - cosine_sim  # Convert similarity to loss
        mse_loss = self.mse_loss(input_emb, target_emb)

        return self.cosine_weight * cosine_loss + self.mse_weight * mse_loss

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–π loss
custom_loss = CustomEmbeddingLoss()
trainer.set_loss_function(custom_loss)

print("Custom loss function configured")
```

---

## üß™ –ü–†–ò–ú–ï–†–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø

### –ü—Ä–∏–º–µ—Ä 12: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–µ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
def test_end_to_end_pipeline():
    """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ pipeline –æ–±—É—á–µ–Ω–∏—è"""

    # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    trainer = CubeTrainer(config=config, mode="autoencoder")

    # 2. –î–∞–Ω–Ω—ã–µ
    test_texts = ["–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ pipeline"]
    dataset = AutoencoderDataset(test_texts, embedding_loader)
    dataloader = DataLoader(dataset, batch_size=1)

    # 3. –û–±—É—á–µ–Ω–∏–µ
    trainer.setup_training(dataloader=dataloader)
    initial_loss = trainer.train_epoch()['loss']

    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è
    final_loss = trainer.train_epoch()['loss']

    assert final_loss < initial_loss, "Loss –¥–æ–ª–∂–µ–Ω —É–º–µ–Ω—å—à–∞—Ç—å—Å—è"
    print("‚úÖ End-to-end pipeline test passed")

# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
test_end_to_end_pipeline()
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**

```
‚úÖ End-to-end pipeline test passed
```

---

## üìã –ü–†–ò–ú–ï–†–´ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò

### –ü—Ä–∏–º–µ—Ä 13: –ü–æ–ª–Ω–∞—è YAML –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```yaml
# config/cube_training_example.yaml
embedding_trainer:
  # –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
  mode: "autoencoder"
  device: "cpu"
  random_seed: 42

  # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
  lattice_size: [8, 8, 8]
  embedding_dim: 768
  batch_size: 16

  # –û–±—É—á–µ–Ω–∏–µ
  learning_rate: 0.0005
  epochs: 30
  optimizer: "adam"
  loss_function: "cosine"

  # –ö–∞—á–µ—Å—Ç–≤–æ
  target_similarity: 0.92
  convergence_threshold: 0.0005
  early_stopping_patience: 5

  # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
  log_interval: 5
  save_interval: 10
  checkpoint_dir: "checkpoints/example_training"

  # –î–∞–Ω–Ω—ã–µ
  autoencoder_data:
    source_type: "embedding_loader"
    cache_embeddings: true
    max_samples: 1000
```

### –ü—Ä–∏–º–µ—Ä 14: –ü—Ä–æ–≥—Ä–∞–º–º–Ω–∞—è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```python
# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ
training_config = {
    'mode': 'dialogue',
    'device': 'cpu',
    'lattice_size': [6, 6, 6],  # –ú–µ–Ω—å—à–∏–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    'embedding_dim': 768,
    'batch_size': 8,
    'learning_rate': 0.002,
    'epochs': 20,
    'target_similarity': 0.88
}

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
trainer.update_config(training_config)
print(f"Configuration updated: {trainer.get_config()}")
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**

```
Configuration updated: {'mode': 'dialogue', 'device': 'cpu', 'lattice_size': [6, 6, 6], ...}
```

---

**üéØ –ü–†–ò–ù–¶–ò–ü: –í—Å–µ –ø—Ä–∏–º–µ—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ç–µ—Å—Ç–∏—Ä—É–µ–º—ã–º–∏ –∏ —Ä–∞–±–æ—á–∏–º–∏**

_–ö–∞–∂–¥—ã–π –ø—Ä–∏–º–µ—Ä –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é._
