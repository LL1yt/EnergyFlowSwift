# DialogueDataset Usage Examples - Stage 1.3

**–ú–æ–¥—É–ª—å:** DialogueDataset  
**–í–µ—Ä—Å–∏—è:** v1.3.0  
**–î–∞—Ç–∞:** 7 –∏—é–Ω—è 2025

---

## üéØ –û–°–ù–û–í–ù–´–ï –ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø

### 1. –ü—Ä–æ—Å—Ç–µ–π—à–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ - Q&A –ø–∞—Ä—ã

```python
from training.embedding_trainer import create_dialogue_dataset

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
dialogue_pairs = [
    {"question": "–ß—Ç–æ —Ç–∞–∫–æ–µ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å?", "answer": "–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å - —ç—Ç–æ –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è."},
    {"question": "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç backpropagation?", "answer": "Backpropagation –æ–±–Ω–æ–≤–ª—è–µ—Ç –≤–µ—Å–∞ —á–µ—Ä–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –æ—à–∏–±–∫–∏."},
    {"question": "–ß—Ç–æ —Ç–∞–∫–æ–µ PyTorch?", "answer": "PyTorch - —ç—Ç–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ Python."}
]

# –°–æ–∑–¥–∞–Ω–∏–µ dataset
dataset = create_dialogue_dataset(
    dialogue_pairs=dialogue_pairs,
    teacher_model="distilbert",
    validation_split=0.2
)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ —Ü–∏–∫–ª–µ –æ–±—É—á–µ–Ω–∏—è
for question_emb, answer_emb in dataset:
    print(f"Q: {question_emb.shape} ‚Üí A: {answer_emb.shape}")  # [768] ‚Üí [768]
```

### 2. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CubeTrainer

```python
from training.embedding_trainer import CubeTrainer, TrainingConfig, create_dialogue_dataset

# 1. –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–æ–≤–æ–≥–æ dataset
dialogue_pairs = [
    {"question": "–ö–∞–∫ –æ–±—É—á–∞—é—Ç—Å—è –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏?", "answer": "–ß–µ—Ä–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫."},
    {"question": "–ß—Ç–æ —Ç–∞–∫–æ–µ overfitting?", "answer": "–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–∞ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö."}
]

dataset = create_dialogue_dataset(
    dialogue_pairs=dialogue_pairs,
    teacher_model="distilbert"
)

# 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CubeTrainer –¥–ª—è dialogue —Ä–µ–∂–∏–º–∞
config = TrainingConfig(
    mode="dialogue",              # –í–∞–∂–Ω–æ: dialogue —Ä–µ–∂–∏–º
    lattice_size=[8, 8, 12],     # [8,8,12] = 768D —Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å DistilBERT
    embedding_dim=768,            # DistilBERT —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
    learning_rate=0.001,
    batch_size=4,
    device="cpu"
)

# 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞
trainer = CubeTrainer(config=config)
trainer.initialize_components()

# 4. –ì–æ—Ç–æ–≤ –∫ –æ–±—É—á–µ–Ω–∏—é!
print("üöÄ –ì–æ—Ç–æ–≤ –∫ dialogue training!")
print(f"Dataset size: {len(dataset)}")
print(f"Cube shape: {config.lattice_size}")

# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è forward pass
sample_q, sample_a = dataset[0]
batch_q = sample_q.unsqueeze(0)  # [768] ‚Üí [1, 768]
output = trainer.forward(batch_q)  # [1, 768]
print(f"Q‚ÜíA: {batch_q.shape} ‚Üí {output.shape}")
```

### 3. Multi-turn –¥–∏–∞–ª–æ–≥–∏

```python
from training.embedding_trainer import create_conversation_dataset

# –ú–Ω–æ–≥–æ—Ö–æ–¥–æ–≤—ã–µ –¥–∏–∞–ª–æ–≥–∏
conversations = [
    [
        {"role": "user", "text": "–ü—Ä–∏–≤–µ—Ç, —Ä–∞—Å—Å–∫–∞–∂–∏ –æ ML"},
        {"role": "assistant", "text": "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ - —ç—Ç–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª –ò–ò –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö"},
        {"role": "user", "text": "–ê —á—Ç–æ —Ç–∞–∫–æ–µ deep learning?"},
        {"role": "assistant", "text": "–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏"}
    ],
    [
        {"role": "user", "text": "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç CNN?"},
        {"role": "assistant", "text": "–°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–µ—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"},
        {"role": "user", "text": "–ê RNN?"},
        {"role": "assistant", "text": "–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–µ—Ç–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö"}
    ]
]

# –°–æ–∑–¥–∞–Ω–∏–µ dataset –∏–∑ –º–Ω–æ–≥–æ—Ö–æ–¥–æ–≤—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤
dataset = create_conversation_dataset(
    conversations=conversations,
    teacher_model="distilbert",
    validation_split=0.0  # –í—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö)
)

print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ Q&A –ø–∞—Ä: {len(dataset)}")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –ø–∞—Ä
for i in range(min(3, len(dataset))):
    metadata = dataset.dialogue_metadata[i] if dataset.dialogue_metadata else {"question": "N/A", "answer": "N/A"}
    print(f"–ü–∞—Ä–∞ {i+1}: Q: '{metadata['question'][:30]}...' ‚Üí A: '{metadata['answer'][:30]}...'")
```

### 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ quality filtering

```python
from training.embedding_trainer import DialogueConfig, DialogueDataset

# –°—Ç—Ä–æ–≥–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
strict_config = DialogueConfig(
    teacher_model="distilbert",
    enable_quality_filter=True,
    min_question_length=10,       # –ú–∏–Ω–∏–º—É–º 10 —Å–∏–º–≤–æ–ª–æ–≤ –≤ –≤–æ–ø—Ä–æ—Å–µ
    min_answer_length=20,         # –ú–∏–Ω–∏–º—É–º 20 —Å–∏–º–≤–æ–ª–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
    max_question_length=100,      # –ú–∞–∫—Å–∏–º—É–º 100 —Å–∏–º–≤–æ–ª–æ–≤ –≤ –≤–æ–ø—Ä–æ—Å–µ
    max_answer_length=200,        # –ú–∞–∫—Å–∏–º—É–º 200 —Å–∏–º–≤–æ–ª–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
    validation_split=0.2
)

# –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å —Ä–∞–∑–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º
mixed_quality_pairs = [
    {"question": "–ß—Ç–æ?", "answer": "–î–∞"},  # –ë—É–¥–µ—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ (—Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ)
    {"question": "–†–∞—Å—Å–∫–∞–∂–∏ –æ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö", "answer": "–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ - —ç—Ç–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö"},  # –ü—Ä–æ–π–¥–µ—Ç —Ñ–∏–ª—å—Ç—Ä
    {"question": "–ê" * 150, "answer": "–ë" * 300},  # –ë—É–¥–µ—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ (—Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ)
]

# –°–æ–∑–¥–∞–Ω–∏–µ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
dataset = DialogueDataset(
    config=strict_config,
    dialogue_pairs=mixed_quality_pairs
)

print(f"–ò—Å—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä—ã: {len(mixed_quality_pairs)}")
print(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(dataset)}")
print(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ: {len(mixed_quality_pairs) - len(dataset)} –ø–∞—Ä")
```

### 5. –†–∞–±–æ—Ç–∞ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º

```python
from training.embedding_trainer import create_dialogue_dataset
import time

# –û–¥–∏–Ω–∞–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫—ç—à–∞
test_pairs = [
    {"question": "–ß—Ç–æ —Ç–∞–∫–æ–µ AI?", "answer": "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"},
    {"question": "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç ML?", "answer": "–ß–µ—Ä–µ–∑ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö"}
]

# –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ (cache miss)
start_time = time.time()
dataset1 = create_dialogue_dataset(
    dialogue_pairs=test_pairs,
    teacher_model="distilbert",
    use_cache=True,
    cache_dir="cache/example_dialogue"
)
time1 = time.time() - start_time

# –í—Ç–æ—Ä–æ–π –∑–∞–ø—É—Å–∫ (cache hit)
start_time = time.time()
dataset2 = create_dialogue_dataset(
    dialogue_pairs=test_pairs,
    teacher_model="distilbert",
    use_cache=True,
    cache_dir="cache/example_dialogue"
)
time2 = time.time() - start_time

print(f"–ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ (cache miss): {time1:.2f}s")
print(f"–í—Ç–æ—Ä–æ–π –∑–∞–ø—É—Å–∫ (cache hit): {time2:.2f}s")
print(f"Speedup: {time1/time2:.1f}x")

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
print(f"Dataset 1 cache stats: {dataset1.cache_stats}")
print(f"Dataset 2 cache stats: {dataset2.cache_stats}")
```

### 6. DataLoader –¥–ª—è –±–∞—Ç—á–µ–≤–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

```python
from training.embedding_trainer import create_dialogue_dataset

# –°–æ–∑–¥–∞–Ω–∏–µ dataset
dataset = create_dialogue_dataset(
    dialogue_pairs=[
        {"question": f"–í–æ–ø—Ä–æ—Å {i}", "answer": f"–û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å {i}"}
        for i in range(20)  # 20 –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –ø–∞—Ä
    ],
    teacher_model="distilbert",
    validation_split=0.2
)

# Train DataLoader
train_loader = dataset.get_dataloader(
    batch_size=4,
    shuffle=True,
    validation=False
)

# Validation DataLoader
val_loader = dataset.get_dataloader(
    batch_size=2,
    shuffle=False,
    validation=True
)

print(f"Train batches: {len(train_loader)}")
print(f"Val batches: {len(val_loader)}")

# –ü—Ä–∏–º–µ—Ä –æ–±—É—á–∞—é—â–µ–≥–æ —Ü–∏–∫–ª–∞
for epoch in range(2):
    print(f"\nEpoch {epoch+1}:")

    # Training
    for batch_idx, (questions, answers) in enumerate(train_loader):
        print(f"  Train batch {batch_idx}: Q{questions.shape} ‚Üí A{answers.shape}")
        # –ó–¥–µ—Å—å –±—ã–ª –±—ã —Ä–µ–∞–ª—å–Ω—ã–π training step

    # Validation
    for batch_idx, (questions, answers) in enumerate(val_loader):
        print(f"  Val batch {batch_idx}: Q{questions.shape} ‚Üí A{answers.shape}")
        # –ó–¥–µ—Å—å –±—ã–ª–∞ –±—ã –≤–∞–ª–∏–¥–∞—Ü–∏—è
```

### 7. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ dataset

```python
from training.embedding_trainer import create_dialogue_dataset
import torch

# –°–æ–∑–¥–∞–Ω–∏–µ dataset —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
dataset = create_dialogue_dataset(
    dialogue_pairs=[
        {"question": "–ß—Ç–æ —Ç–∞–∫–æ–µ PyTorch?", "answer": "PyTorch - –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è deep learning"},
        {"question": "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç CNN?", "answer": "–°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–µ—Ç–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ —Ñ–∏–ª—å—Ç—Ä—ã"},
        {"question": "–ß—Ç–æ —Ç–∞–∫–æ–µ RNN?", "answer": "–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π"}
    ],
    teacher_model="distilbert",
    validation_split=0.0
)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
stats = dataset.get_statistics()

print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê DATASET:")
print(f"–í—Å–µ–≥–æ –ø–∞—Ä: {stats['total_dialogue_pairs']}")
print(f"Teacher –º–æ–¥–µ–ª—å: {stats['teacher_model']}")
print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–∏–Ω–≥–æ–≤: {stats['embedding_dim']}")

# –ö—ç—à —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
cache_stats = stats['cache_stats']
print(f"\nüíæ –ö–≠–®–ò–†–û–í–ê–ù–ò–ï:")
print(f"Cache hits: {cache_stats['cache_hits']}")
print(f"Cache misses: {cache_stats['cache_misses']}")
print(f"Quality filtered: {cache_stats['quality_filtered']}")

# –ö–∞—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤
if 'embedding_quality' in stats:
    eq = stats['embedding_quality']
    print(f"\nüéØ –ö–ê–ß–ï–°–¢–í–û –≠–ú–ë–ï–î–ò–ù–ì–û–í:")
    print(f"Question norm mean: {eq['question_norm_mean']:.4f}")
    print(f"Answer norm mean: {eq['answer_norm_mean']:.4f}")
    print(f"Q&A similarity: {eq['qa_similarity_mean']:.4f} ¬± {eq['qa_similarity_std']:.4f}")

# –ü—Ä–∏–º–µ—Ä—ã –¥–∏–∞–ª–æ–≥–æ–≤ —Å similarity
samples = dataset.get_sample_dialogues(n_samples=3)
if 'samples' in samples:
    print(f"\nüí¨ –ü–†–ò–ú–ï–†–´ –î–ò–ê–õ–û–ì–û–í:")
    for i, sample in enumerate(samples['samples']):
        print(f"–ü—Ä–∏–º–µ—Ä {i+1}:")
        print(f"  Q: '{sample['question']}'")
        print(f"  A: '{sample['answer']}'")
        print(f"  Similarity: {sample['qa_similarity']:.4f}")
```

### 8. –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ —Ñ–∞–π–ª–æ–≤

```python
import json
from training.embedding_trainer import load_dialogue_dataset_from_files

# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ JSON —Ñ–∞–π–ª–∞
test_data = [
    {"question": "–§–∞–π–ª–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å 1", "answer": "–§–∞–π–ª–æ–≤—ã–π –æ—Ç–≤–µ—Ç 1"},
    {"question": "–§–∞–π–ª–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å 2", "answer": "–§–∞–π–ª–æ–≤—ã–π –æ—Ç–≤–µ—Ç 2"}
]

with open("test_dialogues.json", "w", encoding="utf-8") as f:
    json.dump(test_data, f, ensure_ascii=False, indent=2)

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ —Ñ–∞–π–ª–∞
dataset = load_dialogue_dataset_from_files(
    file_paths=["test_dialogues.json"],
    teacher_model="distilbert",
    validation_split=0.0
)

print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ —Ñ–∞–π–ª–∞: {len(dataset)} –ø–∞—Ä")

# –û—á–∏—Å—Ç–∫–∞
import os
os.remove("test_dialogues.json")
```

### 9. –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É train/validation —Ä–µ–∂–∏–º–∞–º–∏

```python
from training.embedding_trainer import create_dialogue_dataset

# Dataset —Å train/val split
dataset = create_dialogue_dataset(
    dialogue_pairs=[
        {"question": f"Q{i}", "answer": f"A{i}"}
        for i in range(10)
    ],
    teacher_model="distilbert",
    validation_split=0.3  # 30% –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
)

print(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {len(dataset)}")
print(f"Train —Ä–∞–∑–º–µ—Ä: {len(dataset.train_questions)}")
print(f"Val —Ä–∞–∑–º–µ—Ä: {len(dataset.val_questions)}")

# –†–µ–∂–∏–º training
dataset.set_validation_mode(False)
print(f"Training mode: {len(dataset)} samples")

# –†–µ–∂–∏–º validation
dataset.set_validation_mode(True)
print(f"Validation mode: {len(dataset)} samples")

# –û–±—Ä–∞—Ç–Ω–æ –∫ training
dataset.set_validation_mode(False)
print(f"Back to training: {len(dataset)} samples")
```

---

## üîß –ü–†–û–î–í–ò–ù–£–¢–´–ï –ü–ê–¢–¢–ï–†–ù–´

### Custom DialogueConfig

```python
from training.embedding_trainer import DialogueConfig, DialogueDataset

# –ü–æ–ª–Ω–∞—è –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è
config = DialogueConfig(
    teacher_model="distilbert",
    embedding_dim=768,
    validation_split=0.15,
    enable_quality_filter=True,
    min_question_length=8,
    min_answer_length=15,
    max_question_length=150,
    max_answer_length=300,
    support_multiturn=True,
    use_cache=True,
    normalize_embeddings=True,
    cache_dir="cache/custom_dialogue",
    cache_batch_size=100,
    max_conversations=2000
)

dataset = DialogueDataset(
    config=config,
    dialogue_pairs=[
        {"question": "Custom question", "answer": "Custom answer"}
    ]
)
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–æ–≤

```python
from training.embedding_trainer import create_dialogue_dataset

# –†–∞–∑–ª–∏—á–Ω—ã–µ Teacher LLM –º–æ–¥–µ–ª–∏
models_to_test = ["distilbert", "bert-base-uncased"]

for model in models_to_test:
    try:
        dataset = create_dialogue_dataset(
            dialogue_pairs=[{"question": "Test", "answer": "Test response"}],
            teacher_model=model,
            validation_split=0.0
        )

        sample_q, sample_a = dataset[0]
        print(f"‚úÖ {model}: {sample_q.shape} compatible")

    except Exception as e:
        print(f"‚ùå {model}: {e}")
```

---

## üéØ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï

**DialogueDataset –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ—â–Ω—ã–π –∏ –≥–∏–±–∫–∏–π API –¥–ª—è dialogue –æ–±—É—á–µ–Ω–∏—è 3D Cubic Core.**

### –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:

- ‚úÖ **Teacher LLM –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** Q‚ÜíA —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
- ‚úÖ **Smart caching** –¥–ª—è 8x+ speedup
- ‚úÖ **Quality filtering** –¥–ª—è —á–∏—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- ‚úÖ **Multi-turn support** –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤
- ‚úÖ **CubeTrainer integration** –¥–ª—è [8,8,12] = 768D —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
- ‚úÖ **Production-ready API** —Å comprehensive testing

**–ì–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ Stage 2.1 - Dialogue Training!**
