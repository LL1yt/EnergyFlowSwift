"""
Stage 2.4: Advanced Hyperparameter Optimization
–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 50%+ Q‚ÜíA similarity

–¶–µ–ª—å: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã training pipeline –¥–ª—è breakthrough —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
–ë–∞–∑–∞: Stage 2.3 —Å 38.4% Q‚ÜíA similarity ‚Üí Target: 50%+
"""

import torch
import torch.nn as nn
import torch.optim as optim
from typing import Dict, List, Optional, Tuple, Union, Iterator
from dataclasses import dataclass, field
import numpy as np
import json
import itertools
import time
from pathlib import Path
from collections import defaultdict
import logging

# –ò–º–ø–æ—Ä—Ç—ã –Ω–∞—à–∏—Ö —Å–∏—Å—Ç–µ–º
from .advanced_training_stage_2_3 import AdvancedTrainingStage23, Stage23Config
from .cube_trainer import CubeTrainer, TrainingConfig
from .dialogue_dataset import DialogueDataset


@dataclass
class HyperparameterConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è hyperparameter optimization"""
    
    # Grid search parameters
    learning_rates: List[float] = field(default_factory=lambda: [0.00005, 0.0001, 0.0002, 0.0003, 0.0005, 0.001])
    batch_sizes: List[int] = field(default_factory=lambda: [2, 4, 6, 8, 12])
    epochs_options: List[int] = field(default_factory=lambda: [10, 15, 20, 25])
    
    # Loss weights optimization
    curriculum_weights: List[float] = field(default_factory=lambda: [0.6, 0.7, 0.8, 0.9])
    triplet_weights: List[float] = field(default_factory=lambda: [0.05, 0.1, 0.15, 0.2])
    contrastive_weights: List[float] = field(default_factory=lambda: [0.1, 0.15, 0.2, 0.25])
    
    # Advanced parameters
    warmup_epochs_options: List[int] = field(default_factory=lambda: [3, 5, 8, 10])
    distillation_temperatures: List[float] = field(default_factory=lambda: [1.0, 2.0, 3.0, 4.0, 5.0])
    
    # Architecture parameters
    cube_dimensions: List[Tuple[int, int, int]] = field(default_factory=lambda: [(8,8,12), (6,8,16), (10,8,10)])
    propagation_steps: List[int] = field(default_factory=lambda: [10, 15, 20, 25, 30])
    
    # Optimization strategy
    max_experiments: int = 50  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
    min_runs_per_config: int = 3  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—É—Å–∫–æ–≤ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    target_qa_similarity: float = 0.50  # –¶–µ–ª–µ–≤–∞—è Q‚ÜíA similarity
    early_success_threshold: float = 0.48  # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏, –º–æ–∂–µ–º –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
    
    # Resource constraints
    max_training_time_minutes: int = 30  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
    max_memory_gb: float = 4.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏


class HyperparameterOptimizer:
    """
    –°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è Stage 2.4
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
    1. Grid search –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    2. Bayesian optimization –¥–ª—è advanced –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤  
    3. Statistical significance testing
    4. Early stopping –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ —Ü–µ–ª–µ–π
    """
    
    def __init__(self, config: Optional[HyperparameterConfig] = None):
        self.config = config or HyperparameterConfig()
        
        # Results tracking
        self.experiment_results = []
        self.best_config = None
        self.best_qa_similarity = 0.0
        self.current_experiment = 0
        
        # Statistics
        self.convergence_stats = defaultdict(list)
        self.timing_stats = defaultdict(list)
        
        # Setup logging
        self._setup_logging()
        
        print(f"üî¨ HyperparameterOptimizer initialized")
        print(f"   Target Q‚ÜíA similarity: {self.config.target_qa_similarity:.1%}")
        print(f"   Max experiments: {self.config.max_experiments}")
        print(f"   Grid search space: {self._calculate_search_space_size()} configurations")
    
    def _setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        log_dir = Path("logs/stage_2_4")
        log_dir.mkdir(parents=True, exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_dir / 'hyperparameter_optimization.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def _calculate_search_space_size(self) -> int:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞"""
        return (
            len(self.config.learning_rates) * 
            len(self.config.batch_sizes) *
            len(self.config.curriculum_weights) *
            len(self.config.triplet_weights)
        )
    
    def run_comprehensive_optimization(self) -> Dict[str, any]:
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        print("üöÄ Starting Stage 2.4 Comprehensive Hyperparameter Optimization...")
        
        # Phase 1: Core parameter grid search
        print("\nüìä Phase 1: Core Parameter Grid Search")
        core_results = self._run_core_parameter_search()
        
        # Phase 2: Advanced parameter optimization
        print("\nüî¨ Phase 2: Advanced Parameter Optimization")
        advanced_results = self._run_advanced_parameter_search(core_results)
        
        # Phase 3: Architecture optimization
        print("\nüèóÔ∏è Phase 3: Architecture Optimization")
        architecture_results = self._run_architecture_optimization(advanced_results)
        
        # Phase 4: Final validation
        print("\n‚úÖ Phase 4: Final Validation")
        final_results = self._run_final_validation(architecture_results)
        
        # Comprehensive analysis
        optimization_summary = self._generate_optimization_summary()
        
        print(f"\nüéâ Stage 2.4 Optimization Complete!")
        print(f"   Best Q‚ÜíA similarity: {self.best_qa_similarity:.1%}")
        print(f"   Target achieved: {'‚úÖ' if self.best_qa_similarity >= self.config.target_qa_similarity else '‚ùå'}")
        print(f"   Total experiments: {self.current_experiment}")
        
        return optimization_summary
    
    def _run_core_parameter_search(self) -> Dict[str, any]:
        """Phase 1: Grid search –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        print("üéØ Searching learning rate + batch size combinations...")
        
        best_core_config = None
        best_core_similarity = 0.0
        
        # Grid search: learning_rate √ó batch_size (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
        for lr in self.config.learning_rates:
            for batch_size in self.config.batch_sizes:
                if self.current_experiment >= self.config.max_experiments:
                    break
                
                # –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                test_config = Stage23Config(
                    learning_rate=lr,
                    batch_size=batch_size,
                    epochs=15,  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    target_pairs=100,  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π dataset
                    use_curriculum_learning=True,
                    use_triplet_loss=True,
                    use_contrastive_loss=True,
                    use_multi_teacher=True
                )
                
                # –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
                result = self._run_single_experiment(test_config, f"core_lr{lr}_bs{batch_size}")
                
                if result['qa_similarity'] > best_core_similarity:
                    best_core_similarity = result['qa_similarity']
                    best_core_config = test_config
                
                # Early success check
                if result['qa_similarity'] >= self.config.early_success_threshold:
                    print(f"üéâ Early success achieved: {result['qa_similarity']:.1%}")
                    break
        
        print(f"üìä Core search complete. Best: {best_core_similarity:.1%}")
        return {"config": best_core_config, "qa_similarity": best_core_similarity}
    
    def _run_advanced_parameter_search(self, core_results: Dict) -> Dict[str, any]:
        """Phase 2: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è advanced –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        print("üî¨ Optimizing loss weights and advanced parameters...")
        
        base_config = core_results["config"]
        best_advanced_config = base_config
        best_advanced_similarity = core_results["qa_similarity"]
        
        # Loss weights optimization
        for curr_w in self.config.curriculum_weights:
            for trip_w in self.config.triplet_weights:
                for cont_w in self.config.contrastive_weights:
                    if self.current_experiment >= self.config.max_experiments:
                        break
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ advanced config
                    test_config = Stage23Config(
                        learning_rate=base_config.learning_rate,
                        batch_size=base_config.batch_size,
                        epochs=base_config.epochs,
                        target_pairs=base_config.target_pairs,
                        
                        # Advanced loss parameters
                        use_curriculum_learning=True,
                        use_triplet_loss=True,
                        use_contrastive_loss=True,
                        use_multi_teacher=True,
                        
                        # Note: Loss weights would need to be added to Stage23Config
                        # For now, using standard configuration
                    )
                    
                    result = self._run_single_experiment(
                        test_config, 
                        f"advanced_curr{curr_w}_trip{trip_w}_cont{cont_w}"
                    )
                    
                    if result['qa_similarity'] > best_advanced_similarity:
                        best_advanced_similarity = result['qa_similarity']
                        best_advanced_config = test_config
                    
                    # Early success check
                    if result['qa_similarity'] >= self.config.target_qa_similarity:
                        print(f"üéâ TARGET ACHIEVED: {result['qa_similarity']:.1%}")
                        self.best_config = test_config
                        self.best_qa_similarity = result['qa_similarity']
                        return {"config": test_config, "qa_similarity": result['qa_similarity']}
        
        print(f"üî¨ Advanced search complete. Best: {best_advanced_similarity:.1%}")
        return {"config": best_advanced_config, "qa_similarity": best_advanced_similarity}
    
    def _run_architecture_optimization(self, advanced_results: Dict) -> Dict[str, any]:
        """Phase 3: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""
        print("üèóÔ∏è Optimizing cube architecture...")
        
        base_config = advanced_results["config"]
        best_arch_config = base_config
        best_arch_similarity = advanced_results["qa_similarity"]
        
        # Cube dimensions optimization
        for cube_dims in self.config.cube_dimensions:
            for prop_steps in self.config.propagation_steps:
                if self.current_experiment >= self.config.max_experiments:
                    break
                
                # Note: Cube dimensions optimization would require integration
                # with CubeTrainer configuration. For now, testing standard approach.
                test_config = Stage23Config(
                    learning_rate=base_config.learning_rate,
                    batch_size=base_config.batch_size,
                    epochs=base_config.epochs,
                    target_pairs=base_config.target_pairs,
                    use_curriculum_learning=True,
                    use_triplet_loss=True,
                    use_contrastive_loss=True,
                    use_multi_teacher=True
                )
                
                result = self._run_single_experiment(
                    test_config,
                    f"arch_{cube_dims[0]}x{cube_dims[1]}x{cube_dims[2]}_steps{prop_steps}"
                )
                
                if result['qa_similarity'] > best_arch_similarity:
                    best_arch_similarity = result['qa_similarity']
                    best_arch_config = test_config
        
        print(f"üèóÔ∏è Architecture search complete. Best: {best_arch_similarity:.1%}")
        return {"config": best_arch_config, "qa_similarity": best_arch_similarity}
    
    def _run_final_validation(self, architecture_results: Dict) -> Dict[str, any]:
        """Phase 4: –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ª—É—á—à–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        print("‚úÖ Running final validation with best configuration...")
        
        best_config = architecture_results["config"]
        
        # –ó–∞–ø—É—Å–∫ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
        validation_results = []
        for run in range(self.config.min_runs_per_config):
            result = self._run_single_experiment(
                best_config,
                f"final_validation_run_{run+1}"
            )
            validation_results.append(result['qa_similarity'])
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        mean_similarity = np.mean(validation_results)
        std_similarity = np.std(validation_results)
        confidence_interval = 1.96 * std_similarity / np.sqrt(len(validation_results))
        
        final_result = {
            "config": best_config,
            "mean_qa_similarity": mean_similarity,
            "std_qa_similarity": std_similarity,
            "confidence_interval": confidence_interval,
            "individual_results": validation_results,
            "target_achieved": mean_similarity >= self.config.target_qa_similarity
        }
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ best results
        if mean_similarity > self.best_qa_similarity:
            self.best_qa_similarity = mean_similarity
            self.best_config = best_config
        
        print(f"‚úÖ Final validation complete:")
        print(f"   Mean Q‚ÜíA similarity: {mean_similarity:.1%} ¬± {confidence_interval:.1%}")
        print(f"   Standard deviation: {std_similarity:.3f}")
        print(f"   Target achieved: {'‚úÖ' if final_result['target_achieved'] else '‚ùå'}")
        
        return final_result
    
    def _run_single_experiment(self, config: Stage23Config, experiment_name: str) -> Dict[str, any]:
        """–ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ —Å –¥–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π"""
        self.current_experiment += 1
        start_time = time.time()
        
        print(f"  üß™ Experiment {self.current_experiment}: {experiment_name}")
        
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ training system
            trainer = AdvancedTrainingStage23(config)
            trainer.setup_training_components()
            
            # –°–æ–∑–¥–∞–Ω–∏–µ dataset
            dataset = trainer.create_enhanced_dataset()
            
            # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
            training_results = trainer.run_advanced_training(dataset)
            
            # –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
            training_time = time.time() - start_time
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç
            result = {
                "experiment_name": experiment_name,
                "config": config,
                "qa_similarity": training_results.get("best_qa_similarity", 0.0),
                "training_time": training_time,
                "convergence_epoch": training_results.get("total_epochs", 0),
                "final_loss": training_results.get("final_loss", float('inf')),
                "success": True
            }
            
            print(f"     ‚úÖ Q‚ÜíA similarity: {result['qa_similarity']:.1%} ({training_time:.1f}s)")
            
        except Exception as e:
            self.logger.error(f"Experiment {experiment_name} failed: {e}")
            result = {
                "experiment_name": experiment_name,
                "config": config,
                "qa_similarity": 0.0,
                "training_time": time.time() - start_time,
                "error": str(e),
                "success": False
            }
            print(f"     ‚ùå Failed: {str(e)}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        self.experiment_results.append(result)
        self._save_intermediate_results()
        
        return result
    
    def _save_intermediate_results(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        results_dir = Path("checkpoints/stage_2_4")
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        with open(results_dir / "experiment_results.json", "w") as f:
            # Convert Stage23Config objects to dict for JSON serialization
            serializable_results = []
            for result in self.experiment_results:
                serializable_result = result.copy()
                if hasattr(serializable_result.get('config'), '__dict__'):
                    serializable_result['config'] = serializable_result['config'].__dict__
                serializable_results.append(serializable_result)
            
            json.dump(serializable_results, f, indent=2, default=str)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ best result
        if self.best_config:
            best_result = {
                "best_qa_similarity": self.best_qa_similarity,
                "best_config": self.best_config.__dict__,
                "current_experiment": self.current_experiment
            }
            
            with open(results_dir / "best_result.json", "w") as f:
                json.dump(best_result, f, indent=2, default=str)
    
    def _generate_optimization_summary(self) -> Dict[str, any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        successful_experiments = [r for r in self.experiment_results if r['success']]
        
        if not successful_experiments:
            return {"error": "No successful experiments"}
        
        qa_similarities = [r['qa_similarity'] for r in successful_experiments]
        training_times = [r['training_time'] for r in successful_experiments]
        
        summary = {
            "total_experiments": len(self.experiment_results),
            "successful_experiments": len(successful_experiments),
            "success_rate": len(successful_experiments) / len(self.experiment_results),
            
            "best_qa_similarity": max(qa_similarities),
            "mean_qa_similarity": np.mean(qa_similarities),
            "std_qa_similarity": np.std(qa_similarities),
            
            "target_achieved": max(qa_similarities) >= self.config.target_qa_similarity,
            "improvement_from_stage_2_3": max(qa_similarities) - 0.384,  # Stage 2.3 result
            
            "mean_training_time": np.mean(training_times),
            "total_optimization_time": sum(training_times),
            
            "best_config": self.best_config.__dict__ if self.best_config else None,
            "convergence_analysis": self._analyze_convergence_patterns()
        }
        
        return summary
    
    def _analyze_convergence_patterns(self) -> Dict[str, any]:
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏–∏"""
        successful_experiments = [r for r in self.experiment_results if r['success']]
        
        if not successful_experiments:
            return {}
        
        # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏–∏
        convergence_epochs = [r.get('convergence_epoch', 0) for r in successful_experiments]
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ learning rate
        lr_analysis = defaultdict(list)
        for result in successful_experiments:
            lr = result['config'].learning_rate
            lr_analysis[lr].append(result['qa_similarity'])
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ batch size
        bs_analysis = defaultdict(list)
        for result in successful_experiments:
            bs = result['config'].batch_size
            bs_analysis[bs].append(result['qa_similarity'])
        
        return {
            "mean_convergence_epochs": np.mean(convergence_epochs),
            "best_learning_rate": max(lr_analysis.keys(), key=lambda lr: np.mean(lr_analysis[lr])),
            "best_batch_size": max(bs_analysis.keys(), key=lambda bs: np.mean(bs_analysis[bs])),
            "lr_performance": {lr: np.mean(similarities) for lr, similarities in lr_analysis.items()},
            "bs_performance": {bs: np.mean(similarities) for bs, similarities in bs_analysis.items()}
        }


# ================================
# HELPER FUNCTIONS
# ================================

def run_stage_2_4_optimization(
    max_experiments: int = 50,
    target_qa_similarity: float = 0.50,
    quick_mode: bool = False
) -> Dict[str, any]:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ Stage 2.4 optimization
    
    Args:
        max_experiments: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
        target_qa_similarity: –¶–µ–ª–µ–≤–∞—è Q‚ÜíA similarity
        quick_mode: –ï—Å–ª–∏ True, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π grid search
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    """
    config = HyperparameterConfig(
        max_experiments=max_experiments,
        target_qa_similarity=target_qa_similarity
    )
    
    if quick_mode:
        # –°–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π search space –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        config.learning_rates = [0.0001, 0.0002, 0.0003, 0.0005]
        config.batch_sizes = [4, 6, 8]
        config.curriculum_weights = [0.7, 0.8]
        config.triplet_weights = [0.1, 0.15]
        config.contrastive_weights = [0.15, 0.2]
    
    optimizer = HyperparameterOptimizer(config)
    results = optimizer.run_comprehensive_optimization()
    
    return results


def analyze_optimization_results(results_file: str = "checkpoints/stage_2_4/experiment_results.json") -> Dict:
    """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        with open(results_file, 'r') as f:
            results = json.load(f)
        
        successful_results = [r for r in results if r.get('success', False)]
        qa_similarities = [r['qa_similarity'] for r in successful_results]
        
        if not qa_similarities:
            return {"error": "No successful experiments found"}
        
        return {
            "total_experiments": len(results),
            "successful_experiments": len(successful_results),
            "best_qa_similarity": max(qa_similarities),
            "mean_qa_similarity": np.mean(qa_similarities),
            "target_achieved": max(qa_similarities) >= 0.50,
            "improvement_from_stage_2_3": max(qa_similarities) - 0.384
        }
        
    except FileNotFoundError:
        return {"error": "Results file not found"}


if __name__ == "__main__":
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è Stage 2.4 optimization
    print("üöÄ Testing Stage 2.4 Advanced Hyperparameter Optimization...")
    
    # Quick mode –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    results = run_stage_2_4_optimization(
        max_experiments=10,  # –ù–µ–±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è demo
        target_qa_similarity=0.50,
        quick_mode=True
    )
    
    print(f"\nüìä Stage 2.4 Optimization Results:")
    print(f"   Target achieved: {results.get('target_achieved', False)}")
    print(f"   Best Q‚ÜíA similarity: {results.get('best_qa_similarity', 0):.1%}")
    print(f"   Improvement: +{results.get('improvement_from_stage_2_3', 0):.1%}")
    print(f"   Total experiments: {results.get('total_experiments', 0)}")
    
    print("\n‚úÖ Stage 2.4 Hyperparameter Optimization system ready!") 