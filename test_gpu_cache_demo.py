#!/usr/bin/env python3
"""
GPU Cache Demo - –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è GPU —É—Å–∫–æ—Ä–µ–Ω–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
======================================================

–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã GPU-—É—Å–∫–æ—Ä–µ–Ω–Ω–æ–≥–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
—Å–≤—è–∑–µ–π –¥–ª—è RTX 5090.
"""

import torch
import time
import sys
import os

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from new_rebuild.config import get_project_config, set_project_config, ProjectConfig
from new_rebuild.core.moe import create_connection_classifier
from new_rebuild.utils.logging import get_logger

logger = get_logger(__name__)


def test_gpu_acceleration():
    """–¢–µ—Å—Ç GPU —É—Å–∫–æ—Ä–µ–Ω–∏—è –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""

    print("üöÄ GPU Cache Acceleration Demo")
    print("=" * 50)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
    if not torch.cuda.is_available():
        print("‚ùå CUDA –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞, —Ç–µ—Å—Ç –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ CPU")
        return

    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    print(f"üéÆ GPU: {gpu_name}")
    print(f"üíæ GPU Memory: {gpu_memory:.1f}GB")

    # –¢–µ—Å—Ç 1: –ú–∞–ª–∞—è —Ä–µ—à–µ—Ç–∫–∞ (–¥–æ–ª–∂–Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CPU)
    print(f"\n1Ô∏è‚É£ –ú–∞–ª–∞—è —Ä–µ—à–µ—Ç–∫–∞ (8x8x8 = 512 –∫–ª–µ—Ç–æ–∫) - –æ–∂–∏–¥–∞–µ—Ç—Å—è CPU")
    config = ProjectConfig()
    config.lattice.dimensions = (8, 8, 8)
    config.expert.cache.enabled = True
    config.expert.cache.use_gpu_acceleration = True
    config.expert.cache.enable_performance_monitoring = True
    set_project_config(config)

    should_use_cache = config.should_use_connection_cache()
    print(f"   Should use cache: {should_use_cache}")

    if should_use_cache:
        start_time = time.time()
        classifier = create_connection_classifier(lattice_dimensions=(8, 8, 8))
        init_time = time.time() - start_time

        print(f"   Cache enabled: {classifier.enable_cache}")
        if classifier.cache_manager:
            print(f"   GPU acceleration: {classifier.cache_manager.use_gpu}")
            print(f"   Device: {classifier.cache_manager.device}")
        print(f"   Initialization time: {init_time:.2f}s")

    # –¢–µ—Å—Ç 2: –°—Ä–µ–¥–Ω—è—è —Ä–µ—à–µ—Ç–∫–∞ (–¥–æ–ª–∂–Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU)
    print(f"\n2Ô∏è‚É£ –°—Ä–µ–¥–Ω—è—è —Ä–µ—à–µ—Ç–∫–∞ (15x15x15 = 3375 –∫–ª–µ—Ç–æ–∫) - –æ–∂–∏–¥–∞–µ—Ç—Å—è GPU")
    config = ProjectConfig()
    config.lattice.dimensions = (15, 15, 15)
    config.expert.cache.enabled = True
    config.expert.cache.use_gpu_acceleration = True
    config.expert.cache.enable_performance_monitoring = True
    config.expert.cache.auto_enable_threshold = 3000
    set_project_config(config)

    should_use_cache = config.should_use_connection_cache()
    print(f"   Should use cache: {should_use_cache}")

    if should_use_cache:
        print("   üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫—ç—à–∞ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)...")
        start_time = time.time()
        classifier = create_connection_classifier(lattice_dimensions=(15, 15, 15))
        init_time = time.time() - start_time

        print(f"   Cache enabled: {classifier.enable_cache}")
        if classifier.cache_manager:
            print(f"   GPU acceleration: {classifier.cache_manager.use_gpu}")
            print(f"   Device: {classifier.cache_manager.device}")
            print(f"   GPU batch size: {classifier.cache_manager.gpu_batch_size}")
        print(f"   Initialization time: {init_time:.2f}s")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞
        cache_stats = classifier.get_cache_stats()
        print(f"   Cache status: {cache_stats.get('status', 'unknown')}")
        if cache_stats.get("cached_cells"):
            print(f"   Cached cells: {cache_stats['cached_cells']}")
            print(f"   Cache size: {cache_stats.get('cache_size_mb', 0):.1f}MB")

    # –¢–µ—Å—Ç 3: –ë–æ–ª—å—à–∞—è —Ä–µ—à–µ—Ç–∫–∞ (–¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ–π –º–æ—â–Ω–æ—Å—Ç–∏)
    if gpu_memory >= 8.0:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ GPU –ø–∞–º—è—Ç–∏
        print(f"\n3Ô∏è‚É£ –ë–æ–ª—å—à–∞—è —Ä–µ—à–µ—Ç–∫–∞ (20x20x20 = 8000 –∫–ª–µ—Ç–æ–∫) - –ø–æ–ª–Ω–∞—è –º–æ—â–Ω–æ—Å—Ç—å GPU")
        config = ProjectConfig()
        config.lattice.dimensions = (20, 20, 20)
        config.expert.cache.enabled = True
        config.expert.cache.use_gpu_acceleration = True
        config.expert.cache.enable_performance_monitoring = True
        config.expert.cache.auto_enable_threshold = 3000
        config.expert.cache.gpu_batch_size = 5000  # –£–º–µ–Ω—å—à–∞–µ–º –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        set_project_config(config)

        should_use_cache = config.should_use_connection_cache()
        print(f"   Should use cache: {should_use_cache}")

        if should_use_cache:
            print("   üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ–ª—å—à–æ–≥–æ –∫—ç—à–∞ –Ω–∞ GPU...")
            print("   ‚è±Ô∏è  –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è...")

            start_time = time.time()
            classifier = create_connection_classifier(lattice_dimensions=(20, 20, 20))
            init_time = time.time() - start_time

            print(f"   ‚úÖ Cache enabled: {classifier.enable_cache}")
            if classifier.cache_manager:
                print(f"   üöÄ GPU acceleration: {classifier.cache_manager.use_gpu}")
                print(f"   üíæ Device: {classifier.cache_manager.device}")
                print(
                    f"   üì¶ GPU batch size: {classifier.cache_manager.gpu_batch_size}"
                )
            print(f"   ‚è±Ô∏è  Total initialization time: {init_time:.2f}s")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            cache_stats = classifier.get_cache_stats()
            print(f"   üìä Cache status: {cache_stats.get('status', 'unknown')}")
            if cache_stats.get("cached_cells"):
                print(f"   üéØ Cached cells: {cache_stats['cached_cells']}")
                print(f"   üíæ Cache size: {cache_stats.get('cache_size_mb', 0):.1f}MB")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫—ç—à —Å–æ—Ö—Ä–∞–Ω–µ–Ω –Ω–∞ –¥–∏—Å–∫
                print(f"   üíΩ Cache saved to disk for future reuse")
        else:
            print("   ‚ö†Ô∏è  Cache disabled for this lattice size")
    else:
        print(
            f"\n3Ô∏è‚É£ –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–æ–ª—å—à—É—é —Ä–µ—à–µ—Ç–∫—É (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ GPU –ø–∞–º—è—Ç–∏: {gpu_memory:.1f}GB < 8GB)"
        )

    print(f"\n‚úÖ GPU Cache Demo –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"üîÑ –ü—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º –∑–∞–ø—É—Å–∫–µ –∫—ç—à –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω —Å –¥–∏—Å–∫–∞ –º–æ–º–µ–Ω—Ç–∞–ª—å–Ω–æ!")


def test_cache_reuse():
    """–¢–µ—Å—Ç –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫—ç—à–∞"""

    print(f"\nüîÑ –¢–µ—Å—Ç –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫—ç—à–∞")
    print("=" * 30)

    # –°–æ–∑–¥–∞–µ–º —Ç—É –∂–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —á—Ç–æ –∏ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º —Ç–µ—Å—Ç–µ
    config = ProjectConfig()
    config.lattice.dimensions = (15, 15, 15)
    config.expert.cache.enabled = True
    config.expert.cache.use_gpu_acceleration = True
    config.expert.cache.auto_enable_threshold = 3000
    set_project_config(config)

    print("   üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫—ç—à...")

    start_time = time.time()
    classifier = create_connection_classifier(lattice_dimensions=(15, 15, 15))
    reuse_time = time.time() - start_time

    print(f"   ‚ö° –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏: {reuse_time:.2f}s")

    if reuse_time < 1.0:
        print("   ‚úÖ –ö—ç—à —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω (–±—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)!")
    else:
        print("   üîÑ –ö—ç—à –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω (–ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –∏–ª–∏ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)")

    cache_stats = classifier.get_cache_stats()
    if cache_stats.get("cached_cells"):
        print(f"   üìä Cached cells: {cache_stats['cached_cells']}")


if __name__ == "__main__":
    test_gpu_acceleration()
    test_cache_reuse()
