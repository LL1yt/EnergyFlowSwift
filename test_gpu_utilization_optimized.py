#!/usr/bin/env python3
"""
Test GPU Utilization –ü–æ—Å–ª–µ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
=====================================

–≠—Ç–æ—Ç —Ç–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —É–ª—É—á—à–µ–Ω–∏–µ GPU —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π:
1. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã memory leaks –≤ training loop (–≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è spatial consistency)
2. –£–±—Ä–∞–Ω—ã –±–ª–æ–∫–∏—Ä—É—é—â–∏–µ torch.cuda.synchronize() –æ–ø–µ—Ä–∞—Ü–∏–∏
3. –£–≤–µ–ª–∏—á–µ–Ω—ã workers –¥–æ 16 –¥–ª—è RTX 5090 (pin_memory=True, prefetch=16)
4. GPU-direct data loading (–∑–∞–≥—Ä—É–∑–∫–∞ —Å—Ä–∞–∑—É –Ω–∞ GPU)
5. –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ spatial operations (—É–±—Ä–∞–Ω—ã nested loops)
6. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ —Å CUDA streams
7. –û—Ç–∫–ª—é—á–µ–Ω–∏–µ debug —Ä–µ–∂–∏–º–∞

–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: GPU —É—Ç–∏–ª–∏–∑–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ —É–≤–µ–ª–∏—á–∏—Ç—å—Å—è —Å 25% –¥–æ 80-90%
"""

import torch
import time
import psutil
import os
from typing import Dict, Any
import threading
import sys
import subprocess

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append('/mnt/c/Users/n0n4a/projects/AA')

from new_rebuild.config.simple_config import SimpleProjectConfig
from new_rebuild.config.config_components import ConfigMode, ModeSettings
from new_rebuild.core.training.embedding_trainer import EmbeddingTrainer
from new_rebuild.core.training.utils.unified_dataset_loader import create_training_dataloader
from new_rebuild.utils.device_manager import get_device_manager
from new_rebuild.utils.logging import get_logger

logger = get_logger(__name__)

class GPUMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
    
    def __init__(self):
        self.monitoring = False
        self.stats = {
            'gpu_utilization': [],
            'memory_usage': [],
            'timestamps': []
        }
        self.thread = None
        
    def start_monitoring(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU"""
        self.monitoring = True
        self.thread = threading.Thread(target=self._monitor_loop)
        self.thread.daemon = True
        self.thread.start()
        
    def stop_monitoring(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"""
        self.monitoring = False
        if self.thread:
            self.thread.join()
            
    def _monitor_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        while self.monitoring:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º nvidia-smi –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ GPU
                result = subprocess.run([
                    'nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total', 
                    '--format=csv,noheader,nounits'
                ], capture_output=True, text=True, timeout=5)
                
                if result.returncode == 0:
                    line = result.stdout.strip()
                    gpu_util, mem_used, mem_total = map(int, line.split(', '))
                    
                    self.stats['gpu_utilization'].append(gpu_util)
                    self.stats['memory_usage'].append((mem_used / mem_total) * 100)
                    self.stats['timestamps'].append(time.time())
                    
            except Exception as e:
                logger.debug(f"GPU monitoring error: {e}")
                
            time.sleep(1.0)  # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
            
    def get_average_stats(self) -> Dict[str, float]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏"""
        if not self.stats['gpu_utilization']:
            return {'avg_gpu_util': 0.0, 'avg_memory_util': 0.0, 'max_gpu_util': 0.0}
            
        return {
            'avg_gpu_util': sum(self.stats['gpu_utilization']) / len(self.stats['gpu_utilization']),
            'avg_memory_util': sum(self.stats['memory_usage']) / len(self.stats['memory_usage']),
            'max_gpu_util': max(self.stats['gpu_utilization']),
            'samples': len(self.stats['gpu_utilization'])
        }

def test_gpu_utilization_optimized():
    """–¢–µ—Å—Ç GPU —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ –ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π"""
    
    logger.info("üöÄ Testing GPU Utilization After Optimizations")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ GPU
    device_manager = get_device_manager()
    if not device_manager.is_cuda():
        logger.error("‚ùå CUDA not available - cannot test GPU utilization")
        return
        
    logger.info(f"üìä GPU Device: {device_manager.get_device()}")
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ —Ä–µ–∂–∏–º–µ OPTIMIZED
    config = SimpleProjectConfig(mode=ModeSettings(mode=ConfigMode.OPTIMIZED))
    
    logger.info("üîß Configuration settings:")
    logger.info(f"  - Training batch size: {config.training.batch_size}")
    logger.info(f"  - Embedding batch size: {config.training_embedding.embedding_batch_size}")
    logger.info(f"  - Debug mode: {config.logging.debug_mode}")
    logger.info(f"  - Fallback CPU: {config.device.fallback_cpu}")
    
    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
    trainer = EmbeddingTrainer(config)
    
    # –°–æ–∑–¥–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    logger.info("üì¶ Creating test dataset...")
    dataset_loader, dataset_stats = create_training_dataloader(
        config=config,
        batch_size=config.training_embedding.embedding_batch_size,
        num_workers=8,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤
        shuffle=True
    )
    
    logger.info(f"üìä Dataset stats: {dataset_stats['total_samples']} samples")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU
    monitor = GPUMonitor()
    monitor.start_monitoring()
    
    try:
        logger.info("üî• Starting training to test GPU utilization...")
        
        # –ó–∞—Å–µ–∫–∞–µ–º –≤—Ä–µ–º—è
        start_time = time.time()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏—Ç–µ—Ä–∞—Ü–∏–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
        trainer.train(dataset_loader, num_epochs=1, max_batches=20)
        
        end_time = time.time()
        training_time = end_time - start_time
        
        logger.info(f"‚è±Ô∏è Training time: {training_time:.2f} seconds")
        
    except Exception as e:
        logger.error(f"‚ùå Training failed: {e}")
        logger.error(f"Error details: {type(e).__name__}: {str(e)}")
        return
    finally:
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        monitor.stop_monitoring()
        
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    stats = monitor.get_average_stats()
    
    logger.info("üìà GPU Utilization Results:")
    logger.info(f"  - Average GPU Utilization: {stats['avg_gpu_util']:.1f}%")
    logger.info(f"  - Maximum GPU Utilization: {stats['max_gpu_util']:.1f}%")
    logger.info(f"  - Average Memory Usage: {stats['avg_memory_util']:.1f}%")
    logger.info(f"  - Monitoring samples: {stats['samples']}")
    
    # –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if stats['avg_gpu_util'] >= 80:
        logger.info("üéâ EXCELLENT: GPU utilization dramatically improved!")
        logger.info(f"üéØ Target exceeded: {stats['avg_gpu_util']:.1f}% >= 80%")
    elif stats['avg_gpu_util'] >= 60:
        logger.info("‚úÖ SUCCESS: GPU utilization significantly improved!")
        logger.info(f"üéØ Target achieved: {stats['avg_gpu_util']:.1f}% >= 60%")
    elif stats['avg_gpu_util'] >= 40:
        logger.info("‚ö†Ô∏è PARTIAL SUCCESS: GPU utilization improved but not optimal")
        logger.info(f"üéØ Improvement noted: {stats['avg_gpu_util']:.1f}% (was ~25%)")
    else:
        logger.warning("‚ùå NO IMPROVEMENT: GPU utilization still low")
        logger.warning(f"üéØ Still low: {stats['avg_gpu_util']:.1f}% (target: 80%+)")
        
    # –ê–Ω–∞–ª–∏–∑ –ø–∞–º—è—Ç–∏
    if stats['avg_memory_util'] >= 80:
        logger.info("‚úÖ GPU memory well utilized")
    elif stats['avg_memory_util'] >= 50:
        logger.info("‚ö†Ô∏è GPU memory moderately utilized")
    else:
        logger.warning("‚ùå GPU memory underutilized - data may be on CPU")
        
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if stats['avg_gpu_util'] < 80:
        logger.info("üí° Recommendations for further optimization:")
        logger.info("  - Consider mixed precision training (AMP)")
        logger.info("  - Profile remaining CPU bottlenecks")
        logger.info("  - Check memory allocation patterns")
        logger.info("  - Consider tensor fusion optimizations")
        
    if stats['avg_memory_util'] < 50:
        logger.info("üí° GPU memory recommendations:")
        logger.info("  - Ensure all data loading uses GPU")
        logger.info("  - Check for CPU tensor operations")
        logger.info("  - Verify strict GPU-only mode is enabled")
        
    return stats

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç
    stats = test_gpu_utilization_optimized()
    
    # –í—ã–≤–æ–¥–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    if stats:
        print(f"\nüéØ FINAL RESULT: {stats['avg_gpu_util']:.1f}% average GPU utilization")
    else:
        print("\n‚ùå TEST FAILED: Could not measure GPU utilization")