# Text→Cube Tokenizer (Swift) — план реализации

_Версия: 0.1 (draft). Стиль — скептический, вдумчивый; везде предполагается возможность ошибки. Оценки уверенности даны там, где это уместно._

что-то очень сложно ахаха без негатива... конвертер TokenSequence → EncodedBatch точно не делаем. 16×16×d - вообще-то это 3D геометрия по сути у нас 3 измерения... но у нас нет много признаков и у нас нет ориентации на картинки и у нас нет внимания. далее насчет header - как будто они тоже не нужны... вот смотри, по сути идея в том, что у нас логические блоки могут быть очень обстрактными на уровне философии - это как бы целая логическая концепция, заключенная в словах - там невозможно будет что-то закодировать, но принципы логики на всех уровнях одинаковы, так что и (x<y, y<z) -> x<z подходит... так что все эти header выглядят лишними, хотя можно будет подумать о том, что бы были блоки с глобальной задачей, локальной задачей на одну логическую итерацию и утверждение логическое, которое требует от куба сделать логическое продолжение согласно глобальной и локальной цели-задачи... но это можно будет реализовать с помощью rnn сети, как поток логической последовательности в рамках определенной цели... но интуиция подсказывает, что нам нужно исследовать простой вариант и основную нагрузку возложить на эмирджентность в кубе, которая сама собой получиться после скармливания ему большого количества логических последовательностей из всевозможных областей от математики до философии... так же как нейронная сеть сама начинает понимать эмоциональную окраску... уже сейчас llm довольно сильны в логике, но наш подход позволяет приучать нейронку действовать логическими шагами блоками небольшими - логика, как каркас, который пронизывает (почти)все аспекты. если мы научимся итерировать по точкам этого каркаса, то потом на него сможем натянуть любую дополнительную структуру... тогда по идее нам нужен инкодер-декодер, который через словарь преобразует некоторый текст в числа - вектор, потом мы этот вектор умно пробразуем в 2d матрицу для входной поверхности куба, а на выходной поверхности получаем ответ короткий логический шаговый в виде 2d матрицы, которую нам нужно обратно преобразовать в слова. вроде нам ничего не нужно больше - куб сам со временем установит связи между логическими блоками и в итоге возможно сможет логически отвечать на неизвестные ему из датасета запросы. обучать куб мы сможем за счет того, что мы же знаем, какой должен быть ответ или следующий логический блок в текстовом формате, так что мы его может так же пропустить через токенизатор, который даст нам 2d матрицу, которая должна быть на выходе куба - это будет эталонный ответ, с которым мы будем сравнивать фактическое предсказание на выходе куба... что скажешь?

## 0) Цель и принципы

- **Задача:** реализовать простой, но эффективный **кастомный токенизатор** на Swift для логических блоков рассуждений, с парой _encoder–decoder_, обратимостью `текст → токены → входная поверхность 16×16 куба → выходная поверхность 16×16 куба → токены → текст` и готовностью к Apple Silicon (M‑серия, Metal/MPS).
- **Философия:** токенизатор — «тонкий мост» (**TextBridge**) без внимания/Transformer; «интеллект» реализуется в **Cube**. Если требуются точные операции (подсчёт букв и т.п.) — выполняются как строгий код, а не через вероятностные эвристики.
- **Открытость:** только бесплатные/OSS-зависимости; без проприетарных SDK. (≈ 95% уверенности, что этого достаточно для MVP.)
- **Обратимость:** гарантируем round‑trip без потерь для длины ≤ 256 токенов; при >256 — контролируемый шум (aggr/pooling). (≈ 90%)

---

## 1) Архитектура проекта (Swift Package)

```
TextCubeTokenizer/
├─ Sources/
│  ├─ TokenizerCore/            # Лексер, словарь, ID-менеджер
│  ├─ Encoder/                  # encode(text) -> TokenSequence
│  ├─ Decoder/                  # decode(TokenSequence) -> text
│  ├─ SurfaceMapping/           # 1D<->2D, Hilbert, padding/masks
│  ├─ MpsEmbedding/             # MPSGraph gather, reshape
│  ├─ Integrity/                # CRC32/Fletcher, валидация
│  └─ Interop/                  # Экспорт/импорт словаря (JSON), мост с Python
├─ Tests/                       # Unit/Property tests, fuzz, benches
└─ Package.swift
```

**Минимальные внешние зависимости:** `MetalPerformanceShadersGraph`, (опц.) `swift-numerics` для CRC/математики. (≈ 90%)

---

## 2) Логический формат входа (MVP-грамматика)

**Цель:** детерминированная, обратимая лексическая токенизация «логических блоков».

### 2.1. Минимальная BNF

```
<block>  ::= "(" <stmt> ("," <stmt>)* ")"                  # пример: (x<y, y<z) - это конечно простейший пример. конечно предполагается, что будет текстовое поясниние сложной логики и общая задача и задача на текущую логическую итерацию... но это уже другой вопрос по реализации датасета и логических потоков. но где-то нужно будет подумать о том, что могут быть выделенные места под утвержден, общуб цель и локальную цель и общий формат может быть вида <global_goal>, <local_goal>, <stmt> или как-то так на каком-то этапе это можно будет добавить, когда база будет работать.
<stmt>   ::= <term> <rel> <term>
           | <term> "->" <term>                            # импликация (опционально)
<term>   ::= <var> | <const>
<var>    ::= [A-Za-z_][A-Za-z0-9_]*                        # идентификаторы
<const>  ::= <number> | <quoted>
<number> ::= [+-]?[0-9]+
<quoted> ::= "…"                                           # строковые константы (опц.)
<rel>    ::= "<" | "<=" | "=" | "!=" | ">" | ">="
```

**Замечание:** грамматика предельно узкая; расширяется позже (кванторы, ∧/∨, скобки-группировка и т.п.). (≈ 85%)

### 2.2. Канонизация идентификаторов

- Для обратимости без проприетарных зависимостей используем **переменный словарь блока**: первая встреча имени присваивает индекс `V1, V2, …`.
- В **префиксе** токен-последовательности хранится **header‑словарь** (ID → исходное имя) как байтовые строки. Само **тело** выражения оперирует _только_ `V1, V2, …`.
- Декодер восстанавливает исходные имена через header. (≈ 95%)

---

## 3) Словарь токенов (стабильные ID)

ID фиксируются один раз и не меняются между версиями (добавления — в хвост). Ниже — **предложение** для MVP:

### 3.1. Спецсимволы и структурные метки

```
[PAD]=0, [BOS]=1, [EOS]=2, [SEP]=3
[HDR_BOS]=4, [HDR_END]=5           # секция словаря имён
[BODY_BOS]=6, [BODY_END]=7         # секция тела рассуждения
[LP]=8, [RP]=9, [COMMA]=10
[IMPL]=11                          # ->
[LT]=12, [LE]=13, [EQ]=14, [NE]=15, [GT]=16, [GE]=17
[NUM_BOS]=18, [NUM_END]=19, [SIGN_MINUS]=20, [SIGN_PLUS]=21
[DIGIT_0]=30..[DIGIT_9]=39
[MAP_PAIR]=40                      # пара (IDX, BYTES)
[BYTES_BOS]=41, [BYTES_END]=42, [BYTE_0]=43..[BYTE_255]=298
[IDX_BOS]=299, [IDX_END]=300, [IDX_0]=301..[IDX_63]=364    # индексы V0..V63
[CRC32_BOS]=400, [CRC32_END]=401, [CRC8_BOS]=402, [CRC8_END]=403
```

### 3.2. Почему так?

- **Обратимость:** числа и имена хранятся как последовательности элементарных токенов (цифры/байты), без скрытых преобразований. (≈ 95%)
- **Простота декодера:** декодер «печатает» по токенам, подставляя имена из header. (≈ 95%)
- **Ограничение V0..V63:** достаточно для многих блоков; расширяется через `IDX_EXT` позже. (≈ 80%)

---

## 4) Encoder: алгоритм

**Вход:** строка блока, например `(x<y, y<z)`  
**Выход:** `TokenSequence { ids: [Int32; ≤256], mask: [Bool; 256], meta: {len, crc, …} }`

### 4.1. Шаги

1. **Лексер**: детерминированный разбор по грамматике; выделение `var`, `number`, операторов, разделителей.
2. **Построение `SymbolTable`**: присвоение порядковых индексов `V0..Vn` по первой встрече идентификатора.
3. **Header‑секция**:
   - `HDR_BOS`
   - Для каждого `Vi -> имя` в порядке `V0..Vn`: `MAP_PAIR, IDX_BOS, IDX_k, IDX_END, BYTES_BOS, BYTE_b1..BYTE_bm, BYTES_END`
   - `HDR_END`
4. **Body‑секция**: `BODY_BOS`, затем токены тела:
   - `LP`, `IDX_BOS, IDX_x, IDX_END, LT, IDX_BOS, IDX_y, IDX_END, COMMA, …`, `RP`
   - `BODY_END`
5. **Маркер длины/паддинг**: завершаем `EOS`; паддинг до 256 токенов `PAD`‑ами.
6. **Целостность**: вычислить `CRC8` (быстро) или `CRC32` (надёжнее); добавить секцию `CRC*_BOS … CRC*_END` **в хвост** (или в header).
7. **Mask‑канал**: для позиций header и CRC выставить `mask=1` («защищено»), чтобы Cube их **не модифицировал**.

(С определённой долей вероятности ≈ 90% этого достаточно для MVP; детали CRC и размещения могут варьировать.)

### 4.2. Числа и строки

- **Числа**: `[NUM_BOS] [SIGN?] [DIGIT_*]… [NUM_END]` (строго обратимо).
- **Строки** (опц.): в теле избегаем; в header — в виде байтов (UTF‑8).

---

## 5) Decoder: алгоритм

1. Проверить `CRC` (если присутствует); при несоответствии — флаг «corrupted».
2. Прочитать `HDR`: собрать `SymbolTable: Vi -> имя`.
3. Пройти `BODY`: печатать выражение, подставляя имена из таблицы; числа восстановить из `DIGIT_*`.
4. Гарантировать **идемпотентность**: `decode(encode(x)) == x` для длины ≤256. (Unit‑тесты.) (≈ 95%)

---

## 6) Отображение 1D → 2D (поверхность 16×16) и обратно

- **Длина цели:** 256 позиций (16×16). Если `len < 256` — **zero‑padding** `PAD`‑ами в хвосте.
- **Порядок размещения:** по **кривой Гильберта** (лучше сохраняет локальность, чем построчная укладка).
- **Обратимость:** поддерживаем таблицы `hilbertIndex(i) -> (x,y)` и `hilbertInverse(x,y) -> i`.
- **Mask‑канал:** отдельный 16×16 bool‑тензор (или битовая маска), указывающий «неизменяемые» позиции (header/CRC). Cube должен их пропускать/копировать.
- **Доп. каналы (опц.):** канал «тип токена» (оператор/индекс/число) для регуляризации; можно добавить позже. (≈ 80%)

---

## 7) Взаимодействие с MPSGraph (Embedding → Surface)

- **Embedding lookup:** использовать `gather` (индексы → строки из `EmbeddingMatrix[|V| × D]`), где `D` — кратно квадрату (например, 256=16×16, 576=24×24).
- **Reshape:** `[L × D] → [H × W × d]` или `[d × H × W]` (в зависимости от Cube). Цель — без копий; reshape внутри графа.
- **Zero‑padding:** задаётся на уровне графа (константный ноль), чтобы не гонять буферы CPU↔GPU.
- **Синхронизация с mask:** mask передаётся параллельным тензором; Cube использует её для «заморозки» header/CRC. (≈ 90%)

---

## 8) Тесты и проверки

### 8.1. Round‑trip

- Набор эталонов: `(x<y, y<z)`, `(a<=b, b<=c, a<=c)`, `(u=v, v=w, u=w)` и т.д.
- Property‑тест: `decode(encode(s)) == s` при `len(ids) ≤ 256`.
- Инвариант по маске: `encode(s).mask` корректно помечает header/CRC.

### 8.2. Обратимость Hilbert

- Для `i in [0,255]`: `inv(h(i)) == i`.
- Фаззинг: случайные L≤256 → encode→map→inverse.

### 8.3. Целостность

- Повреждение 1–2 токенов тела → `CRC` детектирует несоответствие (≈ 85%).

### 8.4. Бенчмарки (M4/M3)

- CPU vs MPS: `gather`, `reshape`, `padding`.
- Профиль: «энкодер» (CPU) << «эмбеддинг/маппинг» (GPU). Цель — накладные расходы < 10% от Cube. (≈ 70%)

---

## 9) Примеры

### 9.1. Пример encode

Вход: `(x<y, y<z)`  
Header (идея):

```
HDR_BOS
  MAP_PAIR IDX_BOS IDX_0 IDX_END BYTES_BOS 'x' BYTES_END
  MAP_PAIR IDX_BOS IDX_1 IDX_END BYTES_BOS 'y' BYTES_END
  MAP_PAIR IDX_BOS IDX_2 IDX_END BYTES_BOS 'z' BYTES_END
HDR_END
```

Body:

```
BODY_BOS
  LP  IDX_BOS IDX_0 IDX_END  LT  IDX_BOS IDX_1 IDX_END  COMMA
      IDX_BOS IDX_1 IDX_END  LT  IDX_BOS IDX_2 IDX_END  RP
BODY_END  EOS
[CRC секция]
```

Mask: все позиции от `HDR_BOS` до `HDR_END` и CRC — 1 (защищены).

### 9.2. После Cube

Допустим, Cube вывел тело: `LP IDX_0 LT IDX_2 RP` (логический вывод `x<z`), header/CRC скопированы.  
Декодер восстановит `x<z` по таблице имён.

---

## 10) API (Swift)

```swift
public struct TokenSequence {
    public var ids: [Int32]        // длина ≤ 256 (с паддингом)
    public var mask: [UInt8]       // 0/1, длина 256
    public var len: Int            // реальная длина до PAD
    public var crc32: UInt32?      // опц.
}

public protocol TextTokenizer {
    func encode(_ text: String) throws -> TokenSequence
    func decode(_ seq: TokenSequence) throws -> String
}

public struct TextCubeTokenizer: TextTokenizer {
    // init(vocab: VocabSpec, options: Options)
    // encode/decode как описано.
}

// MPS embedding (отдельный модуль)
public struct MpsEmbedder {
    public init(vocabSize: Int, dim: Int)
    public func lookup(_ ids: [Int32]) throws -> MPSGraphTensor   // gather
    public func toSurface(_ emb: MPSGraphTensor, h: Int, w: Int) throws -> MPSGraphTensor
}
```

---

## 11) Реализация по этапам (итерации)

1. **Словарь и ID‑схема**: зафиксировать `enum` ID + генерацию из YAML/JSON (_скрипт Interop_). (≈ 95%)
2. **Лексер/парсер MVP**: грамматика из §2; детерминированный автомат. (≈ 90%)
3. **SymbolTable + header**: байтовое кодирование имён; unit‑тесты round‑trip на 50+ кейсах. (≈ 90%)
4. **Числа и знаки**: NUM*BOS/END + DIGIT*\*; edge‑кейсы: `+0`, `-0012`. (≈ 85%)
5. **CRC/маска**: внедрение «защищённых» участков; негативные тесты повреждений. (≈ 85%)
6. **Hilbert 1D↔2D**: таблицы прямого/обратного отображения; property‑тесты. (≈ 90%)
7. **MPSGraph gather+reshape**: минимальный граф; бенчмарк CPU vs MPS. (≈ 80%)
8. **Интеграция с Cube**: контракт по маске/каналам; smoke‑тест на `(x<y, y<z) → (x<z)`. (≈ 75%)
9. **Документация и примеры**: README, схемы данных, диаграммы. (≈ 95%)

---

## 12) Риски и альтернативы

- **Ограничение на 64 переменные (IDX_0..63):** при большом блоке потребуется `IDX_EXT` (вариант: варинт-код). (≈ 70%)
- **Hilbert‑укладка:** может усложнить отладку; альтернатива — построчная или Z‑order. (≈ 60%)
- **CRC‑накладные расходы:** небольшие, но не нулевые; можно выключить в проде. (≈ 85%)
- **Интернационализация имён:** UTF‑8 в header решает, но увеличивает длину. (≈ 85%)

---

## 13) Критерии готовности (MVP)

- Round‑trip без потерь для L≤256.
- Полная обратимость Hilbert 1D↔2D.
- Cube сохраняет header/CRC (по mask) и корректно преобразует тело.
- Бенч: MPS gather+reshape даёт ускорение vs CPU ≥ 1.5× на M‑серии. (целевой ориентир, не жёсткая метрика)

---

## 14) Открытые вопросы

- Нужна ли отдельная «мета‑плоскость» (2‑й канал) вместо inline‑header? (Вариант B.)
- Какой `D` (размер эмбеддинга) максимально удобен для Cube: 256 или 576?
- Поддерживать ли кванторы (`∀`, `∃`) в MVP или отложить?
- Требуется ли «длина» как явный токен `[LEN_k]`? (Сейчас длина известна декодеру из `EOS`/`PAD`.)

---

## 15) Замечания по уверенности

- Архитектурные решения (Header+Body, mask, Hilbert, gather) кажутся разумными для MVP (≈ 85–90%).
- Детали ID‑схемы и CRC могут измениться после первых бенчей (≈ 70%).

— Конец плана v0.1 —
