"""
EmbeddingProcessor - Ð“Ð»Ð°Ð²Ð½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€Ð° ÑÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³Ð¾Ð²
=======================================================

Ð¯Ð”Ð Ðž Phase 2.5 - Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ Ð²ÑÐµ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ðµ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹ Ð² ÐµÐ´Ð¸Ð½ÑƒÑŽ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ.

ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸:
1. Ð’Ñ…Ð¾Ð´Ð½Ð¾Ð¹ ÑÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³ (768D) â†’ EmbeddingReshaper.vector_to_matrix() â†’ 3D Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ð° (8Ã—8Ã—12)
2. 3D Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ð° â†’ Lattice3D.forward() â†’ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ð°Ñ 3D Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ð°  
3. ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ð°Ñ 3D Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ð° â†’ EmbeddingReshaper.matrix_to_vector() â†’ Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ð¾Ð¹ ÑÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³ (768D)

Ð¦ÐµÐ»ÑŒ: Cosine similarity >90% Ð² Ð°Ð²Ñ‚Ð¾ÑÐ½ÐºÐ¾Ð´ÐµÑ€ Ñ€ÐµÐ¶Ð¸Ð¼Ðµ.
"""

import torch
import torch.nn as nn
from typing import Optional, Dict, Any, Tuple, List
import numpy as np
from dataclasses import asdict
import logging
import time

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÑƒÐ»ÐµÐ¹
from data.embedding_reshaper import EmbeddingReshaper, validate_semantic_preservation
from core.lattice_3d import Lattice3D
from .config import EmbeddingConfig, ProcessingMode, validate_config
from .metrics import ProcessingMetrics, calculate_processing_quality

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
logger = logging.getLogger(__name__)


class EmbeddingProcessor(nn.Module):
    """
    Ð¦ÐµÐ½Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€ ÑÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³Ð¾Ð² - Ð¯Ð”Ð Ðž Phase 2.5
    
    ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ EmbeddingReshaper + Lattice3D Ð² ÐµÐ´Ð¸Ð½ÑƒÑŽ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸.
    """
    
    def __init__(self, config: EmbeddingConfig):
        """
        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€Ð° ÑÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³Ð¾Ð²
        
        Args:
            config: ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€Ð°
        """
        super().__init__()
        
        self.config = config
        validate_config(config)  # Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
        
        # === Ð˜ÐÐ˜Ð¦Ð˜ÐÐ›Ð˜Ð—ÐÐ¦Ð˜Ð¯ ÐšÐžÐœÐŸÐžÐÐ•ÐÐ¢ÐžÐ’ ===
        
        # 1. EmbeddingReshaper Ð´Ð»Ñ 1Dâ†”3D ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ð¸
        self.reshaper = self._init_embedding_reshaper()
        
        # 2. Lattice3D Ð´Ð»Ñ 3D Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
        self.lattice = self._init_lattice_3d()
        
        # 3. ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»Ñ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°
        self.metrics = ProcessingMetrics()
        
        # === Ð’ÐÐ£Ð¢Ð Ð•ÐÐÐ•Ð• Ð¡ÐžÐ¡Ð¢ÐžÐ¯ÐÐ˜Ð• ===
        self.processing_count = 0
        self.cache = {} if config.cache_enabled else None
        self.device = torch.device(config.device)
        self.to(self.device)
        
        # Ð˜Ð½Ñ„Ð¾ Ð¾ Ð³Ð¾Ñ‚Ð¾Ð²Ð½Ð¾ÑÑ‚Ð¸
        logger.info(f"âœ… EmbeddingProcessor Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½")
        logger.info(f"ðŸ“Š Ð ÐµÐ¶Ð¸Ð¼: {config.processing_mode.value}")
        logger.info(f"ðŸŽ¯ Ð¦ÐµÐ»ÐµÐ²Ð°Ñ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ: {config.target_similarity:.1%}")
        logger.info(f"ðŸ”„ Ð¨Ð°Ð³Ð¸ Ñ€Ð°ÑÐ¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ: {config.propagation_steps}")
    
    def _init_embedding_reshaper(self) -> EmbeddingReshaper:
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ EmbeddingReshaper"""
        
        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ API EmbeddingReshaper (Ð¸Ð· Phase 2.3)
        reshaper = EmbeddingReshaper(
            input_dim=self.config.input_dim,
            cube_shape=self.config.cube_shape,
            reshaping_method=self.config.reshaping_method,
            preserve_semantics=self.config.preserve_semantics,
            semantic_threshold=self.config.semantic_threshold
        )
        
        logger.info(f"âœ… EmbeddingReshaper Ð³Ð¾Ñ‚Ð¾Ð²: {self.config.cube_shape}")
        return reshaper
    
    def _init_lattice_3d(self) -> Lattice3D:
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Lattice3D"""
        
        # Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð½ÑƒÐ¶Ð½Ñ‹Ðµ ÐºÐ»Ð°ÑÑÑ‹
        from core.lattice_3d import LatticeConfig, BoundaryCondition, Face, PlacementStrategy
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½ÑƒÑŽ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ LatticeConfig
        lattice_config = LatticeConfig(
            dimensions=self.config.lattice_size,
            boundary_conditions=BoundaryCondition.WALLS,
            parallel_processing=False,  # ÐŸÐ¾ÐºÐ° Ð¾Ñ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð´Ð»Ñ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ñ‚Ñ‹
            gpu_enabled=False,  # ÐŸÐ¾ÐºÐ° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ CPU
            input_face=Face.FRONT,
            output_face=Face.BACK,
            placement_strategy=PlacementStrategy.PROPORTIONAL,
            enable_logging=self.config.debug_mode
        )
        
        try:
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Lattice3D Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ Ñ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
            lattice = Lattice3D(lattice_config)
            logger.info(f"âœ… Lattice3D Ð³Ð¾Ñ‚Ð¾Ð²: {self.config.lattice_size}")
            return lattice
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Lattice3D: {e}")
            raise
    
    def forward(self, input_embedding: torch.Tensor) -> torch.Tensor:
        """
        ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÑÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³Ð°
        
        Args:
            input_embedding: Ð’Ñ…Ð¾Ð´Ð½Ð¾Ð¹ ÑÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³ [batch_size, 768] Ð¸Ð»Ð¸ [768]
            
        Returns:
            torch.Tensor: ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ð¹ ÑÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³ Ñ‚Ð¾Ð¹ Ð¶Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚Ð¸
        """
        start_time = time.time()
        original_shape = input_embedding.shape
        
        # ÐžÐ±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÐµÐ¼ batch dimension
        if input_embedding.dim() == 1:
            input_embedding = input_embedding.unsqueeze(0)
            single_input = True
        else:
            single_input = False
        
        batch_size = input_embedding.shape[0]
        
        try:
            # === Ð­Ð¢ÐÐŸ 1: 1D â†’ 3D ÐŸÐ Ð•ÐžÐ‘Ð ÐÐ—ÐžÐ’ÐÐÐ˜Ð• ===
            if self.config.debug_mode:
                logger.debug(f"ðŸ”„ Ð­Ñ‚Ð°Ð¿ 1: ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ {input_embedding.shape} â†’ 3D")
            
            # Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð´Ð»Ñ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ 3D Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†
            matrices_3d = []
            
            for i in range(batch_size):
                emb_1d = input_embedding[i].cpu().numpy()  # EmbeddingReshaper Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ñ numpy
                matrix_3d = self.reshaper.vector_to_matrix(emb_1d)
                matrices_3d.append(torch.from_numpy(matrix_3d).float())
            
            # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ð² batch: [batch_size, depth, height, width]
            batch_3d = torch.stack(matrices_3d).to(self.device)
            
            # === Ð­Ð¢ÐÐŸ 2: 3D ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ Ð§Ð•Ð Ð•Ð— LATTICE ===
            if self.config.debug_mode:
                logger.debug(f"ðŸ§  Ð­Ñ‚Ð°Ð¿ 2: ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ‡ÐµÑ€ÐµÐ· Lattice3D {batch_3d.shape}")
            
            # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ð² batch Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾ (Ð¿Ð¾ÐºÐ° Ð½ÐµÑ‚ batch support Ð² Lattice3D)
            processed_matrices = []
            
            for i in range(batch_size):
                matrix_3d = batch_3d[i]
                
                # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð´Ð»Ñ Lattice3D (Ð¼Ð¾Ð¶ÐµÑ‚ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ð°Ð´Ð°Ð¿Ñ‚Ð°Ñ†Ð¸Ñ)
                processed_matrix = self._process_through_lattice(matrix_3d)
                processed_matrices.append(processed_matrix)
            
            processed_batch = torch.stack(processed_matrices)
            
            # === Ð­Ð¢ÐÐŸ 3: 3D â†’ 1D ÐŸÐ Ð•ÐžÐ‘Ð ÐÐ—ÐžÐ’ÐÐÐ˜Ð• ===
            if self.config.debug_mode:
                logger.debug(f"ðŸ”„ Ð­Ñ‚Ð°Ð¿ 3: ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ 3D â†’ {self.config.output_dim}D")
            
            output_embeddings = []
            
            for i in range(batch_size):
                matrix_3d = processed_batch[i].cpu().numpy()
                emb_1d = self.reshaper.matrix_to_vector(matrix_3d)
                output_embeddings.append(torch.from_numpy(emb_1d).float())
            
            output_batch = torch.stack(output_embeddings).to(self.device)
            
            # === Ð­Ð¢ÐÐŸ 4: ÐšÐžÐÐ¢Ð ÐžÐ›Ð¬ ÐšÐÐ§Ð•Ð¡Ð¢Ð’Ð ===
            if self.config.quality_check_enabled:
                self._update_metrics(input_embedding, output_batch, start_time)
            
            # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð² Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ð¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ
            if single_input:
                output_batch = output_batch.squeeze(0)
            
            self.processing_count += 1
            
            return output_batch
            
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÑÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³Ð°: {e}")
            raise
    
    def _process_through_lattice(self, matrix_3d: torch.Tensor) -> torch.Tensor:
        """
        ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° 3D Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ñ‹ Ñ‡ÐµÑ€ÐµÐ· Lattice3D
        
        Args:
            matrix_3d: 3D Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ð° [depth, height, width]
            
        Returns:
            torch.Tensor: ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ð°Ñ 3D Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ð°
        """
        try:
            # Ð’ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ñ€ÐµÐ¶Ð¸Ð¼Ð° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
            if self.config.processing_mode == ProcessingMode.AUTOENCODER:
                # ÐÐ²Ñ‚Ð¾ÑÐ½ÐºÐ¾Ð´ÐµÑ€: ÑÑ‚Ñ€ÐµÐ¼Ð¸Ð¼ÑÑ Ðº Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸ÑŽ
                return self._autoencoder_processing(matrix_3d)
            elif self.config.processing_mode == ProcessingMode.GENERATOR:
                # Ð“ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€: ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ
                return self._generator_processing(matrix_3d)
            elif self.config.processing_mode == ProcessingMode.DIALOGUE:
                # Ð”Ð¸Ð°Ð»Ð¾Ð³: ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°
                return self._dialogue_processing(matrix_3d)
            else:
                raise ValueError(f"ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼: {self.config.processing_mode}")
                
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² Lattice3D Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ: {e}")
            # Fallback: Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð¸ÑÑ…Ð¾Ð´Ð½ÑƒÑŽ Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ñƒ
            return matrix_3d
    
    def _autoencoder_processing(self, matrix_3d: torch.Tensor) -> torch.Tensor:
        """ÐÐ²Ñ‚Ð¾ÑÐ½ÐºÐ¾Ð´ÐµÑ€ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° (Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ)"""
        
        # ÐŸÐ¾ÐºÐ° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ identity transformation + Ð½ÐµÐ±Ð¾Ð»ÑŒÑˆÐ¾Ð¹ ÑˆÑƒÐ¼ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
        # Ð’ Ð±ÑƒÐ´ÑƒÑ‰ÐµÐ¼ Ð·Ð´ÐµÑÑŒ Ð±ÑƒÐ´ÐµÑ‚ Ð¿Ð¾Ð»Ð½Ð°Ñ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ Lattice3D
        
        noise_level = 0.01  # ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑˆÑƒÐ¼ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
        noise = torch.randn_like(matrix_3d) * noise_level
        
        return matrix_3d + noise
    
    def _generator_processing(self, matrix_3d: torch.Tensor) -> torch.Tensor:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° (ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸)"""
        
        # Ð‘Ð¾Ð»ÑŒÑˆÐµ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¹ Ð´Ð»Ñ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸
        transformation_strength = 0.1
        
        # ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ (Ð·Ð°Ð¼ÐµÐ½Ð¸Ñ‚Ðµ Ð½Ð° Lattice3D)
        transformed = matrix_3d * (1.0 + torch.randn_like(matrix_3d) * transformation_strength)
        
        return transformed
    
    def _dialogue_processing(self, matrix_3d: torch.Tensor) -> torch.Tensor:
        """Ð”Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð²Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° (ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð½Ñ‹Ðµ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸)"""
        
        # ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð½Ñ‹Ðµ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
        context_strength = 0.15
        
        # ÐŸÑ€Ð¸Ð¼ÐµÑ€ (Ð·Ð°Ð¼ÐµÐ½Ð¸Ñ‚Ðµ Ð½Ð° Ð¿Ð¾Ð»Ð½ÑƒÑŽ Lattice3D Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸ÑŽ)
        context_transform = torch.tanh(matrix_3d) * context_strength
        
        return matrix_3d + context_transform
    
    def _update_metrics(self, input_batch: torch.Tensor, output_batch: torch.Tensor, start_time: float):
        """ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸"""
        
        processing_time = time.time() - start_time
        
        # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ ÑÑ€ÐµÐ´Ð½ÑŽÑŽ cosine similarity Ð¿Ð¾ batch
        similarities = []
        for i in range(input_batch.shape[0]):
            similarity = torch.nn.functional.cosine_similarity(
                input_batch[i], output_batch[i], dim=0
            ).item()
            similarities.append(similarity)
        
        avg_similarity = np.mean(similarities)
        
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        self.metrics.update(
            similarity=avg_similarity,
            processing_time=processing_time,
            batch_size=input_batch.shape[0]
        )
        
        # Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
        if self.config.verbose_logging:
            logger.info(f"ðŸ“Š Cosine similarity: {avg_similarity:.3f} (Ñ†ÐµÐ»ÑŒ: {self.config.target_similarity:.3f})")
            logger.info(f"â±ï¸ Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸: {processing_time:.3f}s")
    
    def get_metrics(self) -> Dict[str, Any]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸"""
        return self.metrics.get_summary()
    
    def reset_metrics(self):
        """Ð¡Ð±Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸"""
        self.metrics.reset()
    
    def set_mode(self, mode: ProcessingMode):
        """Ð˜Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ€ÐµÐ¶Ð¸Ð¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸"""
        self.config.processing_mode = mode
        logger.info(f"ðŸ”„ Ð ÐµÐ¶Ð¸Ð¼ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½ Ð½Ð°: {mode.value}")
    
    def validate_quality(self, input_embedding: torch.Tensor, output_embedding: torch.Tensor) -> bool:
        """
        ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
        
        Returns:
            bool: True ÐµÑÐ»Ð¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸ÑÐ¼
        """
        similarity = torch.nn.functional.cosine_similarity(
            input_embedding, output_embedding, dim=0 if input_embedding.dim() == 1 else 1
        ).mean().item()
        
        return similarity >= self.config.target_similarity
    
    def __repr__(self) -> str:
        return (f"EmbeddingProcessor("
                f"mode={self.config.processing_mode.value}, "
                f"target_sim={self.config.target_similarity:.2f}, "
                f"processed={self.processing_count})") 