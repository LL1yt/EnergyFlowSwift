#!/usr/bin/env python3
"""
–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è NCA –∫–ª–µ—Ç–∫–∞ - drop-in replacement –¥–ª—è GatedMLPCell
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è ŒºNCA –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)


class MinimalNCACell(nn.Module):
    """
    –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è Neural Cellular Automata –∫–ª–µ—Ç–∫–∞

    Drop-in replacement –¥–ª—è GatedMLPCell —Å:
    - –°–æ–≤–º–µ—Å—Ç–∏–º—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º
    - 68-300 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤–º–µ—Å—Ç–æ 1,888
    - ŒºNCA –ø—Ä–∏–Ω—Ü–∏–ø–∞–º–∏
    - –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å—é —á–µ—Ä–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    """

    def __init__(
        self,
        state_size: int = 8,
        neighbor_count: int = 6,
        hidden_dim: int = 4,  # –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –º–µ–Ω—å—à–µ —á–µ–º –≤ gMLP
        external_input_size: int = 1,
        activation: str = "tanh",
        dropout: float = 0.0,  # NCA –æ–±—ã—á–Ω–æ –Ω–µ –Ω—É–∂–¥–∞–µ—Ç—Å—è –≤ dropout
        use_memory: bool = False,  # NCA –∏–º–µ–µ—Ç implicit memory
        memory_dim: int = 4,  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        target_params: int = 150,
    ):

        super().__init__()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        self.neighbor_count = neighbor_count
        self.original_state_size = state_size  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        self.original_hidden_dim = hidden_dim
        self.original_external_input_size = external_input_size
        self.use_memory = use_memory
        self.memory_dim = memory_dim
        self.target_params = target_params

        # === –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ê–Ø NCA –ê–†–•–ò–¢–ï–ö–¢–£–†–ê ===
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø–æ–¥ target_params

        # 1. Neighbor weighting (learnable)
        self.neighbor_weights = nn.Parameter(
            torch.ones(neighbor_count) / neighbor_count
        )

        # 2. –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –í–°–ï–ô –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ø–æ–¥ target_params

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –≤—Å–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ target_params
        if target_params >= 1000:
            # –ë–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏: —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤—Å–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
            scale_factor = (
                target_params / 150
            ) ** 0.5  # –ö–≤–∞–¥—Ä–∞—Ç–Ω—ã–π –∫–æ—Ä–µ–Ω—å –¥–ª—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–æ—Å—Ç–∞
            self.state_size = max(state_size, int(state_size * scale_factor * 0.3))
            self.hidden_dim = max(hidden_dim, int(hidden_dim * scale_factor * 0.6))
            self.external_input_size = max(
                external_input_size, int(external_input_size * scale_factor * 0.2)
            )
        elif target_params <= 100:
            # –ú–∞–ª–µ–Ω—å–∫–∏–µ –º–æ–¥–µ–ª–∏: —É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
            self.state_size = max(4, state_size)
            self.hidden_dim = max(2, hidden_dim)
            self.external_input_size = max(1, external_input_size)
        else:
            # –°—Ä–µ–¥–Ω–∏–µ –º–æ–¥–µ–ª–∏: –∏—Å–ø–æ–ª—å–∑—É–µ–º config –∑–Ω–∞—á–µ–Ω–∏—è
            self.state_size = state_size
            self.hidden_dim = hidden_dim
            self.external_input_size = external_input_size

        perception_input_size = self.state_size + self.external_input_size

        logger.info(
            f"[ARCHITECTURE] Scaled for {target_params} params: "
            f"state={self.state_size}, hidden={self.hidden_dim}, input={self.external_input_size}"
        )

        # 3. Perception layer (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
        self.perception = nn.Linear(perception_input_size, self.hidden_dim, bias=False)

        # 4. Update rule (core NCA component)
        if activation == "tanh":
            self.activation = nn.Tanh()
        elif activation == "gelu":
            self.activation = nn.GELU()
        else:
            self.activation = nn.ReLU()

        self.update_rule = nn.Sequential(
            nn.Linear(self.hidden_dim, self.hidden_dim, bias=False),
            self.activation,
            nn.Linear(self.hidden_dim, state_size, bias=False),
        )

        # 5. NCA update parameters (learnable)
        self.alpha = nn.Parameter(torch.tensor(0.1))  # Update strength
        self.beta = nn.Parameter(torch.tensor(0.05))  # Neighbor influence

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —Å–æ–∑–¥–∞–Ω–∏–∏
        if not hasattr(MinimalNCACell, "_param_count_logged"):
            self._log_parameter_count()
            MinimalNCACell._param_count_logged = True

    def _log_parameter_count(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å gMLP)"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)

        logger.info(f"[OK] MinimalNCACell –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        logger.info(f"   Total: {total_params:,} parameters")
        logger.info(f"   Trainable: {trainable_params:,} parameters")
        logger.info(f"   Target: ~{self.target_params:,} (current: {total_params:,})")

        if total_params <= self.target_params:
            logger.info(f"[SUCCESS] Parameter count –≤ —Ä–∞–º–∫–∞—Ö target!")
        elif total_params <= self.target_params * 1.2:
            logger.warning(f"[WARNING] Parameter count –±–ª–∏–∑–∫–æ –∫ target")
        else:
            logger.warning(
                f"[WARNING] Parameter count –ø—Ä–µ–≤—ã—à–∞–µ—Ç target {self.target_params:,}: {total_params:,}"
            )

    def forward(
        self,
        neighbor_states: torch.Tensor,
        own_state: torch.Tensor,
        external_input: Optional[torch.Tensor] = None,
    ) -> torch.Tensor:
        """
        Forward pass —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å GatedMLPCell

        Args:
            neighbor_states: [batch, neighbor_count, state_size]
            own_state: [batch, state_size]
            external_input: [batch, external_input_size]

        Returns:
            new_state: [batch, state_size]
        """
        batch_size = own_state.shape[0]

        # === STEP 1: NEIGHBOR AGGREGATION ===
        if neighbor_states.numel() > 0:
            # Weighted aggregation of neighbors
            weighted_neighbors = torch.einsum(
                "bnc,n->bc", neighbor_states, self.neighbor_weights
            )
        else:
            # No neighbors case
            weighted_neighbors = torch.zeros_like(own_state)

        # === STEP 2: EXTERNAL INPUT HANDLING ===
        if external_input is None:
            external_input = torch.zeros(
                batch_size,
                self.external_input_size,
                device=own_state.device,
                dtype=own_state.dtype,
            )

        # === STEP 3: PERCEPTION ===
        perception_input = torch.cat([own_state, external_input], dim=1)
        perceived = self.perception(perception_input)

        # === STEP 4: UPDATE RULE ===
        delta = self.update_rule(perceived)

        # === STEP 5: NCA STATE UPDATE ===
        # Core NCA principle: gradual state evolution
        new_state = own_state + self.alpha * delta + self.beta * weighted_neighbors

        return new_state

    def reset_memory(self):
        """–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å GatedMLPCell –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º"""
        # NCA –Ω–µ –∏–º–µ–µ—Ç explicit memory state, –ø–æ—ç—Ç–æ–º—É —ç—Ç–æ no-op
        pass

    def get_info(self) -> Dict[str, Any]:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–µ—Ç–∫–µ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å GatedMLPCell)"""
        total_params = sum(p.numel() for p in self.parameters())

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        architecture_optimized = (
            self.state_size != self.original_state_size
            or self.hidden_dim != self.original_hidden_dim
            or self.external_input_size != self.original_external_input_size
        )

        return {
            "architecture": "MinimalNCA",
            "state_size": self.state_size,
            "neighbor_count": self.neighbor_count,
            "hidden_dim": self.hidden_dim,
            "external_input_size": self.external_input_size,
            "memory_enabled": False,  # NCA –∏–º–µ–µ—Ç implicit memory
            "total_parameters": total_params,
            "target_parameters": self.target_params,
            "parameter_efficiency": total_params / max(1, self.target_params),
            "memory_state_active": False,
            "nca_alpha": float(self.alpha.item()),
            "nca_beta": float(self.beta.item()),
            "architecture_optimized": architecture_optimized,
            "original_dimensions": {
                "state_size": self.original_state_size,
                "hidden_dim": self.original_hidden_dim,
                "external_input_size": self.original_external_input_size,
            },
        }


def create_nca_cell_from_config(config: Dict[str, Any]) -> MinimalNCACell:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ NCA –∫–ª–µ—Ç–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–∞–Ω–∞–ª–æ–≥ create_gmlp_cell_from_config)

    Args:
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∞–∫ gMLP —Ç–∞–∫ –∏ NCA –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

    Returns:
        MinimalNCACell: –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –∫–ª–µ—Ç–∫–∞
    """
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ gmlp_config (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    gmlp_config = config.get("gmlp_config", {})

    # NCA specific config
    nca_config = config.get("nca_config", {})

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å fallback –Ω–∞ gMLP –∑–Ω–∞—á–µ–Ω–∏—è
    params = {
        "state_size": gmlp_config.get("state_size", nca_config.get("state_size", 8)),
        "neighbor_count": gmlp_config.get(
            "neighbor_count", nca_config.get("neighbor_count", 6)
        ),
        "hidden_dim": nca_config.get("hidden_dim", 4),  # –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –º–µ–Ω—å—à–µ —á–µ–º gMLP
        "external_input_size": gmlp_config.get(
            "external_input_size", nca_config.get("external_input_size", 1)
        ),
        "activation": gmlp_config.get(
            "activation", nca_config.get("activation", "tanh")
        ),
        "dropout": nca_config.get("dropout", 0.0),  # NCA –æ–±—ã—á–Ω–æ –±–µ–∑ dropout
        "target_params": gmlp_config.get(
            "target_params", nca_config.get("target_params", 150)
        ),
    }

    logger.info(f"üî¨ –°–æ–∑–¥–∞–Ω–∏–µ MinimalNCACell —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: {params}")

    return MinimalNCACell(**params)


def test_nca_cell_basic() -> bool:
    """
    –ë–∞–∑–æ–≤–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ NCA –∫–ª–µ—Ç–∫–∏ (–∞–Ω–∞–ª–æ–≥ test_gmlp_cell_basic)

    Returns:
        bool: True –µ—Å–ª–∏ –≤—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏
    """
    logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ MinimalNCACell...")

    try:
        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–µ—Ç–∫–∏
        cell = MinimalNCACell(
            state_size=8,
            neighbor_count=6,
            hidden_dim=4,
            external_input_size=1,
            target_params=150,
        )

        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        batch_size = 4
        neighbor_states = torch.randn(batch_size, 6, 8)
        own_state = torch.randn(batch_size, 8)
        external_input = torch.randn(batch_size, 1)

        # Forward pass
        new_state = cell(neighbor_states, own_state, external_input)

        # –ü—Ä–æ–≤–µ—Ä–∫–∏
        assert new_state.shape == (
            batch_size,
            8,
        ), f"Wrong output shape: {new_state.shape}"
        assert not torch.isnan(new_state).any(), "NaN values in output"
        assert not torch.isinf(new_state).any(), "Inf values in output"

        # –¢–µ—Å—Ç memory reset (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        cell.reset_memory()

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–µ—Ç–∫–µ
        info = cell.get_info()
        logger.info(f"[OK] NCA Cell —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω: {info['total_parameters']} params")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if info["total_parameters"] <= info["target_parameters"]:
            logger.info(f"[SUCCESS] Parameters –≤ —Ä–∞–º–∫–∞—Ö target!")

        return True

    except Exception as e:
        logger.error(f"[ERROR] NCA Cell —Ç–µ—Å—Ç failed: {e}")
        return False


# Convenience function –¥–ª—è –ø—Ä—è–º–æ–π –∑–∞–º–µ–Ω—ã gMLP
def create_compatible_nca_cell(**kwargs) -> MinimalNCACell:
    """
    –°–æ–∑–¥–∞–µ—Ç NCA –∫–ª–µ—Ç–∫—É —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏ —Å GatedMLPCell
    –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∑–∞–º–µ–Ω—ã
    """
    # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º gMLP –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥ NCA
    nca_params = {
        "state_size": kwargs.get("state_size", 8),
        "neighbor_count": kwargs.get("neighbor_count", 6),
        "hidden_dim": min(kwargs.get("hidden_dim", 8), 6),  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è NCA
        "external_input_size": min(
            kwargs.get("external_input_size", 4), 2
        ),  # –£–º–µ–Ω—å—à–∞–µ–º
        "activation": kwargs.get("activation", "tanh"),
        "target_params": kwargs.get("target_params", 150),
    }

    return MinimalNCACell(**nca_params)
